,title,citation,pdf_url,page_url,abstract,introduction,predicted_rq,score_problem,score_method,is_target_rq_type
0,Measuring and Mitigating Name Biases in Neural Machine Translation,"Jun Wang, Benjamin Rubinstein, and Trevor Cohn. 2022. Measuring and Mitigating Name Biases in Neural Machine Translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2576–2590, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.184.pdf,https://aclanthology.org/2022.acl-long.184/,"Neural Machine Translation (NMT) systems exhibit problematic biases, such as stereotypical gender bias in the translation of occupation terms into languages with grammatical gender. In this paper we describe a new source of bias prevalent in NMT systems, relating to translations of sentences containing person names. To correctly translate such sentences, a NMT system needs to estimate the gender of names. We show that leading systems are particularly poor at this task, especially for female given names. This bias is deeper than given name gender: we show that the translation of terms with ambiguous sentiment can also be affected by person names, and the same holds true for proper nouns denoting race. To mitigate these biases we propose a simple but effective data augmentation method based on randomly switching entities during translation, which effectively eliminates the problem without any effect on translation quality.","Natural language processing systems are seeing widespread adoption, prompting careful study into cultural biases they exhibit, and methods for bias mitigation. Gender bias is common in automated systems (Park et al., 2018; Borkan et al., 2019; Stanovsky et al., 2019; Saunders and Byrne, 2020), with a leading cause being training corpora that include far more sentences referring to men than to women. A neural machine translation (NMT) system naïvely trained on such data is more likely to translate text that should be feminine into masculine when translating into a language with grammatical gender. Previously, researchers (Stanovsky et al., 2019; Escudé Font and Costa-jussà, 2019; Saunders and Byrne, 2020; Stafanovics et al., 2020) have demonstrated that NMT systems can still be biased even when there are explicit gender pronouns in the input sentences. NMT systems are not only biased for gender, and gender bias is not limited to gender pronouns. Other biases include racial biases, professional biases, and individual biases, among others. In this paper, we focus on two kinds of biases of person name translations by NMT systems: gender biases and sentiment biases. As an important category of named entity, person names are particularly sensitive to translation errors since they refer to realworld individuals, and systematic biases may cause serious distress to users, and reputational damage, libel or other legal consequences for vendors. Gender bias in the translation of person names is a natural extension of gender biases in previous work. For instance, (Stanovsky et al., 2019; Escudé Font and Costa-jussà, 2019; Saunders and Byrne, 2020; Stafanovics et al., 2020) considered whether translation systems can translate keywords such as occupation terms into the correct form when there is explicit gender information in the text. This paper can be seen as replacing this explicit gender information (pronouns) with implicit gender information (person names), to test whether an NMT system can correctly determine the gender of a name. Our results indicate that NMT systems often mistakes female names for males, but the reverse is rarely seen; a situation that may cause widespread offence. Biases pertaining to sentiment of sentences containing person names have been studied in sentiment analysis (Kiritchenko and Mohammad, 2018), where model predictions of sentiment are sensitive to changing the person name. We present a method for detecting sentiment bias in translation based on the translation of sentiment ambiguous words, where the system must choose between a commendatory and derogatory translation (e.g., proud can mean either satisfied or arrogant about one’s achievements). When the correct translation is not clear from the context, NMT systems use the person name to decide. When this occurs consistently towards a specific sentiment, this can result in insidious bias against (or towards) individuals (or as we also show, racial groups.) To mitigate the above biases against person names in translation, we propose a dataaugmentation method ‘switch-entity’ (SE), which works by altering training sentences containing named entities by randomly switching the entities for other entities of the same type (e.g., with matching gender). This simple strategy normalises the distribution of named entities, such that all names are observed sufficiently many times and in a diverse range of contexts. This ensures gender signals are learned correctly, and also stops the translation system from associating the name with idiosyncracies of the contexts in which is appears, thus mitigating sentiment bias. Modifying the training data carries the risk of degrading sentence quality, and thus degrading accuracy. Although replacing a named entity with another does change sentence meaning, it is unlikely to compromise grammaticality or render the sentence semantically incoherent. Our results show that SE beneficially mitigates gender bias when translating names into gendered languages, which we show leads to more accurate morphological inflection in sentences with female entities. At the same time, it does not sacrifice accuracy: the BLEU score of the SE-trained model is the same as for standard training. Our contributions: • We show two new biases for person names in NMT, relating to gender and sentiment. • Using constructed templates we show this is a widespread problem affecting state-of-the-art NMT systems. • We propose a data augmentation method, switch-entity, to mitigate these biases in training, without the need for extra data.","How effectively can a data augmentation method, which involves randomly switching entities during neural machine translation, mitigate biases related to gender and sentiment in the translation of sentences containing person names without compromising the quality of translation?",2.0,2.0,1.0
1,Measuring and Mitigating Name Biases in Neural Machine Translation,"Jun Wang, Benjamin Rubinstein, and Trevor Cohn. 2022. Measuring and Mitigating Name Biases in Neural Machine Translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2576–2590, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.184.pdf,https://aclanthology.org/2022.acl-long.184/,"Neural Machine Translation (NMT) systems exhibit problematic biases, such as stereotypical gender bias in the translation of occupation terms into languages with grammatical gender. In this paper we describe a new source of bias prevalent in NMT systems, relating to translations of sentences containing person names. To correctly translate such sentences, a NMT system needs to estimate the gender of names. We show that leading systems are particularly poor at this task, especially for female given names. This bias is deeper than given name gender: we show that the translation of terms with ambiguous sentiment can also be affected by person names, and the same holds true for proper nouns denoting race. To mitigate these biases we propose a simple but effective data augmentation method based on randomly switching entities during translation, which effectively eliminates the problem without any effect on translation quality.","Natural language processing systems are seeing widespread adoption, prompting careful study into cultural biases they exhibit, and methods for bias mitigation. Gender bias is common in automated systems (Park et al., 2018; Borkan et al., 2019; Stanovsky et al., 2019; Saunders and Byrne, 2020), with a leading cause being training corpora that include far more sentences referring to men than to women. A neural machine translation (NMT) system naïvely trained on such data is more likely to translate text that should be feminine into masculine when translating into a language with grammatical gender. Previously, researchers (Stanovsky et al., 2019; Escudé Font and Costa-jussà, 2019; Saunders and Byrne, 2020; Stafanovics et al., 2020) have demonstrated that NMT systems can still be biased even when there are explicit gender pronouns in the input sentences. NMT systems are not only biased for gender, and gender bias is not limited to gender pronouns. Other biases include racial biases, professional biases, and individual biases, among others. In this paper, we focus on two kinds of biases of person name translations by NMT systems: gender biases and sentiment biases. As an important category of named entity, person names are particularly sensitive to translation errors since they refer to realworld individuals, and systematic biases may cause serious distress to users, and reputational damage, libel or other legal consequences for vendors. Gender bias in the translation of person names is a natural extension of gender biases in previous work. For instance, (Stanovsky et al., 2019; Escudé Font and Costa-jussà, 2019; Saunders and Byrne, 2020; Stafanovics et al., 2020) considered whether translation systems can translate keywords such as occupation terms into the correct form when there is explicit gender information in the text. This paper can be seen as replacing this explicit gender information (pronouns) with implicit gender information (person names), to test whether an NMT system can correctly determine the gender of a name. Our results indicate that NMT systems often mistakes female names for males, but the reverse is rarely seen; a situation that may cause widespread offence. Biases pertaining to sentiment of sentences containing person names have been studied in sentiment analysis (Kiritchenko and Mohammad, 2018), where model predictions of sentiment are sensitive to changing the person name. We present a method for detecting sentiment bias in translation based on the translation of sentiment ambiguous words, where the system must choose between a commendatory and derogatory translation (e.g., proud can mean either satisfied or arrogant about one’s achievements). When the correct translation is not clear from the context, NMT systems use the person name to decide. When this occurs consistently towards a specific sentiment, this can result in insidious bias against (or towards) individuals (or as we also show, racial groups.) To mitigate the above biases against person names in translation, we propose a dataaugmentation method ‘switch-entity’ (SE), which works by altering training sentences containing named entities by randomly switching the entities for other entities of the same type (e.g., with matching gender). This simple strategy normalises the distribution of named entities, such that all names are observed sufficiently many times and in a diverse range of contexts. This ensures gender signals are learned correctly, and also stops the translation system from associating the name with idiosyncracies of the contexts in which is appears, thus mitigating sentiment bias. Modifying the training data carries the risk of degrading sentence quality, and thus degrading accuracy. Although replacing a named entity with another does change sentence meaning, it is unlikely to compromise grammaticality or render the sentence semantically incoherent. Our results show that SE beneficially mitigates gender bias when translating names into gendered languages, which we show leads to more accurate morphological inflection in sentences with female entities. At the same time, it does not sacrifice accuracy: the BLEU score of the SE-trained model is the same as for standard training. Our contributions: • We show two new biases for person names in NMT, relating to gender and sentiment. • Using constructed templates we show this is a widespread problem affecting state-of-the-art NMT systems. • We propose a data augmentation method, switch-entity, to mitigate these biases in training, without the need for extra data.","Can biases regarding gender and sentiment in translations of sentences containing person names by Neural Machine Translation (NMT) systems be mitigated by a data augmentation method, specifically the switch-entity method?",2.0,1.0,1.0
2,Measuring and Mitigating Name Biases in Neural Machine Translation,"Jun Wang, Benjamin Rubinstein, and Trevor Cohn. 2022. Measuring and Mitigating Name Biases in Neural Machine Translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2576–2590, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.184.pdf,https://aclanthology.org/2022.acl-long.184/,"Neural Machine Translation (NMT) systems exhibit problematic biases, such as stereotypical gender bias in the translation of occupation terms into languages with grammatical gender. In this paper we describe a new source of bias prevalent in NMT systems, relating to translations of sentences containing person names. To correctly translate such sentences, a NMT system needs to estimate the gender of names. We show that leading systems are particularly poor at this task, especially for female given names. This bias is deeper than given name gender: we show that the translation of terms with ambiguous sentiment can also be affected by person names, and the same holds true for proper nouns denoting race. To mitigate these biases we propose a simple but effective data augmentation method based on randomly switching entities during translation, which effectively eliminates the problem without any effect on translation quality.","Natural language processing systems are seeing widespread adoption, prompting careful study into cultural biases they exhibit, and methods for bias mitigation. Gender bias is common in automated systems (Park et al., 2018; Borkan et al., 2019; Stanovsky et al., 2019; Saunders and Byrne, 2020), with a leading cause being training corpora that include far more sentences referring to men than to women. A neural machine translation (NMT) system naïvely trained on such data is more likely to translate text that should be feminine into masculine when translating into a language with grammatical gender. Previously, researchers (Stanovsky et al., 2019; Escudé Font and Costa-jussà, 2019; Saunders and Byrne, 2020; Stafanovics et al., 2020) have demonstrated that NMT systems can still be biased even when there are explicit gender pronouns in the input sentences. NMT systems are not only biased for gender, and gender bias is not limited to gender pronouns. Other biases include racial biases, professional biases, and individual biases, among others. In this paper, we focus on two kinds of biases of person name translations by NMT systems: gender biases and sentiment biases. As an important category of named entity, person names are particularly sensitive to translation errors since they refer to realworld individuals, and systematic biases may cause serious distress to users, and reputational damage, libel or other legal consequences for vendors. Gender bias in the translation of person names is a natural extension of gender biases in previous work. For instance, (Stanovsky et al., 2019; Escudé Font and Costa-jussà, 2019; Saunders and Byrne, 2020; Stafanovics et al., 2020) considered whether translation systems can translate keywords such as occupation terms into the correct form when there is explicit gender information in the text. This paper can be seen as replacing this explicit gender information (pronouns) with implicit gender information (person names), to test whether an NMT system can correctly determine the gender of a name. Our results indicate that NMT systems often mistakes female names for males, but the reverse is rarely seen; a situation that may cause widespread offence. Biases pertaining to sentiment of sentences containing person names have been studied in sentiment analysis (Kiritchenko and Mohammad, 2018), where model predictions of sentiment are sensitive to changing the person name. We present a method for detecting sentiment bias in translation based on the translation of sentiment ambiguous words, where the system must choose between a commendatory and derogatory translation (e.g., proud can mean either satisfied or arrogant about one’s achievements). When the correct translation is not clear from the context, NMT systems use the person name to decide. When this occurs consistently towards a specific sentiment, this can result in insidious bias against (or towards) individuals (or as we also show, racial groups.) To mitigate the above biases against person names in translation, we propose a dataaugmentation method ‘switch-entity’ (SE), which works by altering training sentences containing named entities by randomly switching the entities for other entities of the same type (e.g., with matching gender). This simple strategy normalises the distribution of named entities, such that all names are observed sufficiently many times and in a diverse range of contexts. This ensures gender signals are learned correctly, and also stops the translation system from associating the name with idiosyncracies of the contexts in which is appears, thus mitigating sentiment bias. Modifying the training data carries the risk of degrading sentence quality, and thus degrading accuracy. Although replacing a named entity with another does change sentence meaning, it is unlikely to compromise grammaticality or render the sentence semantically incoherent. Our results show that SE beneficially mitigates gender bias when translating names into gendered languages, which we show leads to more accurate morphological inflection in sentences with female entities. At the same time, it does not sacrifice accuracy: the BLEU score of the SE-trained model is the same as for standard training. Our contributions: • We show two new biases for person names in NMT, relating to gender and sentiment. • Using constructed templates we show this is a widespread problem affecting state-of-the-art NMT systems. • We propose a data augmentation method, switch-entity, to mitigate these biases in training, without the need for extra data.",Can the biases in the translation of sentences containing person names by Neural Machine Translation (NMT) systems be mitigated by a data augmentation technique named 'switch-entity' that normalizes the distribution of named entities in training data without compromising translation quality?,1.0,2.0,1.0
3,Implicit Discourse Relation Detection via a Deep Architecture with Gated Relevance Network,"Jifan Chen, Qi Zhang, Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Implicit Discourse Relation Detection via a Deep Architecture with Gated Relevance Network. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1726–1735, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1163.pdf,https://aclanthology.org/P16-1163/,"Word pairs, which are one of the most easily accessible features between two text segments, have been proven to be very useful for detecting the discourse relations held between text segments. However, because of the data sparsity problem, the performance achieved by using word pair features is limited. In this paper, in order to overcome the data sparsity problem, we propose the use of word embeddings to replace the original words. Moreover, we adopt a gated relevance network to capture the semantic interaction between word pairs, and then aggregate those semantic interactions using a pooling layer to select the most informative interactions. Experimental results on Penn Discourse Tree Bank show that the proposed method without using manually designed features can achieve better performance on recognizing the discourse level relations in all of the relations.","In a well-written document, no unit of the text is completely isolated, discourse relations describe how two units (e.g. clauses, sentences, and larger multi-clause groupings) of discourse are logically connected. Many downstream NLP applications such as opinion mining, summarization, and event detection, can benefit from those relations. The task of automatically identify discourse relation is relatively simple when explicit connectives such as however and because are given (Pitler et al., 2009). However, the identification becomes much more challenging when such connectives are missing. In fact, such implicit discourse relations outnumber explicit relations in naturally occurring text, and identify those relations have been shown to be the performance bottleneck of an end-to-end discourse parser (Lin et al., 2014). Most of the existing researches used rich linguistic features and supervised learning methods to achieve the task (Soricut and Marcu, 2003; Pitler et al., 2009; Rutherford and Xue, 2014). Among their works, word pairs are heavily used as an important feature, since word pairs like (warm,cold) might directly trigger a contrast relation. However, because of the data sparsity problem (McKeown and Biran, 2013) and the lack of metrics to measure the semantic relation between those pairs, which is so-called the semantic gap problem (Zhao and Grosky, 2002), the classifiers based on word pairs in the previous studies did not work well. Moreover, some text segment pairs are more complicated, it is hard to determine the relation held between them using only word pairs. Consider the following sentence pair with a casual relation as an example: S1: Psyllium’s not a good crop. S2: You get a rain at the wrong time and the crop is ruined. Intuitively, (good, wrong) and (good, ruined), seem to be the most informative word pairs, and it is likely that they will trigger a contrast relation. Therefore, we can see that another main disadvantage of using word pairs is the lack of contextual information, and using n-gram pairs will again suffer from data sparsity problem. Recently, the distributed word representations (Bengio et al., 2006; Mikolov et al., 2013) have shown an advantage when dealing with data sparsity problem (Braud and Denis, 2015), and many deep learning based models are generating substantial interests in text semantic matching and have achieved some significant progresses (Hu et al., 2014; Qiu and Huang, 2015; Wan et al., 2015). Inspired by their work, we in this paper propose the use of word embeddings to replace the original words in the text segments to fight against the data sparsity problem. Further more, in order to preserve the contextual information around the word embeddings, we encode the text segment to its positional representation via a recurrent neural network, specifically, we use a bidirectional LSTM (Hochreiter and Schmidhuber, 1997). Then, to overcome the semantic gap, we propose the use of a gated relevance network to capture the semantic interaction between those positional representations. Finally, all the interactions generated by the relevance network are fed to a max pooling layer to get the strongest interactions. We then aggregate them to predict the discourse relation through a multi-layer perceptron (MLP). Our model is trained end to end by BackPropagation and Adagrad. The main contribution of this paper can be summarized as follows: • We use word embeddings to replace the original words in the text segments to overcome data sparsity problem. In order to preserve the contextual information, we further encode the text segment to its positional representation through a recurrent neural network. • To deal with the semantic gap problem, we adopt a gated relevance network to capture the semantic interaction between the intermediate representations of the text segments. • Experimental results on PDTB (Prasad et al., 2008) show that the proposed method can achieve better performance in recognizing discourse level relations in all of the relations than the previous methods.",How does the use of word embeddings and a gated relevance network address the data sparsity and semantic gap problems in detecting discourse relations between text segments?,1.0,1.0,1.0
4,Implicit Discourse Relation Detection via a Deep Architecture with Gated Relevance Network,"Jifan Chen, Qi Zhang, Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016. Implicit Discourse Relation Detection via a Deep Architecture with Gated Relevance Network. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1726–1735, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1163.pdf,https://aclanthology.org/P16-1163/,"Word pairs, which are one of the most easily accessible features between two text segments, have been proven to be very useful for detecting the discourse relations held between text segments. However, because of the data sparsity problem, the performance achieved by using word pair features is limited. In this paper, in order to overcome the data sparsity problem, we propose the use of word embeddings to replace the original words. Moreover, we adopt a gated relevance network to capture the semantic interaction between word pairs, and then aggregate those semantic interactions using a pooling layer to select the most informative interactions. Experimental results on Penn Discourse Tree Bank show that the proposed method without using manually designed features can achieve better performance on recognizing the discourse level relations in all of the relations.","In a well-written document, no unit of the text is completely isolated, discourse relations describe how two units (e.g. clauses, sentences, and larger multi-clause groupings) of discourse are logically connected. Many downstream NLP applications such as opinion mining, summarization, and event detection, can benefit from those relations. The task of automatically identify discourse relation is relatively simple when explicit connectives such as however and because are given (Pitler et al., 2009). However, the identification becomes much more challenging when such connectives are missing. In fact, such implicit discourse relations outnumber explicit relations in naturally occurring text, and identify those relations have been shown to be the performance bottleneck of an end-to-end discourse parser (Lin et al., 2014). Most of the existing researches used rich linguistic features and supervised learning methods to achieve the task (Soricut and Marcu, 2003; Pitler et al., 2009; Rutherford and Xue, 2014). Among their works, word pairs are heavily used as an important feature, since word pairs like (warm,cold) might directly trigger a contrast relation. However, because of the data sparsity problem (McKeown and Biran, 2013) and the lack of metrics to measure the semantic relation between those pairs, which is so-called the semantic gap problem (Zhao and Grosky, 2002), the classifiers based on word pairs in the previous studies did not work well. Moreover, some text segment pairs are more complicated, it is hard to determine the relation held between them using only word pairs. Consider the following sentence pair with a casual relation as an example: S1: Psyllium’s not a good crop. S2: You get a rain at the wrong time and the crop is ruined. Intuitively, (good, wrong) and (good, ruined), seem to be the most informative word pairs, and it is likely that they will trigger a contrast relation. Therefore, we can see that another main disadvantage of using word pairs is the lack of contextual information, and using n-gram pairs will again suffer from data sparsity problem. Recently, the distributed word representations (Bengio et al., 2006; Mikolov et al., 2013) have shown an advantage when dealing with data sparsity problem (Braud and Denis, 2015), and many deep learning based models are generating substantial interests in text semantic matching and have achieved some significant progresses (Hu et al., 2014; Qiu and Huang, 2015; Wan et al., 2015). Inspired by their work, we in this paper propose the use of word embeddings to replace the original words in the text segments to fight against the data sparsity problem. Further more, in order to preserve the contextual information around the word embeddings, we encode the text segment to its positional representation via a recurrent neural network, specifically, we use a bidirectional LSTM (Hochreiter and Schmidhuber, 1997). Then, to overcome the semantic gap, we propose the use of a gated relevance network to capture the semantic interaction between those positional representations. Finally, all the interactions generated by the relevance network are fed to a max pooling layer to get the strongest interactions. We then aggregate them to predict the discourse relation through a multi-layer perceptron (MLP). Our model is trained end to end by BackPropagation and Adagrad. The main contribution of this paper can be summarized as follows: • We use word embeddings to replace the original words in the text segments to overcome data sparsity problem. In order to preserve the contextual information, we further encode the text segment to its positional representation through a recurrent neural network. • To deal with the semantic gap problem, we adopt a gated relevance network to capture the semantic interaction between the intermediate representations of the text segments. • Experimental results on PDTB (Prasad et al., 2008) show that the proposed method can achieve better performance in recognizing discourse level relations in all of the relations than the previous methods.","Can the problem of detecting discourse relations between text segments in natural language processing, especially in cases lacking explicit connectives, be effectively addressed by utilizing word embeddings instead of original words alongside a gated relevance network to capture semantic interactions between word pairs, supplemented by a pooling layer for aggregating the most informative interactions and using a bidirectional LSTM for contextual information preservation?",2.0,2.0,1.0
5,"Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms","Tianshu Zhang, Changchang Liu, Wei-Han Lee, Yu Su, and Huan Sun. 2023. Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12149–12163, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.678.pdf,https://aclanthology.org/2023.acl-long.678/,"This paper studies a new task of federated learning (FL) for semantic parsing, where multiple clients collaboratively train one global model without sharing their semantic parsing data. By leveraging data from multiple clients, the FL paradigm can be especially beneficial for clients that have little training data to develop a data-hungry neural semantic parser on their own. We propose an evaluation setup to study this task, where we re-purpose widely-used single-domain text-to-SQL datasets as clients to form a realistic heterogeneous FL setting and collaboratively train a global model. As standard FL algorithms suffer from the high client heterogeneity in our realistic setup, we further propose a novel LOss Reduction Adjusted Reweighting (Lorar) mechanism to mitigate the performance degradation, which adjusts each client’s contribution to the global model update based on its training loss reduction during each round. Our intuition is that the larger the loss reduction, the further away the current global model is from the client’s local optimum, and the larger weight the client should get. By applying Lorar to three widely adopted FL algorithms (FedAvg, FedOPT and FedProx), we observe that their performance can be improved substantially on average (4%-20% absolute gain under MacroAvg) and that clients with smaller datasets enjoy larger performance gains. In addition, the global model converges faster for almost all the clients.","Semantic parsing aims to translate natural language utterances into formal meaning representations such as SQL queries and API calls and can be applied to build natural language interfaces that enable users to query data and invoke services without programming (Berant et al., 2013; Thomason et al., 2015; Su et al., 2017; Campagna et al., 2017). Neural semantic parsers have achieved remarkable performance in recent years (Wang et al., 2020a; Rubin and Berant, 2021; Scholak et al., 2021). However, they are data-hungry; bootstrapping a neural semantic parser by annotating data on a large scale can be very challenging for many institutions, as it requires the annotators to have intimate knowledge of formal programs. One natural thought is to leverage data from different institutions and train a unified model that can be used for all institutions. However, in practice, institutions such as hospitals, banks, and legal firms are prohibited from sharing their data with others, due to privacy concerns. Therefore, for institutions that only have very limited data, it is extremely hard to build their own neural semantic parsers. Federated learning (FL) (Konecnˇ y et al. ` , 2016; McMahan et al., 2017; Yang et al., 2018) has turned out to be a popular training paradigm where multiple clients can collaboratively train a global model without exchanging their own data. In this paper, we study a new task of federated learning for semantic parsing. Through FL on the data scattered on different clients (e.g., institutions), we aim to obtain a global model that works well for all clients, especially those that have insufficient data to build their own neural models. Towards that end, we propose an evaluation setup by re-purposing eight existing datasets that are widely adopted for text-to-SQL parsing, such as ATIS (Srinivasan Iyer and Zettlemoyer, 2017) and Yelp (Navid Yaghmazadeh and Dillig, 2017). These datasets demonstrate great heterogeneity, in terms of dataset sizes, language usage, database structures, and SQL complexity, as they were collected from the real life by different researchers, at different times, and for different purposes. Therefore, we use this collection to simulate a realistic scenario where eight clients with very different data participate in the FL paradigm to jointly train a neural semantic parser. Heterogeneity, where the data distributions and dataset sizes on different clients are different, is recognized as one of the biggest challenges in FL (McMahan et al., 2017; Reddi et al., 2020; Li et al., 2020a, 2021; Shoham et al., 2019; T Dinh et al., 2020). Existing work either uses synthetic data (Li et al., 2020a) or splits a classification dataset based on Dirichlet distribution (Lin et al., 2022) to simulate the non-IID federated learning setting, while we propose a more realistic setup to study this setting for semantic parsing. Pre-trained language models such as T5 (Raffel et al., 2020) have been shown as a powerful unified model for various semantic parsing tasks (Xie et al., 2022; Rajkumar et al., 2022), which can be leveraged to save us the efforts for client-specific model designs. Specifically, we adopt T5-base as our backbone semantic parser in the FL paradigm, and conduct extensive experiments and analysis using three widelyadopted FL algorithms: FedAvg (McMahan et al., 2017), FedOPT (Reddi et al., 2020) and FedProx (Li et al., 2020a). As standard FL algorithms suffer from the high client heterogeneity in our realistic setup, we further propose a novel re-weighting mechanism for combining the gradient updates from each client during the global model update. The high-level idea is shown in Figure 1. Our intuition is that, for each client, the reduction of training loss during each round can signalize how far the current global model is away from the local optimum. By giving larger weights to those clients that have larger training loss reduction, the global model update can accommodate those clients better, thus mitigating potential performance degradation caused by high heterogeneity. We formulate this intuition as a re-weighting factor to adjust how much each client should contribute to the global model update during each round. Our proposed mechanism can be applied to all the three FL algorithms and experiments show that it can substantially improve both their parsing performance and their convergence speed, despite being very simple. In summary, our main contributions are: • To the best of our knowledge, we are the first to study federated learning for semantic parsing, a promising paradigm for multiple institutions to collaboratively build natural language interfaces without data sharing, which is especially beneficial for institutions with little training data. • We propose an evaluation setup to simulate a realistic heterogeneous FL setting where different participating institutions have very different data. We re-purpose eight single-domain text-to-SQL datasets as eight clients, which demonstrate high heterogeneity in terms of dataset sizes, language usage, database structures, and SQL complexity. • We propose a novel re-weighting mechanism, which uses the training loss reduction of each client to adjust its contribution to the global model update during each round. Experiments show that our re-weighting mechanism can substantially improve the model performance of existing FL algorithms on average, and clients with smaller training data observe larger performance gains. We discuss the limitations of our work and encourage future work to further study this task.",Can federated learning for semantic parsing be improved by using a Loss Reduction Adjusted Reweighting mechanism to adjust client contributions based on their training loss reduction?,0.0,1.0,1.0
6,"Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms","Tianshu Zhang, Changchang Liu, Wei-Han Lee, Yu Su, and Huan Sun. 2023. Federated Learning for Semantic Parsing: Task Formulation, Evaluation Setup, New Algorithms. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12149–12163, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.678.pdf,https://aclanthology.org/2023.acl-long.678/,"This paper studies a new task of federated learning (FL) for semantic parsing, where multiple clients collaboratively train one global model without sharing their semantic parsing data. By leveraging data from multiple clients, the FL paradigm can be especially beneficial for clients that have little training data to develop a data-hungry neural semantic parser on their own. We propose an evaluation setup to study this task, where we re-purpose widely-used single-domain text-to-SQL datasets as clients to form a realistic heterogeneous FL setting and collaboratively train a global model. As standard FL algorithms suffer from the high client heterogeneity in our realistic setup, we further propose a novel LOss Reduction Adjusted Reweighting (Lorar) mechanism to mitigate the performance degradation, which adjusts each client’s contribution to the global model update based on its training loss reduction during each round. Our intuition is that the larger the loss reduction, the further away the current global model is from the client’s local optimum, and the larger weight the client should get. By applying Lorar to three widely adopted FL algorithms (FedAvg, FedOPT and FedProx), we observe that their performance can be improved substantially on average (4%-20% absolute gain under MacroAvg) and that clients with smaller datasets enjoy larger performance gains. In addition, the global model converges faster for almost all the clients.","Semantic parsing aims to translate natural language utterances into formal meaning representations such as SQL queries and API calls and can be applied to build natural language interfaces that enable users to query data and invoke services without programming (Berant et al., 2013; Thomason et al., 2015; Su et al., 2017; Campagna et al., 2017). Neural semantic parsers have achieved remarkable performance in recent years (Wang et al., 2020a; Rubin and Berant, 2021; Scholak et al., 2021). However, they are data-hungry; bootstrapping a neural semantic parser by annotating data on a large scale can be very challenging for many institutions, as it requires the annotators to have intimate knowledge of formal programs. One natural thought is to leverage data from different institutions and train a unified model that can be used for all institutions. However, in practice, institutions such as hospitals, banks, and legal firms are prohibited from sharing their data with others, due to privacy concerns. Therefore, for institutions that only have very limited data, it is extremely hard to build their own neural semantic parsers. Federated learning (FL) (Konecnˇ y et al. ` , 2016; McMahan et al., 2017; Yang et al., 2018) has turned out to be a popular training paradigm where multiple clients can collaboratively train a global model without exchanging their own data. In this paper, we study a new task of federated learning for semantic parsing. Through FL on the data scattered on different clients (e.g., institutions), we aim to obtain a global model that works well for all clients, especially those that have insufficient data to build their own neural models. Towards that end, we propose an evaluation setup by re-purposing eight existing datasets that are widely adopted for text-to-SQL parsing, such as ATIS (Srinivasan Iyer and Zettlemoyer, 2017) and Yelp (Navid Yaghmazadeh and Dillig, 2017). These datasets demonstrate great heterogeneity, in terms of dataset sizes, language usage, database structures, and SQL complexity, as they were collected from the real life by different researchers, at different times, and for different purposes. Therefore, we use this collection to simulate a realistic scenario where eight clients with very different data participate in the FL paradigm to jointly train a neural semantic parser. Heterogeneity, where the data distributions and dataset sizes on different clients are different, is recognized as one of the biggest challenges in FL (McMahan et al., 2017; Reddi et al., 2020; Li et al., 2020a, 2021; Shoham et al., 2019; T Dinh et al., 2020). Existing work either uses synthetic data (Li et al., 2020a) or splits a classification dataset based on Dirichlet distribution (Lin et al., 2022) to simulate the non-IID federated learning setting, while we propose a more realistic setup to study this setting for semantic parsing. Pre-trained language models such as T5 (Raffel et al., 2020) have been shown as a powerful unified model for various semantic parsing tasks (Xie et al., 2022; Rajkumar et al., 2022), which can be leveraged to save us the efforts for client-specific model designs. Specifically, we adopt T5-base as our backbone semantic parser in the FL paradigm, and conduct extensive experiments and analysis using three widelyadopted FL algorithms: FedAvg (McMahan et al., 2017), FedOPT (Reddi et al., 2020) and FedProx (Li et al., 2020a). As standard FL algorithms suffer from the high client heterogeneity in our realistic setup, we further propose a novel re-weighting mechanism for combining the gradient updates from each client during the global model update. The high-level idea is shown in Figure 1. Our intuition is that, for each client, the reduction of training loss during each round can signalize how far the current global model is away from the local optimum. By giving larger weights to those clients that have larger training loss reduction, the global model update can accommodate those clients better, thus mitigating potential performance degradation caused by high heterogeneity. We formulate this intuition as a re-weighting factor to adjust how much each client should contribute to the global model update during each round. Our proposed mechanism can be applied to all the three FL algorithms and experiments show that it can substantially improve both their parsing performance and their convergence speed, despite being very simple. In summary, our main contributions are: • To the best of our knowledge, we are the first to study federated learning for semantic parsing, a promising paradigm for multiple institutions to collaboratively build natural language interfaces without data sharing, which is especially beneficial for institutions with little training data. • We propose an evaluation setup to simulate a realistic heterogeneous FL setting where different participating institutions have very different data. We re-purpose eight single-domain text-to-SQL datasets as eight clients, which demonstrate high heterogeneity in terms of dataset sizes, language usage, database structures, and SQL complexity. • We propose a novel re-weighting mechanism, which uses the training loss reduction of each client to adjust its contribution to the global model update during each round. Experiments show that our re-weighting mechanism can substantially improve the model performance of existing FL algorithms on average, and clients with smaller training data observe larger performance gains. We discuss the limitations of our work and encourage future work to further study this task.","Can traditional federated learning approaches for semantic parsing be significantly improved by employing a novel LOss Reduction Adjusted Reweighting (Lorar) mechanism that adjusts each client's contribution based on its training loss reduction, thereby overcoming the challenges posed by high client heterogeneity and privacy constraints?",1.0,2.0,1.0
7,CIL: Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction,"Tao Chen, Haizhou Shi, Siliang Tang, Zhigang Chen, Fei Wu, and Yueting Zhuang. 2021. CIL: Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6191–6200, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.483.pdf,https://aclanthology.org/2021.acl-long.483/,"The journey of reducing noise from distant supervision (DS) generated training data has been started since the DS was first introduced into the relation extraction (RE) task. For the past decade, researchers apply the multiinstance learning (MIL) framework to find the most reliable feature from a bag of sentences. Although the pattern of MIL bags can greatly reduce DS noise, it fails to represent many other useful sentence features in the datasets. In many cases, these sentence features can only be acquired by extra sentence-level human annotation with heavy costs. Therefore, the performance of distantly supervised RE models is bounded. In this paper, we go beyond typical MIL framework and propose a novel Contrastive Instance Learning (CIL) framework. Specifically, we regard the initial MIL as the relational triple encoder and constraint positive pairs against negative pairs for each instance. Experiments demonstrate the effectiveness of our proposed framework, with significant improvements over the previous methods on NYT10, GDS and KBP.","Relation extraction (RE) aims at predicting the relation between entities based on their context. Several studies have been carried out to handle this crucial and complicated task over decades as the extracted information can serve as a significant role for many downstream tasks. Since the amount of training data generally limits traditional supervised RE systems, current RE systems usually resort to distant supervision (DS) to fetch abundant training data by aligning knowledge bases (KBs) and texts. However, such a heuristic way inevitably introduces some noise to the generated data. Training a robust and unbiased RE system under DS data noise becomes the biggest challenge for distantly supervised relation extraction (DSRE). With awareness of the existing DS noise, Zeng et al. (2015) introduces the multi-instance learning (MIL) framework to DSRE by dividing training instances into several bags and using bags as new data units. Regarding the strategy for selecting instances inside the bag, the soft attention mechanism proposed by Lin et al. (2016) is widely used for its better performance than the hard selection method. The ability to form accurate representations from noisy data makes the MIL framework soon become a paradigm of following-up works. However, we argue that the MIL framework is effective to alleviate data noise for DSRE, but is not data-efficient indeed: As Figure 1 shows: The attention mechanism in the MIL can help select relatively informative instances (e.g.h1, h2) inside the bag, but may ignore the potential information of other abundant instances (e.g.hm). In other words, no matter how many instances a bag contains, only the formed bag-level representation can be used for further training in the MIL, which is quite inefficient. Thus, our focus is on how to make the initial MIL framework efficient enough to leverage all instances while maintaining the ability to obtain an accurate model under DS data noise? Here, we propose a contrastive-based method to help the MIL framework learn efficiently. In detail, we regard the initial MIL framework as the bag encoder, which provides relatively accurate representations for different relational triples. Then we develop contrastive instance learning (CIL) to utilize each instance in an unsupervised manner: In short, the goal of our CIL is that the instances sharing the same relational triples (i.e.positive pairs) ought to be close in the semantic space, while the representations of instances with different relational triples (i.e.negative pairs) should be far away. Experiments on three public DSRE benchmarks — NYT10 (Riedel et al., 2010; Hoffmann et al., 2011), GDS (Jat et al., 2018) and KBP (Ling and Weld, 2012) demonstrate the effectiveness of our proposed framework CIL, with consistent improvements over several baseline models and far exceed the state-of-the-art (SOTA) systems. Furthermore, the ablation study shows the rationality of our proposed positive/negative pair construction strategy. Accordingly, the major contributions of this paper are summarized as follows: • We discuss the long-standing MIL framework and point out that it can not effectively utilize abundant instances inside MIL bags. • We propose a novel contrastive instance learning method to boost the DSRE model performances under the MIL framework. • Evaluation on held-out and human-annotated sets shows that CIL leads to significant improvements over the previous SOTA models.","How does the implementation of a Contrastive Instance Learning (CIL) framework within the Multi-Instance Learning (MIL) paradigm for Distantly Supervised Relation Extraction (DSRE) models impact the ability to effectively leverage all instances in training data, thereby improving model performance while maintaining accuracy under DS data noise?",2.0,1.0,1.0
8,CIL: Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction,"Tao Chen, Haizhou Shi, Siliang Tang, Zhigang Chen, Fei Wu, and Yueting Zhuang. 2021. CIL: Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6191–6200, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.483.pdf,https://aclanthology.org/2021.acl-long.483/,"The journey of reducing noise from distant supervision (DS) generated training data has been started since the DS was first introduced into the relation extraction (RE) task. For the past decade, researchers apply the multiinstance learning (MIL) framework to find the most reliable feature from a bag of sentences. Although the pattern of MIL bags can greatly reduce DS noise, it fails to represent many other useful sentence features in the datasets. In many cases, these sentence features can only be acquired by extra sentence-level human annotation with heavy costs. Therefore, the performance of distantly supervised RE models is bounded. In this paper, we go beyond typical MIL framework and propose a novel Contrastive Instance Learning (CIL) framework. Specifically, we regard the initial MIL as the relational triple encoder and constraint positive pairs against negative pairs for each instance. Experiments demonstrate the effectiveness of our proposed framework, with significant improvements over the previous methods on NYT10, GDS and KBP.","Relation extraction (RE) aims at predicting the relation between entities based on their context. Several studies have been carried out to handle this crucial and complicated task over decades as the extracted information can serve as a significant role for many downstream tasks. Since the amount of training data generally limits traditional supervised RE systems, current RE systems usually resort to distant supervision (DS) to fetch abundant training data by aligning knowledge bases (KBs) and texts. However, such a heuristic way inevitably introduces some noise to the generated data. Training a robust and unbiased RE system under DS data noise becomes the biggest challenge for distantly supervised relation extraction (DSRE). With awareness of the existing DS noise, Zeng et al. (2015) introduces the multi-instance learning (MIL) framework to DSRE by dividing training instances into several bags and using bags as new data units. Regarding the strategy for selecting instances inside the bag, the soft attention mechanism proposed by Lin et al. (2016) is widely used for its better performance than the hard selection method. The ability to form accurate representations from noisy data makes the MIL framework soon become a paradigm of following-up works. However, we argue that the MIL framework is effective to alleviate data noise for DSRE, but is not data-efficient indeed: As Figure 1 shows: The attention mechanism in the MIL can help select relatively informative instances (e.g.h1, h2) inside the bag, but may ignore the potential information of other abundant instances (e.g.hm). In other words, no matter how many instances a bag contains, only the formed bag-level representation can be used for further training in the MIL, which is quite inefficient. Thus, our focus is on how to make the initial MIL framework efficient enough to leverage all instances while maintaining the ability to obtain an accurate model under DS data noise? Here, we propose a contrastive-based method to help the MIL framework learn efficiently. In detail, we regard the initial MIL framework as the bag encoder, which provides relatively accurate representations for different relational triples. Then we develop contrastive instance learning (CIL) to utilize each instance in an unsupervised manner: In short, the goal of our CIL is that the instances sharing the same relational triples (i.e.positive pairs) ought to be close in the semantic space, while the representations of instances with different relational triples (i.e.negative pairs) should be far away. Experiments on three public DSRE benchmarks — NYT10 (Riedel et al., 2010; Hoffmann et al., 2011), GDS (Jat et al., 2018) and KBP (Ling and Weld, 2012) demonstrate the effectiveness of our proposed framework CIL, with consistent improvements over several baseline models and far exceed the state-of-the-art (SOTA) systems. Furthermore, the ablation study shows the rationality of our proposed positive/negative pair construction strategy. Accordingly, the major contributions of this paper are summarized as follows: • We discuss the long-standing MIL framework and point out that it can not effectively utilize abundant instances inside MIL bags. • We propose a novel contrastive instance learning method to boost the DSRE model performances under the MIL framework. • Evaluation on held-out and human-annotated sets shows that CIL leads to significant improvements over the previous SOTA models.","Can the performance limitations of distantly supervised relation extraction models, caused by noise from distant supervision and the MIL framework's inability to capture all useful sentence features, be overcome by introducing a novel Contrastive Instance Learning framework that encodes relational triples and contrasts positive pairs against negative pairs for each instance?",2.0,2.0,1.0
9,ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer,"Yuanmeng Yan, Rumei Li, Sirui Wang, Fuzheng Zhang, Wei Wu, and Weiran Xu. 2021. ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5065–5075, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.393.pdf,https://aclanthology.org/2021.acl-long.393/,"Learning high-quality sentence representations benefits a wide range of natural language processing tasks. Though BERT-based pretrained language models achieve high performance on many downstream tasks, the native derived sentence representations are proved to be collapsed and thus produce a poor performance on the semantic textual similarity (STS) tasks. In this paper, we present ConSERT, a Contrastive Framework for Self-Supervised SEntence Representation Transfer, that adopts contrastive learning to fine-tune BERT in an unsupervised and effective way. By making use of unlabeled texts, ConSERT solves the collapse issue of BERT-derived sentence representations and make them more applicable for downstream tasks. Experiments on STS datasets demonstrate that ConSERT achieves an 8% relative improvement over the previous state-of-the-art, even comparable to the supervised SBERT-NLI. And when further incorporating NLI supervision, we achieve new stateof-the-art performance on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios.","Sentence representation learning plays a vital role in natural language processing tasks (Kiros et al., 2015; Hill et al., 2016; Conneau et al., 2017; Cer et al., 2018). Good sentence representations benefit a wide range of downstream tasks, especially for computationally expensive ones, including largescale semantic similarity comparison and information retrieval. Recently, BERT-based pre-trained language models have achieved high performance on many downstream tasks with additional supervision. However, the native sentence representations derived from BERT1 are proved to be of low-quality (Reimers and Gurevych, 2019; Li et al., 2020). As shown in Figure 1a, when directly adopt BERTbased sentence representations to semantic textual similarity (STS) tasks, almost all pairs of sentences achieved a similarity score between 0.6 to 1.0 , even if some pairs are regarded as completely unrelated by the human annotators. In other words, the BERT-derived native sentence representations are somehow collapsed (Chen and He, 2020), which means almost all sentences are mapped into a small area and therefore produce high similarity. Such phenomenon is also observed in several previous works (Gao et al., 2019; Wang et al., 2019; Li et al., 2020). They find the word representation space of BERT is anisotropic, the high-frequency words are clustered and close to the origin, while low-frequency words disperse sparsely. When averaging token embeddings, those high-frequency words dominate the sentence representations, inducing biases against their real semantics 2 . As a result, it is inappropriate to directly apply BERT’s native sentence representations for semantic matching or text retrieval. Traditional methods usually fine-tune BERT with additional supervision. However, human annotation is costly and often unavailable in real-world scenarios. To alleviate the collapse issue of BERT as well as reduce the requirement for labeled data, we propose a novel sentence-level training objective based on contrastive learning (He et al., 2020; Chen et al., 2020a,b). By encouraging two augmented views from the same sentence to be closer while keeping views from other sentences away, we reshape the BERT-derived sentence representation space and successfully solve the collapse issue (shown in Figure 1b). Moreover, we propose multiple data augmentation strategies for contrastive learning, including adversarial attack (Goodfellow et al., 2014; Kurakin et al., 2016), token shuffling, cutoff (Shen et al., 2020) and dropout (Hinton et al., 2012), that effectively transfer the sentence representations to downstream tasks. We name our approach ConSERT, a Contrastive Framework for SEntence Representation Transfer. ConSERT has several advantages over previous approaches. Firstly, it introduces no extra structure or specialized implementation during inference. The parameter size of ConSERT keeps the same as BERT, making it easy to use. Secondly, compared with pre-training approaches, ConSERT is more efficient. With only 1,000 unlabeled texts drawn from the target distribution (which is easy to collect in real-world applications), we achieve 35% relative performance gain over BERT, and the training stage takes only a few minutes (1-2k steps) on a single V100 GPU. Finally, it includes several effective and convenient data augmentation methods with minimal semantic impact. Their effects are validated and analyzed in the ablation studies. Our contributions can be summarized as follows: 1) We propose a simple but effective sentence-level training objective based on contrastive learning. It mitigates the collapse of BERT-derived representations and transfers them to downstream tasks. 2) We explore various effective text augmentation strategies to generate views for contrastive learning and analyze their effects on unsupervised sentence representation transfer. 3) With only fine-tuning on unsupervised target datasets, our approach achieves significant improvement on STS tasks. When further incorporating with NLI supervision, our approach achieves new state-of-the-art performance. We also show the robustness of our approach in data scarcity scenarios and intuitive analysis of the transferred representations.3","How does the ConSERT framework, by adopting contrastive learning, address the sentence representation collapse issue in BERT-derived models and improve semantic textual similarity tasks' performance, including in scenarios with limited data?",2.0,1.0,1.0
10,ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer,"Yuanmeng Yan, Rumei Li, Sirui Wang, Fuzheng Zhang, Wei Wu, and Weiran Xu. 2021. ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5065–5075, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.393.pdf,https://aclanthology.org/2021.acl-long.393/,"Learning high-quality sentence representations benefits a wide range of natural language processing tasks. Though BERT-based pretrained language models achieve high performance on many downstream tasks, the native derived sentence representations are proved to be collapsed and thus produce a poor performance on the semantic textual similarity (STS) tasks. In this paper, we present ConSERT, a Contrastive Framework for Self-Supervised SEntence Representation Transfer, that adopts contrastive learning to fine-tune BERT in an unsupervised and effective way. By making use of unlabeled texts, ConSERT solves the collapse issue of BERT-derived sentence representations and make them more applicable for downstream tasks. Experiments on STS datasets demonstrate that ConSERT achieves an 8% relative improvement over the previous state-of-the-art, even comparable to the supervised SBERT-NLI. And when further incorporating NLI supervision, we achieve new stateof-the-art performance on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios.","Sentence representation learning plays a vital role in natural language processing tasks (Kiros et al., 2015; Hill et al., 2016; Conneau et al., 2017; Cer et al., 2018). Good sentence representations benefit a wide range of downstream tasks, especially for computationally expensive ones, including largescale semantic similarity comparison and information retrieval. Recently, BERT-based pre-trained language models have achieved high performance on many downstream tasks with additional supervision. However, the native sentence representations derived from BERT1 are proved to be of low-quality (Reimers and Gurevych, 2019; Li et al., 2020). As shown in Figure 1a, when directly adopt BERTbased sentence representations to semantic textual similarity (STS) tasks, almost all pairs of sentences achieved a similarity score between 0.6 to 1.0 , even if some pairs are regarded as completely unrelated by the human annotators. In other words, the BERT-derived native sentence representations are somehow collapsed (Chen and He, 2020), which means almost all sentences are mapped into a small area and therefore produce high similarity. Such phenomenon is also observed in several previous works (Gao et al., 2019; Wang et al., 2019; Li et al., 2020). They find the word representation space of BERT is anisotropic, the high-frequency words are clustered and close to the origin, while low-frequency words disperse sparsely. When averaging token embeddings, those high-frequency words dominate the sentence representations, inducing biases against their real semantics 2 . As a result, it is inappropriate to directly apply BERT’s native sentence representations for semantic matching or text retrieval. Traditional methods usually fine-tune BERT with additional supervision. However, human annotation is costly and often unavailable in real-world scenarios. To alleviate the collapse issue of BERT as well as reduce the requirement for labeled data, we propose a novel sentence-level training objective based on contrastive learning (He et al., 2020; Chen et al., 2020a,b). By encouraging two augmented views from the same sentence to be closer while keeping views from other sentences away, we reshape the BERT-derived sentence representation space and successfully solve the collapse issue (shown in Figure 1b). Moreover, we propose multiple data augmentation strategies for contrastive learning, including adversarial attack (Goodfellow et al., 2014; Kurakin et al., 2016), token shuffling, cutoff (Shen et al., 2020) and dropout (Hinton et al., 2012), that effectively transfer the sentence representations to downstream tasks. We name our approach ConSERT, a Contrastive Framework for SEntence Representation Transfer. ConSERT has several advantages over previous approaches. Firstly, it introduces no extra structure or specialized implementation during inference. The parameter size of ConSERT keeps the same as BERT, making it easy to use. Secondly, compared with pre-training approaches, ConSERT is more efficient. With only 1,000 unlabeled texts drawn from the target distribution (which is easy to collect in real-world applications), we achieve 35% relative performance gain over BERT, and the training stage takes only a few minutes (1-2k steps) on a single V100 GPU. Finally, it includes several effective and convenient data augmentation methods with minimal semantic impact. Their effects are validated and analyzed in the ablation studies. Our contributions can be summarized as follows: 1) We propose a simple but effective sentence-level training objective based on contrastive learning. It mitigates the collapse of BERT-derived representations and transfers them to downstream tasks. 2) We explore various effective text augmentation strategies to generate views for contrastive learning and analyze their effects on unsupervised sentence representation transfer. 3) With only fine-tuning on unsupervised target datasets, our approach achieves significant improvement on STS tasks. When further incorporating with NLI supervision, our approach achieves new state-of-the-art performance. We also show the robustness of our approach in data scarcity scenarios and intuitive analysis of the transferred representations.3",Can the collapse issue of BERT-derived sentence representations be solved by adopting a Contrastive Framework for Self-Supervised SEntence Representation Transfer (ConSERT) with contrastive learning?,1.0,1.0,1.0
11,ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer,"Yuanmeng Yan, Rumei Li, Sirui Wang, Fuzheng Zhang, Wei Wu, and Weiran Xu. 2021. ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5065–5075, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.393.pdf,https://aclanthology.org/2021.acl-long.393/,"Learning high-quality sentence representations benefits a wide range of natural language processing tasks. Though BERT-based pretrained language models achieve high performance on many downstream tasks, the native derived sentence representations are proved to be collapsed and thus produce a poor performance on the semantic textual similarity (STS) tasks. In this paper, we present ConSERT, a Contrastive Framework for Self-Supervised SEntence Representation Transfer, that adopts contrastive learning to fine-tune BERT in an unsupervised and effective way. By making use of unlabeled texts, ConSERT solves the collapse issue of BERT-derived sentence representations and make them more applicable for downstream tasks. Experiments on STS datasets demonstrate that ConSERT achieves an 8% relative improvement over the previous state-of-the-art, even comparable to the supervised SBERT-NLI. And when further incorporating NLI supervision, we achieve new stateof-the-art performance on STS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples available, showing its robustness in data scarcity scenarios.","Sentence representation learning plays a vital role in natural language processing tasks (Kiros et al., 2015; Hill et al., 2016; Conneau et al., 2017; Cer et al., 2018). Good sentence representations benefit a wide range of downstream tasks, especially for computationally expensive ones, including largescale semantic similarity comparison and information retrieval. Recently, BERT-based pre-trained language models have achieved high performance on many downstream tasks with additional supervision. However, the native sentence representations derived from BERT1 are proved to be of low-quality (Reimers and Gurevych, 2019; Li et al., 2020). As shown in Figure 1a, when directly adopt BERTbased sentence representations to semantic textual similarity (STS) tasks, almost all pairs of sentences achieved a similarity score between 0.6 to 1.0 , even if some pairs are regarded as completely unrelated by the human annotators. In other words, the BERT-derived native sentence representations are somehow collapsed (Chen and He, 2020), which means almost all sentences are mapped into a small area and therefore produce high similarity. Such phenomenon is also observed in several previous works (Gao et al., 2019; Wang et al., 2019; Li et al., 2020). They find the word representation space of BERT is anisotropic, the high-frequency words are clustered and close to the origin, while low-frequency words disperse sparsely. When averaging token embeddings, those high-frequency words dominate the sentence representations, inducing biases against their real semantics 2 . As a result, it is inappropriate to directly apply BERT’s native sentence representations for semantic matching or text retrieval. Traditional methods usually fine-tune BERT with additional supervision. However, human annotation is costly and often unavailable in real-world scenarios. To alleviate the collapse issue of BERT as well as reduce the requirement for labeled data, we propose a novel sentence-level training objective based on contrastive learning (He et al., 2020; Chen et al., 2020a,b). By encouraging two augmented views from the same sentence to be closer while keeping views from other sentences away, we reshape the BERT-derived sentence representation space and successfully solve the collapse issue (shown in Figure 1b). Moreover, we propose multiple data augmentation strategies for contrastive learning, including adversarial attack (Goodfellow et al., 2014; Kurakin et al., 2016), token shuffling, cutoff (Shen et al., 2020) and dropout (Hinton et al., 2012), that effectively transfer the sentence representations to downstream tasks. We name our approach ConSERT, a Contrastive Framework for SEntence Representation Transfer. ConSERT has several advantages over previous approaches. Firstly, it introduces no extra structure or specialized implementation during inference. The parameter size of ConSERT keeps the same as BERT, making it easy to use. Secondly, compared with pre-training approaches, ConSERT is more efficient. With only 1,000 unlabeled texts drawn from the target distribution (which is easy to collect in real-world applications), we achieve 35% relative performance gain over BERT, and the training stage takes only a few minutes (1-2k steps) on a single V100 GPU. Finally, it includes several effective and convenient data augmentation methods with minimal semantic impact. Their effects are validated and analyzed in the ablation studies. Our contributions can be summarized as follows: 1) We propose a simple but effective sentence-level training objective based on contrastive learning. It mitigates the collapse of BERT-derived representations and transfers them to downstream tasks. 2) We explore various effective text augmentation strategies to generate views for contrastive learning and analyze their effects on unsupervised sentence representation transfer. 3) With only fine-tuning on unsupervised target datasets, our approach achieves significant improvement on STS tasks. When further incorporating with NLI supervision, our approach achieves new state-of-the-art performance. We also show the robustness of our approach in data scarcity scenarios and intuitive analysis of the transferred representations.3","Can the collapse issue of BERT-derived sentence representations, which leads to poor performance on semantic textual similarity tasks, be addressed by fine-tuning BERT with an unsupervised contrastive learning framework (ConSERT) using data augmentation techniques?",2.0,2.0,1.0
12,A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings,"Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018. A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 789–798, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1073.pdf,https://aclanthology.org/P18-1073/,"Recent work has managed to learn crosslingual word embeddings without parallel data by mapping monolingual embeddings to a shared space through adversarial training. However, their evaluation has focused on favorable conditions, using comparable corpora or closely-related languages, and we show that they often fail in more realistic scenarios. This work proposes an alternative approach based on a fully unsupervised initialization that explicitly exploits the structural similarity of the embeddings, and a robust self-learning algorithm that iteratively improves this solution. Our method succeeds in all tested scenarios and obtains the best published results in standard datasets, even surpassing previous supervised systems. Our implementation is released as an open source project at https://github. com/artetxem/vecmap.","Cross-lingual embedding mappings have shown to be an effective way to learn bilingual word embeddings (Mikolov et al., 2013; Lazaridou et al., 2015). The underlying idea is to independently train the embeddings in different languages using monolingual corpora, and then map them to a shared space through a linear transformation. This allows to learn high-quality cross-lingual representations without expensive supervision, opening new research avenues like unsupervised neural machine translation (Artetxe et al., 2018b; Lample et al., 2018). While most embedding mapping methods rely on a small seed dictionary, adversarial training has recently produced exciting results in fully unsupervised settings (Zhang et al., 2017a,b; Conneau et al., 2018). However, their evaluation has focused on particularly favorable conditions, limited to closely-related languages or comparable Wikipedia corpora. When tested on more realistic scenarios, we find that they often fail to produce meaningful results. For instance, none of the existing methods works in the standard EnglishFinnish dataset from Artetxe et al. (2017), obtaining translation accuracies below 2% in all cases (see Section 5). On another strand of work, Artetxe et al. (2017) showed that an iterative self-learning method is able to bootstrap a high quality mapping from very small seed dictionaries (as little as 25 pairs of words). However, their analysis reveals that the self-learning method gets stuck in poor local optima when the initial solution is not good enough, thus failing for smaller training dictionaries. In this paper, we follow this second approach and propose a new unsupervised method to build an initial solution without the need of a seed dictionary, based on the observation that, given the similarity matrix of all words in the vocabulary, each word has a different distribution of similarity values. Two equivalent words in different languages should have a similar distribution, and we can use this fact to induce the initial set of word pairings (see Figure 1). We combine this initialization with a more robust self-learning method, which is able to start from the weak initial solution and iteratively improve the mapping. Coupled together, we provide a fully unsupervised crosslingual mapping method that is effective in realistic settings, converges to a good solution in all cases tested, and sets a new state-of-the-art in bilingual lexicon extraction, even surpassing previous supervised methods.",Can unsupervised crosslingual mapping methods be made effective in realistic settings by leveraging a fully unsupervised initialization that exploits structural similarities and a robust self-learning algorithm?,2.0,2.0,1.0
13,A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings,"Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018. A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 789–798, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1073.pdf,https://aclanthology.org/P18-1073/,"Recent work has managed to learn crosslingual word embeddings without parallel data by mapping monolingual embeddings to a shared space through adversarial training. However, their evaluation has focused on favorable conditions, using comparable corpora or closely-related languages, and we show that they often fail in more realistic scenarios. This work proposes an alternative approach based on a fully unsupervised initialization that explicitly exploits the structural similarity of the embeddings, and a robust self-learning algorithm that iteratively improves this solution. Our method succeeds in all tested scenarios and obtains the best published results in standard datasets, even surpassing previous supervised systems. Our implementation is released as an open source project at https://github. com/artetxem/vecmap.","Cross-lingual embedding mappings have shown to be an effective way to learn bilingual word embeddings (Mikolov et al., 2013; Lazaridou et al., 2015). The underlying idea is to independently train the embeddings in different languages using monolingual corpora, and then map them to a shared space through a linear transformation. This allows to learn high-quality cross-lingual representations without expensive supervision, opening new research avenues like unsupervised neural machine translation (Artetxe et al., 2018b; Lample et al., 2018). While most embedding mapping methods rely on a small seed dictionary, adversarial training has recently produced exciting results in fully unsupervised settings (Zhang et al., 2017a,b; Conneau et al., 2018). However, their evaluation has focused on particularly favorable conditions, limited to closely-related languages or comparable Wikipedia corpora. When tested on more realistic scenarios, we find that they often fail to produce meaningful results. For instance, none of the existing methods works in the standard EnglishFinnish dataset from Artetxe et al. (2017), obtaining translation accuracies below 2% in all cases (see Section 5). On another strand of work, Artetxe et al. (2017) showed that an iterative self-learning method is able to bootstrap a high quality mapping from very small seed dictionaries (as little as 25 pairs of words). However, their analysis reveals that the self-learning method gets stuck in poor local optima when the initial solution is not good enough, thus failing for smaller training dictionaries. In this paper, we follow this second approach and propose a new unsupervised method to build an initial solution without the need of a seed dictionary, based on the observation that, given the similarity matrix of all words in the vocabulary, each word has a different distribution of similarity values. Two equivalent words in different languages should have a similar distribution, and we can use this fact to induce the initial set of word pairings (see Figure 1). We combine this initialization with a more robust self-learning method, which is able to start from the weak initial solution and iteratively improve the mapping. Coupled together, we provide a fully unsupervised crosslingual mapping method that is effective in realistic settings, converges to a good solution in all cases tested, and sets a new state-of-the-art in bilingual lexicon extraction, even surpassing previous supervised methods.","Can the problem of learning crosslingual word embeddings under realistic scenarios, where languages may not be closely related and without the need for parallel data, be solved by a fully unsupervised method that initializes embeddings based on structural similarities between languages and iteratively refines them using a robust self-learning algorithm?",1.0,2.0,1.0
14,BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance,"Timo Schick and Hinrich Schütze. 2020. BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3996–4007, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.368.pdf,https://aclanthology.org/2020.acl-main.368/,"Pretraining deep language models has led to large performance gains in NLP. Despite this success, Schick and Schutze ¨ (2020) recently showed that these models struggle to understand rare words. For static word embeddings, this problem has been addressed by separately learning representations for rare words. In this work, we transfer this idea to pretrained language models: We introduce BERTRAM, a powerful architecture based on BERT that is capable of inferring high-quality embeddings for rare words that are suitable as input representations for deep language models. This is achieved by enabling the surface form and contexts of a word to interact with each other in a deep architecture. Integrating BERTRAM into BERT leads to large performance increases due to improved representations of rare and medium frequency words on both a rare word probing task and three downstream tasks.1","As word embedding algorithms (e.g. Mikolov et al., 2013) are known to struggle with rare words, several techniques for improving their representations have been proposed. These approaches exploit either the contexts in which rare words occur (Lazaridou et al., 2017; Herbelot and Baroni, 2017; Khodak et al., 2018; Liu et al., 2019a), their surfaceform (Luong et al., 2013; Bojanowski et al., 2017; Pinter et al., 2017), or both (Schick and Schutze ¨ , 2019a,b; Hautte et al., 2019). However, all of this prior work is designed for and evaluated on uncontextualized word embeddings. Contextualized representations obtained from pretrained deep language models (e.g. Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Liu et al., 2019b) already handle rare words implicitly using methods such as byte-pair encoding (Sennrich et al., 2016), WordPiece embeddings (Wu et al., 2016) and character-level CNNs (Baevski et al., 2019). Nevertheless, Schick and Schutze ¨ (2020) recently showed that BERT’s (Devlin et al., 2019) performance on a rare word probing task can be significantly improved by explicitly learning representations of rare words using Attentive Mimicking (AM) (Schick and Schutze ¨ , 2019a). However, AM is limited in two important respects: • For processing contexts, it uses a simple bagof-words model, making poor use of the available information. • It combines form and context in a shallow fashion, preventing both input signals from interacting in a complex manner. These limitations apply not only to AM, but to all previous work on obtaining representations for rare words by leveraging form and context. While using bag-of-words models is a reasonable choice for static embeddings, which are often themselves bagof-words (e.g. Mikolov et al., 2013; Bojanowski et al., 2017), it stands to reason that they are not the best choice to generate input representations for position-aware, deep language models. To overcome these limitations, we introduce BERTRAM (BERT for Attentive Mimicking), a novel architecture for learning rare word representations that combines a pretrained BERT model with AM. As shown in Figure 1, the learned rare word representations can then be used as an improved input representation for another BERT model. By giving BERTRAM access to both surface form and contexts starting at the lowest layer, a deep integration of both input signals becomes possible. Assessing the effectiveness of methods like BERTRAM in a contextualized setting is challenging: While most previous work on rare words was evaluated on datasets explicitly focusing on rare words (e.g Luong et al., 2013; Herbelot and Baroni, 2017; Khodak et al., 2018; Liu et al., 2019a), these datasets are tailored to uncontextualized embeddings and thus not suitable for evaluating our model. Furthermore, rare words are not well represented in commonly used downstream task datasets. We therefore introduce rarification, a procedure to automatically convert evaluation datasets into ones for which rare words are guaranteed to be important. This is achieved by replacing task-relevant frequent words with rare synonyms obtained using semantic resources such as WordNet (Miller, 1995). We rarify three common text (or text pair) classification datasets: MNLI (Williams et al., 2018), AG’s News (Zhang et al., 2015) and DBPedia (Lehmann et al., 2015). BERTRAM outperforms previous work on four English datasets by a large margin: on the three rarified datasets and on WNLaMPro (Schick and Schutze ¨ , 2020). In summary, our contributions are as follows: • We introduce BERTRAM, a model that integrates BERT into Attentive Mimicking, enabling a deep integration of surface-form and contexts and much better representations for rare words. • We devise rarification, a method that transforms evaluation datasets into ones for which rare words are guaranteed to be important. • We show that adding BERTRAM to BERT achieves a new state-of-the-art on WNLaMPro (Schick and Schutze ¨ , 2020) and beats all baselines on rarified AG’s News, MNLI and DBPedia, resulting in an absolute improvement of up to 25% over BERT.","How does the introduction of BERTRAM, a new architecture that integrates BERT with Attentive Mimicking for the deep integration of surface form and word contexts, improve the representation quality of rare words in pretrained language models, and how does this impact performance on rarified evaluation datasets and a rare word probing task?",2.0,2.0,1.0
15,BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance,"Timo Schick and Hinrich Schütze. 2020. BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3996–4007, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.368.pdf,https://aclanthology.org/2020.acl-main.368/,"Pretraining deep language models has led to large performance gains in NLP. Despite this success, Schick and Schutze ¨ (2020) recently showed that these models struggle to understand rare words. For static word embeddings, this problem has been addressed by separately learning representations for rare words. In this work, we transfer this idea to pretrained language models: We introduce BERTRAM, a powerful architecture based on BERT that is capable of inferring high-quality embeddings for rare words that are suitable as input representations for deep language models. This is achieved by enabling the surface form and contexts of a word to interact with each other in a deep architecture. Integrating BERTRAM into BERT leads to large performance increases due to improved representations of rare and medium frequency words on both a rare word probing task and three downstream tasks.1","As word embedding algorithms (e.g. Mikolov et al., 2013) are known to struggle with rare words, several techniques for improving their representations have been proposed. These approaches exploit either the contexts in which rare words occur (Lazaridou et al., 2017; Herbelot and Baroni, 2017; Khodak et al., 2018; Liu et al., 2019a), their surfaceform (Luong et al., 2013; Bojanowski et al., 2017; Pinter et al., 2017), or both (Schick and Schutze ¨ , 2019a,b; Hautte et al., 2019). However, all of this prior work is designed for and evaluated on uncontextualized word embeddings. Contextualized representations obtained from pretrained deep language models (e.g. Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Liu et al., 2019b) already handle rare words implicitly using methods such as byte-pair encoding (Sennrich et al., 2016), WordPiece embeddings (Wu et al., 2016) and character-level CNNs (Baevski et al., 2019). Nevertheless, Schick and Schutze ¨ (2020) recently showed that BERT’s (Devlin et al., 2019) performance on a rare word probing task can be significantly improved by explicitly learning representations of rare words using Attentive Mimicking (AM) (Schick and Schutze ¨ , 2019a). However, AM is limited in two important respects: • For processing contexts, it uses a simple bagof-words model, making poor use of the available information. • It combines form and context in a shallow fashion, preventing both input signals from interacting in a complex manner. These limitations apply not only to AM, but to all previous work on obtaining representations for rare words by leveraging form and context. While using bag-of-words models is a reasonable choice for static embeddings, which are often themselves bagof-words (e.g. Mikolov et al., 2013; Bojanowski et al., 2017), it stands to reason that they are not the best choice to generate input representations for position-aware, deep language models. To overcome these limitations, we introduce BERTRAM (BERT for Attentive Mimicking), a novel architecture for learning rare word representations that combines a pretrained BERT model with AM. As shown in Figure 1, the learned rare word representations can then be used as an improved input representation for another BERT model. By giving BERTRAM access to both surface form and contexts starting at the lowest layer, a deep integration of both input signals becomes possible. Assessing the effectiveness of methods like BERTRAM in a contextualized setting is challenging: While most previous work on rare words was evaluated on datasets explicitly focusing on rare words (e.g Luong et al., 2013; Herbelot and Baroni, 2017; Khodak et al., 2018; Liu et al., 2019a), these datasets are tailored to uncontextualized embeddings and thus not suitable for evaluating our model. Furthermore, rare words are not well represented in commonly used downstream task datasets. We therefore introduce rarification, a procedure to automatically convert evaluation datasets into ones for which rare words are guaranteed to be important. This is achieved by replacing task-relevant frequent words with rare synonyms obtained using semantic resources such as WordNet (Miller, 1995). We rarify three common text (or text pair) classification datasets: MNLI (Williams et al., 2018), AG’s News (Zhang et al., 2015) and DBPedia (Lehmann et al., 2015). BERTRAM outperforms previous work on four English datasets by a large margin: on the three rarified datasets and on WNLaMPro (Schick and Schutze ¨ , 2020). In summary, our contributions are as follows: • We introduce BERTRAM, a model that integrates BERT into Attentive Mimicking, enabling a deep integration of surface-form and contexts and much better representations for rare words. • We devise rarification, a method that transforms evaluation datasets into ones for which rare words are guaranteed to be important. • We show that adding BERTRAM to BERT achieves a new state-of-the-art on WNLaMPro (Schick and Schutze ¨ , 2020) and beats all baselines on rarified AG’s News, MNLI and DBPedia, resulting in an absolute improvement of up to 25% over BERT.",Can high-quality embeddings for rare words be inferred using a novel architecture that integrates BERT into Attentive Mimicking?,1.0,1.0,1.0
16,BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance,"Timo Schick and Hinrich Schütze. 2020. BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3996–4007, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.368.pdf,https://aclanthology.org/2020.acl-main.368/,"Pretraining deep language models has led to large performance gains in NLP. Despite this success, Schick and Schutze ¨ (2020) recently showed that these models struggle to understand rare words. For static word embeddings, this problem has been addressed by separately learning representations for rare words. In this work, we transfer this idea to pretrained language models: We introduce BERTRAM, a powerful architecture based on BERT that is capable of inferring high-quality embeddings for rare words that are suitable as input representations for deep language models. This is achieved by enabling the surface form and contexts of a word to interact with each other in a deep architecture. Integrating BERTRAM into BERT leads to large performance increases due to improved representations of rare and medium frequency words on both a rare word probing task and three downstream tasks.1","As word embedding algorithms (e.g. Mikolov et al., 2013) are known to struggle with rare words, several techniques for improving their representations have been proposed. These approaches exploit either the contexts in which rare words occur (Lazaridou et al., 2017; Herbelot and Baroni, 2017; Khodak et al., 2018; Liu et al., 2019a), their surfaceform (Luong et al., 2013; Bojanowski et al., 2017; Pinter et al., 2017), or both (Schick and Schutze ¨ , 2019a,b; Hautte et al., 2019). However, all of this prior work is designed for and evaluated on uncontextualized word embeddings. Contextualized representations obtained from pretrained deep language models (e.g. Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Liu et al., 2019b) already handle rare words implicitly using methods such as byte-pair encoding (Sennrich et al., 2016), WordPiece embeddings (Wu et al., 2016) and character-level CNNs (Baevski et al., 2019). Nevertheless, Schick and Schutze ¨ (2020) recently showed that BERT’s (Devlin et al., 2019) performance on a rare word probing task can be significantly improved by explicitly learning representations of rare words using Attentive Mimicking (AM) (Schick and Schutze ¨ , 2019a). However, AM is limited in two important respects: • For processing contexts, it uses a simple bagof-words model, making poor use of the available information. • It combines form and context in a shallow fashion, preventing both input signals from interacting in a complex manner. These limitations apply not only to AM, but to all previous work on obtaining representations for rare words by leveraging form and context. While using bag-of-words models is a reasonable choice for static embeddings, which are often themselves bagof-words (e.g. Mikolov et al., 2013; Bojanowski et al., 2017), it stands to reason that they are not the best choice to generate input representations for position-aware, deep language models. To overcome these limitations, we introduce BERTRAM (BERT for Attentive Mimicking), a novel architecture for learning rare word representations that combines a pretrained BERT model with AM. As shown in Figure 1, the learned rare word representations can then be used as an improved input representation for another BERT model. By giving BERTRAM access to both surface form and contexts starting at the lowest layer, a deep integration of both input signals becomes possible. Assessing the effectiveness of methods like BERTRAM in a contextualized setting is challenging: While most previous work on rare words was evaluated on datasets explicitly focusing on rare words (e.g Luong et al., 2013; Herbelot and Baroni, 2017; Khodak et al., 2018; Liu et al., 2019a), these datasets are tailored to uncontextualized embeddings and thus not suitable for evaluating our model. Furthermore, rare words are not well represented in commonly used downstream task datasets. We therefore introduce rarification, a procedure to automatically convert evaluation datasets into ones for which rare words are guaranteed to be important. This is achieved by replacing task-relevant frequent words with rare synonyms obtained using semantic resources such as WordNet (Miller, 1995). We rarify three common text (or text pair) classification datasets: MNLI (Williams et al., 2018), AG’s News (Zhang et al., 2015) and DBPedia (Lehmann et al., 2015). BERTRAM outperforms previous work on four English datasets by a large margin: on the three rarified datasets and on WNLaMPro (Schick and Schutze ¨ , 2020). In summary, our contributions are as follows: • We introduce BERTRAM, a model that integrates BERT into Attentive Mimicking, enabling a deep integration of surface-form and contexts and much better representations for rare words. • We devise rarification, a method that transforms evaluation datasets into ones for which rare words are guaranteed to be important. • We show that adding BERTRAM to BERT achieves a new state-of-the-art on WNLaMPro (Schick and Schutze ¨ , 2020) and beats all baselines on rarified AG’s News, MNLI and DBPedia, resulting in an absolute improvement of up to 25% over BERT.","Can the challenge of representing rare words in pretrained language models be effectively addressed by introducing BERTRAM, an architecture that enhances word representations through deep integration of surface form and contexts, and assessing its impact using rarification?",2.0,2.0,1.0
17,Style Transformer: Unpaired Text Style Transfer without Disentangled Latent Representation,"Ning Dai, Jianze Liang, Xipeng Qiu, and Xuanjing Huang. 2019. Style Transformer: Unpaired Text Style Transfer without Disentangled Latent Representation. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5997–6007, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1601.pdf,https://aclanthology.org/P19-1601/,"Disentangling the content and style in the latent space is prevalent in unpaired text style transfer. However, two major issues exist in most of the current neural models. 1) It is difficult to completely strip the style information from the semantics for a sentence. 2) The recurrent neural network (RNN) based encoder and decoder, mediated by the latent representation, cannot well deal with the issue of the long-term dependency, resulting in poor preservation of non-stylistic semantic content. In this paper, we propose the Style Transformer, which makes no assumption about the latent representation of source sentence and equips the power of attention mechanism in Transformer to achieve better style transfer and better content preservation. Source code will be available on Github1 .","Text style transfer is the task of changing the stylistic properties (e.g., sentiment) of the text while retaining the style-independent content within the context. Since the definition of the text style is vague, it is difficult to construct paired sentences with the same content and differing styles. Therefore, the studies of text style transfer focus on the unpaired transfer. Recently, neural networks have become the dominant methods in text style transfer. Most of the previous methods (Hu et al., 2017; Shen et al., 2017; Fu et al., 2018; Carlson et al., 2017; Zhang et al., 2018b,a; Prabhumoye et al., 2018; Jin et al., 2019; Melnyk et al., 2017; dos Santos et al., 2018) formulate the style transfer problem into the “encoder-decoder” framework. The encoder maps the text into a style-independent latent representation (vector representation), and the decoder generates a new text with the same content but a different style from the disentangled latent representation plus a style variable. These methods focus on how to disentangle the content and style in the latent space. The latent representation needs better preserve the meaning of the text while reducing its stylistic properties. Due to lacking paired sentence, an adversarial loss (Goodfellow et al., 2014) is used in the latent space to discourage encoding style information in the latent representation. Although the disentangled latent representation brings better interpretability, in this paper, we address the following concerns for these models. 1) It is difficult to judge the quality of disentanglement. As reported in (Elazar and Goldberg, 2018; Lample et al., 2019), the style information can be still recovered from the latent representation even the model has trained adversarially. Therefore, it is not easy to disentangle the stylistic property from the semantics of a sentence. 2) Disentanglement is also unnecessary. Lample et al. (2019) reported that a good decoder can generate the text with the desired style from an entangled latent representation by “overwriting” the original style. 3) Due to the limited capacity of vector representation, the latent representation is hard to capture the rich semantic information, especially for the long text. The recent progress of neural machine translation also proves that it is hard to recover the target sentence from the latent representation without referring to the original sentence. 4) To disentangle the content and style information in the latent space, all of the existing approaches have to assume the input sentence is encoded by a fix-sized latent vector. As a result, these approaches can not directly apply the attention mechanism to enhance the ability to preserve the information in the input sentence. 5) Most of these models adopt recurrent neural networks (RNNs) as encoder and decoder, which has a weak ability to capture the long-range dependencies between words in a sentence. Besides, without referring the original text, RNN-based decoder is also hard to preserve the content. The generation quality for long text is also uncontrollable. In this paper, we address the above concerns of disentangled models for style transfer. Different from them, we propose Style Transformer, which takes Transformer (Vaswani et al., 2017) as the basic block. Transformer is a fully-connected selfattention neural architecture, which has achieved many exciting results on natural language processing (NLP) tasks, such as machine translation (Vaswani et al., 2017), language modeling (Dai et al., 2019), text classification (Devlin et al., 2018). Different from RNNs, Transformer uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. Moreover, Transformer decoder fetches the information from the encoder part via attention mechanism, compared to a fixed size vector used by RNNs. With the strong ability of Transformer, our model can transfer the style of a sentence while better preserving its meaning. The difference between our model and the previous model is shown in Figure 1. Our contributions are summarized as follows: • We introduce a novel training algorithm which makes no assumptions about the disentangled latent representations of the input sentences, and thus the model can employ attention mechanisms to improve its performance further. • To the best of our knowledge, this is the first work that applies the Transformer architecture to style transfer task. • Experimental results show that our proposed approach generally outperforms the other approaches on two style transfer datasets. Specifically, to the content preservation, Style Transformer achieves the best performance with a significant improvement.",Can the issues of style-content disentanglement and long-term dependency in text style transfer be solved by employing the Transformer architecture?,1.0,2.0,1.0
18,Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation,"Chenze Shao and Yang Feng. 2022. Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2023–2036, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.143.pdf,https://aclanthology.org/2022.acl-long.143/,"Neural networks tend to gradually forget the previously learned knowledge when learning multiple tasks sequentially from dynamic data distributions. This problem is called catastrophic forgetting, which is a fundamental challenge in the continual learning of neural networks. In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. Neural networks, especially neural machine translation models, suffer from catastrophic forgetting even if they learn from a static training set. To be specific, the final model pays imbalanced attention to training samples, where recently exposed samples attract more attention than earlier samples. The underlying cause is that training samples do not get balanced training in each model update, so we name this problem imbalanced training. To alleviate this problem, we propose Complementary Online Knowledge Distillation (COKD), which uses dynamically updated teacher models trained on specific data orders to iteratively provide complementary knowledge to the student model. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems.","Neural Machine Translation (NMT) has achieved impressive translation performance on many benchmark datasets in the past few years (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017). In the domain adaptation task where we have large-scale outdomain data to improve the in-domain translation performance, continual learning, which is also referred to as fine-tuning, is often employed to transfer the out-domain knowledge to in-domain (Luong and Manning, 2015). After fine-tuning, the model performs well in in-domain translation, but there is significant performance degradation in out-domain translation because it “forgets” the previously learned knowledge. This phenomenon is called catastrophic forgetting (McCloskey and Cohen, 1989; French, 1999) and has attracted a lot of attention (Goodfellow et al., 2013; Kirkpatrick et al., 2017; Li and Hoiem, 2017; Lee et al., 2017). In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. To be specific, the final model pays imbalanced attention to training samples. At the end of training, the recently exposed samples attract more attention and tend to have lower losses, while earlier samples are partially forgotten by the model and have higher losses. In short, training samples receive imbalanced attention from the model, which mainly depends on the time when the model last saw the training sample (i.e., the data order of the last training epoch). The underlying cause of this phenomenon is mini-batch gradient descent (LeCun et al., 2012), that is, we do not simultaneously use all training samples to train the model but divide them into mini-batches. Therefore, training samples do not get balanced training in each update step, so we name this problem imbalanced training. This problem is less severe in some tasks (e.g., image classification and text classification), but it has a significant impact on NMT as machine translation is a challenging task containing numerous translation rules, which are easily forgotten during the training process. Besides, we find that the imbalanced training problem is especially severe and non-negligible on low-resource machine translation. To demonstrate that the imbalanced training problem does affect the model accuracy, we first review a widely used technique called checkpoint averaging technique, which has proved to be effective in improving model accuracy but its internal mechanisms are not fully understood. We analyze it from the perspective of catastrophic forgetting and find that their success can be attributed to the alleviation of imbalanced training. We also notice that checkpoint averaging has some limitations, leaving room for further improvements. Inspired by the existing solution of checkpoint averaging which leverages the complementarity of checkpoints to improve model accuracy, we propose Complementary Online Knowledge Distillation (COKD) to address the problem of imbalanced training. As the model tends to forget knowledge learned from early samples, the main idea of COKD is to construct complementary teachers to re-provide this forgotten knowledge to the student. Specifically, we divide the training set into mutually exclusive subsets and reorganize them in a specific orders to train the student and teachers. We perform COKD in an online manner where teachers are on-the-fly updated to fit the need of student. When training the student on a subset, teachers can always provide the student with complementary knowledge on the other subsets, thereby preventing the student from catastrophic forgetting. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems. Especially, on the low-resource translation tasks that are severely affected by imbalanced training, our method is particularly effective and improves baseline models by about 2 BLEU points on average. In summary, our contribution is threefold: • We observe the problem of imbalanced training that training samples receive imbalanced attention from the model. We find that NMT, especially low-resource translation tasks, is seriously affected by imbalanced training. • We rethink the widely used checkpoint averaging technique and explain its success from the perspective of imbalanced training, which also demonstrates that the imbalanced training problem does affect the model accuracy. • We propose Complementary Online Knowledge Distillation for NMT, which can successfully alleviate the imbalanced training problem and improve the translation quality.",How does the Complementary Online Knowledge Distillation (COKD) method address the problem of imbalanced training and improve neural machine translation performance by mitigating catastrophic forgetting of early training samples?,1.0,1.0,1.0
19,Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation,"Chenze Shao and Yang Feng. 2022. Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2023–2036, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.143.pdf,https://aclanthology.org/2022.acl-long.143/,"Neural networks tend to gradually forget the previously learned knowledge when learning multiple tasks sequentially from dynamic data distributions. This problem is called catastrophic forgetting, which is a fundamental challenge in the continual learning of neural networks. In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. Neural networks, especially neural machine translation models, suffer from catastrophic forgetting even if they learn from a static training set. To be specific, the final model pays imbalanced attention to training samples, where recently exposed samples attract more attention than earlier samples. The underlying cause is that training samples do not get balanced training in each model update, so we name this problem imbalanced training. To alleviate this problem, we propose Complementary Online Knowledge Distillation (COKD), which uses dynamically updated teacher models trained on specific data orders to iteratively provide complementary knowledge to the student model. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems.","Neural Machine Translation (NMT) has achieved impressive translation performance on many benchmark datasets in the past few years (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017). In the domain adaptation task where we have large-scale outdomain data to improve the in-domain translation performance, continual learning, which is also referred to as fine-tuning, is often employed to transfer the out-domain knowledge to in-domain (Luong and Manning, 2015). After fine-tuning, the model performs well in in-domain translation, but there is significant performance degradation in out-domain translation because it “forgets” the previously learned knowledge. This phenomenon is called catastrophic forgetting (McCloskey and Cohen, 1989; French, 1999) and has attracted a lot of attention (Goodfellow et al., 2013; Kirkpatrick et al., 2017; Li and Hoiem, 2017; Lee et al., 2017). In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. To be specific, the final model pays imbalanced attention to training samples. At the end of training, the recently exposed samples attract more attention and tend to have lower losses, while earlier samples are partially forgotten by the model and have higher losses. In short, training samples receive imbalanced attention from the model, which mainly depends on the time when the model last saw the training sample (i.e., the data order of the last training epoch). The underlying cause of this phenomenon is mini-batch gradient descent (LeCun et al., 2012), that is, we do not simultaneously use all training samples to train the model but divide them into mini-batches. Therefore, training samples do not get balanced training in each update step, so we name this problem imbalanced training. This problem is less severe in some tasks (e.g., image classification and text classification), but it has a significant impact on NMT as machine translation is a challenging task containing numerous translation rules, which are easily forgotten during the training process. Besides, we find that the imbalanced training problem is especially severe and non-negligible on low-resource machine translation. To demonstrate that the imbalanced training problem does affect the model accuracy, we first review a widely used technique called checkpoint averaging technique, which has proved to be effective in improving model accuracy but its internal mechanisms are not fully understood. We analyze it from the perspective of catastrophic forgetting and find that their success can be attributed to the alleviation of imbalanced training. We also notice that checkpoint averaging has some limitations, leaving room for further improvements. Inspired by the existing solution of checkpoint averaging which leverages the complementarity of checkpoints to improve model accuracy, we propose Complementary Online Knowledge Distillation (COKD) to address the problem of imbalanced training. As the model tends to forget knowledge learned from early samples, the main idea of COKD is to construct complementary teachers to re-provide this forgotten knowledge to the student. Specifically, we divide the training set into mutually exclusive subsets and reorganize them in a specific orders to train the student and teachers. We perform COKD in an online manner where teachers are on-the-fly updated to fit the need of student. When training the student on a subset, teachers can always provide the student with complementary knowledge on the other subsets, thereby preventing the student from catastrophic forgetting. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems. Especially, on the low-resource translation tasks that are severely affected by imbalanced training, our method is particularly effective and improves baseline models by about 2 BLEU points on average. In summary, our contribution is threefold: • We observe the problem of imbalanced training that training samples receive imbalanced attention from the model. We find that NMT, especially low-resource translation tasks, is seriously affected by imbalanced training. • We rethink the widely used checkpoint averaging technique and explain its success from the perspective of imbalanced training, which also demonstrates that the imbalanced training problem does affect the model accuracy. • We propose Complementary Online Knowledge Distillation for NMT, which can successfully alleviate the imbalanced training problem and improve the translation quality.",Can the imbalanced training problem in neural machine translation be solved by Complementary Online Knowledge Distillation (COKD)?,1.0,1.0,1.0
20,Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation,"Chenze Shao and Yang Feng. 2022. Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2023–2036, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.143.pdf,https://aclanthology.org/2022.acl-long.143/,"Neural networks tend to gradually forget the previously learned knowledge when learning multiple tasks sequentially from dynamic data distributions. This problem is called catastrophic forgetting, which is a fundamental challenge in the continual learning of neural networks. In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. Neural networks, especially neural machine translation models, suffer from catastrophic forgetting even if they learn from a static training set. To be specific, the final model pays imbalanced attention to training samples, where recently exposed samples attract more attention than earlier samples. The underlying cause is that training samples do not get balanced training in each model update, so we name this problem imbalanced training. To alleviate this problem, we propose Complementary Online Knowledge Distillation (COKD), which uses dynamically updated teacher models trained on specific data orders to iteratively provide complementary knowledge to the student model. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems.","Neural Machine Translation (NMT) has achieved impressive translation performance on many benchmark datasets in the past few years (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017). In the domain adaptation task where we have large-scale outdomain data to improve the in-domain translation performance, continual learning, which is also referred to as fine-tuning, is often employed to transfer the out-domain knowledge to in-domain (Luong and Manning, 2015). After fine-tuning, the model performs well in in-domain translation, but there is significant performance degradation in out-domain translation because it “forgets” the previously learned knowledge. This phenomenon is called catastrophic forgetting (McCloskey and Cohen, 1989; French, 1999) and has attracted a lot of attention (Goodfellow et al., 2013; Kirkpatrick et al., 2017; Li and Hoiem, 2017; Lee et al., 2017). In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. To be specific, the final model pays imbalanced attention to training samples. At the end of training, the recently exposed samples attract more attention and tend to have lower losses, while earlier samples are partially forgotten by the model and have higher losses. In short, training samples receive imbalanced attention from the model, which mainly depends on the time when the model last saw the training sample (i.e., the data order of the last training epoch). The underlying cause of this phenomenon is mini-batch gradient descent (LeCun et al., 2012), that is, we do not simultaneously use all training samples to train the model but divide them into mini-batches. Therefore, training samples do not get balanced training in each update step, so we name this problem imbalanced training. This problem is less severe in some tasks (e.g., image classification and text classification), but it has a significant impact on NMT as machine translation is a challenging task containing numerous translation rules, which are easily forgotten during the training process. Besides, we find that the imbalanced training problem is especially severe and non-negligible on low-resource machine translation. To demonstrate that the imbalanced training problem does affect the model accuracy, we first review a widely used technique called checkpoint averaging technique, which has proved to be effective in improving model accuracy but its internal mechanisms are not fully understood. We analyze it from the perspective of catastrophic forgetting and find that their success can be attributed to the alleviation of imbalanced training. We also notice that checkpoint averaging has some limitations, leaving room for further improvements. Inspired by the existing solution of checkpoint averaging which leverages the complementarity of checkpoints to improve model accuracy, we propose Complementary Online Knowledge Distillation (COKD) to address the problem of imbalanced training. As the model tends to forget knowledge learned from early samples, the main idea of COKD is to construct complementary teachers to re-provide this forgotten knowledge to the student. Specifically, we divide the training set into mutually exclusive subsets and reorganize them in a specific orders to train the student and teachers. We perform COKD in an online manner where teachers are on-the-fly updated to fit the need of student. When training the student on a subset, teachers can always provide the student with complementary knowledge on the other subsets, thereby preventing the student from catastrophic forgetting. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems. Especially, on the low-resource translation tasks that are severely affected by imbalanced training, our method is particularly effective and improves baseline models by about 2 BLEU points on average. In summary, our contribution is threefold: • We observe the problem of imbalanced training that training samples receive imbalanced attention from the model. We find that NMT, especially low-resource translation tasks, is seriously affected by imbalanced training. • We rethink the widely used checkpoint averaging technique and explain its success from the perspective of imbalanced training, which also demonstrates that the imbalanced training problem does affect the model accuracy. • We propose Complementary Online Knowledge Distillation for NMT, which can successfully alleviate the imbalanced training problem and improve the translation quality.","Can the problem of imbalanced training in neural machine translation models, leading to catastrophic forgetting of earlier training samples, be mitigated by using Complementary Online Knowledge Distillation (COKD) that employs dynamically updated teacher models to provide iterative complementary knowledge to the student model?",2.0,2.0,1.0
21,MarkupLM: Pre-training of Text and Markup Language for Visually Rich Document Understanding,"Junlong Li, Yiheng Xu, Lei Cui, and Furu Wei. 2022. MarkupLM: Pre-training of Text and Markup Language for Visually Rich Document Understanding. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6078–6087, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.420.pdf,https://aclanthology.org/2022.acl-long.420/,"Multimodal pre-training with text, layout, and image has made significant progress for Visually Rich Document Understanding (VRDU), especially the fixed-layout documents such as scanned document images. While, there are still a large number of digital documents where the layout information is not fixed and needs to be interactively and dynamically rendered for visualization, making existing layout-based pre-training approaches not easy to apply. In this paper, we propose MarkupLM for document understanding tasks with markup languages as the backbone, such as HTML/XMLbased documents, where text and markup information is jointly pre-trained. Experiment results show that the pre-trained MarkupLM significantly outperforms the existing strong baseline models on several document understanding tasks. The pre-trained model and code will be publicly available at https:// aka.ms/markuplm.","Multimodal pre-training with text, layout, and visual information has recently become the de facto approach (Xu et al., 2020, 2021a,b; Pramanik et al., 2020; Garncarek et al., 2021; Hong et al., 2021; Powalski et al., 2021; Wu et al., 2021; Li et al., 2021a,b; Appalaraju et al., 2021) in Visually-rich Document Understanding (VRDU) tasks. These multimodal models are usually pre-trained with the Transformer architecture (Vaswani et al., 2017) using large-scale unlabeled scanned document images (Lewis et al., 2006) or digital-born PDF files, followed by task-specific fine-tuning with relatively small-scale labeled training samples to achieve the state-of-the-art performance on a variety of document understanding tasks, including form understanding (Jaume et al., 2019; Xu et al., 2021b), receipt understanding (Huang et al., 2019; Park et al., 2019), complex document understanding (Gralinski et al. ´ , 2020), document type classification (Harley et al., 2015), and document visual question answering (Mathew et al., 2021), etc. Significant progress has been witnessed not only in research tasks within academia, but also in different real-world business applications such as finance, insurance, and many others. Visually rich documents can be generally divided into two categories. The first one is the fixed-layout documents such as scanned document images and digital-born PDF files, where the layout and style information is pre-rendered and independent of software, hardware, or operating system. This property makes existing layout-based pre-training approaches easily applicable to document understanding tasks. While, the second category is the markup-language-based documents such as HTML/XML, where the layout and style information needs to be interactively and dynamically rendered for visualization depending on the software, hardware, or operating system, which is shown in Figure 1. For markup-language-based documents, the 2D layout information does not exist in an explicit format but usually needs to be dynamically rendered for different devices, e.g., mobile/tablet/desktop, which makes current layoutbased pre-trained models hard to apply. Therefore, it is indispensable to leverage the markup structure into document-level pre-training for downstream VRDU tasks. To this end, we propose MarkupLM to jointly pre-train text and markup language in a single framework for markup-based VRDU tasks. Distinct from fixed-layout documents, markup-based documents provide another viewpoint for the document representation learning through markup structures because the 2D position information and document image information cannot be used straightforwardly during the pre-training. Instead, MarkupLM takes advantage of the tree-based markup structures to model the relationship among different units within the document. Similar to other multimodal pre-trained layout-based models, MarkupLM has four input embedding layers: (1) a text embedding that represents the token sequence information; (2) an XPath embedding that represents the markup tag sequence information from the root node to the current node; (3) a 1D position embedding that represents the sequence order information; (4) a segment embedding for downstream tasks. The overall architecture of MarkupLM is shown in Figure 2. The XPath embedding layer can be considered as the replacement of 2D position embeddings compared with the LayoutLM model family (Xu et al., 2020, 2021a,b). To effectively pre-train the MarkupLM, we use three pretraining strategies. The first is the Masked Markup Language Modeling (MMLM), which is used to jointly learn the contextual information of text and markups. The second is the Node Relationship Prediction (NRP), where the relationships are defined according to the hierarchy from the markup trees. The third is the Title-Page Matching (TPM), where the content within “<title> ... </title>” is randomly replaced by a title from another page to make the model learn whether they are correlated. In this way, MarkupLM can better understand the contextual information through both the language and markup hierarchy perspectives. We evaluate the MarkupLM models on the Web-based Structural Reading Comprehension (WebSRC) dataset (Chen et al., 2021) and the Structured Web Data Extraction (SWDE) dataset (Hao et al., 2011). Experiment results show that the pre-trained MarkupLM significantly outperforms the several strong baseline models in these tasks. The contributions of this paper are summarized as follows: • We propose MarkupLM to address the document representation learning where the layout information is not fixed and needs to be dynamically rendered. For the first time, the text and markup information is pre-trained in a single framework for the VRDU tasks. • MarkupLM integrates new input embedding layers and pre-training strategies, which have been confirmed effective on HTML-based downstream tasks. • The pre-trained MarkupLM models and codes for fine-tuning will be publicly available at https://aka.ms/markuplm.","Can the problem of understanding visually rich documents with dynamic layout information presented through markup languages like HTML/XML be effectively addressed by introducing MarkupLM, a model that jointly pre-trains on text and markup language information, and integrates markup structures into document-level pre-training to understand documents from both language and markup hierarchy perspectives?",2.0,2.0,1.0
22,Linguistically Regularized LSTM for Sentiment Classification,"Qiao Qian, Minlie Huang, Jinhao Lei, and Xiaoyan Zhu. 2017. Linguistically Regularized LSTM for Sentiment Classification. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1679–1689, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1154.pdf,https://aclanthology.org/P17-1154/,"This paper deals with sentence-level sentiment classification. Though a variety of neural network models have been proposed recently, however, previous models either depend on expensive phrase-level annotation, most of which has remarkably degraded performance when trained with only sentence-level annotation; or do not fully employ linguistic resources (e.g., sentiment lexicons, negation words, intensity words). In this paper, we propose simple models trained with sentence-level annotation, but also attempt to model the linguistic role of sentiment lexicons, negation words, and intensity words. Results show that our models are able to capture the linguistic role of sentiment words, negation words, and intensity words in sentiment expression.","Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with sentence-level annotation. Second, linguistic knowledge such as sentiment lexicon, negation words or negators (e.g., not, never), and intensity words or intensifiers (e.g., very, absolutely), has not been fully employed in neural models. The goal of this research is to developing simple sequence models but also attempts to fully employing linguistic resources to benefit sentiment classification. Firstly, we attempts to develop simple models that do not depend on parsing trees and do not require phrase-level annotation which is too expensive in real-world applications. Secondly, in order to obtain competitive performance, simple models can benefit from linguistic resources. Three types of resources will be addressed in this paper: sentiment lexicon, negation words, and intensity words. Sentiment lexicon offers the prior polarity of a word which can be useful in determining the sentiment polarity of longer texts such as phrases and sentences. Negators are typical sentiment shifters (Zhu et al., 2014), which constantly change the polarity of sentiment expression. Intensifiers change the valence degree of the modified text, which is important for fine-grained sentiment classification. In order to model the linguistic role of sentiment, negation, and intensity words, our central idea is to regularize the difference between the predicted sentiment distribution of the current position 1 , and that of the previous or next positions, in a sequence model. For instance, if the current position is a negator not, the negator should change the sentiment distribution of the next position accordingly. To summarize, our contributions lie in two folds: • We discover that modeling the linguistic role of sentiment, negation, and intensity words can enhance sentence-level sentiment classification. We address the issue by imposing linguistic-inspired regularizers on sequence LSTM models. • Unlike previous models that depend on parsing structures and expensive phrase-level annotation, our models are simple and efficient, but the performance is on a par with the stateof-the-art. The rest of the paper is organized as follows: In the following section, we survey related work. In Section 3, we briefly introduce the background of LSTM and bidirectional LSTM, and then describe in detail the lingistic regularizers for sentiment/negation/intensity words in Section 4. Experiments are presented in Section 5, and Conclusion follows in Section 6.","Can the problem of degraded performance in existing neural network models for sentence-level sentiment classification, due to dependency on phrase-level annotation and failure to fully utilize linguistic resources, be solved by developing simpler models that incorporate the linguistic roles of sentiment lexicons, negation words, and intensity words without depending on tree structures or expensive phrase-level annotations?",2.0,1.0,1.0
23,Neural Topic Modeling with Bidirectional Adversarial Training,"Rui Wang, Xuemeng Hu, Deyu Zhou, Yulan He, Yuxuan Xiong, Chenchen Ye, and Haiyang Xu. 2020. Neural Topic Modeling with Bidirectional Adversarial Training. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 340–350, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.32.pdf,https://aclanthology.org/2020.acl-main.32/,"Recent years have witnessed a surge of interests of using neural topic models for automatic topic extraction from text, since they avoid the complicated mathematical derivations for model inference as in traditional topic models such as Latent Dirichlet Allocation (LDA). However, these models either typically assume improper prior (e.g. Gaussian or Logistic Normal) over latent topic space or could not infer topic distribution for a given document. To address these limitations, we propose a neural topic modeling approach, called Bidirectional Adversarial Topic (BAT) model, which represents the first attempt of applying bidirectional adversarial training for neural topic modeling. The proposed BAT builds a twoway projection between the document-topic distribution and the document-word distribution. It uses a generator to capture the semantic patterns from texts and an encoder for topic inference. Furthermore, to incorporate word relatedness information, the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To verify the effectiveness of BAT and GaussianBAT, three benchmark corpora are used in our experiments. The experimental results show that BAT and Gaussian-BAT obtain more coherent topics, outperforming several competitive baselines. Moreover, when performing text clustering based on the extracted topics, our models outperform all the baselines, with more significant improvements achieved by Gaussian-BAT where an increase of near 6% is observed in accuracy.","Topic models have been extensively explored in the Natural Language Processing (NLP) community for unsupervised knowledge discovery. Latent Dirichlet Allocation (LDA) (Blei et al., 2003), the most popular topic model, has been extended (Lin and He, 2009; Zhou et al., 2014; Cheng et al., 2014) for various extraction tasks. Due to the difficulty of exact inference, most LDA variants require approximate inference methods, such as mean-field methods and collapsed Gibbs sampling. However, these approximate approaches have the drawback that small changes to the modeling assumptions result in a re-derivation of the inference algorithm, which can be mathematically arduous. One possible way in addressing this limitation is through neural topic models which employ blackbox inference mechanism with neural networks. Inspired by variational autoencoder (VAE) (Kingma and Welling, 2013), Srivastava and Sutton (2017) used the Logistic-Normal prior to mimic the simplex in latent topic space and proposed the Neural Variational LDA (NVLDA). Moreover, they replaced the word-level mixture in NVLDA with a weighted product of experts and proposed the ProdLDA (Srivastava and Sutton, 2017) to further enhance the topic quality. Although Srivastava and Sutton (2017) used the Logistic-Normal distribution to approximate the Dirichlet distribution, they are not exactly the same. An illustration of these two distributions is shown in Figure 1 in which the Logistic-Normal distribution does not exhibit multiple peaks at the vertices of the simplex as that in the Dirichlet distribution and as such, it is less capable to capture the multi-modality which is crucial in topic modeling (Wallach et al., 2009). To deal with the limitation, Wang et al. (2019a) proposed the Adversarialneural Topic Model (ATM) based on adversarial training, it uses a generator network to capture the semantic patterns lying behind the documents. However, given a document, ATM is not able to infer the document-topic distribution which is useful for downstream applications, such as text clustering. Moreover, ATM take the bag-of-words assumption and do not utilize any word relatedness information captured in word embeddings which have been proved to be crucial for better performance in many NLP tasks (Liu et al., 2018; Lei et al., 2018). To address these limitations, we model topics with Dirichlet prior and propose a novel Bidirectional Adversarial Topic model (BAT) based on bidirectional adversarial training. The proposed BAT employs a generator network to learn the projection function from randomly-sampled documenttopic distribution to document-word distribution. Moreover, an encoder network is used to learn the inverse projection, transforming a document-word distribution into a document-topic distribution. Different from traditional models that often resort to analytic approximations, BAT employs a discriminator which aims to discriminate between real distribution pair and fake distribution pair, thereby helps the networks (generator and encoder) to learn the two-way projections better. During the adversarial training phase, the supervision signal provided by the discriminator will guide the generator to construct a more realistic document and thus better capture the semantic patterns in text. Meanwhile, the encoder network is also guided to generate a more reasonable topic distribution conditioned on specific document-word distributions. Finally, to incorporate the word relatedness information captured by word embeddings, we extend the BAT by modeling each topic with a multivariate Gaussian in the generator and propose the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT). The main contributions of the paper are: • We propose a novel Bidirectional Adversarial Topic (BAT) model, which is, to our best knowledge, the first attempt of using bidirectional adversarial training in neural topic modeling; • We extend BAT to incorporate the word relatedness information into the modeling process and propose the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT); • Experimental results on three public datasets show that BAT and Gaussian-BAT outperform the state-of-the-art approaches in terms of topic coherence measures. The effectiveness of BAT and Gaussian-BAT is further verified in text clustering.",Can the limitations of traditional neural topic models be addressed by implementing a Bidirectional Adversarial Topic (BAT) model that utilizes bidirectional adversarial training and incorporates word relatedness information?,0.0,2.0,1.0
24,Neural Topic Modeling with Bidirectional Adversarial Training,"Rui Wang, Xuemeng Hu, Deyu Zhou, Yulan He, Yuxuan Xiong, Chenchen Ye, and Haiyang Xu. 2020. Neural Topic Modeling with Bidirectional Adversarial Training. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 340–350, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.32.pdf,https://aclanthology.org/2020.acl-main.32/,"Recent years have witnessed a surge of interests of using neural topic models for automatic topic extraction from text, since they avoid the complicated mathematical derivations for model inference as in traditional topic models such as Latent Dirichlet Allocation (LDA). However, these models either typically assume improper prior (e.g. Gaussian or Logistic Normal) over latent topic space or could not infer topic distribution for a given document. To address these limitations, we propose a neural topic modeling approach, called Bidirectional Adversarial Topic (BAT) model, which represents the first attempt of applying bidirectional adversarial training for neural topic modeling. The proposed BAT builds a twoway projection between the document-topic distribution and the document-word distribution. It uses a generator to capture the semantic patterns from texts and an encoder for topic inference. Furthermore, to incorporate word relatedness information, the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To verify the effectiveness of BAT and GaussianBAT, three benchmark corpora are used in our experiments. The experimental results show that BAT and Gaussian-BAT obtain more coherent topics, outperforming several competitive baselines. Moreover, when performing text clustering based on the extracted topics, our models outperform all the baselines, with more significant improvements achieved by Gaussian-BAT where an increase of near 6% is observed in accuracy.","Topic models have been extensively explored in the Natural Language Processing (NLP) community for unsupervised knowledge discovery. Latent Dirichlet Allocation (LDA) (Blei et al., 2003), the most popular topic model, has been extended (Lin and He, 2009; Zhou et al., 2014; Cheng et al., 2014) for various extraction tasks. Due to the difficulty of exact inference, most LDA variants require approximate inference methods, such as mean-field methods and collapsed Gibbs sampling. However, these approximate approaches have the drawback that small changes to the modeling assumptions result in a re-derivation of the inference algorithm, which can be mathematically arduous. One possible way in addressing this limitation is through neural topic models which employ blackbox inference mechanism with neural networks. Inspired by variational autoencoder (VAE) (Kingma and Welling, 2013), Srivastava and Sutton (2017) used the Logistic-Normal prior to mimic the simplex in latent topic space and proposed the Neural Variational LDA (NVLDA). Moreover, they replaced the word-level mixture in NVLDA with a weighted product of experts and proposed the ProdLDA (Srivastava and Sutton, 2017) to further enhance the topic quality. Although Srivastava and Sutton (2017) used the Logistic-Normal distribution to approximate the Dirichlet distribution, they are not exactly the same. An illustration of these two distributions is shown in Figure 1 in which the Logistic-Normal distribution does not exhibit multiple peaks at the vertices of the simplex as that in the Dirichlet distribution and as such, it is less capable to capture the multi-modality which is crucial in topic modeling (Wallach et al., 2009). To deal with the limitation, Wang et al. (2019a) proposed the Adversarialneural Topic Model (ATM) based on adversarial training, it uses a generator network to capture the semantic patterns lying behind the documents. However, given a document, ATM is not able to infer the document-topic distribution which is useful for downstream applications, such as text clustering. Moreover, ATM take the bag-of-words assumption and do not utilize any word relatedness information captured in word embeddings which have been proved to be crucial for better performance in many NLP tasks (Liu et al., 2018; Lei et al., 2018). To address these limitations, we model topics with Dirichlet prior and propose a novel Bidirectional Adversarial Topic model (BAT) based on bidirectional adversarial training. The proposed BAT employs a generator network to learn the projection function from randomly-sampled documenttopic distribution to document-word distribution. Moreover, an encoder network is used to learn the inverse projection, transforming a document-word distribution into a document-topic distribution. Different from traditional models that often resort to analytic approximations, BAT employs a discriminator which aims to discriminate between real distribution pair and fake distribution pair, thereby helps the networks (generator and encoder) to learn the two-way projections better. During the adversarial training phase, the supervision signal provided by the discriminator will guide the generator to construct a more realistic document and thus better capture the semantic patterns in text. Meanwhile, the encoder network is also guided to generate a more reasonable topic distribution conditioned on specific document-word distributions. Finally, to incorporate the word relatedness information captured by word embeddings, we extend the BAT by modeling each topic with a multivariate Gaussian in the generator and propose the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT). The main contributions of the paper are: • We propose a novel Bidirectional Adversarial Topic (BAT) model, which is, to our best knowledge, the first attempt of using bidirectional adversarial training in neural topic modeling; • We extend BAT to incorporate the word relatedness information into the modeling process and propose the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT); • Experimental results on three public datasets show that BAT and Gaussian-BAT outperform the state-of-the-art approaches in terms of topic coherence measures. The effectiveness of BAT and Gaussian-BAT is further verified in text clustering.",Can existing neural topic model limitations—specifically the assumption of improper priors and the inability to infer topic distribution for a given document—be overcome by introducing a new neural topic modeling approach utilizing bidirectional adversarial training and incorporating word relatedness information?,2.0,2.0,1.0
25,SimulSpeech: End-to-End Simultaneous Speech to Text Translation,"Yi Ren, Jinglin Liu, Xu Tan, Chen Zhang, Tao Qin, Zhou Zhao, and Tie-Yan Liu. 2020. SimulSpeech: End-to-End Simultaneous Speech to Text Translation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3787–3796, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.350.pdf,https://aclanthology.org/2020.acl-main.350/,"In this work, we develop SimulSpeech, an endto-end simultaneous speech to text translation system which translates speech in source language to text in target language concurrently. SimulSpeech consists of a speech encoder, a speech segmenter and a text decoder, where 1) the segmenter builds upon the encoder and leverages a connectionist temporal classification (CTC) loss to split the input streaming speech in real time, 2) the encoder-decoder attention adopts a wait-k strategy for simultaneous translation. SimulSpeech is more challenging than previous cascaded systems (with simultaneous automatic speech recognition (ASR) and simultaneous neural machine translation (NMT)). We introduce two novel knowledge distillation methods to ensure the performance: 1) Attention-level knowledge distillation transfers the knowledge from the multiplication of the attention matrices of simultaneous NMT and ASR models to help the training of the attention mechanism in SimulSpeech; 2) Data-level knowledge distillation transfers the knowledge from the full-sentence NMT model and also reduces the complexity of data distribution to help on the optimization of SimulSpeech. Experiments on MuST-C EnglishSpanish and English-German spoken language translation datasets show that SimulSpeech achieves reasonable BLEU scores and lower delay compared to full-sentence end-to-end speech to text translation (without simultaneous translation), and better performance than the two-stage cascaded simultaneous translation model in terms of BLEU scores and translation delay.","Simultaneous speech to text translation (Fugen ¨ et al., 2007; Oda et al., 2014; Dalvi et al., 2018), which translates source-language speech into targetlanguage text concurrently, is of great importance to the real-time understanding of spoken lectures or conversations and now widely used in many scenarios including live video streaming and international conferences. However, it is widely considered as one of the challenging tasks in machine translation domain because simultaneous speech to text translation has to understand the speech and trade off translation accuracy and delay. Conventional approaches to simultaneous speech to text translation (Fugen et al. ¨ , 2007; Oda et al., 2014; Dalvi et al., 2018) divide the translation process into two stages: simultaneous automatic speech recognition (ASR) (Rao et al., 2017) and simultaneous neural machine translation (NMT) (Gu et al., 2016), which cannot be optimized jointly and result in inferior accuracy, and also incurs more translation delay due to two stages. In this paper, we move a step further to translate the source speech to target text simultaneously, and develop SimulSpeech, an end-to-end simultaneous speech to text translation system. The SimulSpeech model consists of 1) a speech encoder where each speech frame can only see its previous frames to simulate streaming speech inputs; 2) a text decoder where the encoder-decoder attention follows the wait-k strategy (Ma et al., 2018) to decide when to listen and write on the source speech and target text respectively (see Figure 1); 3) a speech segmenter that builds upon the encoder and leverages a CTC loss to detect the word boundary, which is used to decide when to stop listening according to the wait-k strategy. Considering the difficulty of this task, we elaborately design two techniques to boost the performance of SimulSpeech: 1) attention-level knowledge distillation that transfers the knowledge from the multiplication of the attention matrices of simultaneous NMT and ASR model to SimulSpeech to help the training of its attention mechanism; 2) data-level knowledge distillation that transfers the knowledge from a full-sentence NMT model to SimulSpeech and also reduces the complexity of data distribution (Zhou et al., 2019) to help on the optimization of SimulSpeech model. Compared with the cascaded pipeline that trains simultaneous ASR and NMT models separately, SimulSpeech can alleviate the error propagation problem and optimize all model parameters jointly towards the end goal, as well as reduce the delay of simultaneous translation. Experiments on MuST-C1 English-Spanish and English-German spoken language translation datasets demonstrate that SimulSpeech: 1) achieves reasonable BLEU scores and lower delay compared to full-sentence end-to-end speech to text translation (without simultaneous translation), and 2) obtains better performance than the two-stage cascaded simultaneous translation model in terms of BLEU scores and translation delay.",Can simultaneous speech to text translation be improved by employing an end-to-end system with attention-level and data-level knowledge distillation methods?,1.0,1.0,1.0
26,SimulSpeech: End-to-End Simultaneous Speech to Text Translation,"Yi Ren, Jinglin Liu, Xu Tan, Chen Zhang, Tao Qin, Zhou Zhao, and Tie-Yan Liu. 2020. SimulSpeech: End-to-End Simultaneous Speech to Text Translation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3787–3796, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.350.pdf,https://aclanthology.org/2020.acl-main.350/,"In this work, we develop SimulSpeech, an endto-end simultaneous speech to text translation system which translates speech in source language to text in target language concurrently. SimulSpeech consists of a speech encoder, a speech segmenter and a text decoder, where 1) the segmenter builds upon the encoder and leverages a connectionist temporal classification (CTC) loss to split the input streaming speech in real time, 2) the encoder-decoder attention adopts a wait-k strategy for simultaneous translation. SimulSpeech is more challenging than previous cascaded systems (with simultaneous automatic speech recognition (ASR) and simultaneous neural machine translation (NMT)). We introduce two novel knowledge distillation methods to ensure the performance: 1) Attention-level knowledge distillation transfers the knowledge from the multiplication of the attention matrices of simultaneous NMT and ASR models to help the training of the attention mechanism in SimulSpeech; 2) Data-level knowledge distillation transfers the knowledge from the full-sentence NMT model and also reduces the complexity of data distribution to help on the optimization of SimulSpeech. Experiments on MuST-C EnglishSpanish and English-German spoken language translation datasets show that SimulSpeech achieves reasonable BLEU scores and lower delay compared to full-sentence end-to-end speech to text translation (without simultaneous translation), and better performance than the two-stage cascaded simultaneous translation model in terms of BLEU scores and translation delay.","Simultaneous speech to text translation (Fugen ¨ et al., 2007; Oda et al., 2014; Dalvi et al., 2018), which translates source-language speech into targetlanguage text concurrently, is of great importance to the real-time understanding of spoken lectures or conversations and now widely used in many scenarios including live video streaming and international conferences. However, it is widely considered as one of the challenging tasks in machine translation domain because simultaneous speech to text translation has to understand the speech and trade off translation accuracy and delay. Conventional approaches to simultaneous speech to text translation (Fugen et al. ¨ , 2007; Oda et al., 2014; Dalvi et al., 2018) divide the translation process into two stages: simultaneous automatic speech recognition (ASR) (Rao et al., 2017) and simultaneous neural machine translation (NMT) (Gu et al., 2016), which cannot be optimized jointly and result in inferior accuracy, and also incurs more translation delay due to two stages. In this paper, we move a step further to translate the source speech to target text simultaneously, and develop SimulSpeech, an end-to-end simultaneous speech to text translation system. The SimulSpeech model consists of 1) a speech encoder where each speech frame can only see its previous frames to simulate streaming speech inputs; 2) a text decoder where the encoder-decoder attention follows the wait-k strategy (Ma et al., 2018) to decide when to listen and write on the source speech and target text respectively (see Figure 1); 3) a speech segmenter that builds upon the encoder and leverages a CTC loss to detect the word boundary, which is used to decide when to stop listening according to the wait-k strategy. Considering the difficulty of this task, we elaborately design two techniques to boost the performance of SimulSpeech: 1) attention-level knowledge distillation that transfers the knowledge from the multiplication of the attention matrices of simultaneous NMT and ASR model to SimulSpeech to help the training of its attention mechanism; 2) data-level knowledge distillation that transfers the knowledge from a full-sentence NMT model to SimulSpeech and also reduces the complexity of data distribution (Zhou et al., 2019) to help on the optimization of SimulSpeech model. Compared with the cascaded pipeline that trains simultaneous ASR and NMT models separately, SimulSpeech can alleviate the error propagation problem and optimize all model parameters jointly towards the end goal, as well as reduce the delay of simultaneous translation. Experiments on MuST-C1 English-Spanish and English-German spoken language translation datasets demonstrate that SimulSpeech: 1) achieves reasonable BLEU scores and lower delay compared to full-sentence end-to-end speech to text translation (without simultaneous translation), and 2) obtains better performance than the two-stage cascaded simultaneous translation model in terms of BLEU scores and translation delay.","Can the challenge of balancing translation accuracy and delay in simultaneous speech to text translation be solved by developing and implementing SimulSpeech, an end-to-end system that incorporates a wait-k strategy and novel knowledge distillation techniques for real-time translation?",2.0,2.0,1.0
27,Improving Personalized Explanation Generation through Visualization,"Shijie Geng, Zuohui Fu, Yingqiang Ge, Lei Li, Gerard de Melo, and Yongfeng Zhang. 2022. Improving Personalized Explanation Generation through Visualization. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 244–255, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.20.pdf,https://aclanthology.org/2022.acl-long.20/,"In modern recommender systems, there are usually comments or reviews from users that justify their ratings for different items. Trained on such textual corpus, explainable recommendation models learn to discover user interests and generate personalized explanations. Though able to provide plausible explanations, existing models tend to generate repeated sentences for different items or empty sentences with insufficient details. This begs an interesting question: can we immerse the models in a multimodal environment to gain proper awareness of real-world concepts and alleviate above shortcomings? To this end, we propose a visuallyenhanced approach named METER with the help of visualization generation and text–image matching discrimination: the explainable recommendation model is encouraged to visualize what it refers to while incurring a penalty if the visualization is incongruent with the textual explanation. Experimental results and a manual assessment demonstrate that our approach can improve not only the text quality but also the diversity and explainability of the generated explanations.","Explainable recommender systems have recently attracted increasing attention both in industry and in the academic community. Such systems aim to provide high-quality recommendations and simultaneously generate explanations for the recommendations (Zhang et al., 2014; Zhang and Chen, 2020). The explanations not only can bridge the gap between how systems and users perceive the relevance of the recommended items, but also can serve to shed light on the recommendation decision process so as to avoid a black box. To provide appropriate explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causalitybased (Tan et al., 2021, 2022; Xu et al., 2021a,b) and neural-symbolic (Shi et al., 2020; Chen et al., 2021, 2022) approaches have been explored in recent years. Among them, PETER (Li et al., 2021a) is a representative sentence-based method that directly generates explanation sentences for given user–item pairs based on Personalized Transformer. While PETER outperforms previous methods in terms of both explainability and text quality metrics, it also suffers from several shortcomings: PETER tends to repeat certain universally applicable “safe” sentences as explanations (e.g., “the hotel is very nice”). For the 32,003 records in the test split of the TripAdvisor dataset by Li et al. (2020), PETER only generates around 8,100 unique sentences. The duplicate rate is close to 75%, while in reality, the duplicate rate of the TripAdvisor ground truth explanations is only 5.4%. In addition, such models are trained solely on a textual corpus, lacking real-world experiences to generate more authentic explanations, which may lead to empty sentences with insufficient details. Recently, Vokenization (Tan and Bansal, 2020) demonstrates that language understanding can be improved with token-level visual supervisions. This motivates us to consider enhancing text explanation generation with the aid of real-world images. In this paper, we present an entirely new form of explanation generation model that is immersed in a multimodal environment. The goal is to encourage it to perceive real-world signals and generate visually-enhanced explanations to better assist a user’s decision. Specifically, we propose the Multimodally-Enhanced Transformer for Explainable Recommendation (METER) approach for improved text explanations based on conditional image generation and text–image matching. Unlike traditional caption-to-image generation, our training sentences are explanations that are more comprehensive reviews based on user experiences rather than simple abstract descriptions of the image content. We adopt the generation order “rating → text → image” based on the consideration that the generation difficulty should gradually increase. With this approach, we seek to guide the model to understand real-world concepts regarding both item attributes and user interests (e.g., a spacious room or modern decoration). Furthermore, METER is encouraged to visualize what it is talking about for the given user–item pair and is penalized in case of a mismatch between the generated visualization and the textual explanation. This is in line with the spirit of the context token prediction module in Li et al. (2021a). While PETER only predicts text tokens as contextual information, our METER additionally generates visual tokens as a supplement. We claim that if a sentence contains more real-world concepts, it is easier to visualize it as an image with higher fidelity. To this end, we introduce a text–image matching discriminator based on contrastive learning which helps to improve both the diversity and faithfulness of the textual explanations. Beyond an auxiliary task for text generation, another advantage of METER is that the generated image visualizations may provide intuitive visual explanations in addition to rating scores and textual explanations. To empirically evaluate our framework, we conduct experiments and user studies on two realworld datasets in terms of diversity and faithfulness of text explanations, as well as consistency and quality of image visualizations. Our results reveal that using the proposed METER leads to improvements on text diversity and faithfulness, and that the generated image visualizations show high fidelity and good consistency. Overall, we make the following key contributions: • To the best of our knowledge, this is the first exploration of a multimodal explainable recommender system that jointly generates rating scores, textual explanations, and images. The system will also be promising in creative advertising applications. • By immersing the model into a multimodal environment, we help it explore the real-world concepts mentioned in the text explanations and in turn enable it to generate more diverse and faithful natural language rationales that are consistent with visual grounding. • Experiments and a user study on real-world datasets demonstrate the superiority of our approach over several strong baselines.","Can immersing explainable recommendation models in a multimodal environment, by integrating visualization generation and text-image matching, effectively address the shortcomings of repetitive and detail-lacking textual explanations, thereby improving the diversity, detail, and authenticity of the explanations?",2.0,2.0,1.0
28,Improving Personalized Explanation Generation through Visualization,"Shijie Geng, Zuohui Fu, Yingqiang Ge, Lei Li, Gerard de Melo, and Yongfeng Zhang. 2022. Improving Personalized Explanation Generation through Visualization. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 244–255, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.20.pdf,https://aclanthology.org/2022.acl-long.20/,"In modern recommender systems, there are usually comments or reviews from users that justify their ratings for different items. Trained on such textual corpus, explainable recommendation models learn to discover user interests and generate personalized explanations. Though able to provide plausible explanations, existing models tend to generate repeated sentences for different items or empty sentences with insufficient details. This begs an interesting question: can we immerse the models in a multimodal environment to gain proper awareness of real-world concepts and alleviate above shortcomings? To this end, we propose a visuallyenhanced approach named METER with the help of visualization generation and text–image matching discrimination: the explainable recommendation model is encouraged to visualize what it refers to while incurring a penalty if the visualization is incongruent with the textual explanation. Experimental results and a manual assessment demonstrate that our approach can improve not only the text quality but also the diversity and explainability of the generated explanations.","Explainable recommender systems have recently attracted increasing attention both in industry and in the academic community. Such systems aim to provide high-quality recommendations and simultaneously generate explanations for the recommendations (Zhang et al., 2014; Zhang and Chen, 2020). The explanations not only can bridge the gap between how systems and users perceive the relevance of the recommended items, but also can serve to shed light on the recommendation decision process so as to avoid a black box. To provide appropriate explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causalitybased (Tan et al., 2021, 2022; Xu et al., 2021a,b) and neural-symbolic (Shi et al., 2020; Chen et al., 2021, 2022) approaches have been explored in recent years. Among them, PETER (Li et al., 2021a) is a representative sentence-based method that directly generates explanation sentences for given user–item pairs based on Personalized Transformer. While PETER outperforms previous methods in terms of both explainability and text quality metrics, it also suffers from several shortcomings: PETER tends to repeat certain universally applicable “safe” sentences as explanations (e.g., “the hotel is very nice”). For the 32,003 records in the test split of the TripAdvisor dataset by Li et al. (2020), PETER only generates around 8,100 unique sentences. The duplicate rate is close to 75%, while in reality, the duplicate rate of the TripAdvisor ground truth explanations is only 5.4%. In addition, such models are trained solely on a textual corpus, lacking real-world experiences to generate more authentic explanations, which may lead to empty sentences with insufficient details. Recently, Vokenization (Tan and Bansal, 2020) demonstrates that language understanding can be improved with token-level visual supervisions. This motivates us to consider enhancing text explanation generation with the aid of real-world images. In this paper, we present an entirely new form of explanation generation model that is immersed in a multimodal environment. The goal is to encourage it to perceive real-world signals and generate visually-enhanced explanations to better assist a user’s decision. Specifically, we propose the Multimodally-Enhanced Transformer for Explainable Recommendation (METER) approach for improved text explanations based on conditional image generation and text–image matching. Unlike traditional caption-to-image generation, our training sentences are explanations that are more comprehensive reviews based on user experiences rather than simple abstract descriptions of the image content. We adopt the generation order “rating → text → image” based on the consideration that the generation difficulty should gradually increase. With this approach, we seek to guide the model to understand real-world concepts regarding both item attributes and user interests (e.g., a spacious room or modern decoration). Furthermore, METER is encouraged to visualize what it is talking about for the given user–item pair and is penalized in case of a mismatch between the generated visualization and the textual explanation. This is in line with the spirit of the context token prediction module in Li et al. (2021a). While PETER only predicts text tokens as contextual information, our METER additionally generates visual tokens as a supplement. We claim that if a sentence contains more real-world concepts, it is easier to visualize it as an image with higher fidelity. To this end, we introduce a text–image matching discriminator based on contrastive learning which helps to improve both the diversity and faithfulness of the textual explanations. Beyond an auxiliary task for text generation, another advantage of METER is that the generated image visualizations may provide intuitive visual explanations in addition to rating scores and textual explanations. To empirically evaluate our framework, we conduct experiments and user studies on two realworld datasets in terms of diversity and faithfulness of text explanations, as well as consistency and quality of image visualizations. Our results reveal that using the proposed METER leads to improvements on text diversity and faithfulness, and that the generated image visualizations show high fidelity and good consistency. Overall, we make the following key contributions: • To the best of our knowledge, this is the first exploration of a multimodal explainable recommender system that jointly generates rating scores, textual explanations, and images. The system will also be promising in creative advertising applications. • By immersing the model into a multimodal environment, we help it explore the real-world concepts mentioned in the text explanations and in turn enable it to generate more diverse and faithful natural language rationales that are consistent with visual grounding. • Experiments and a user study on real-world datasets demonstrate the superiority of our approach over several strong baselines.",Can the generation of repeated or empty sentences in explainable recommendation models be improved by immersing the models in a multimodal environment with the help of visualization generation and text–image matching discrimination?,2.0,2.0,1.0
29,Improving Personalized Explanation Generation through Visualization,"Shijie Geng, Zuohui Fu, Yingqiang Ge, Lei Li, Gerard de Melo, and Yongfeng Zhang. 2022. Improving Personalized Explanation Generation through Visualization. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 244–255, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.20.pdf,https://aclanthology.org/2022.acl-long.20/,"In modern recommender systems, there are usually comments or reviews from users that justify their ratings for different items. Trained on such textual corpus, explainable recommendation models learn to discover user interests and generate personalized explanations. Though able to provide plausible explanations, existing models tend to generate repeated sentences for different items or empty sentences with insufficient details. This begs an interesting question: can we immerse the models in a multimodal environment to gain proper awareness of real-world concepts and alleviate above shortcomings? To this end, we propose a visuallyenhanced approach named METER with the help of visualization generation and text–image matching discrimination: the explainable recommendation model is encouraged to visualize what it refers to while incurring a penalty if the visualization is incongruent with the textual explanation. Experimental results and a manual assessment demonstrate that our approach can improve not only the text quality but also the diversity and explainability of the generated explanations.","Explainable recommender systems have recently attracted increasing attention both in industry and in the academic community. Such systems aim to provide high-quality recommendations and simultaneously generate explanations for the recommendations (Zhang et al., 2014; Zhang and Chen, 2020). The explanations not only can bridge the gap between how systems and users perceive the relevance of the recommended items, but also can serve to shed light on the recommendation decision process so as to avoid a black box. To provide appropriate explanations, feature-based (Zhang et al., 2014), graph-based (Xian et al., 2019, 2020; Geng et al., 2022; Fu et al., 2020), sentence-based (Chen et al., 2019a; Li et al., 2020, 2021a, 2022), causalitybased (Tan et al., 2021, 2022; Xu et al., 2021a,b) and neural-symbolic (Shi et al., 2020; Chen et al., 2021, 2022) approaches have been explored in recent years. Among them, PETER (Li et al., 2021a) is a representative sentence-based method that directly generates explanation sentences for given user–item pairs based on Personalized Transformer. While PETER outperforms previous methods in terms of both explainability and text quality metrics, it also suffers from several shortcomings: PETER tends to repeat certain universally applicable “safe” sentences as explanations (e.g., “the hotel is very nice”). For the 32,003 records in the test split of the TripAdvisor dataset by Li et al. (2020), PETER only generates around 8,100 unique sentences. The duplicate rate is close to 75%, while in reality, the duplicate rate of the TripAdvisor ground truth explanations is only 5.4%. In addition, such models are trained solely on a textual corpus, lacking real-world experiences to generate more authentic explanations, which may lead to empty sentences with insufficient details. Recently, Vokenization (Tan and Bansal, 2020) demonstrates that language understanding can be improved with token-level visual supervisions. This motivates us to consider enhancing text explanation generation with the aid of real-world images. In this paper, we present an entirely new form of explanation generation model that is immersed in a multimodal environment. The goal is to encourage it to perceive real-world signals and generate visually-enhanced explanations to better assist a user’s decision. Specifically, we propose the Multimodally-Enhanced Transformer for Explainable Recommendation (METER) approach for improved text explanations based on conditional image generation and text–image matching. Unlike traditional caption-to-image generation, our training sentences are explanations that are more comprehensive reviews based on user experiences rather than simple abstract descriptions of the image content. We adopt the generation order “rating → text → image” based on the consideration that the generation difficulty should gradually increase. With this approach, we seek to guide the model to understand real-world concepts regarding both item attributes and user interests (e.g., a spacious room or modern decoration). Furthermore, METER is encouraged to visualize what it is talking about for the given user–item pair and is penalized in case of a mismatch between the generated visualization and the textual explanation. This is in line with the spirit of the context token prediction module in Li et al. (2021a). While PETER only predicts text tokens as contextual information, our METER additionally generates visual tokens as a supplement. We claim that if a sentence contains more real-world concepts, it is easier to visualize it as an image with higher fidelity. To this end, we introduce a text–image matching discriminator based on contrastive learning which helps to improve both the diversity and faithfulness of the textual explanations. Beyond an auxiliary task for text generation, another advantage of METER is that the generated image visualizations may provide intuitive visual explanations in addition to rating scores and textual explanations. To empirically evaluate our framework, we conduct experiments and user studies on two realworld datasets in terms of diversity and faithfulness of text explanations, as well as consistency and quality of image visualizations. Our results reveal that using the proposed METER leads to improvements on text diversity and faithfulness, and that the generated image visualizations show high fidelity and good consistency. Overall, we make the following key contributions: • To the best of our knowledge, this is the first exploration of a multimodal explainable recommender system that jointly generates rating scores, textual explanations, and images. The system will also be promising in creative advertising applications. • By immersing the model into a multimodal environment, we help it explore the real-world concepts mentioned in the text explanations and in turn enable it to generate more diverse and faithful natural language rationales that are consistent with visual grounding. • Experiments and a user study on real-world datasets demonstrate the superiority of our approach over several strong baselines.",Can existing explainable recommendation models' issues of generating repeated or insufficiently detailed explanations be addressed by immersing the models in a multimodal environment that employs visualization generation and text-image matching discrimination?,2.0,2.0,1.0
30,Value-Agnostic Conversational Semantic Parsing,"Emmanouil Antonios Platanios, Adam Pauls, Subhro Roy, Yuchen Zhang, Alexander Kyte, Alan Guo, Sam Thomson, Jayant Krishnamurthy, Jason Wolfe, Jacob Andreas, and Dan Klein. 2021. Value-Agnostic Conversational Semantic Parsing. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3666–3681, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.284.pdf,https://aclanthology.org/2021.acl-long.284/,"Conversational semantic parsers map user utterances to executable programs given dialogue histories composed of previous utterances, programs, and system responses. Existing parsers typically condition on rich representations of history that include the complete set of values and computations previously discussed. We propose a model that abstracts over values to focus prediction on type- and function-level context. This approach provides a compact encoding of dialogue histories and predicted programs, improving generalization and computational efficiency. Our model incorporates several other components, including an atomic span copy operation and structural enforcement of well-formedness constraints on predicted programs, that are particularly advantageous in the low-data regime. Trained on the SMCALFLOW and TREEDST datasets, our model outperforms prior work by 7.3% and 10.6% respectively in terms of absolute accuracy. Trained on only a thousand examples from each dataset, it outperforms strong baselines by 12.4% and 6.4%. These results indicate that simple representations are key to effective generalization in conversational semantic parsing.","Conversational semantic parsers, which translate natural language utterances into executable programs while incorporating conversational context, play an increasingly central role in systems for interactive data analysis (Yu et al., 2019), instruction following (Guu et al., 2017), and task-oriented dialogue (Zettlemoyer and Collins, 2009). An example of this task is shown in Figure 1. Typical models are based on an autoregressive sequence prediction approach, in which a detailed representation of the dialogue history is concatenated to the input sequence, and predictors condition on this sequence and all previously generated components of the output (Suhr et al., 2018). While this approach can capture arbitrary dependencies between inputs and outputs, it comes at the cost of sample- and computational inefficiency. We propose a new “value-agnostic” approach to contextual semantic parsing driven by type-based representations of the dialogue history and functionbased representations of the generated programs. Types and functions have long served as a foundation for formal reasoning about programs, but their use in neural semantic parsing has been limited, e.g., to constraining the hypothesis space (Krishnamurthy et al., 2017), guiding data augmentation (Jia and Liang, 2016), and coarsening in coarse-to-fine models (Dong and Lapata, 2018). We show that representing conversation histories and partial programs via the types and functions they contain enables fast, accurate, and sample-efficient contextual semantic parsing. We propose a neural encoder– decoder contextual semantic parsing model which, in contrast to prior work: 1. uses a compact yet informative representation of discourse context in the encoder that considers only the types of salient entities that were predicted by the model in previous turns or that appeared in the execution results of the predicted programs, and 2. conditions the decoder state on the sequence of function invocations so far, without conditioning on any concrete values passed as arguments to the functions. Our model substantially improves upon the best published results on the SMCALFLOW (Semantic Machines et al., 2020) and TREEDST (Cheng et al., 2020) conversational semantic parsing datasets, improving model performance by 7.3% and 10.6%, respectively, in terms of absolute accuracy. In further experiments aimed at quantifying sample efficiency, it improves accuracy by 12.4% and 6.4% respectively when trained on only a thousand examples from each dataset. Our model is also effective at non-contextual semantic parsing, matching state-ofthe-art results on the JOBS, GEOQUERY, and ATIS datasets (Dong and Lapata, 2016). This is achieved while also reducing the test time computational cost by a factor of 10 (from 80ms per utterance down to 8ms when running on the same machine; more details are provided in Appendix H), when compared to our fastest baseline, which makes it usable as part of a real-time conversational system. One conclusion from these experiments is that most semantic parses have structures that depend only weakly on the values that appear in the dialogue history or in the programs themselves. Our experiments find that hiding values alone results in a 2.6% accuracy improvement in the low-data regime. By treating types and functions, rather than values, as the main ingredients in learned representations for semantic parsing, we improve model accuracy and sample efficiency across a diverse set of language understanding problems, while also significantly reducing computational costs.","How does abstracting over values to focus on type- and function-level context in conversational semantic parsers affect model generalization, computational efficiency, and performance in low-data regimes compared to existing parsers that utilize detailed representations of dialogue history?",2.0,2.0,1.0
31,Value-Agnostic Conversational Semantic Parsing,"Emmanouil Antonios Platanios, Adam Pauls, Subhro Roy, Yuchen Zhang, Alexander Kyte, Alan Guo, Sam Thomson, Jayant Krishnamurthy, Jason Wolfe, Jacob Andreas, and Dan Klein. 2021. Value-Agnostic Conversational Semantic Parsing. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3666–3681, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.284.pdf,https://aclanthology.org/2021.acl-long.284/,"Conversational semantic parsers map user utterances to executable programs given dialogue histories composed of previous utterances, programs, and system responses. Existing parsers typically condition on rich representations of history that include the complete set of values and computations previously discussed. We propose a model that abstracts over values to focus prediction on type- and function-level context. This approach provides a compact encoding of dialogue histories and predicted programs, improving generalization and computational efficiency. Our model incorporates several other components, including an atomic span copy operation and structural enforcement of well-formedness constraints on predicted programs, that are particularly advantageous in the low-data regime. Trained on the SMCALFLOW and TREEDST datasets, our model outperforms prior work by 7.3% and 10.6% respectively in terms of absolute accuracy. Trained on only a thousand examples from each dataset, it outperforms strong baselines by 12.4% and 6.4%. These results indicate that simple representations are key to effective generalization in conversational semantic parsing.","Conversational semantic parsers, which translate natural language utterances into executable programs while incorporating conversational context, play an increasingly central role in systems for interactive data analysis (Yu et al., 2019), instruction following (Guu et al., 2017), and task-oriented dialogue (Zettlemoyer and Collins, 2009). An example of this task is shown in Figure 1. Typical models are based on an autoregressive sequence prediction approach, in which a detailed representation of the dialogue history is concatenated to the input sequence, and predictors condition on this sequence and all previously generated components of the output (Suhr et al., 2018). While this approach can capture arbitrary dependencies between inputs and outputs, it comes at the cost of sample- and computational inefficiency. We propose a new “value-agnostic” approach to contextual semantic parsing driven by type-based representations of the dialogue history and functionbased representations of the generated programs. Types and functions have long served as a foundation for formal reasoning about programs, but their use in neural semantic parsing has been limited, e.g., to constraining the hypothesis space (Krishnamurthy et al., 2017), guiding data augmentation (Jia and Liang, 2016), and coarsening in coarse-to-fine models (Dong and Lapata, 2018). We show that representing conversation histories and partial programs via the types and functions they contain enables fast, accurate, and sample-efficient contextual semantic parsing. We propose a neural encoder– decoder contextual semantic parsing model which, in contrast to prior work: 1. uses a compact yet informative representation of discourse context in the encoder that considers only the types of salient entities that were predicted by the model in previous turns or that appeared in the execution results of the predicted programs, and 2. conditions the decoder state on the sequence of function invocations so far, without conditioning on any concrete values passed as arguments to the functions. Our model substantially improves upon the best published results on the SMCALFLOW (Semantic Machines et al., 2020) and TREEDST (Cheng et al., 2020) conversational semantic parsing datasets, improving model performance by 7.3% and 10.6%, respectively, in terms of absolute accuracy. In further experiments aimed at quantifying sample efficiency, it improves accuracy by 12.4% and 6.4% respectively when trained on only a thousand examples from each dataset. Our model is also effective at non-contextual semantic parsing, matching state-ofthe-art results on the JOBS, GEOQUERY, and ATIS datasets (Dong and Lapata, 2016). This is achieved while also reducing the test time computational cost by a factor of 10 (from 80ms per utterance down to 8ms when running on the same machine; more details are provided in Appendix H), when compared to our fastest baseline, which makes it usable as part of a real-time conversational system. One conclusion from these experiments is that most semantic parses have structures that depend only weakly on the values that appear in the dialogue history or in the programs themselves. Our experiments find that hiding values alone results in a 2.6% accuracy improvement in the low-data regime. By treating types and functions, rather than values, as the main ingredients in learned representations for semantic parsing, we improve model accuracy and sample efficiency across a diverse set of language understanding problems, while also significantly reducing computational costs.",Can conversational semantic parsing be improved by using a value-agnostic approach focusing on types and functions rather than detailed representations of dialogue history?,0.0,2.0,0.0
32,Modeling Stance in Student Essays,"Isaac Persing and Vincent Ng. 2016. Modeling Stance in Student Essays. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2174–2184, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1205.pdf,https://aclanthology.org/P16-1205/,"Essay stance classification, the task of determining how much an essay’s author agrees with a given proposition, is an important yet under-investigated subtask in understanding an argumentative essay’s overall content. We introduce a new corpus of argumentative student essays annotated with stance information and propose a computational model for automatically predicting essay stance. In an evaluation on 826 essays, our approach significantly outperforms four baselines, one of which relies on features previously developed specifically for stance classification in student essays, yielding relative error reductions of at least 11.3% and 5.3%, in micro and macro F-score, respectively.","State-of-the-art automated essay scoring engines such as E-rater (Attali and Burstein, 2006) do not grade essay content, focusing instead on providing diagnostic trait feedback on categories such as grammar, usage, mechanics, style and organization. Hence, persuasiveness and other content-dependent dimensions of argumentative essay quality are largely ignored in existing automated essay scoring research. While full-fledged content-based essay scoring is still beyond the reach of state-of-the-art essay scoring engines, recent work has enabled us to move one step closer to this ambitious goal by analyzing essay content, attempting to determine the argumentative structure of student essays (Stab and Gurevych, 2014) and the persuasiveness of the arguments made in these essays (Persing and Ng, 2015). Stance classification is an important first step in determining how persuasive an argumentative student essay is because persuasiveness depends on how well the author argues w.r.t. the stance she takes using the supporting evidence she provides. For instance, if her stance is Agree Somewhat, a persuasive argument would involve explaining what reservations she has about the given proposition. As another example, an argumentative essay in which the author takes a neutral stance or the author presents evidence that does not support the stance she claims to take should receive a low persuasiveness score. Given the important role played by stance classification in determining an essay’s persuasiveness, our goal in this paper is to examine stance classification in argumentative student essays. While there is a large body of work on stance classification1 , stance classification in argumentative essays is largely under-investigated and is different from previous work in several respects. First, in automated essay grading, the majority of the essays to be assessed are written by students who are learners of English. Hence our stance classification task could be complicated by the authors’ lack of fluency in English. Second, essays are longer and more formally written than the text typically used in previous stance classification research (e.g., debate posts). In particular, a student essay writer typically expresses her stance on the essay’s topic in a thesis sentence/clause, while a debate post’s author may never even explicitly express her stance. Although the explicit expression of stance in essays seems to make our task easier, identifying stancetaking text in the midst of nonstancetaking sentences in a potentially long essay, as we will see, is by no means a trivial task. To our knowledge, the essay stance classification task has only been attempted by Faulkner (2014). However, the version of the task we address is different from his. First, Faulkner only performed two-class stance classification: while his corpus contains essays labeled with For (Agree), Against (Disagree), and Neither, he simplified the task by leaving out the arguably most difficult-to-identify stance, Neither. In contrast, we perform fine-grained stance classification, where we allow essay stance to take one of six values: Agree Strongly, Agree Somewhat, Neutral, Disagree Somewhat, Disagree Strongly, and Never Addressed, given the practical need to perform fine-grained stance classification in student essays, as discussed above. Second, given that many essay prompts are composed of multiple simpler propositions (e.g., the prompt “Most university degrees are theoretical and do not prepare students for the real world” has two parts, “Most university degrees are theoretical” and “Most university degrees do not prepare students for the real world.”), we manually split such prompts into prompt parts and determine the stance of the author w.r.t. each part, whereas Faulkner assigned an overall stance to a given prompt regardless of whether it is composed of multiple propositions. The distinction is important because an analysis of our annotations described in Section 2 shows that essay authors take different stances w.r.t. different prompt parts in 49% of essays, and in 39% of essays, authors even take stances with different polarities w.r.t. different prompt parts. In sum, our contributions in this paper are twofold. First, we propose a computational model for essay stance classification that outperforms four baselines, including our re-implementation of Faulkner’s approach. Second, in order to stimulate further research on this task, we make our annotations publicly available. Since progress on this task is hindered in part by the lack of a publicly annotated corpus, we believe that our data set will be a valuable resource for the NLP community.","What is the effectiveness of a computational model in automatically predicting the stance of argumentative student essays, as measured against multiple baselines and considering the nuanced diversity of stances that essays can embody?",1.0,1.0,1.0
33,Modeling Stance in Student Essays,"Isaac Persing and Vincent Ng. 2016. Modeling Stance in Student Essays. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2174–2184, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1205.pdf,https://aclanthology.org/P16-1205/,"Essay stance classification, the task of determining how much an essay’s author agrees with a given proposition, is an important yet under-investigated subtask in understanding an argumentative essay’s overall content. We introduce a new corpus of argumentative student essays annotated with stance information and propose a computational model for automatically predicting essay stance. In an evaluation on 826 essays, our approach significantly outperforms four baselines, one of which relies on features previously developed specifically for stance classification in student essays, yielding relative error reductions of at least 11.3% and 5.3%, in micro and macro F-score, respectively.","State-of-the-art automated essay scoring engines such as E-rater (Attali and Burstein, 2006) do not grade essay content, focusing instead on providing diagnostic trait feedback on categories such as grammar, usage, mechanics, style and organization. Hence, persuasiveness and other content-dependent dimensions of argumentative essay quality are largely ignored in existing automated essay scoring research. While full-fledged content-based essay scoring is still beyond the reach of state-of-the-art essay scoring engines, recent work has enabled us to move one step closer to this ambitious goal by analyzing essay content, attempting to determine the argumentative structure of student essays (Stab and Gurevych, 2014) and the persuasiveness of the arguments made in these essays (Persing and Ng, 2015). Stance classification is an important first step in determining how persuasive an argumentative student essay is because persuasiveness depends on how well the author argues w.r.t. the stance she takes using the supporting evidence she provides. For instance, if her stance is Agree Somewhat, a persuasive argument would involve explaining what reservations she has about the given proposition. As another example, an argumentative essay in which the author takes a neutral stance or the author presents evidence that does not support the stance she claims to take should receive a low persuasiveness score. Given the important role played by stance classification in determining an essay’s persuasiveness, our goal in this paper is to examine stance classification in argumentative student essays. While there is a large body of work on stance classification1 , stance classification in argumentative essays is largely under-investigated and is different from previous work in several respects. First, in automated essay grading, the majority of the essays to be assessed are written by students who are learners of English. Hence our stance classification task could be complicated by the authors’ lack of fluency in English. Second, essays are longer and more formally written than the text typically used in previous stance classification research (e.g., debate posts). In particular, a student essay writer typically expresses her stance on the essay’s topic in a thesis sentence/clause, while a debate post’s author may never even explicitly express her stance. Although the explicit expression of stance in essays seems to make our task easier, identifying stancetaking text in the midst of nonstancetaking sentences in a potentially long essay, as we will see, is by no means a trivial task. To our knowledge, the essay stance classification task has only been attempted by Faulkner (2014). However, the version of the task we address is different from his. First, Faulkner only performed two-class stance classification: while his corpus contains essays labeled with For (Agree), Against (Disagree), and Neither, he simplified the task by leaving out the arguably most difficult-to-identify stance, Neither. In contrast, we perform fine-grained stance classification, where we allow essay stance to take one of six values: Agree Strongly, Agree Somewhat, Neutral, Disagree Somewhat, Disagree Strongly, and Never Addressed, given the practical need to perform fine-grained stance classification in student essays, as discussed above. Second, given that many essay prompts are composed of multiple simpler propositions (e.g., the prompt “Most university degrees are theoretical and do not prepare students for the real world” has two parts, “Most university degrees are theoretical” and “Most university degrees do not prepare students for the real world.”), we manually split such prompts into prompt parts and determine the stance of the author w.r.t. each part, whereas Faulkner assigned an overall stance to a given prompt regardless of whether it is composed of multiple propositions. The distinction is important because an analysis of our annotations described in Section 2 shows that essay authors take different stances w.r.t. different prompt parts in 49% of essays, and in 39% of essays, authors even take stances with different polarities w.r.t. different prompt parts. In sum, our contributions in this paper are twofold. First, we propose a computational model for essay stance classification that outperforms four baselines, including our re-implementation of Faulkner’s approach. Second, in order to stimulate further research on this task, we make our annotations publicly available. Since progress on this task is hindered in part by the lack of a publicly annotated corpus, we believe that our data set will be a valuable resource for the NLP community.",Can essay stance classification in argumentative student essays be automated using a computational model?,0.0,0.0,1.0
34,Modeling Stance in Student Essays,"Isaac Persing and Vincent Ng. 2016. Modeling Stance in Student Essays. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2174–2184, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1205.pdf,https://aclanthology.org/P16-1205/,"Essay stance classification, the task of determining how much an essay’s author agrees with a given proposition, is an important yet under-investigated subtask in understanding an argumentative essay’s overall content. We introduce a new corpus of argumentative student essays annotated with stance information and propose a computational model for automatically predicting essay stance. In an evaluation on 826 essays, our approach significantly outperforms four baselines, one of which relies on features previously developed specifically for stance classification in student essays, yielding relative error reductions of at least 11.3% and 5.3%, in micro and macro F-score, respectively.","State-of-the-art automated essay scoring engines such as E-rater (Attali and Burstein, 2006) do not grade essay content, focusing instead on providing diagnostic trait feedback on categories such as grammar, usage, mechanics, style and organization. Hence, persuasiveness and other content-dependent dimensions of argumentative essay quality are largely ignored in existing automated essay scoring research. While full-fledged content-based essay scoring is still beyond the reach of state-of-the-art essay scoring engines, recent work has enabled us to move one step closer to this ambitious goal by analyzing essay content, attempting to determine the argumentative structure of student essays (Stab and Gurevych, 2014) and the persuasiveness of the arguments made in these essays (Persing and Ng, 2015). Stance classification is an important first step in determining how persuasive an argumentative student essay is because persuasiveness depends on how well the author argues w.r.t. the stance she takes using the supporting evidence she provides. For instance, if her stance is Agree Somewhat, a persuasive argument would involve explaining what reservations she has about the given proposition. As another example, an argumentative essay in which the author takes a neutral stance or the author presents evidence that does not support the stance she claims to take should receive a low persuasiveness score. Given the important role played by stance classification in determining an essay’s persuasiveness, our goal in this paper is to examine stance classification in argumentative student essays. While there is a large body of work on stance classification1 , stance classification in argumentative essays is largely under-investigated and is different from previous work in several respects. First, in automated essay grading, the majority of the essays to be assessed are written by students who are learners of English. Hence our stance classification task could be complicated by the authors’ lack of fluency in English. Second, essays are longer and more formally written than the text typically used in previous stance classification research (e.g., debate posts). In particular, a student essay writer typically expresses her stance on the essay’s topic in a thesis sentence/clause, while a debate post’s author may never even explicitly express her stance. Although the explicit expression of stance in essays seems to make our task easier, identifying stancetaking text in the midst of nonstancetaking sentences in a potentially long essay, as we will see, is by no means a trivial task. To our knowledge, the essay stance classification task has only been attempted by Faulkner (2014). However, the version of the task we address is different from his. First, Faulkner only performed two-class stance classification: while his corpus contains essays labeled with For (Agree), Against (Disagree), and Neither, he simplified the task by leaving out the arguably most difficult-to-identify stance, Neither. In contrast, we perform fine-grained stance classification, where we allow essay stance to take one of six values: Agree Strongly, Agree Somewhat, Neutral, Disagree Somewhat, Disagree Strongly, and Never Addressed, given the practical need to perform fine-grained stance classification in student essays, as discussed above. Second, given that many essay prompts are composed of multiple simpler propositions (e.g., the prompt “Most university degrees are theoretical and do not prepare students for the real world” has two parts, “Most university degrees are theoretical” and “Most university degrees do not prepare students for the real world.”), we manually split such prompts into prompt parts and determine the stance of the author w.r.t. each part, whereas Faulkner assigned an overall stance to a given prompt regardless of whether it is composed of multiple propositions. The distinction is important because an analysis of our annotations described in Section 2 shows that essay authors take different stances w.r.t. different prompt parts in 49% of essays, and in 39% of essays, authors even take stances with different polarities w.r.t. different prompt parts. In sum, our contributions in this paper are twofold. First, we propose a computational model for essay stance classification that outperforms four baselines, including our re-implementation of Faulkner’s approach. Second, in order to stimulate further research on this task, we make our annotations publicly available. Since progress on this task is hindered in part by the lack of a publicly annotated corpus, we believe that our data set will be a valuable resource for the NLP community.","Can the problem of accurately classifying essay stance in argumentative student essays, taking into account the nuanced and complex nature of such texts, be effectively addressed by introducing a new annotated corpus and a specifically designed computational model?",1.0,2.0,1.0
35,Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning,"Subhajit Chaudhury, Sarathkrishna Swaminathan, Daiki Kimura, Prithviraj Sen, Keerthiram Murugesan, Rosario Uceda-Sosa, Michiaki Tatsubori, Achille Fokoue, Pavan Kapanipathi, Asim Munawar, and Alexander Gray. 2023. Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6764–6776, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.373.pdf,https://aclanthology.org/2023.acl-long.373/,"Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games. On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks. This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data. Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies. Our experiments on established textbased game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions.","Text-based games (TBGs) (Côté et al., 2018) serve as popular sandbox environments for evaluating natural language-based reinforcement learning. The agent observes the state of the game in pure text and issues a textual command to interact with the environment. TBGs are partially observable where the full state of the world is hidden and action commands facilitate the agent to explore the unobserved parts of the environment. The reward signal from the environment is used to improve the agent’s policy and make progress in the game. Text-based games sit at the intersection of two research areas, i.e., language understanding and reinforcement learning. Existing RL agents for TBGs primarily use embeddings for observation as representations and are fed to an action scorer for predicting the next action (Narasimhan et al., 2015a; Yuan et al., 2019; He et al., 2016), ignoring the advances in language understanding. On the other hand, there has been a recent surge in neurosymbolic techniques, particularly those that use symbolic representations, for better language understanding (Lu et al., 2021; Kapanipathi et al., 2021) through reasoning. In light of exploring such advances for text-based reinforcement learning, this work proposes a neuro-symbolic approach. Our approach, named NESTA (NEuro Symbolic Textual Agent) is a modular approach comprising a generic semantic parser in combination with a symbolic rule induction system as shown in Figure 1. The semantic parser translates text into the form of symbolic triples. NESTA uses Abstract Meaning Representation (Banarescu et al., 2013) as the initial parse which is then transformed into triples. This symbolic representation is used by an adaptation of the Inductive Logic Programming (ILP) system using Logical Neural Networks (Riegel et al., 2020) for learning horn clauses as action rules. NESTA, in comparison to other end-to-end learning approaches, has the following advantages: (a) modular language understanding using pre-trained large language models enabling our system to leverage the advances in semantic parsing. While such modular semantic parsing-based techniques have been around for other NLP tasks such as reading comprehension (Mitra and Baral, 2016; Galitsky, 2020), knowledge base question answering (Kapanipathi et al., 2021), and natural language inference (Lien and Kouylekov, 2015), this work is the first to demonstrate the application for TBGs ; (b) learning symbolic rules for model-free RL using a neuro-symbolic framework facilitates inherent interpretability and generalizability to unseen situations (Ma et al., 2021; Jiang and Luo, 2019; Dong et al., 2019). The rules learned by NESTA are abstract and not specific to entities in the training data. These abstract action rules in policies for TBGs enable reasoning over unseen entities during training. Our main contributions in this work are: (1) We propose a novel and modular neuro-symbolic agent named NESTA. To the best of our knowledge, NESTA is the first to use a generic semantic parser with a rule learning system for TBGs, (2) Our empirical analysis of commonsense-aware textworld games shows that NESTA outperforms deep RL methods by a significant margin. We also show that NESTA has better sample efficiency compared to traditional text-based RL agents obtaining better test performance with up to 5× lesser training interactions, and (3) Our method produces interpretable abstract rules from the rule induction system.",Can the problem of generalization and interpretability in reinforcement learning for text-based games be solved by a modular neuro-symbolic approach that combines a generic semantic parser with a rule induction system?,2.0,2.0,1.0
36,Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning,"Subhajit Chaudhury, Sarathkrishna Swaminathan, Daiki Kimura, Prithviraj Sen, Keerthiram Murugesan, Rosario Uceda-Sosa, Michiaki Tatsubori, Achille Fokoue, Pavan Kapanipathi, Asim Munawar, and Alexander Gray. 2023. Learning Symbolic Rules over Abstract Meaning Representations for Textual Reinforcement Learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6764–6776, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.373.pdf,https://aclanthology.org/2023.acl-long.373/,"Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games. On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks. This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data. Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies. Our experiments on established textbased game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions.","Text-based games (TBGs) (Côté et al., 2018) serve as popular sandbox environments for evaluating natural language-based reinforcement learning. The agent observes the state of the game in pure text and issues a textual command to interact with the environment. TBGs are partially observable where the full state of the world is hidden and action commands facilitate the agent to explore the unobserved parts of the environment. The reward signal from the environment is used to improve the agent’s policy and make progress in the game. Text-based games sit at the intersection of two research areas, i.e., language understanding and reinforcement learning. Existing RL agents for TBGs primarily use embeddings for observation as representations and are fed to an action scorer for predicting the next action (Narasimhan et al., 2015a; Yuan et al., 2019; He et al., 2016), ignoring the advances in language understanding. On the other hand, there has been a recent surge in neurosymbolic techniques, particularly those that use symbolic representations, for better language understanding (Lu et al., 2021; Kapanipathi et al., 2021) through reasoning. In light of exploring such advances for text-based reinforcement learning, this work proposes a neuro-symbolic approach. Our approach, named NESTA (NEuro Symbolic Textual Agent) is a modular approach comprising a generic semantic parser in combination with a symbolic rule induction system as shown in Figure 1. The semantic parser translates text into the form of symbolic triples. NESTA uses Abstract Meaning Representation (Banarescu et al., 2013) as the initial parse which is then transformed into triples. This symbolic representation is used by an adaptation of the Inductive Logic Programming (ILP) system using Logical Neural Networks (Riegel et al., 2020) for learning horn clauses as action rules. NESTA, in comparison to other end-to-end learning approaches, has the following advantages: (a) modular language understanding using pre-trained large language models enabling our system to leverage the advances in semantic parsing. While such modular semantic parsing-based techniques have been around for other NLP tasks such as reading comprehension (Mitra and Baral, 2016; Galitsky, 2020), knowledge base question answering (Kapanipathi et al., 2021), and natural language inference (Lien and Kouylekov, 2015), this work is the first to demonstrate the application for TBGs ; (b) learning symbolic rules for model-free RL using a neuro-symbolic framework facilitates inherent interpretability and generalizability to unseen situations (Ma et al., 2021; Jiang and Luo, 2019; Dong et al., 2019). The rules learned by NESTA are abstract and not specific to entities in the training data. These abstract action rules in policies for TBGs enable reasoning over unseen entities during training. Our main contributions in this work are: (1) We propose a novel and modular neuro-symbolic agent named NESTA. To the best of our knowledge, NESTA is the first to use a generic semantic parser with a rule learning system for TBGs, (2) Our empirical analysis of commonsense-aware textworld games shows that NESTA outperforms deep RL methods by a significant margin. We also show that NESTA has better sample efficiency compared to traditional text-based RL agents obtaining better test performance with up to 5× lesser training interactions, and (3) Our method produces interpretable abstract rules from the rule induction system.",Can the limited generalization and interpretability of neural network-based models for text-based reinforcement learning agents be overcome by the development of a neuro-symbolic agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies?,2.0,2.0,1.0
37,Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs,"Chao Shang, Guangtao Wang, Peng Qi, and Jing Huang. 2022. Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8017–8026, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.552.pdf,https://aclanthology.org/2022.acl-long.552/,"Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., “Who was the president of the US before Obama?”). These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., “Obama” instead of 2000); 2) subtle lexical differences in time relations (e.g., “before” vs “after”); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems. TSQA features a timestamp estimation module to infer the unwritten timestamp from the question. We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on. With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG.","Temporal knowledge graphs (KGs) record the relations between entities and the timestamp or time period when such relation hold, e.g., in the form of a quadruple: (Franklin D. Roosevelt, position held, President of USA, [1933, 1945]). This makes them a perfect source of knowledge to answer questions that involve knowledge of when certain events occurred as well as how they are related temporally (see Figure 1 for an example). Unlike question answering (QA) over non-temporal KGs that is mainly concerned with relational inference, a core challenge in temporal KGQA is correctly identifying the time of reference mentioned explicitly or implicitly in the question, and locating relevant facts by jointly reasoning over relations and timestamps. Inspired by work on relational KGQA (Huang et al., 2019; Saxena et al., 2020), where knowledge graph embeddings (Dasgupta et al., 2018; García-Durán et al., 2018; Goel et al., 2020; Wu et al., 2020; Lacroix et al., 2020) learned independently of question answering are used as input to KGQA models, previous work (Saxena et al., 2021) employs temporal KG embeddings to attack the problem of temporal KGQA. Despite its relative success on simple temporal questions that directly queries facts in the KG with one out of the four facts left as the answer (e.g., “When was Franklin D. Roosevelt the President of USA?” or “What position did Franklin D. Roosevelt hold between 1933 and 1945?”), this approach still struggles to handle questions that require multiple steps of relationaltemporal reasoning (e.g., the example in Figure1). We identify three main challenges that hinder further progress on temporal KGQA. Firstly, complex temporal questions often require inferring the correct point of reference in time, which is not considered by previous work. For instance, to correctly answer the question in Figure 1, it is crucial that we first identify that World War II took place between 1939 and 1945, and look for entities with the desired relation with President of USA in the time interval specified by these times. Secondly, unlike entity relations, which are usually expressed in natural language with a handful of content words that correspond well with their recorded relations in KGs (e.g., “What position did ... hold ...” vs the “position held” relation), temporal relations often involve just one or two prepositions (e.g., “before” or “during”) and are expressed only implicitly in temporal KGs (e.g., nowhere is it clearly stated that 1931 is earlier than, or before, 1934, by a gap of 3 years). As a result, a small lexical change can drastically alter the temporal relation expressed by the question, and therefore the answer set. Thirdly, previous work on temporal KGQA build on temporal KG embeddings, where each timestamp is assigned a randomly initialized vector representation that is jointly optimized with entity and relation representations to reconstruct quadruples in the KG from embeddings. While sound as a standalone method for encoding knowledge in temporal KGs, this approach does not guarantee that the learned timestamp representations can recover implicit temporal relations like temporal orders or distance, which are crucial for temporal KGQA. In this paper, we propose a time-sensitive question answering framework (TSQA) to address these challenges. We first equip the temporal KGQA model with a time estimation module that infers the unstated timestamps from questions as the first step of reasoning, and feed the result into relational inference as a reference timestamp. Even without explicit training data for this module, the explicit factorization of the problem yields significant improvement over previous work on complex questions that require reasoning over multiple temporal quadruples. To improve the sensitivity of our question encoder to time relation words, we also propose auxiliary contrastive losses that contrast the answer prediction and time estimation for questions that differ only by the time relation word (e.g., “before” vs “after”). By leveraging the mutual exclusiveness of answers and the prior knowledge regarding potential time estimates from different time relation words, we observe further improvements in model performance on complex questions. Next, to learn temporal KG embeddings with prior knowledge of temporal order and distance built in, we introduce an auxiliary loss of time-order classification between each pair of timestamp embeddings. As a result, the knowledge in the temporal KG can be distilled into the entity, relation, and timestamp embeddings where the timestamp embeddings can naturally recover order and distance information between the underlying timestamps, thus improving the performance of temporal KGQA where such information is crucial. Finally, we enhance TSQA with KG-based approaches to narrow the search space to speed up model training and inference, as well as reduce the number of false positives in model prediction. As a result, TSQA outperforms the previous state of the art on the CRONQUESTIONS benchmark (Saxena et al., 2021) by a large margin. To summarize, our contributions in this paper are: a) we propose a time-sensitive question answering framework (TSQA) that performs time estimation for complex temporal answers; b) we present contrastive losses that improve model sensitivity to time relation words in the question; c) we propose a time-sensitive temporal KG embedding approach that benefits temporal KGQA; d) with the help of KG-based pruning technique, our TSQA model outperforms the previous state of the art by a large margin.","How can a time-sensitive question answering framework effectively address the challenges of inferring unstated timestamps, interpreting subtle lexical differences in time relations, and encoding temporal order in temporal knowledge graph embeddings to improve the accuracy of answering complex temporal questions?",2.0,1.0,1.0
38,Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs,"Chao Shang, Guangtao Wang, Peng Qi, and Jing Huang. 2022. Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8017–8026, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.552.pdf,https://aclanthology.org/2022.acl-long.552/,"Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., “Who was the president of the US before Obama?”). These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., “Obama” instead of 2000); 2) subtle lexical differences in time relations (e.g., “before” vs “after”); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems. TSQA features a timestamp estimation module to infer the unwritten timestamp from the question. We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on. With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG.","Temporal knowledge graphs (KGs) record the relations between entities and the timestamp or time period when such relation hold, e.g., in the form of a quadruple: (Franklin D. Roosevelt, position held, President of USA, [1933, 1945]). This makes them a perfect source of knowledge to answer questions that involve knowledge of when certain events occurred as well as how they are related temporally (see Figure 1 for an example). Unlike question answering (QA) over non-temporal KGs that is mainly concerned with relational inference, a core challenge in temporal KGQA is correctly identifying the time of reference mentioned explicitly or implicitly in the question, and locating relevant facts by jointly reasoning over relations and timestamps. Inspired by work on relational KGQA (Huang et al., 2019; Saxena et al., 2020), where knowledge graph embeddings (Dasgupta et al., 2018; García-Durán et al., 2018; Goel et al., 2020; Wu et al., 2020; Lacroix et al., 2020) learned independently of question answering are used as input to KGQA models, previous work (Saxena et al., 2021) employs temporal KG embeddings to attack the problem of temporal KGQA. Despite its relative success on simple temporal questions that directly queries facts in the KG with one out of the four facts left as the answer (e.g., “When was Franklin D. Roosevelt the President of USA?” or “What position did Franklin D. Roosevelt hold between 1933 and 1945?”), this approach still struggles to handle questions that require multiple steps of relationaltemporal reasoning (e.g., the example in Figure1). We identify three main challenges that hinder further progress on temporal KGQA. Firstly, complex temporal questions often require inferring the correct point of reference in time, which is not considered by previous work. For instance, to correctly answer the question in Figure 1, it is crucial that we first identify that World War II took place between 1939 and 1945, and look for entities with the desired relation with President of USA in the time interval specified by these times. Secondly, unlike entity relations, which are usually expressed in natural language with a handful of content words that correspond well with their recorded relations in KGs (e.g., “What position did ... hold ...” vs the “position held” relation), temporal relations often involve just one or two prepositions (e.g., “before” or “during”) and are expressed only implicitly in temporal KGs (e.g., nowhere is it clearly stated that 1931 is earlier than, or before, 1934, by a gap of 3 years). As a result, a small lexical change can drastically alter the temporal relation expressed by the question, and therefore the answer set. Thirdly, previous work on temporal KGQA build on temporal KG embeddings, where each timestamp is assigned a randomly initialized vector representation that is jointly optimized with entity and relation representations to reconstruct quadruples in the KG from embeddings. While sound as a standalone method for encoding knowledge in temporal KGs, this approach does not guarantee that the learned timestamp representations can recover implicit temporal relations like temporal orders or distance, which are crucial for temporal KGQA. In this paper, we propose a time-sensitive question answering framework (TSQA) to address these challenges. We first equip the temporal KGQA model with a time estimation module that infers the unstated timestamps from questions as the first step of reasoning, and feed the result into relational inference as a reference timestamp. Even without explicit training data for this module, the explicit factorization of the problem yields significant improvement over previous work on complex questions that require reasoning over multiple temporal quadruples. To improve the sensitivity of our question encoder to time relation words, we also propose auxiliary contrastive losses that contrast the answer prediction and time estimation for questions that differ only by the time relation word (e.g., “before” vs “after”). By leveraging the mutual exclusiveness of answers and the prior knowledge regarding potential time estimates from different time relation words, we observe further improvements in model performance on complex questions. Next, to learn temporal KG embeddings with prior knowledge of temporal order and distance built in, we introduce an auxiliary loss of time-order classification between each pair of timestamp embeddings. As a result, the knowledge in the temporal KG can be distilled into the entity, relation, and timestamp embeddings where the timestamp embeddings can naturally recover order and distance information between the underlying timestamps, thus improving the performance of temporal KGQA where such information is crucial. Finally, we enhance TSQA with KG-based approaches to narrow the search space to speed up model training and inference, as well as reduce the number of false positives in model prediction. As a result, TSQA outperforms the previous state of the art on the CRONQUESTIONS benchmark (Saxena et al., 2021) by a large margin. To summarize, our contributions in this paper are: a) we propose a time-sensitive question answering framework (TSQA) that performs time estimation for complex temporal answers; b) we present contrastive losses that improve model sensitivity to time relation words in the question; c) we propose a time-sensitive temporal KG embedding approach that benefits temporal KGQA; d) with the help of KG-based pruning technique, our TSQA model outperforms the previous state of the art by a large margin.","Can the challenges in question answering over temporal knowledge graphs be overcome by employing a time-sensitive question answering framework (TSQA) that incorporates time estimation, contrastive losses for time relation sensitivity, and time-sensitive knowledge graph embeddings?",0.0,2.0,1.0
39,Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs,"Chao Shang, Guangtao Wang, Peng Qi, and Jing Huang. 2022. Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8017–8026, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.552.pdf,https://aclanthology.org/2022.acl-long.552/,"Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., “Who was the president of the US before Obama?”). These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., “Obama” instead of 2000); 2) subtle lexical differences in time relations (e.g., “before” vs “after”); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems. TSQA features a timestamp estimation module to infer the unwritten timestamp from the question. We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on. With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG.","Temporal knowledge graphs (KGs) record the relations between entities and the timestamp or time period when such relation hold, e.g., in the form of a quadruple: (Franklin D. Roosevelt, position held, President of USA, [1933, 1945]). This makes them a perfect source of knowledge to answer questions that involve knowledge of when certain events occurred as well as how they are related temporally (see Figure 1 for an example). Unlike question answering (QA) over non-temporal KGs that is mainly concerned with relational inference, a core challenge in temporal KGQA is correctly identifying the time of reference mentioned explicitly or implicitly in the question, and locating relevant facts by jointly reasoning over relations and timestamps. Inspired by work on relational KGQA (Huang et al., 2019; Saxena et al., 2020), where knowledge graph embeddings (Dasgupta et al., 2018; García-Durán et al., 2018; Goel et al., 2020; Wu et al., 2020; Lacroix et al., 2020) learned independently of question answering are used as input to KGQA models, previous work (Saxena et al., 2021) employs temporal KG embeddings to attack the problem of temporal KGQA. Despite its relative success on simple temporal questions that directly queries facts in the KG with one out of the four facts left as the answer (e.g., “When was Franklin D. Roosevelt the President of USA?” or “What position did Franklin D. Roosevelt hold between 1933 and 1945?”), this approach still struggles to handle questions that require multiple steps of relationaltemporal reasoning (e.g., the example in Figure1). We identify three main challenges that hinder further progress on temporal KGQA. Firstly, complex temporal questions often require inferring the correct point of reference in time, which is not considered by previous work. For instance, to correctly answer the question in Figure 1, it is crucial that we first identify that World War II took place between 1939 and 1945, and look for entities with the desired relation with President of USA in the time interval specified by these times. Secondly, unlike entity relations, which are usually expressed in natural language with a handful of content words that correspond well with their recorded relations in KGs (e.g., “What position did ... hold ...” vs the “position held” relation), temporal relations often involve just one or two prepositions (e.g., “before” or “during”) and are expressed only implicitly in temporal KGs (e.g., nowhere is it clearly stated that 1931 is earlier than, or before, 1934, by a gap of 3 years). As a result, a small lexical change can drastically alter the temporal relation expressed by the question, and therefore the answer set. Thirdly, previous work on temporal KGQA build on temporal KG embeddings, where each timestamp is assigned a randomly initialized vector representation that is jointly optimized with entity and relation representations to reconstruct quadruples in the KG from embeddings. While sound as a standalone method for encoding knowledge in temporal KGs, this approach does not guarantee that the learned timestamp representations can recover implicit temporal relations like temporal orders or distance, which are crucial for temporal KGQA. In this paper, we propose a time-sensitive question answering framework (TSQA) to address these challenges. We first equip the temporal KGQA model with a time estimation module that infers the unstated timestamps from questions as the first step of reasoning, and feed the result into relational inference as a reference timestamp. Even without explicit training data for this module, the explicit factorization of the problem yields significant improvement over previous work on complex questions that require reasoning over multiple temporal quadruples. To improve the sensitivity of our question encoder to time relation words, we also propose auxiliary contrastive losses that contrast the answer prediction and time estimation for questions that differ only by the time relation word (e.g., “before” vs “after”). By leveraging the mutual exclusiveness of answers and the prior knowledge regarding potential time estimates from different time relation words, we observe further improvements in model performance on complex questions. Next, to learn temporal KG embeddings with prior knowledge of temporal order and distance built in, we introduce an auxiliary loss of time-order classification between each pair of timestamp embeddings. As a result, the knowledge in the temporal KG can be distilled into the entity, relation, and timestamp embeddings where the timestamp embeddings can naturally recover order and distance information between the underlying timestamps, thus improving the performance of temporal KGQA where such information is crucial. Finally, we enhance TSQA with KG-based approaches to narrow the search space to speed up model training and inference, as well as reduce the number of false positives in model prediction. As a result, TSQA outperforms the previous state of the art on the CRONQUESTIONS benchmark (Saxena et al., 2021) by a large margin. To summarize, our contributions in this paper are: a) we propose a time-sensitive question answering framework (TSQA) that performs time estimation for complex temporal answers; b) we present contrastive losses that improve model sensitivity to time relation words in the question; c) we propose a time-sensitive temporal KG embedding approach that benefits temporal KGQA; d) with the help of KG-based pruning technique, our TSQA model outperforms the previous state of the art by a large margin.","Can the problem of inefficient question answering over temporal knowledge graphs, due to the lack of precise timestamps, subtle lexical differences in time relations, and the absence of consideration for temporal order in existing solutions, be solved by the proposed time-sensitive question answering (TSQA) framework that includes a timestamp estimation module, a time-sensitive KG encoder, and answer search space reduction techniques?",2.0,2.0,1.0
40,Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks,"Weicheng Ma, Kai Zhang, Renze Lou, Lili Wang, and Soroush Vosoughi. 2021. Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1956–1966, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.152.pdf,https://aclanthology.org/2021.acl-long.152/,"This paper studies the relative importance of attention heads in Transformer-based models to aid their interpretability in cross-lingual and multi-lingual tasks. Prior research has found that only a few attention heads are important in each mono-lingual Natural Language Processing (NLP) task and pruning the remaining heads leads to comparable or improved performance of the model. However, the impact of pruning attention heads is not yet clear in cross-lingual and multi-lingual tasks. Through extensive experiments, we show that (1) pruning a number of attention heads in a multilingual Transformer-based model has, in general, positive effects on its performance in cross-lingual and multi-lingual tasks and (2) the attention heads to be pruned can be ranked using gradients and identified with a few trial experiments. Our experiments focus on sequence labeling tasks, with potential applicability on other cross-lingual and multi-lingual tasks. For comprehensiveness, we examine two pre-trained multi-lingual models, namely multi-lingual BERT (mBERT) and XLM-R, on three tasks across 9 languages each. We also discuss the validity of our findings and their extensibility to truly resource-scarce languages and other task settings.","Prior research on mono-lingual Transformer-based (Vaswani et al., 2017) models reveals that a subset of their attention heads makes key contributions to each task, and the models perform comparably well (Voita et al., 2019; Michel et al., 2019) or even better (Kovaleva et al., 2019) with the remaining heads pruned 1 . While multi-lingual Transformer-based models, e.g. mBERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020), are widely applied in cross-lingual and multi-lingual NLP tasks 2 (Wang et al., 2019; Keung et al., 2019; Eskander et al., 2020), no attempt has been made to extend the findings on the aforementioned mono-lingual research to this context. In this paper, we explore the roles of attention heads in cross-lingual and multi-lingual tasks for two reasons. First, better understanding and interpretability of Transformerbased models leads to efficient model designs and parameter tuning. Second, head-pruning makes Transformer-based models more applicable to truly resource-scarce languages if it does not negatively affect model performance significantly. The biggest challenge we face when studying the roles of attention heads in cross-lingual and multi-lingual tasks is locating the heads to prune. Existing research has shown that each attention head is specialized to extract a collection of linguistic features, e.g., the middle layers of BERT mainly extract syntactic features (Vig and Belinkov, 2019; Hewitt and Manning, 2019) and the fourth head on the fifth layer of BERT greatly contributes to the coreference resolution task (Clark et al., 2019). Thus, we hypothesize that important feature extractors for a task should be shared across languages and the remaining heads can be pruned. We evaluate two approaches used to rank attention heads, the first of which is layer-wise relevance propagation (LRP, Ding et al. (2017)). Voita et al. (2019) interpreted the adaptation of LRP in Transformerbased models on machine translation. Motivated by Feng et al. (2018) and Serrano and Smith (2019), we design a second ranking method based on gradients since the gradients on each attention head reflect its contribution to the predictions. We study the effects of pruning attention heads on three sequence labeling tasks, namely part-ofspeech tagging (POS), named entity recognition (NER), and slot filling (SF). We focus on sequence labeling tasks since they are more difficult to annotate than document- or sentence-level classification datasets and require more treatment in crosslingual and multi-lingual research. We choose POS and NER datasets in 9 languages, where English (EN), Chinese (ZH), and Arabic (AR) are candidate source languages. The MultiAtis++ corpus (Xu et al., 2020) is used in the SF evaluations with EN as the source language. We do not include syntactic chunking and semantic role labeling tasks due to lack of availability of manually written and annotated corpora. In these experiments, we rank attention heads based only on the source language(s) to ensure the extensibility of the learned knowledge to cross-lingual tasks and resource-poor languages. In our preliminary experiments comparing the gradient-based method and LRP, the average F1 score improvements on NER with mBERT are 0.69 (cross-lingual) and 0.24 (multi-lingual) for LRP and 0.81 (cross-lingual) and 0.31 (multi-lingual) for the gradient-based method, though both methods rank attention heads similarly. Thus we choose the gradient-based method to rank attention heads in all our experiments. Our evaluations confirm that only a subset of attention heads in each Transformer-based model makes key contributions to each cross-lingual or multi-lingual task and that these heads are shared across languages. Performance of models generally drop when the highest-ranked or randomly selected heads are pruned, validating the head rankings generated by our gradient-based method. We also observe performance improvements on tasks with multiple source languages by pruning attention heads. Our findings potentially apply to truly resource-scarce languages since we show that the models perform better with attention heads pruned when fewer training instances are available in the target languages. The contributions of this paper are three-fold: • We explore the roles of attention heads in multilingual Transformer-based models and find that pruning certain heads leads to comparable or better performance in cross-lingual and multilingual sequence labeling tasks. • We adapt a gradient-based method to locate attention heads that can be pruned without exhaustive experiments on all possible combinations. • We show the correctness, robustness, and extensibility of the findings and our head ranking method under a wide range of settings through comprehensive experiments.","What is the impact of pruning attention heads on the performance of Transformer-based models in cross-lingual and multi-lingual tasks, and how can the heads to be pruned be effectively identified?",0.0,0.0,0.0
41,Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks,"Weicheng Ma, Kai Zhang, Renze Lou, Lili Wang, and Soroush Vosoughi. 2021. Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1956–1966, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.152.pdf,https://aclanthology.org/2021.acl-long.152/,"This paper studies the relative importance of attention heads in Transformer-based models to aid their interpretability in cross-lingual and multi-lingual tasks. Prior research has found that only a few attention heads are important in each mono-lingual Natural Language Processing (NLP) task and pruning the remaining heads leads to comparable or improved performance of the model. However, the impact of pruning attention heads is not yet clear in cross-lingual and multi-lingual tasks. Through extensive experiments, we show that (1) pruning a number of attention heads in a multilingual Transformer-based model has, in general, positive effects on its performance in cross-lingual and multi-lingual tasks and (2) the attention heads to be pruned can be ranked using gradients and identified with a few trial experiments. Our experiments focus on sequence labeling tasks, with potential applicability on other cross-lingual and multi-lingual tasks. For comprehensiveness, we examine two pre-trained multi-lingual models, namely multi-lingual BERT (mBERT) and XLM-R, on three tasks across 9 languages each. We also discuss the validity of our findings and their extensibility to truly resource-scarce languages and other task settings.","Prior research on mono-lingual Transformer-based (Vaswani et al., 2017) models reveals that a subset of their attention heads makes key contributions to each task, and the models perform comparably well (Voita et al., 2019; Michel et al., 2019) or even better (Kovaleva et al., 2019) with the remaining heads pruned 1 . While multi-lingual Transformer-based models, e.g. mBERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020), are widely applied in cross-lingual and multi-lingual NLP tasks 2 (Wang et al., 2019; Keung et al., 2019; Eskander et al., 2020), no attempt has been made to extend the findings on the aforementioned mono-lingual research to this context. In this paper, we explore the roles of attention heads in cross-lingual and multi-lingual tasks for two reasons. First, better understanding and interpretability of Transformerbased models leads to efficient model designs and parameter tuning. Second, head-pruning makes Transformer-based models more applicable to truly resource-scarce languages if it does not negatively affect model performance significantly. The biggest challenge we face when studying the roles of attention heads in cross-lingual and multi-lingual tasks is locating the heads to prune. Existing research has shown that each attention head is specialized to extract a collection of linguistic features, e.g., the middle layers of BERT mainly extract syntactic features (Vig and Belinkov, 2019; Hewitt and Manning, 2019) and the fourth head on the fifth layer of BERT greatly contributes to the coreference resolution task (Clark et al., 2019). Thus, we hypothesize that important feature extractors for a task should be shared across languages and the remaining heads can be pruned. We evaluate two approaches used to rank attention heads, the first of which is layer-wise relevance propagation (LRP, Ding et al. (2017)). Voita et al. (2019) interpreted the adaptation of LRP in Transformerbased models on machine translation. Motivated by Feng et al. (2018) and Serrano and Smith (2019), we design a second ranking method based on gradients since the gradients on each attention head reflect its contribution to the predictions. We study the effects of pruning attention heads on three sequence labeling tasks, namely part-ofspeech tagging (POS), named entity recognition (NER), and slot filling (SF). We focus on sequence labeling tasks since they are more difficult to annotate than document- or sentence-level classification datasets and require more treatment in crosslingual and multi-lingual research. We choose POS and NER datasets in 9 languages, where English (EN), Chinese (ZH), and Arabic (AR) are candidate source languages. The MultiAtis++ corpus (Xu et al., 2020) is used in the SF evaluations with EN as the source language. We do not include syntactic chunking and semantic role labeling tasks due to lack of availability of manually written and annotated corpora. In these experiments, we rank attention heads based only on the source language(s) to ensure the extensibility of the learned knowledge to cross-lingual tasks and resource-poor languages. In our preliminary experiments comparing the gradient-based method and LRP, the average F1 score improvements on NER with mBERT are 0.69 (cross-lingual) and 0.24 (multi-lingual) for LRP and 0.81 (cross-lingual) and 0.31 (multi-lingual) for the gradient-based method, though both methods rank attention heads similarly. Thus we choose the gradient-based method to rank attention heads in all our experiments. Our evaluations confirm that only a subset of attention heads in each Transformer-based model makes key contributions to each cross-lingual or multi-lingual task and that these heads are shared across languages. Performance of models generally drop when the highest-ranked or randomly selected heads are pruned, validating the head rankings generated by our gradient-based method. We also observe performance improvements on tasks with multiple source languages by pruning attention heads. Our findings potentially apply to truly resource-scarce languages since we show that the models perform better with attention heads pruned when fewer training instances are available in the target languages. The contributions of this paper are three-fold: • We explore the roles of attention heads in multilingual Transformer-based models and find that pruning certain heads leads to comparable or better performance in cross-lingual and multilingual sequence labeling tasks. • We adapt a gradient-based method to locate attention heads that can be pruned without exhaustive experiments on all possible combinations. • We show the correctness, robustness, and extensibility of the findings and our head ranking method under a wide range of settings through comprehensive experiments.",Can the performance of multi-lingual Transformer-based models in cross-lingual and multi-lingual tasks be improved by pruning a number of attention heads identified using gradients?,0.0,1.0,0.0
42,Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks,"Weicheng Ma, Kai Zhang, Renze Lou, Lili Wang, and Soroush Vosoughi. 2021. Contributions of Transformer Attention Heads in Multi- and Cross-lingual Tasks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1956–1966, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.152.pdf,https://aclanthology.org/2021.acl-long.152/,"This paper studies the relative importance of attention heads in Transformer-based models to aid their interpretability in cross-lingual and multi-lingual tasks. Prior research has found that only a few attention heads are important in each mono-lingual Natural Language Processing (NLP) task and pruning the remaining heads leads to comparable or improved performance of the model. However, the impact of pruning attention heads is not yet clear in cross-lingual and multi-lingual tasks. Through extensive experiments, we show that (1) pruning a number of attention heads in a multilingual Transformer-based model has, in general, positive effects on its performance in cross-lingual and multi-lingual tasks and (2) the attention heads to be pruned can be ranked using gradients and identified with a few trial experiments. Our experiments focus on sequence labeling tasks, with potential applicability on other cross-lingual and multi-lingual tasks. For comprehensiveness, we examine two pre-trained multi-lingual models, namely multi-lingual BERT (mBERT) and XLM-R, on three tasks across 9 languages each. We also discuss the validity of our findings and their extensibility to truly resource-scarce languages and other task settings.","Prior research on mono-lingual Transformer-based (Vaswani et al., 2017) models reveals that a subset of their attention heads makes key contributions to each task, and the models perform comparably well (Voita et al., 2019; Michel et al., 2019) or even better (Kovaleva et al., 2019) with the remaining heads pruned 1 . While multi-lingual Transformer-based models, e.g. mBERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020), are widely applied in cross-lingual and multi-lingual NLP tasks 2 (Wang et al., 2019; Keung et al., 2019; Eskander et al., 2020), no attempt has been made to extend the findings on the aforementioned mono-lingual research to this context. In this paper, we explore the roles of attention heads in cross-lingual and multi-lingual tasks for two reasons. First, better understanding and interpretability of Transformerbased models leads to efficient model designs and parameter tuning. Second, head-pruning makes Transformer-based models more applicable to truly resource-scarce languages if it does not negatively affect model performance significantly. The biggest challenge we face when studying the roles of attention heads in cross-lingual and multi-lingual tasks is locating the heads to prune. Existing research has shown that each attention head is specialized to extract a collection of linguistic features, e.g., the middle layers of BERT mainly extract syntactic features (Vig and Belinkov, 2019; Hewitt and Manning, 2019) and the fourth head on the fifth layer of BERT greatly contributes to the coreference resolution task (Clark et al., 2019). Thus, we hypothesize that important feature extractors for a task should be shared across languages and the remaining heads can be pruned. We evaluate two approaches used to rank attention heads, the first of which is layer-wise relevance propagation (LRP, Ding et al. (2017)). Voita et al. (2019) interpreted the adaptation of LRP in Transformerbased models on machine translation. Motivated by Feng et al. (2018) and Serrano and Smith (2019), we design a second ranking method based on gradients since the gradients on each attention head reflect its contribution to the predictions. We study the effects of pruning attention heads on three sequence labeling tasks, namely part-ofspeech tagging (POS), named entity recognition (NER), and slot filling (SF). We focus on sequence labeling tasks since they are more difficult to annotate than document- or sentence-level classification datasets and require more treatment in crosslingual and multi-lingual research. We choose POS and NER datasets in 9 languages, where English (EN), Chinese (ZH), and Arabic (AR) are candidate source languages. The MultiAtis++ corpus (Xu et al., 2020) is used in the SF evaluations with EN as the source language. We do not include syntactic chunking and semantic role labeling tasks due to lack of availability of manually written and annotated corpora. In these experiments, we rank attention heads based only on the source language(s) to ensure the extensibility of the learned knowledge to cross-lingual tasks and resource-poor languages. In our preliminary experiments comparing the gradient-based method and LRP, the average F1 score improvements on NER with mBERT are 0.69 (cross-lingual) and 0.24 (multi-lingual) for LRP and 0.81 (cross-lingual) and 0.31 (multi-lingual) for the gradient-based method, though both methods rank attention heads similarly. Thus we choose the gradient-based method to rank attention heads in all our experiments. Our evaluations confirm that only a subset of attention heads in each Transformer-based model makes key contributions to each cross-lingual or multi-lingual task and that these heads are shared across languages. Performance of models generally drop when the highest-ranked or randomly selected heads are pruned, validating the head rankings generated by our gradient-based method. We also observe performance improvements on tasks with multiple source languages by pruning attention heads. Our findings potentially apply to truly resource-scarce languages since we show that the models perform better with attention heads pruned when fewer training instances are available in the target languages. The contributions of this paper are three-fold: • We explore the roles of attention heads in multilingual Transformer-based models and find that pruning certain heads leads to comparable or better performance in cross-lingual and multilingual sequence labeling tasks. • We adapt a gradient-based method to locate attention heads that can be pruned without exhaustive experiments on all possible combinations. • We show the correctness, robustness, and extensibility of the findings and our head ranking method under a wide range of settings through comprehensive experiments.","Can pruning attention heads, as ranked by a gradient-based method, maintain or enhance the performance of Transformer-based models in cross-lingual and multi-lingual sequence labeling tasks?",0.0,2.0,0.0
43,A Mixture of h - 1 Heads is Better than h Heads,"Hao Peng, Roy Schwartz, Dianqi Li, and Noah A. Smith. 2020. A Mixture of h - 1 Heads is Better than h Heads. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6566–6577, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.587.pdf,https://aclanthology.org/2020.acl-main.587/,"Multi-head attentive neural architectures have achieved state-of-the-art results on a variety of natural language processing tasks. Evidence has shown that they are overparameterized; attention heads can be pruned without significant performance loss. In this work, we instead “reallocate” them—the model learns to activate different heads on different inputs. Drawing connections between multi-head attention and mixture of experts, we propose the mixture of attentive experts model (MAE). MAE is trained using a block coordinate descent algorithm that alternates between updating (1) the responsibilities of the experts and (2) their parameters. Experiments on machine translation and language modeling show that MAE outperforms strong baselines on both tasks. Particularly, on the WMT14 English to German translation dataset, MAE improves over “transformer-base” by 0.8 BLEU, with a comparable number of parameters. Our analysis shows that our model learns to specialize different experts to different inputs.1","The transformer architecture and its variants achieve state-of-the-art performance across a variety of NLP tasks, including machine translation (Vaswani et al., 2017; Ott et al., 2018), language modeling (Radford et al., 2018; Baevski and Auli, 2019), semantic role labeling (Strubell et al., 2018), and more (Devlin et al., 2019; Liu et al., 2019b; Yang et al., 2019b). Under the hood, multihead attention provides the driving force: multiple separately parameterized attention functions act in parallel to contextualize the input representations; their outputs are then gathered by an affine transformation, and fed to onward computation. Recent efforts by Voita et al. (2019) and Michel et al. (2019) suggest that typical transformer networks are overparameterized, in the sense that at test time, many of the heads, or even a full layer (Fan et al., 2020), can be removed without significant loss in performance.2 In response to this observation, they propose to prune the unimportant attention heads in the model after it is trained, aiming for faster inference. In this paper, we ask whether, instead of reducing the model capacity, we can use it more effectively. We propose mixture of attentive experts (MAE). MAE retains all attention heads, and learns to activate different heads on different inputs (see illustration in Figure 1). We start by showing that multi-head attention can be seen as an uniform, input-agnostic mixture of experts (Jacobs et al., 1991), by grouping a subset of attention heads as an expert (§2.2). We then introduce MAE, which instead of uniformly weighting the experts, complements the experts with a learned, input-dependent function that assigns their responsibilities (§2.3). To train MAE, we propose a two-step algorithm based on block coordinate descent (§3), which alternates between updating the experts’ responsibilities and their parameters. We evaluate MAE on machine translation and language modeling (§4). Our approach outperforms strong baselines on both; on the WMT14 English to German MT dataset, MAE outperforms transformer-base (Vaswani et al., 2017) by 0.8 BLEU with a negligible increase in the number parameters. Our analysis shows that MAE learns to encourage different experts to specialize on different inputs (§5).","Can the overparameterization of attention heads in transformer architectures and the potential inefficiency in using the same set of heads for all inputs be mitigated by employing the mixture of attentive experts (MAE) model, which reallocates attention heads based on the input?",2.0,2.0,1.0
44,A Critical Evaluation of Evaluations for Long-form Question Answering,"Fangyuan Xu, Yixiao Song, Mohit Iyyer, and Eunsol Choi. 2023. A Critical Evaluation of Evaluations for Long-form Question Answering. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3225–3245, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.181.pdf,https://aclanthology.org/2023.acl-long.181/,"Long-form question answering (LFQA) enables answering a wide range of questions, but its flexibility poses enormous challenges for evaluation. We perform the first targeted study of the evaluation of long-form answers, covering both human and automatic evaluation practices. We hire domain experts in seven areas to provide preference judgments over pairs of answers, along with free-form justifications for their choices. We present a careful analysis of experts’ evaluation, which focuses on new aspects such as the comprehensiveness of the answer. Next, we examine automatic text generation metrics, finding that no existing metrics are predictive of human preference judgments. However, some metrics correlate with fine-grained aspects of answers (e.g., coherence). We encourage future work to move away from a single “overall score” of the answer and adopt a multi-faceted evaluation, targeting aspects such as factuality and completeness. We publicly release all of our annotations and code to spur future work into LFQA evaluation.","Long-form question answering (Fan et al., 2019; Krishna et al., 2021; Nakano et al., 2021; Su et al., 2022, henceforth LFQA), an emerging research area within QA, requires systems to generate long and complex answers to questions by leveraging large language models and evidence document retrievers. While remarkable strides have been made in LFQA model development, the current state of LFQA evaluation is dire: most prior papers use a combination of crowdsourced human annotations and simple string-matching metrics (e.g., ROUGE). We present the first study of the evaluation of longform answers, exploring both human and automatic evaluation protocols to better understand how we should evaluate LFQA moving forward. Human evaluation: In most prior human LFQA evaluations (Krishna et al., 2021; Nakano et al., 2021), crowd annotators are given a question, two candidate answers, and (optionally) evidence documents, and they are asked to identify the better answer. However, crowdworkers do not necessarily have the expertise or background knowledge to reliably judge properties such as factuality (Gillick and Liu, 2010; Iskender et al., 2020). Thus, we hire domain experts in seven different fields (e.g., biology, economics) to perform the same answer preference task and additionally provide detailed justifications as to why they chose a particular answer. Analyzing their justifications reveals that experts consider properties such as completeness and factuality to be more decisive than surface-level aspects (e.g., conciseness and level of detail) on which crowdworkers tend to fixate. Additionally, even experts often disagree with each other about which answer is better; this disagreement stems from valuing finegrained answer properties differently. Automatic evaluation: As human evaluation is slow and expensive, developing a reliable automatic LFQA evaluation metric is crucial for speeding up model development. While ROUGE (Lin, 2004) has been shown to be misleading for LFQA (Krishna et al., 2021; Wang et al., 2022), do any other existing text generation metrics correlate to human judgments of answer quality? Can we train a metric to mimic human preference judgments? To answer these questions, we curate a suite of 12 automatic metrics and measure how they correlate to human judgments of both “overall quality” and two fine-grained aspects (coherence and faithfulness). None of these metrics reliably matches human judgments of overall answer quality. However, automatic metrics such as QAFactEval (Fabbri et al., 2022) and RankGen (Krishna et al., 2022) show potential at modeling fine-grained aspects of LFQA answers, which can spur research on a new generation of automatic LFQA metrics. Overall, we provide the first thorough study of LFQA evaluation and shed light on the components of good long-form answers. As part of our exploration, we collected and will release a small-scale dataset of expert evaluation of long-form answers (260 ratings and justifications over 140 answer pairs). We conclude by providing recommendations for the future of human and automatic LFQA evaluation, encouraging the community to hire expert evaluators and move from poorly-defined judgments of “overall preference” to a multi-faceted evaluation modeling attributes such as answer completeness, factuality, and ease of understanding.","What evaluation practices and metrics can effectively measure the quality of long-form answers in LFQA, correlating closely with expert human judgments on aspects such as factuality, completeness, and coherence?",0.0,0.0,0.0
45,A Critical Evaluation of Evaluations for Long-form Question Answering,"Fangyuan Xu, Yixiao Song, Mohit Iyyer, and Eunsol Choi. 2023. A Critical Evaluation of Evaluations for Long-form Question Answering. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3225–3245, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.181.pdf,https://aclanthology.org/2023.acl-long.181/,"Long-form question answering (LFQA) enables answering a wide range of questions, but its flexibility poses enormous challenges for evaluation. We perform the first targeted study of the evaluation of long-form answers, covering both human and automatic evaluation practices. We hire domain experts in seven areas to provide preference judgments over pairs of answers, along with free-form justifications for their choices. We present a careful analysis of experts’ evaluation, which focuses on new aspects such as the comprehensiveness of the answer. Next, we examine automatic text generation metrics, finding that no existing metrics are predictive of human preference judgments. However, some metrics correlate with fine-grained aspects of answers (e.g., coherence). We encourage future work to move away from a single “overall score” of the answer and adopt a multi-faceted evaluation, targeting aspects such as factuality and completeness. We publicly release all of our annotations and code to spur future work into LFQA evaluation.","Long-form question answering (Fan et al., 2019; Krishna et al., 2021; Nakano et al., 2021; Su et al., 2022, henceforth LFQA), an emerging research area within QA, requires systems to generate long and complex answers to questions by leveraging large language models and evidence document retrievers. While remarkable strides have been made in LFQA model development, the current state of LFQA evaluation is dire: most prior papers use a combination of crowdsourced human annotations and simple string-matching metrics (e.g., ROUGE). We present the first study of the evaluation of longform answers, exploring both human and automatic evaluation protocols to better understand how we should evaluate LFQA moving forward. Human evaluation: In most prior human LFQA evaluations (Krishna et al., 2021; Nakano et al., 2021), crowd annotators are given a question, two candidate answers, and (optionally) evidence documents, and they are asked to identify the better answer. However, crowdworkers do not necessarily have the expertise or background knowledge to reliably judge properties such as factuality (Gillick and Liu, 2010; Iskender et al., 2020). Thus, we hire domain experts in seven different fields (e.g., biology, economics) to perform the same answer preference task and additionally provide detailed justifications as to why they chose a particular answer. Analyzing their justifications reveals that experts consider properties such as completeness and factuality to be more decisive than surface-level aspects (e.g., conciseness and level of detail) on which crowdworkers tend to fixate. Additionally, even experts often disagree with each other about which answer is better; this disagreement stems from valuing finegrained answer properties differently. Automatic evaluation: As human evaluation is slow and expensive, developing a reliable automatic LFQA evaluation metric is crucial for speeding up model development. While ROUGE (Lin, 2004) has been shown to be misleading for LFQA (Krishna et al., 2021; Wang et al., 2022), do any other existing text generation metrics correlate to human judgments of answer quality? Can we train a metric to mimic human preference judgments? To answer these questions, we curate a suite of 12 automatic metrics and measure how they correlate to human judgments of both “overall quality” and two fine-grained aspects (coherence and faithfulness). None of these metrics reliably matches human judgments of overall answer quality. However, automatic metrics such as QAFactEval (Fabbri et al., 2022) and RankGen (Krishna et al., 2022) show potential at modeling fine-grained aspects of LFQA answers, which can spur research on a new generation of automatic LFQA metrics. Overall, we provide the first thorough study of LFQA evaluation and shed light on the components of good long-form answers. As part of our exploration, we collected and will release a small-scale dataset of expert evaluation of long-form answers (260 ratings and justifications over 140 answer pairs). We conclude by providing recommendations for the future of human and automatic LFQA evaluation, encouraging the community to hire expert evaluators and move from poorly-defined judgments of “overall preference” to a multi-faceted evaluation modeling attributes such as answer completeness, factuality, and ease of understanding.",Can the evaluation of long-form question answering (LFQA) be improved by adopting multi-faceted evaluation criteria and developing new automatic metrics that better correlate with human judgments?,0.0,0.0,0.0
46,A Critical Evaluation of Evaluations for Long-form Question Answering,"Fangyuan Xu, Yixiao Song, Mohit Iyyer, and Eunsol Choi. 2023. A Critical Evaluation of Evaluations for Long-form Question Answering. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3225–3245, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.181.pdf,https://aclanthology.org/2023.acl-long.181/,"Long-form question answering (LFQA) enables answering a wide range of questions, but its flexibility poses enormous challenges for evaluation. We perform the first targeted study of the evaluation of long-form answers, covering both human and automatic evaluation practices. We hire domain experts in seven areas to provide preference judgments over pairs of answers, along with free-form justifications for their choices. We present a careful analysis of experts’ evaluation, which focuses on new aspects such as the comprehensiveness of the answer. Next, we examine automatic text generation metrics, finding that no existing metrics are predictive of human preference judgments. However, some metrics correlate with fine-grained aspects of answers (e.g., coherence). We encourage future work to move away from a single “overall score” of the answer and adopt a multi-faceted evaluation, targeting aspects such as factuality and completeness. We publicly release all of our annotations and code to spur future work into LFQA evaluation.","Long-form question answering (Fan et al., 2019; Krishna et al., 2021; Nakano et al., 2021; Su et al., 2022, henceforth LFQA), an emerging research area within QA, requires systems to generate long and complex answers to questions by leveraging large language models and evidence document retrievers. While remarkable strides have been made in LFQA model development, the current state of LFQA evaluation is dire: most prior papers use a combination of crowdsourced human annotations and simple string-matching metrics (e.g., ROUGE). We present the first study of the evaluation of longform answers, exploring both human and automatic evaluation protocols to better understand how we should evaluate LFQA moving forward. Human evaluation: In most prior human LFQA evaluations (Krishna et al., 2021; Nakano et al., 2021), crowd annotators are given a question, two candidate answers, and (optionally) evidence documents, and they are asked to identify the better answer. However, crowdworkers do not necessarily have the expertise or background knowledge to reliably judge properties such as factuality (Gillick and Liu, 2010; Iskender et al., 2020). Thus, we hire domain experts in seven different fields (e.g., biology, economics) to perform the same answer preference task and additionally provide detailed justifications as to why they chose a particular answer. Analyzing their justifications reveals that experts consider properties such as completeness and factuality to be more decisive than surface-level aspects (e.g., conciseness and level of detail) on which crowdworkers tend to fixate. Additionally, even experts often disagree with each other about which answer is better; this disagreement stems from valuing finegrained answer properties differently. Automatic evaluation: As human evaluation is slow and expensive, developing a reliable automatic LFQA evaluation metric is crucial for speeding up model development. While ROUGE (Lin, 2004) has been shown to be misleading for LFQA (Krishna et al., 2021; Wang et al., 2022), do any other existing text generation metrics correlate to human judgments of answer quality? Can we train a metric to mimic human preference judgments? To answer these questions, we curate a suite of 12 automatic metrics and measure how they correlate to human judgments of both “overall quality” and two fine-grained aspects (coherence and faithfulness). None of these metrics reliably matches human judgments of overall answer quality. However, automatic metrics such as QAFactEval (Fabbri et al., 2022) and RankGen (Krishna et al., 2022) show potential at modeling fine-grained aspects of LFQA answers, which can spur research on a new generation of automatic LFQA metrics. Overall, we provide the first thorough study of LFQA evaluation and shed light on the components of good long-form answers. As part of our exploration, we collected and will release a small-scale dataset of expert evaluation of long-form answers (260 ratings and justifications over 140 answer pairs). We conclude by providing recommendations for the future of human and automatic LFQA evaluation, encouraging the community to hire expert evaluators and move from poorly-defined judgments of “overall preference” to a multi-faceted evaluation modeling attributes such as answer completeness, factuality, and ease of understanding.","Can the evaluation of long-form question answering (LFQA) systems be improved by conducting a detailed study of both human and automatic evaluation practices, hiring domain experts for human evaluations, analyzing existing automatic text generation metrics, and exploring the potential for more accurate metrics that consider fine-grained aspects of answers?",2.0,2.0,1.0
47,ERASER: A Benchmark to Evaluate Rationalized NLP Models,"Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming Xiong, Richard Socher, and Byron C. Wallace. 2020. ERASER: A Benchmark to Evaluate Rationalized NLP Models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4443–4458, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.408.pdf,https://aclanthology.org/2020.acl-main.408/,"State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the ‘reasoning’ behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of “rationales” (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/","Interest has recently grown in designing NLP systems that can reveal why models make specific predictions. But work in this direction has been conducted on different datasets and using different metrics to quantify performance; this has made it difficult to compare methods and track progress. We aim to address this issue by releasing a standardized benchmark of datasets — repurposed and augmented from pre-existing corpora, spanning a range of NLP tasks — and associated metrics for measuring different properties of rationales. We refer to this as the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark. In curating and releasing ERASER we take inspiration from the stickiness of the GLUE (Wang et al., 2019b) and SuperGLUE (Wang et al., 2019a) benchmarks for evaluating progress in natural language understanding tasks, which have driven rapid progress on models for general language representation learning. We believe the still somewhat nascent subfield of interpretable NLP stands to benefit similarly from an analogous collection of standardized datasets and tasks; we hope these will aid the design of standardized metrics to measure different properties of ‘interpretability’, and we propose a set of such metrics as a starting point. Interpretability is a broad topic with many possible realizations (Doshi-Velez and Kim, 2017; Lipton, 2016). In ERASER we focus specifically on rationales, i.e., snippets that support outputs. All datasets in ERASER include such rationales, explicitly marked by human annotators. By definition, rationales should be sufficient to make predictions, but they may not be comprehensive. Therefore, for some datasets, we have also collected comprehensive rationales (in which all evidence supporting an output has been marked) on test instances. The ‘quality’ of extracted rationales will depend on their intended use. Therefore, we propose an initial set of metrics to evaluate rationales that are meant to measure different varieties of ‘interpretability’. Broadly, this includes measures of agreement with human-provided rationales, and assessments of faithfulness. The latter aim to capture the extent to which rationales provided by a model in fact informed its predictions. We believe these provide a reasonable start, but view the problem of designing metrics for evaluating rationales — especially for measuring faithfulness — as a topic for further research that ERASER can facilitate. And while we will provide a ‘leaderboard’, this is better viewed as a ‘results board’; we do not privilege any one metric. Instead, ERASER permits comparison between models that provide rationales with respect to different criteria of interest. We implement baseline models and report their performance across the corpora in ERASER. We find that no single ‘off-the-shelf’ architecture is readily adaptable to datasets with very different instance lengths and associated rationale snippets (Section 3). This highlights a need for new models that can consume potentially lengthy inputs and adaptively provide rationales at a task-appropriate level of granularity. ERASER provides a resource to develop such models. In sum, we introduce the ERASER benchmark (www.eraserbenchmark.com), a unified set of diverse NLP datasets (these are repurposed and augmented from existing corpora,1 including sentiment analysis, Natural Language Inference, and QA tasks, among others) in a standardized format featuring human rationales for decisions, along with starter code and tools, baseline models, and standardized (initial) metrics for rationales.","What metrics best capture the alignment of machine-generated rationales with human rationales in NLP models, and how can these metrics comprehensively evaluate the faithfulness of these rationales in informing model predictions?",0.0,0.0,0.0
48,ERASER: A Benchmark to Evaluate Rationalized NLP Models,"Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming Xiong, Richard Socher, and Byron C. Wallace. 2020. ERASER: A Benchmark to Evaluate Rationalized NLP Models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4443–4458, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.408.pdf,https://aclanthology.org/2020.acl-main.408/,"State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the ‘reasoning’ behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of “rationales” (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/","Interest has recently grown in designing NLP systems that can reveal why models make specific predictions. But work in this direction has been conducted on different datasets and using different metrics to quantify performance; this has made it difficult to compare methods and track progress. We aim to address this issue by releasing a standardized benchmark of datasets — repurposed and augmented from pre-existing corpora, spanning a range of NLP tasks — and associated metrics for measuring different properties of rationales. We refer to this as the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark. In curating and releasing ERASER we take inspiration from the stickiness of the GLUE (Wang et al., 2019b) and SuperGLUE (Wang et al., 2019a) benchmarks for evaluating progress in natural language understanding tasks, which have driven rapid progress on models for general language representation learning. We believe the still somewhat nascent subfield of interpretable NLP stands to benefit similarly from an analogous collection of standardized datasets and tasks; we hope these will aid the design of standardized metrics to measure different properties of ‘interpretability’, and we propose a set of such metrics as a starting point. Interpretability is a broad topic with many possible realizations (Doshi-Velez and Kim, 2017; Lipton, 2016). In ERASER we focus specifically on rationales, i.e., snippets that support outputs. All datasets in ERASER include such rationales, explicitly marked by human annotators. By definition, rationales should be sufficient to make predictions, but they may not be comprehensive. Therefore, for some datasets, we have also collected comprehensive rationales (in which all evidence supporting an output has been marked) on test instances. The ‘quality’ of extracted rationales will depend on their intended use. Therefore, we propose an initial set of metrics to evaluate rationales that are meant to measure different varieties of ‘interpretability’. Broadly, this includes measures of agreement with human-provided rationales, and assessments of faithfulness. The latter aim to capture the extent to which rationales provided by a model in fact informed its predictions. We believe these provide a reasonable start, but view the problem of designing metrics for evaluating rationales — especially for measuring faithfulness — as a topic for further research that ERASER can facilitate. And while we will provide a ‘leaderboard’, this is better viewed as a ‘results board’; we do not privilege any one metric. Instead, ERASER permits comparison between models that provide rationales with respect to different criteria of interest. We implement baseline models and report their performance across the corpora in ERASER. We find that no single ‘off-the-shelf’ architecture is readily adaptable to datasets with very different instance lengths and associated rationale snippets (Section 3). This highlights a need for new models that can consume potentially lengthy inputs and adaptively provide rationales at a task-appropriate level of granularity. ERASER provides a resource to develop such models. In sum, we introduce the ERASER benchmark (www.eraserbenchmark.com), a unified set of diverse NLP datasets (these are repurposed and augmented from existing corpora,1 including sentiment analysis, Natural Language Inference, and QA tasks, among others) in a standardized format featuring human rationales for decisions, along with starter code and tools, baseline models, and standardized (initial) metrics for rationales.",Can the interpretability of NLP systems be improved by employing the ERASER benchmark to standardize the evaluation of model rationales?,0.0,1.0,1.0
49,ERASER: A Benchmark to Evaluate Rationalized NLP Models,"Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming Xiong, Richard Socher, and Byron C. Wallace. 2020. ERASER: A Benchmark to Evaluate Rationalized NLP Models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4443–4458, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.408.pdf,https://aclanthology.org/2020.acl-main.408/,"State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the ‘reasoning’ behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of “rationales” (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/","Interest has recently grown in designing NLP systems that can reveal why models make specific predictions. But work in this direction has been conducted on different datasets and using different metrics to quantify performance; this has made it difficult to compare methods and track progress. We aim to address this issue by releasing a standardized benchmark of datasets — repurposed and augmented from pre-existing corpora, spanning a range of NLP tasks — and associated metrics for measuring different properties of rationales. We refer to this as the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark. In curating and releasing ERASER we take inspiration from the stickiness of the GLUE (Wang et al., 2019b) and SuperGLUE (Wang et al., 2019a) benchmarks for evaluating progress in natural language understanding tasks, which have driven rapid progress on models for general language representation learning. We believe the still somewhat nascent subfield of interpretable NLP stands to benefit similarly from an analogous collection of standardized datasets and tasks; we hope these will aid the design of standardized metrics to measure different properties of ‘interpretability’, and we propose a set of such metrics as a starting point. Interpretability is a broad topic with many possible realizations (Doshi-Velez and Kim, 2017; Lipton, 2016). In ERASER we focus specifically on rationales, i.e., snippets that support outputs. All datasets in ERASER include such rationales, explicitly marked by human annotators. By definition, rationales should be sufficient to make predictions, but they may not be comprehensive. Therefore, for some datasets, we have also collected comprehensive rationales (in which all evidence supporting an output has been marked) on test instances. The ‘quality’ of extracted rationales will depend on their intended use. Therefore, we propose an initial set of metrics to evaluate rationales that are meant to measure different varieties of ‘interpretability’. Broadly, this includes measures of agreement with human-provided rationales, and assessments of faithfulness. The latter aim to capture the extent to which rationales provided by a model in fact informed its predictions. We believe these provide a reasonable start, but view the problem of designing metrics for evaluating rationales — especially for measuring faithfulness — as a topic for further research that ERASER can facilitate. And while we will provide a ‘leaderboard’, this is better viewed as a ‘results board’; we do not privilege any one metric. Instead, ERASER permits comparison between models that provide rationales with respect to different criteria of interest. We implement baseline models and report their performance across the corpora in ERASER. We find that no single ‘off-the-shelf’ architecture is readily adaptable to datasets with very different instance lengths and associated rationale snippets (Section 3). This highlights a need for new models that can consume potentially lengthy inputs and adaptively provide rationales at a task-appropriate level of granularity. ERASER provides a resource to develop such models. In sum, we introduce the ERASER benchmark (www.eraserbenchmark.com), a unified set of diverse NLP datasets (these are repurposed and augmented from existing corpora,1 including sentiment analysis, Natural Language Inference, and QA tasks, among others) in a standardized format featuring human rationales for decisions, along with starter code and tools, baseline models, and standardized (initial) metrics for rationales.","Can the problem of opacity in state-of-the-art deep learning models in NLP be addressed by introducing the ERASER benchmark, which comprises standardized datasets, tasks, and metrics for evaluating models based on how well the rationales they provide align with human-annotated rationales and the faithfulness of these rationales?",0.0,2.0,1.0
50,Automatically Labeled Data Generation for Large Scale Event Extraction,"Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and Jun Zhao. 2017. Automatically Labeled Data Generation for Large Scale Event Extraction. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 409–419, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1038.pdf,https://aclanthology.org/P17-1038/,"Modern models of event extraction for tasks like ACE are based on supervised learning of events from small hand-labeled data. However, hand-labeled training data is expensive to produce, in low coverage of event types, and limited in size, which makes supervised methods hard to extract large scale of events for knowledge base population. To solve the data labeling problem, we propose to automatically label training data for event extraction via world knowledge and linguistic knowledge, which can detect key arguments and trigger words for each event type and employ them to label events in texts automatically. The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately human-labeled data. And our automatically labeled data can incorporate with human-labeled data, then improve the performance of models learned from these data.","Event Extraction (EE), a challenging task in Information Extraction, aims at detecting and typing events (Event Detection), and extracting arguments with different roles (Argument Identification) from natural-language texts. For example, in the sentence shown in Figure 1, an EE system is expected to identify an Attack event triggered by threw and extract the corresponding five augments with different roles: Yesterday (Role=Time), demonstrators (Role=Attacker), stones (Role=Instrument), soldiers (Role=Target), and Israeli (Role=Place). To this end, so far most methods (Nguyen et al.,2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 20051 , to train extractors. Although this paradigm was widely studied, existing approaches still suffer from high costs for manually labeling training data and low coverage of predefined event types. In ACE 2005, all 33 event types are manually predefined and the corresponding event information (including triggers, event types, arguments and their roles) are manually annotated only in 599 English documents since the annotation process is extremely expensive. As Figure 2 shown, nearly 60% of event types in ACE 2005 have less than 100 labeled samples and there are even three event types which have less than ten labeled samples. Moreover, those predefined 33 event types are in low coverage for Natural Language Processing (NLP) applications on large-scale data. Therefore, for extracting large scale events, especially in open domain scenarios, how to automatically and efficiently generate sufficient training data is an important problem. This paper aims to automatically generate training data for EE, which involves labeling triggers, event types, arguments and their roles. Figure 1 shows an example of labeled sentence. Recent improvements of Distant Supervision (DS) have been proven to be effective to label training data for Relation Extraction (RE), which aims to predict semantic relations between pairs of entities, formulated as (entity1, relation, entity2). And DS for RE assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way (Mintz et al., 2009). However, when we use DS for RE to EE, we meet following challenges: Triggers are not given out in existing knowledge bases. EE aims to detect an event instance of a specific type and extract their arguments and roles, formulated as (event instance, event type; role1, argument1; role2, argument2; ...; rolen, argumentn), which can be regarded as a kind of multiple or complicated relational data. In Figure 3, the right part shows an example of spouse of relation between Barack Obama and Michelle Obama, where two rectangles represent two entities and the edge connecting them represents their relation. DS for RE uses two entities to automatically label training data; In comparison, the left part in Figure 3 shows a marriage event of Barack Obama and M ichelle Obama, where the dash circle represents the marriage event instance of Barack Obama and Michelle Obama, rectangles represent arguments of the event instance, and each edge connecting an argument and the event instance expresses the role of the argument. For example, Barack Obama plays a Spouse role in this marriage event instance. It seems that we could use an event instance and an argument to automatically generate training data for argument identification just like DS for RE. However, an event instance is a virtual node in existing knowledge bases and mentioned implicitly in texts. For example, in Freebase, the aforementioned marriage event instance is represented as m.02nqglv (see details in Section 2). Thus we cannot directly use an event instance and an argument, like m.02nqglv and Barack Obama, to label back in sentences. In ACE event extraction program, an event instance is represented as a trigger word, which is the main word that most clearly represents an event occurrence in sentences, like threw in Figure 1. Following ACE, we can use trigger words to represent event instance, like married for people.marriage event instance. Unfortunately, triggers are not given out in existing knowledge bases. To resolve the trigger missing problem mentioned above, we need to discover trigger words before employing distant supervision to automatically label event arguments. Following DS in RE, we could naturally assume that a sentence contains all arguments of an event in the knowledge base tend to express that event, and the verbs occur in these sentences tend to evoke this type of events. However, arguments for a specific event instance are usually mentioned in multiple sentences. Simply employing all arguments in the knowledge base to label back in sentences will generate few sentences as training samples. As shown in Table 1, only 0.02% of instances can find all argument mentions in one sentence. To solve above problems, we propose an approach to automatically generate labeled data for large scale EE by jointly using world knowledge (Freebase) and linguistic knowledge (FrameNet). At first, we put forward an approach to prioritize arguments and select key or representative arguments (see details in Section 3.1) for each event type by using Freebase; Secondly, we merely use key arguments to label events and figure out trigger words; Thirdly, an external linguistic knowledge resource, FrameNet, is employed to filter noisy trigger words and expand more triggers; After that, we propose a Soft Distant Supervision (SDS) for EE to automatically label training data, which assumes that any sentence containing all key arguments in Freebase and a corresponding trigger word is likely to express that event in some way, and arguments occurring in that sentence are likely to play the corresponding roles in that event. Finally, we evaluate the quality of the automatically labeled training data by both manual and automatic evaluations. In addition, we employ a CNNbased EE approach with multi-instance learning for the automatically labeled data as a baseline for further research on this data. In summary, the contributions of this paper are as follows: • To our knowledge, it is the first work to automatically label data for large scale EE via world knowledge and linguistic knowledge. All the labeled data in this paper have been released and can be downloaded freely2 . • We propose an approach to figure out key arguments of an event by using Freebase, and use them to automatically detect events and corresponding trigger words. Moreover, we employ FrameNet to filter noisy triggers and expand more triggers. • The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately humanannotated data. Also, our automatically labeled data can augment traditional humanannotated data, which could significantly improve the extraction performance.","How can world knowledge and linguistic knowledge be leveraged to automatically generate high-quality labeled training data for event extraction, thereby addressing the challenges posed by the expensive and time-consuming process of manual data labeling, low coverage of event types, and the difficulties in identifying trigger words for event instances in existing knowledge bases?",2.0,1.0,1.0
51,Automatically Labeled Data Generation for Large Scale Event Extraction,"Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and Jun Zhao. 2017. Automatically Labeled Data Generation for Large Scale Event Extraction. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 409–419, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1038.pdf,https://aclanthology.org/P17-1038/,"Modern models of event extraction for tasks like ACE are based on supervised learning of events from small hand-labeled data. However, hand-labeled training data is expensive to produce, in low coverage of event types, and limited in size, which makes supervised methods hard to extract large scale of events for knowledge base population. To solve the data labeling problem, we propose to automatically label training data for event extraction via world knowledge and linguistic knowledge, which can detect key arguments and trigger words for each event type and employ them to label events in texts automatically. The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately human-labeled data. And our automatically labeled data can incorporate with human-labeled data, then improve the performance of models learned from these data.","Event Extraction (EE), a challenging task in Information Extraction, aims at detecting and typing events (Event Detection), and extracting arguments with different roles (Argument Identification) from natural-language texts. For example, in the sentence shown in Figure 1, an EE system is expected to identify an Attack event triggered by threw and extract the corresponding five augments with different roles: Yesterday (Role=Time), demonstrators (Role=Attacker), stones (Role=Instrument), soldiers (Role=Target), and Israeli (Role=Place). To this end, so far most methods (Nguyen et al.,2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 20051 , to train extractors. Although this paradigm was widely studied, existing approaches still suffer from high costs for manually labeling training data and low coverage of predefined event types. In ACE 2005, all 33 event types are manually predefined and the corresponding event information (including triggers, event types, arguments and their roles) are manually annotated only in 599 English documents since the annotation process is extremely expensive. As Figure 2 shown, nearly 60% of event types in ACE 2005 have less than 100 labeled samples and there are even three event types which have less than ten labeled samples. Moreover, those predefined 33 event types are in low coverage for Natural Language Processing (NLP) applications on large-scale data. Therefore, for extracting large scale events, especially in open domain scenarios, how to automatically and efficiently generate sufficient training data is an important problem. This paper aims to automatically generate training data for EE, which involves labeling triggers, event types, arguments and their roles. Figure 1 shows an example of labeled sentence. Recent improvements of Distant Supervision (DS) have been proven to be effective to label training data for Relation Extraction (RE), which aims to predict semantic relations between pairs of entities, formulated as (entity1, relation, entity2). And DS for RE assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way (Mintz et al., 2009). However, when we use DS for RE to EE, we meet following challenges: Triggers are not given out in existing knowledge bases. EE aims to detect an event instance of a specific type and extract their arguments and roles, formulated as (event instance, event type; role1, argument1; role2, argument2; ...; rolen, argumentn), which can be regarded as a kind of multiple or complicated relational data. In Figure 3, the right part shows an example of spouse of relation between Barack Obama and Michelle Obama, where two rectangles represent two entities and the edge connecting them represents their relation. DS for RE uses two entities to automatically label training data; In comparison, the left part in Figure 3 shows a marriage event of Barack Obama and M ichelle Obama, where the dash circle represents the marriage event instance of Barack Obama and Michelle Obama, rectangles represent arguments of the event instance, and each edge connecting an argument and the event instance expresses the role of the argument. For example, Barack Obama plays a Spouse role in this marriage event instance. It seems that we could use an event instance and an argument to automatically generate training data for argument identification just like DS for RE. However, an event instance is a virtual node in existing knowledge bases and mentioned implicitly in texts. For example, in Freebase, the aforementioned marriage event instance is represented as m.02nqglv (see details in Section 2). Thus we cannot directly use an event instance and an argument, like m.02nqglv and Barack Obama, to label back in sentences. In ACE event extraction program, an event instance is represented as a trigger word, which is the main word that most clearly represents an event occurrence in sentences, like threw in Figure 1. Following ACE, we can use trigger words to represent event instance, like married for people.marriage event instance. Unfortunately, triggers are not given out in existing knowledge bases. To resolve the trigger missing problem mentioned above, we need to discover trigger words before employing distant supervision to automatically label event arguments. Following DS in RE, we could naturally assume that a sentence contains all arguments of an event in the knowledge base tend to express that event, and the verbs occur in these sentences tend to evoke this type of events. However, arguments for a specific event instance are usually mentioned in multiple sentences. Simply employing all arguments in the knowledge base to label back in sentences will generate few sentences as training samples. As shown in Table 1, only 0.02% of instances can find all argument mentions in one sentence. To solve above problems, we propose an approach to automatically generate labeled data for large scale EE by jointly using world knowledge (Freebase) and linguistic knowledge (FrameNet). At first, we put forward an approach to prioritize arguments and select key or representative arguments (see details in Section 3.1) for each event type by using Freebase; Secondly, we merely use key arguments to label events and figure out trigger words; Thirdly, an external linguistic knowledge resource, FrameNet, is employed to filter noisy trigger words and expand more triggers; After that, we propose a Soft Distant Supervision (SDS) for EE to automatically label training data, which assumes that any sentence containing all key arguments in Freebase and a corresponding trigger word is likely to express that event in some way, and arguments occurring in that sentence are likely to play the corresponding roles in that event. Finally, we evaluate the quality of the automatically labeled training data by both manual and automatic evaluations. In addition, we employ a CNNbased EE approach with multi-instance learning for the automatically labeled data as a baseline for further research on this data. In summary, the contributions of this paper are as follows: • To our knowledge, it is the first work to automatically label data for large scale EE via world knowledge and linguistic knowledge. All the labeled data in this paper have been released and can be downloaded freely2 . • We propose an approach to figure out key arguments of an event by using Freebase, and use them to automatically detect events and corresponding trigger words. Moreover, we employ FrameNet to filter noisy triggers and expand more triggers. • The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately humanannotated data. Also, our automatically labeled data can augment traditional humanannotated data, which could significantly improve the extraction performance.",Can the problem of low coverage and high cost of hand-labeled training data for event extraction be solved by automatically generating training data using world knowledge and linguistic knowledge?,1.0,1.0,1.0
52,Automatically Labeled Data Generation for Large Scale Event Extraction,"Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and Jun Zhao. 2017. Automatically Labeled Data Generation for Large Scale Event Extraction. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 409–419, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1038.pdf,https://aclanthology.org/P17-1038/,"Modern models of event extraction for tasks like ACE are based on supervised learning of events from small hand-labeled data. However, hand-labeled training data is expensive to produce, in low coverage of event types, and limited in size, which makes supervised methods hard to extract large scale of events for knowledge base population. To solve the data labeling problem, we propose to automatically label training data for event extraction via world knowledge and linguistic knowledge, which can detect key arguments and trigger words for each event type and employ them to label events in texts automatically. The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately human-labeled data. And our automatically labeled data can incorporate with human-labeled data, then improve the performance of models learned from these data.","Event Extraction (EE), a challenging task in Information Extraction, aims at detecting and typing events (Event Detection), and extracting arguments with different roles (Argument Identification) from natural-language texts. For example, in the sentence shown in Figure 1, an EE system is expected to identify an Attack event triggered by threw and extract the corresponding five augments with different roles: Yesterday (Role=Time), demonstrators (Role=Attacker), stones (Role=Instrument), soldiers (Role=Target), and Israeli (Role=Place). To this end, so far most methods (Nguyen et al.,2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 20051 , to train extractors. Although this paradigm was widely studied, existing approaches still suffer from high costs for manually labeling training data and low coverage of predefined event types. In ACE 2005, all 33 event types are manually predefined and the corresponding event information (including triggers, event types, arguments and their roles) are manually annotated only in 599 English documents since the annotation process is extremely expensive. As Figure 2 shown, nearly 60% of event types in ACE 2005 have less than 100 labeled samples and there are even three event types which have less than ten labeled samples. Moreover, those predefined 33 event types are in low coverage for Natural Language Processing (NLP) applications on large-scale data. Therefore, for extracting large scale events, especially in open domain scenarios, how to automatically and efficiently generate sufficient training data is an important problem. This paper aims to automatically generate training data for EE, which involves labeling triggers, event types, arguments and their roles. Figure 1 shows an example of labeled sentence. Recent improvements of Distant Supervision (DS) have been proven to be effective to label training data for Relation Extraction (RE), which aims to predict semantic relations between pairs of entities, formulated as (entity1, relation, entity2). And DS for RE assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way (Mintz et al., 2009). However, when we use DS for RE to EE, we meet following challenges: Triggers are not given out in existing knowledge bases. EE aims to detect an event instance of a specific type and extract their arguments and roles, formulated as (event instance, event type; role1, argument1; role2, argument2; ...; rolen, argumentn), which can be regarded as a kind of multiple or complicated relational data. In Figure 3, the right part shows an example of spouse of relation between Barack Obama and Michelle Obama, where two rectangles represent two entities and the edge connecting them represents their relation. DS for RE uses two entities to automatically label training data; In comparison, the left part in Figure 3 shows a marriage event of Barack Obama and M ichelle Obama, where the dash circle represents the marriage event instance of Barack Obama and Michelle Obama, rectangles represent arguments of the event instance, and each edge connecting an argument and the event instance expresses the role of the argument. For example, Barack Obama plays a Spouse role in this marriage event instance. It seems that we could use an event instance and an argument to automatically generate training data for argument identification just like DS for RE. However, an event instance is a virtual node in existing knowledge bases and mentioned implicitly in texts. For example, in Freebase, the aforementioned marriage event instance is represented as m.02nqglv (see details in Section 2). Thus we cannot directly use an event instance and an argument, like m.02nqglv and Barack Obama, to label back in sentences. In ACE event extraction program, an event instance is represented as a trigger word, which is the main word that most clearly represents an event occurrence in sentences, like threw in Figure 1. Following ACE, we can use trigger words to represent event instance, like married for people.marriage event instance. Unfortunately, triggers are not given out in existing knowledge bases. To resolve the trigger missing problem mentioned above, we need to discover trigger words before employing distant supervision to automatically label event arguments. Following DS in RE, we could naturally assume that a sentence contains all arguments of an event in the knowledge base tend to express that event, and the verbs occur in these sentences tend to evoke this type of events. However, arguments for a specific event instance are usually mentioned in multiple sentences. Simply employing all arguments in the knowledge base to label back in sentences will generate few sentences as training samples. As shown in Table 1, only 0.02% of instances can find all argument mentions in one sentence. To solve above problems, we propose an approach to automatically generate labeled data for large scale EE by jointly using world knowledge (Freebase) and linguistic knowledge (FrameNet). At first, we put forward an approach to prioritize arguments and select key or representative arguments (see details in Section 3.1) for each event type by using Freebase; Secondly, we merely use key arguments to label events and figure out trigger words; Thirdly, an external linguistic knowledge resource, FrameNet, is employed to filter noisy trigger words and expand more triggers; After that, we propose a Soft Distant Supervision (SDS) for EE to automatically label training data, which assumes that any sentence containing all key arguments in Freebase and a corresponding trigger word is likely to express that event in some way, and arguments occurring in that sentence are likely to play the corresponding roles in that event. Finally, we evaluate the quality of the automatically labeled training data by both manual and automatic evaluations. In addition, we employ a CNNbased EE approach with multi-instance learning for the automatically labeled data as a baseline for further research on this data. In summary, the contributions of this paper are as follows: • To our knowledge, it is the first work to automatically label data for large scale EE via world knowledge and linguistic knowledge. All the labeled data in this paper have been released and can be downloaded freely2 . • We propose an approach to figure out key arguments of an event by using Freebase, and use them to automatically detect events and corresponding trigger words. Moreover, we employ FrameNet to filter noisy triggers and expand more triggers. • The experimental results show that the quality of our large scale automatically labeled data is competitive with elaborately humanannotated data. Also, our automatically labeled data can augment traditional humanannotated data, which could significantly improve the extraction performance.","Can the problem of high cost, low coverage, and limited size of hand-labeled training data for event extraction be solved by automatically labeling training data via world knowledge and linguistic knowledge?",1.0,2.0,1.0
53,The Limitations of Limited Context for Constituency Parsing,"Yuchen Li and Andrej Risteski. 2021. The Limitations of Limited Context for Constituency Parsing. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2675–2687, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.208.pdf,https://aclanthology.org/2021.acl-long.208/,"Incorporating syntax into neural approaches in NLP has a multitude of practical and scientific benefits. For instance, a language model that is syntax-aware is likely to be able to produce better samples; even a discriminative model like BERT with a syntax module could be used for core NLP tasks like unsupervised syntactic parsing. Rapid progress in recent years was arguably spurred on by the empirical success of the Parsing-Reading-Predict architecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM of (Shen et al., 2019). Most notably, this is the first time neural approaches were able to successfully perform unsupervised syntactic parsing (evaluated by various metrics like F-1 score). However, even heuristic (much less fully mathematical) understanding of why and when these architectures work is lagging severely behind. In this work, we answer representational questions raised by the architectures in (Shen et al., 2018a, 2019), as well as some transition-based syntax-aware language models (Dyer et al., 2016): what kind of syntactic structure can current neural approaches to syntax represent? Concretely, we ground this question in the sandbox of probabilistic context-free-grammars (PCFGs), and identify a key aspect of the representational power of these approaches: the amount and directionality of context that the predictor has access to when forced to make parsing decision. We show that with limited context (either bounded, or unidirectional), there are PCFGs, for which these approaches cannot represent the max-likelihood parse; conversely, if the context is unlimited, they can represent the max-likelihood parse of any PCFG.","Neural approaches have been steadily making their way to NLP in recent years. By and large however, the neural techniques that have been scaled-up the most and receive widespread usage do not explicitly try to encode discrete structure that is natural to language, e.g. syntax. The reason for this is perhaps not surprising: neural models have largely achieved substantial improvements in unsupervised settings, BERT (Devlin et al., 2019) being the defacto method for unsupervised pre-training in most NLP settings. On the other hand unsupervised syntactic tasks, e.g. unsupervised syntactic parsing, have long been known to be very difficult tasks (Htut et al., 2018). However, since incorporating syntax has been shown to improve language modeling (Kim et al., 2019b) as well as natural language inference (Chen et al., 2017; Pang et al., 2019; He et al., 2020), syntactic parsing remains important even in the current era when large pre-trained models, like BERT (Devlin et al., 2019), are available. Arguably, the breakthrough works in unsupervised constituency parsing in a neural manner were (Shen et al., 2018a, 2019), achieving F1 scores 42.8 and 49.4 on the WSJ Penn Treebank dataset (Htut et al., 2018; Shen et al., 2019). Both of these architectures, however (especially Shen et al., 2018a) are quite intricate, and it’s difficult to evaluate what their representational power is (i.e. what kinds of structure can they recover). Moreover, as subsequent more thorough evaluations show (Kim et al., 2019b,a), these methods still have a rather large performance gap with the oracle binary tree (which is the best binary parse tree according to F1-score) — raising the question of what is missing in these methods. We theoretically answer both questions raised in the prior paragraph. We quantify the representational power of two major frameworks in neural approaches to syntax: learning a syntactic distance (Shen et al., 2018a,b, 2019) and learning to parse through sequential transitions (Dyer et al., 2016; Chelba, 1997). To formalize our results, we consider the well-established sandbox of probabilistic context-free grammars (PCFGs). Namely, we ask: When is a neural model based on a syntactic distance or transitions able to represent the maxlikelihood parse of a sentence generated from a PCFG? We focus on a crucial “hyperparameter” common to practical implementations of both families of methods that turns out to govern the representational power: the amount and type of context the model is allowed to use when making its predictions. Briefly, for every position t in the sentence, syntactic distance models learn a distance dt to the previous token — the tree is then inferred from this distance; transition-based models iteratively construct the parse tree by deciding, at each position t, what operations to perform on a partial parse up to token t. A salient feature of both is the context, that is, which tokens is dt a function of (correspondingly, which tokens can the choice of operations at token t depend on)? We show that when the context is either bounded (that is, dt only depends on a bounded window around the t-th token) or unidirectional (that is, dt only considers the tokens to the left of the tth token), there are PCFGs for which no distance metric (correspondingly, no algorithm to choose the sequence of transitions) works. On the other hand, if the context is unbounded in both directions then both methods work: that is, for any parse, we can design a distance metric (correspondingly, a sequence of transitions) that recovers it. This is of considerable importance: in practical implementations the context is either bounded (e.g. in Shen et al., 2018a, the distance metric is parametrized by a convolutional kernel with a constant width) or unidirectional (e.g. in Shen et al., 2019, the distance metric is computed by a LSTM, which performs a left-to-right computation). This formally confirms a conjecture of Htut et al. (2018), who suggested that because these models commit to parsing decision in a left-to-right fashion and are trained as a part of a language model, it may be difficult for them to capture sufficiently complex syntactic dependencies. Our techniques are fairly generic and seem amenable to analyzing other approaches to syntax. Finally, while the existence of a particular PCFG that is problematic for these methods doesn’t necessarily imply that the difficulties will carry over to real-life data, the PCFGs that are used in our proofs closely track linguistic intuitions about difficult syntactic structures to infer: the parse depends on words that come much later in the sentence.",What is the impact of the amount and directionality of context a predictor uses for parsing decisions on the representational ability of neural approaches to model the max-likelihood parse of any given Probabilistic Context-Free Grammar?,2.0,2.0,1.0
54,The Limitations of Limited Context for Constituency Parsing,"Yuchen Li and Andrej Risteski. 2021. The Limitations of Limited Context for Constituency Parsing. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2675–2687, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.208.pdf,https://aclanthology.org/2021.acl-long.208/,"Incorporating syntax into neural approaches in NLP has a multitude of practical and scientific benefits. For instance, a language model that is syntax-aware is likely to be able to produce better samples; even a discriminative model like BERT with a syntax module could be used for core NLP tasks like unsupervised syntactic parsing. Rapid progress in recent years was arguably spurred on by the empirical success of the Parsing-Reading-Predict architecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM of (Shen et al., 2019). Most notably, this is the first time neural approaches were able to successfully perform unsupervised syntactic parsing (evaluated by various metrics like F-1 score). However, even heuristic (much less fully mathematical) understanding of why and when these architectures work is lagging severely behind. In this work, we answer representational questions raised by the architectures in (Shen et al., 2018a, 2019), as well as some transition-based syntax-aware language models (Dyer et al., 2016): what kind of syntactic structure can current neural approaches to syntax represent? Concretely, we ground this question in the sandbox of probabilistic context-free-grammars (PCFGs), and identify a key aspect of the representational power of these approaches: the amount and directionality of context that the predictor has access to when forced to make parsing decision. We show that with limited context (either bounded, or unidirectional), there are PCFGs, for which these approaches cannot represent the max-likelihood parse; conversely, if the context is unlimited, they can represent the max-likelihood parse of any PCFG.","Neural approaches have been steadily making their way to NLP in recent years. By and large however, the neural techniques that have been scaled-up the most and receive widespread usage do not explicitly try to encode discrete structure that is natural to language, e.g. syntax. The reason for this is perhaps not surprising: neural models have largely achieved substantial improvements in unsupervised settings, BERT (Devlin et al., 2019) being the defacto method for unsupervised pre-training in most NLP settings. On the other hand unsupervised syntactic tasks, e.g. unsupervised syntactic parsing, have long been known to be very difficult tasks (Htut et al., 2018). However, since incorporating syntax has been shown to improve language modeling (Kim et al., 2019b) as well as natural language inference (Chen et al., 2017; Pang et al., 2019; He et al., 2020), syntactic parsing remains important even in the current era when large pre-trained models, like BERT (Devlin et al., 2019), are available. Arguably, the breakthrough works in unsupervised constituency parsing in a neural manner were (Shen et al., 2018a, 2019), achieving F1 scores 42.8 and 49.4 on the WSJ Penn Treebank dataset (Htut et al., 2018; Shen et al., 2019). Both of these architectures, however (especially Shen et al., 2018a) are quite intricate, and it’s difficult to evaluate what their representational power is (i.e. what kinds of structure can they recover). Moreover, as subsequent more thorough evaluations show (Kim et al., 2019b,a), these methods still have a rather large performance gap with the oracle binary tree (which is the best binary parse tree according to F1-score) — raising the question of what is missing in these methods. We theoretically answer both questions raised in the prior paragraph. We quantify the representational power of two major frameworks in neural approaches to syntax: learning a syntactic distance (Shen et al., 2018a,b, 2019) and learning to parse through sequential transitions (Dyer et al., 2016; Chelba, 1997). To formalize our results, we consider the well-established sandbox of probabilistic context-free grammars (PCFGs). Namely, we ask: When is a neural model based on a syntactic distance or transitions able to represent the maxlikelihood parse of a sentence generated from a PCFG? We focus on a crucial “hyperparameter” common to practical implementations of both families of methods that turns out to govern the representational power: the amount and type of context the model is allowed to use when making its predictions. Briefly, for every position t in the sentence, syntactic distance models learn a distance dt to the previous token — the tree is then inferred from this distance; transition-based models iteratively construct the parse tree by deciding, at each position t, what operations to perform on a partial parse up to token t. A salient feature of both is the context, that is, which tokens is dt a function of (correspondingly, which tokens can the choice of operations at token t depend on)? We show that when the context is either bounded (that is, dt only depends on a bounded window around the t-th token) or unidirectional (that is, dt only considers the tokens to the left of the tth token), there are PCFGs for which no distance metric (correspondingly, no algorithm to choose the sequence of transitions) works. On the other hand, if the context is unbounded in both directions then both methods work: that is, for any parse, we can design a distance metric (correspondingly, a sequence of transitions) that recovers it. This is of considerable importance: in practical implementations the context is either bounded (e.g. in Shen et al., 2018a, the distance metric is parametrized by a convolutional kernel with a constant width) or unidirectional (e.g. in Shen et al., 2019, the distance metric is computed by a LSTM, which performs a left-to-right computation). This formally confirms a conjecture of Htut et al. (2018), who suggested that because these models commit to parsing decision in a left-to-right fashion and are trained as a part of a language model, it may be difficult for them to capture sufficiently complex syntactic dependencies. Our techniques are fairly generic and seem amenable to analyzing other approaches to syntax. Finally, while the existence of a particular PCFG that is problematic for these methods doesn’t necessarily imply that the difficulties will carry over to real-life data, the PCFGs that are used in our proofs closely track linguistic intuitions about difficult syntactic structures to infer: the parse depends on words that come much later in the sentence.","Can the max-likelihood parse of a sentence generated from a probabilistic context-free grammar (PCFG) be represented by neural models based on syntactic distance or transitions, considering the amount and type of context used in predictions?",1.0,1.0,1.0
55,The Limitations of Limited Context for Constituency Parsing,"Yuchen Li and Andrej Risteski. 2021. The Limitations of Limited Context for Constituency Parsing. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2675–2687, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.208.pdf,https://aclanthology.org/2021.acl-long.208/,"Incorporating syntax into neural approaches in NLP has a multitude of practical and scientific benefits. For instance, a language model that is syntax-aware is likely to be able to produce better samples; even a discriminative model like BERT with a syntax module could be used for core NLP tasks like unsupervised syntactic parsing. Rapid progress in recent years was arguably spurred on by the empirical success of the Parsing-Reading-Predict architecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM of (Shen et al., 2019). Most notably, this is the first time neural approaches were able to successfully perform unsupervised syntactic parsing (evaluated by various metrics like F-1 score). However, even heuristic (much less fully mathematical) understanding of why and when these architectures work is lagging severely behind. In this work, we answer representational questions raised by the architectures in (Shen et al., 2018a, 2019), as well as some transition-based syntax-aware language models (Dyer et al., 2016): what kind of syntactic structure can current neural approaches to syntax represent? Concretely, we ground this question in the sandbox of probabilistic context-free-grammars (PCFGs), and identify a key aspect of the representational power of these approaches: the amount and directionality of context that the predictor has access to when forced to make parsing decision. We show that with limited context (either bounded, or unidirectional), there are PCFGs, for which these approaches cannot represent the max-likelihood parse; conversely, if the context is unlimited, they can represent the max-likelihood parse of any PCFG.","Neural approaches have been steadily making their way to NLP in recent years. By and large however, the neural techniques that have been scaled-up the most and receive widespread usage do not explicitly try to encode discrete structure that is natural to language, e.g. syntax. The reason for this is perhaps not surprising: neural models have largely achieved substantial improvements in unsupervised settings, BERT (Devlin et al., 2019) being the defacto method for unsupervised pre-training in most NLP settings. On the other hand unsupervised syntactic tasks, e.g. unsupervised syntactic parsing, have long been known to be very difficult tasks (Htut et al., 2018). However, since incorporating syntax has been shown to improve language modeling (Kim et al., 2019b) as well as natural language inference (Chen et al., 2017; Pang et al., 2019; He et al., 2020), syntactic parsing remains important even in the current era when large pre-trained models, like BERT (Devlin et al., 2019), are available. Arguably, the breakthrough works in unsupervised constituency parsing in a neural manner were (Shen et al., 2018a, 2019), achieving F1 scores 42.8 and 49.4 on the WSJ Penn Treebank dataset (Htut et al., 2018; Shen et al., 2019). Both of these architectures, however (especially Shen et al., 2018a) are quite intricate, and it’s difficult to evaluate what their representational power is (i.e. what kinds of structure can they recover). Moreover, as subsequent more thorough evaluations show (Kim et al., 2019b,a), these methods still have a rather large performance gap with the oracle binary tree (which is the best binary parse tree according to F1-score) — raising the question of what is missing in these methods. We theoretically answer both questions raised in the prior paragraph. We quantify the representational power of two major frameworks in neural approaches to syntax: learning a syntactic distance (Shen et al., 2018a,b, 2019) and learning to parse through sequential transitions (Dyer et al., 2016; Chelba, 1997). To formalize our results, we consider the well-established sandbox of probabilistic context-free grammars (PCFGs). Namely, we ask: When is a neural model based on a syntactic distance or transitions able to represent the maxlikelihood parse of a sentence generated from a PCFG? We focus on a crucial “hyperparameter” common to practical implementations of both families of methods that turns out to govern the representational power: the amount and type of context the model is allowed to use when making its predictions. Briefly, for every position t in the sentence, syntactic distance models learn a distance dt to the previous token — the tree is then inferred from this distance; transition-based models iteratively construct the parse tree by deciding, at each position t, what operations to perform on a partial parse up to token t. A salient feature of both is the context, that is, which tokens is dt a function of (correspondingly, which tokens can the choice of operations at token t depend on)? We show that when the context is either bounded (that is, dt only depends on a bounded window around the t-th token) or unidirectional (that is, dt only considers the tokens to the left of the tth token), there are PCFGs for which no distance metric (correspondingly, no algorithm to choose the sequence of transitions) works. On the other hand, if the context is unbounded in both directions then both methods work: that is, for any parse, we can design a distance metric (correspondingly, a sequence of transitions) that recovers it. This is of considerable importance: in practical implementations the context is either bounded (e.g. in Shen et al., 2018a, the distance metric is parametrized by a convolutional kernel with a constant width) or unidirectional (e.g. in Shen et al., 2019, the distance metric is computed by a LSTM, which performs a left-to-right computation). This formally confirms a conjecture of Htut et al. (2018), who suggested that because these models commit to parsing decision in a left-to-right fashion and are trained as a part of a language model, it may be difficult for them to capture sufficiently complex syntactic dependencies. Our techniques are fairly generic and seem amenable to analyzing other approaches to syntax. Finally, while the existence of a particular PCFG that is problematic for these methods doesn’t necessarily imply that the difficulties will carry over to real-life data, the PCFGs that are used in our proofs closely track linguistic intuitions about difficult syntactic structures to infer: the parse depends on words that come much later in the sentence.","Can the representational power of neural architectures for syntactic parsing, in the context of probabilistic context-free grammars (PCFGs), be explained by the amount and directionality of context available to the model when making parsing decisions?",2.0,2.0,1.0
56,Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models,"Qingyu Tan, Hwee Tou Ng, and Lidong Bing. 2023. Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14820–14835, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.828.pdf,https://aclanthology.org/2023.acl-long.828/,"Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset TEMPREASON to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach1 .","In recent years, large language models (LLMs) have achieved significant success in many natural language processing (NLP) tasks, such as natural language understanding (NLU) (Fei et al., 2023), information extraction (IE) (Ding et al., 2023), and question answering (QA) (Ye et al., 2023; Zhao et al., 2023). Many facts and answers are dependent on their related time scopes, such as ‘What soccer club was Lionel Messi playing for?’. Chia et al. (2022) has pointed out around 48% of the qualifiers in the widely-used knowledge base Wikidata (Vrandeciˇ c and Krötzsch ´ , 2014) are time-related. That is, a significant number of the knowledge triples in the Wikidata KB have their expiry dates. Correct understanding of temporal concepts is crucial for language models to be successful in real-world applications. To examine the temporal reasoning capabilities of LLMs, the Time-Sensitive Question Answering (TSQA) task has been proposed and several evaluation datasets were published for research purposes. The Time-sensitive QA dataset (Chen et al., 2021) and the TEMPLAMA dataset (Dhingra et al., 2022) were constructed based on the Wikidata temporal KB. StreamingQA (Liska et al., 2022) was constructed by news article collections in English WMT challenges from 2007 to 2020. One consensus of prior work is that time-sensitive QA is a challenging task and its performance is still far below human performance. However, they did not provide a systematic analysis of LM’s temporal reasoning capability. In this paper, we aim to systematically analyze such capability and identify the strengths and weaknesses of LMs on temporal reasoning. As shown in Figure 1, humans’ understanding of temporal reasoning could be broken down into three levels: time-time (L1) relation, time-event (L2) relation, and event-event (L3) relation. For the understanding of time-time relations, humans can easily determine the relation between two timestamps t1 and t2 on the time axis. For example, when humans are asked ‘What is the year after 2020?’, they are able to answer this question without any external information. This level of temporal understanding could be regarded as a set of logic rules and is highly generalizable across different times, while this type of reasoning was overlooked in prior TSQA research (Ning et al., 2020; Chen et al., 2021; Dhingra et al., 2022). For time-event relations, the reasoning process requires grounding events to their specific time ranges. In this paper, the concept of events includes time-dependent facts. Humans either memorize a large number of timeevent pairs or need to rely on relevant contexts to deduce such relations. An example question is ‘What soccer club was Lionel Messi playing for in Dec 2010?’, where a time is specified in the question, and the answer changes based on the given time. If this question is posed to a person who is unfamiliar with sports, this person also needs external information to provide the answer. Answering this type of questions requires information retrieval and temporal grounding. For event-event relations, there are multiple reasoning paths to determine such relations. One possible path is to first identify the timestamps of different events and perform time-time reasoning. Another path is to search for the textual cues of relative relation, such as ‘before’, ‘after’, ‘during’, and ‘simultaneous’. We first conducted a simple preliminary experiment for probing LLM’s L1 temporal reasoning capability. We found that not only do LMs perform poorly on the time-time relation task, but they are also heavily biased in favor of contemporary years (2000 - 2020). This may be due to the imbalanced term frequencies in the pre-training corpora. Most LLMs (such as BERT, GPT, and T5) are pre-trained on raw texts from a snapshot at a specific timestamp, typically around 2018 to 2020. Therefore, the time expression vocabulary is highly dependent on term frequencies in the pre-training corpora. Typically, year tokens that occur frequently will have a smaller index in the vocabulary and the uncommon years generally have larger indices or will be split into subtokens. Take the T5 tokenizer as an example, the year ‘2014’ is tokenized as ‘2014’, however, the year ‘2021’ is tokenized as ‘20’ and ‘21’. This means that language models only learn the co-occurrences of time expressions and their context. Given such findings, we found that the recently proposed TSQA TEMPLAMA dataset has several main drawbacks. Firstly, the time span of the dataset is only from 2010 to 2020, which is a highly biased distribution in favor of LM. Secondly, it only focused on the questions of time-event relations. To overcome these shortcomings, we created a more comprehensive TSQA benchmark TEMPREASON, which spans a longer time range and all three types of temporal understanding. We conducted comprehensive experiments in closed book QA, open book QA, and reasoning QA settings. We found that the temporal reasoning capabilities of LLMs are highly variable with respect to the reference time in the question. LLMs perform well on the contemporary years and poorly on low-resource years. Moreover, we proposed a novel temporal learning framework based on temporal span extraction and time-sensitive reinforcement learning. Our proposed framework encourages LMs to generate temporally correct answers while penalizing predictions that do not satisfy the temporal constraints. Experimental results showed that our proposed benchmark TEMPREASON provides a more comprehensive evaluation for LM’s temporal reasoning capability and our model consistently outperforms strong baselines.","What are the precise strengths and weaknesses of large language models (LLMs) in temporal reasoning across different levels of time-related reasoning tasks, and how can a novel learning framework based on temporal span extraction and time-sensitive reinforcement learning enhance their performance in these tasks?",1.0,1.0,1.0
57,Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models,"Qingyu Tan, Hwee Tou Ng, and Lidong Bing. 2023. Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14820–14835, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.828.pdf,https://aclanthology.org/2023.acl-long.828/,"Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset TEMPREASON to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach1 .","In recent years, large language models (LLMs) have achieved significant success in many natural language processing (NLP) tasks, such as natural language understanding (NLU) (Fei et al., 2023), information extraction (IE) (Ding et al., 2023), and question answering (QA) (Ye et al., 2023; Zhao et al., 2023). Many facts and answers are dependent on their related time scopes, such as ‘What soccer club was Lionel Messi playing for?’. Chia et al. (2022) has pointed out around 48% of the qualifiers in the widely-used knowledge base Wikidata (Vrandeciˇ c and Krötzsch ´ , 2014) are time-related. That is, a significant number of the knowledge triples in the Wikidata KB have their expiry dates. Correct understanding of temporal concepts is crucial for language models to be successful in real-world applications. To examine the temporal reasoning capabilities of LLMs, the Time-Sensitive Question Answering (TSQA) task has been proposed and several evaluation datasets were published for research purposes. The Time-sensitive QA dataset (Chen et al., 2021) and the TEMPLAMA dataset (Dhingra et al., 2022) were constructed based on the Wikidata temporal KB. StreamingQA (Liska et al., 2022) was constructed by news article collections in English WMT challenges from 2007 to 2020. One consensus of prior work is that time-sensitive QA is a challenging task and its performance is still far below human performance. However, they did not provide a systematic analysis of LM’s temporal reasoning capability. In this paper, we aim to systematically analyze such capability and identify the strengths and weaknesses of LMs on temporal reasoning. As shown in Figure 1, humans’ understanding of temporal reasoning could be broken down into three levels: time-time (L1) relation, time-event (L2) relation, and event-event (L3) relation. For the understanding of time-time relations, humans can easily determine the relation between two timestamps t1 and t2 on the time axis. For example, when humans are asked ‘What is the year after 2020?’, they are able to answer this question without any external information. This level of temporal understanding could be regarded as a set of logic rules and is highly generalizable across different times, while this type of reasoning was overlooked in prior TSQA research (Ning et al., 2020; Chen et al., 2021; Dhingra et al., 2022). For time-event relations, the reasoning process requires grounding events to their specific time ranges. In this paper, the concept of events includes time-dependent facts. Humans either memorize a large number of timeevent pairs or need to rely on relevant contexts to deduce such relations. An example question is ‘What soccer club was Lionel Messi playing for in Dec 2010?’, where a time is specified in the question, and the answer changes based on the given time. If this question is posed to a person who is unfamiliar with sports, this person also needs external information to provide the answer. Answering this type of questions requires information retrieval and temporal grounding. For event-event relations, there are multiple reasoning paths to determine such relations. One possible path is to first identify the timestamps of different events and perform time-time reasoning. Another path is to search for the textual cues of relative relation, such as ‘before’, ‘after’, ‘during’, and ‘simultaneous’. We first conducted a simple preliminary experiment for probing LLM’s L1 temporal reasoning capability. We found that not only do LMs perform poorly on the time-time relation task, but they are also heavily biased in favor of contemporary years (2000 - 2020). This may be due to the imbalanced term frequencies in the pre-training corpora. Most LLMs (such as BERT, GPT, and T5) are pre-trained on raw texts from a snapshot at a specific timestamp, typically around 2018 to 2020. Therefore, the time expression vocabulary is highly dependent on term frequencies in the pre-training corpora. Typically, year tokens that occur frequently will have a smaller index in the vocabulary and the uncommon years generally have larger indices or will be split into subtokens. Take the T5 tokenizer as an example, the year ‘2014’ is tokenized as ‘2014’, however, the year ‘2021’ is tokenized as ‘20’ and ‘21’. This means that language models only learn the co-occurrences of time expressions and their context. Given such findings, we found that the recently proposed TSQA TEMPLAMA dataset has several main drawbacks. Firstly, the time span of the dataset is only from 2010 to 2020, which is a highly biased distribution in favor of LM. Secondly, it only focused on the questions of time-event relations. To overcome these shortcomings, we created a more comprehensive TSQA benchmark TEMPREASON, which spans a longer time range and all three types of temporal understanding. We conducted comprehensive experiments in closed book QA, open book QA, and reasoning QA settings. We found that the temporal reasoning capabilities of LLMs are highly variable with respect to the reference time in the question. LLMs perform well on the contemporary years and poorly on low-resource years. Moreover, we proposed a novel temporal learning framework based on temporal span extraction and time-sensitive reinforcement learning. Our proposed framework encourages LMs to generate temporally correct answers while penalizing predictions that do not satisfy the temporal constraints. Experimental results showed that our proposed benchmark TEMPREASON provides a more comprehensive evaluation for LM’s temporal reasoning capability and our model consistently outperforms strong baselines.",Can the temporal reasoning capability of large language models be improved by a novel learning framework based on temporal span extraction and time-sensitive reinforcement learning?,1.0,1.0,1.0
58,Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models,"Qingyu Tan, Hwee Tou Ng, and Lidong Bing. 2023. Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14820–14835, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.828.pdf,https://aclanthology.org/2023.acl-long.828/,"Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset TEMPREASON to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach1 .","In recent years, large language models (LLMs) have achieved significant success in many natural language processing (NLP) tasks, such as natural language understanding (NLU) (Fei et al., 2023), information extraction (IE) (Ding et al., 2023), and question answering (QA) (Ye et al., 2023; Zhao et al., 2023). Many facts and answers are dependent on their related time scopes, such as ‘What soccer club was Lionel Messi playing for?’. Chia et al. (2022) has pointed out around 48% of the qualifiers in the widely-used knowledge base Wikidata (Vrandeciˇ c and Krötzsch ´ , 2014) are time-related. That is, a significant number of the knowledge triples in the Wikidata KB have their expiry dates. Correct understanding of temporal concepts is crucial for language models to be successful in real-world applications. To examine the temporal reasoning capabilities of LLMs, the Time-Sensitive Question Answering (TSQA) task has been proposed and several evaluation datasets were published for research purposes. The Time-sensitive QA dataset (Chen et al., 2021) and the TEMPLAMA dataset (Dhingra et al., 2022) were constructed based on the Wikidata temporal KB. StreamingQA (Liska et al., 2022) was constructed by news article collections in English WMT challenges from 2007 to 2020. One consensus of prior work is that time-sensitive QA is a challenging task and its performance is still far below human performance. However, they did not provide a systematic analysis of LM’s temporal reasoning capability. In this paper, we aim to systematically analyze such capability and identify the strengths and weaknesses of LMs on temporal reasoning. As shown in Figure 1, humans’ understanding of temporal reasoning could be broken down into three levels: time-time (L1) relation, time-event (L2) relation, and event-event (L3) relation. For the understanding of time-time relations, humans can easily determine the relation between two timestamps t1 and t2 on the time axis. For example, when humans are asked ‘What is the year after 2020?’, they are able to answer this question without any external information. This level of temporal understanding could be regarded as a set of logic rules and is highly generalizable across different times, while this type of reasoning was overlooked in prior TSQA research (Ning et al., 2020; Chen et al., 2021; Dhingra et al., 2022). For time-event relations, the reasoning process requires grounding events to their specific time ranges. In this paper, the concept of events includes time-dependent facts. Humans either memorize a large number of timeevent pairs or need to rely on relevant contexts to deduce such relations. An example question is ‘What soccer club was Lionel Messi playing for in Dec 2010?’, where a time is specified in the question, and the answer changes based on the given time. If this question is posed to a person who is unfamiliar with sports, this person also needs external information to provide the answer. Answering this type of questions requires information retrieval and temporal grounding. For event-event relations, there are multiple reasoning paths to determine such relations. One possible path is to first identify the timestamps of different events and perform time-time reasoning. Another path is to search for the textual cues of relative relation, such as ‘before’, ‘after’, ‘during’, and ‘simultaneous’. We first conducted a simple preliminary experiment for probing LLM’s L1 temporal reasoning capability. We found that not only do LMs perform poorly on the time-time relation task, but they are also heavily biased in favor of contemporary years (2000 - 2020). This may be due to the imbalanced term frequencies in the pre-training corpora. Most LLMs (such as BERT, GPT, and T5) are pre-trained on raw texts from a snapshot at a specific timestamp, typically around 2018 to 2020. Therefore, the time expression vocabulary is highly dependent on term frequencies in the pre-training corpora. Typically, year tokens that occur frequently will have a smaller index in the vocabulary and the uncommon years generally have larger indices or will be split into subtokens. Take the T5 tokenizer as an example, the year ‘2014’ is tokenized as ‘2014’, however, the year ‘2021’ is tokenized as ‘20’ and ‘21’. This means that language models only learn the co-occurrences of time expressions and their context. Given such findings, we found that the recently proposed TSQA TEMPLAMA dataset has several main drawbacks. Firstly, the time span of the dataset is only from 2010 to 2020, which is a highly biased distribution in favor of LM. Secondly, it only focused on the questions of time-event relations. To overcome these shortcomings, we created a more comprehensive TSQA benchmark TEMPREASON, which spans a longer time range and all three types of temporal understanding. We conducted comprehensive experiments in closed book QA, open book QA, and reasoning QA settings. We found that the temporal reasoning capabilities of LLMs are highly variable with respect to the reference time in the question. LLMs perform well on the contemporary years and poorly on low-resource years. Moreover, we proposed a novel temporal learning framework based on temporal span extraction and time-sensitive reinforcement learning. Our proposed framework encourages LMs to generate temporally correct answers while penalizing predictions that do not satisfy the temporal constraints. Experimental results showed that our proposed benchmark TEMPREASON provides a more comprehensive evaluation for LM’s temporal reasoning capability and our model consistently outperforms strong baselines.","Can temporal reasoning capability of large language models be improved by introducing a comprehensive probing dataset, TEMPREASON, that includes questions of three temporal reasoning levels, and proposing a novel learning framework based on temporal span extraction and time-sensitive reinforcement learning?",1.0,2.0,1.0
59,A Spreading Activation Framework for Tracking Conceptual Complexity of Texts,"Ioana Hulpuș, Sanja Štajner, and Heiner Stuckenschmidt. 2019. A Spreading Activation Framework for Tracking Conceptual Complexity of Texts. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3878–3887, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1377.pdf,https://aclanthology.org/P19-1377/,"We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation. Using DBpedia knowledge graph as a proxy to long-term memory, mentioned concepts become activated and trigger further activation as the text is sequentially traversed. Drawing inspiration from psycholinguistic theories of reading comprehension, we model memory processes such as semantic priming, sentence wrap-up, and forgetting. We show that our models capture various aspects of conceptual text complexity and significantly outperform current state of the art.","Reading comprehension has long been linked to processes over semantic memory, such as semantic priming through spreading activation (Anderson, 1981; Collins and Loftus, 1975; Neely, 1991; Gulan and Valerjev, 2010). While psycholinguistic literature abounds in research and demonstration of such processes (Just and Carpenter, 1980; Kutas and Hillyard, 1984; Carroll and Slowiaczek, 1986), there is a gap in understanding if they can be modeled in an automated way for capturing the cognitive load required by texts. At the same time, the recent advances in the publication of encyclopedic knowledge graphs provide an unprecedented opportunity for modeling human knowledge at scale. We focus on conceptual complexity which, as opposed to lexical and syntactic complexity (Vajjala and Meurers, 2014; Ambati et al., 2016), has received very little attention so far. Conceptual complexity accounts for the background knowledge necessary to understand mentioned concepts as well as the implicit connections that the reader has to access between the mentioned concepts in order to fully understand a text. It plays an important role in making texts accessible to children, non-native speakers, as well as people with low literacy levels or intellectual disabilities (Arfe et al. ´ , 2017). Apart from being one of the main factors for understanding the story, conceptual complexity also influences the readers’ interest in the text: readers who lack relevant background knowledge have difficulties in understanding conceptually complex texts (Arfe et al. ´ , 2017; Benjamin, 2012), while high-knowledge readers need some obstacles (more conceptual complexity) to maintain their interest (Arfe et al. ´ , 2017; Benjamin, 2012; Kalyuga et al., 2003). Therefore, correctly estimating conceptual complexity of a text, and offering a reader a text of an appropriate cognitive load, is of utmost importance for: (1) ensuring correct understanding of a text; (2) maintaining the readers’ interest; and (3) promoting deeper-level processing and enhancing the readers knowledge. In this paper, we are building on top of the psycholinguistic findings that words are recognized faster if preceded by words related in meaning (semantic priming) (Gulan and Valerjev, 2010), and we adopt spreading activation theory as one of the main theories that tries to explain how priming occurs. Specifically, we introduce a framework that considers sequential text reading and models two simultaneous processes: (i) a spreading activation process that runs over long-term memory (approximated by the knowledge graph), activates concepts and transfers them to working memory, and (ii) a process that tracks concepts and their activation in working memory and subjects them to forgetting. We use the activation values of concepts in working memory at different points in the text in order to assess the amount of priming triggered by the text. Our hypothesis is that the higher these activation values (more priming), the lower the conceptual complexity. We validate our framework through extensive experiments, and show that the models we propose on top of it outperform state-of-the-art measures that aim to predict conceptual complexity.",Can the conceptual complexity of texts be assessed using an unsupervised approach based on spreading activation from the DBpedia knowledge graph?,0.0,1.0,0.0
60,A Spreading Activation Framework for Tracking Conceptual Complexity of Texts,"Ioana Hulpuș, Sanja Štajner, and Heiner Stuckenschmidt. 2019. A Spreading Activation Framework for Tracking Conceptual Complexity of Texts. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3878–3887, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1377.pdf,https://aclanthology.org/P19-1377/,"We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation. Using DBpedia knowledge graph as a proxy to long-term memory, mentioned concepts become activated and trigger further activation as the text is sequentially traversed. Drawing inspiration from psycholinguistic theories of reading comprehension, we model memory processes such as semantic priming, sentence wrap-up, and forgetting. We show that our models capture various aspects of conceptual text complexity and significantly outperform current state of the art.","Reading comprehension has long been linked to processes over semantic memory, such as semantic priming through spreading activation (Anderson, 1981; Collins and Loftus, 1975; Neely, 1991; Gulan and Valerjev, 2010). While psycholinguistic literature abounds in research and demonstration of such processes (Just and Carpenter, 1980; Kutas and Hillyard, 1984; Carroll and Slowiaczek, 1986), there is a gap in understanding if they can be modeled in an automated way for capturing the cognitive load required by texts. At the same time, the recent advances in the publication of encyclopedic knowledge graphs provide an unprecedented opportunity for modeling human knowledge at scale. We focus on conceptual complexity which, as opposed to lexical and syntactic complexity (Vajjala and Meurers, 2014; Ambati et al., 2016), has received very little attention so far. Conceptual complexity accounts for the background knowledge necessary to understand mentioned concepts as well as the implicit connections that the reader has to access between the mentioned concepts in order to fully understand a text. It plays an important role in making texts accessible to children, non-native speakers, as well as people with low literacy levels or intellectual disabilities (Arfe et al. ´ , 2017). Apart from being one of the main factors for understanding the story, conceptual complexity also influences the readers’ interest in the text: readers who lack relevant background knowledge have difficulties in understanding conceptually complex texts (Arfe et al. ´ , 2017; Benjamin, 2012), while high-knowledge readers need some obstacles (more conceptual complexity) to maintain their interest (Arfe et al. ´ , 2017; Benjamin, 2012; Kalyuga et al., 2003). Therefore, correctly estimating conceptual complexity of a text, and offering a reader a text of an appropriate cognitive load, is of utmost importance for: (1) ensuring correct understanding of a text; (2) maintaining the readers’ interest; and (3) promoting deeper-level processing and enhancing the readers knowledge. In this paper, we are building on top of the psycholinguistic findings that words are recognized faster if preceded by words related in meaning (semantic priming) (Gulan and Valerjev, 2010), and we adopt spreading activation theory as one of the main theories that tries to explain how priming occurs. Specifically, we introduce a framework that considers sequential text reading and models two simultaneous processes: (i) a spreading activation process that runs over long-term memory (approximated by the knowledge graph), activates concepts and transfers them to working memory, and (ii) a process that tracks concepts and their activation in working memory and subjects them to forgetting. We use the activation values of concepts in working memory at different points in the text in order to assess the amount of priming triggered by the text. Our hypothesis is that the higher these activation values (more priming), the lower the conceptual complexity. We validate our framework through extensive experiments, and show that the models we propose on top of it outperform state-of-the-art measures that aim to predict conceptual complexity.","Can the cognitive load required by texts, specifically in terms of conceptual complexity, be accurately assessed and modeled using an unsupervised approach that leverages the DBpedia knowledge graph, spreading activation theory, and a framework that simulates memory processes like semantic priming, sentence wrap-up, and forgetting?",0.0,2.0,0.0
61,ExCAR: Event Graph Knowledge Enhanced Explainable Causal Reasoning,"Li Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin. 2021. ExCAR: Event Graph Knowledge Enhanced Explainable Causal Reasoning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2354–2363, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.183.pdf,https://aclanthology.org/2021.acl-long.183/,"Prior work infers the causation between events mainly based on the knowledge induced from the annotated causal event pairs. However, additional evidence information intermediate to the cause and effect remains unexploited. By incorporating such information, the logical law behind the causality can be unveiled, and the interpretability and stability of the causal reasoning system can be improved. To facilitate this, we present an Event graph knowledge enhanced explainable CAusal Reasoning framework (ExCAR). ExCAR first acquires additional evidence information from a large-scale causal event graph as logical rules for causal reasoning. To learn the conditional probabilistic of logical rules, we propose the Conditional Markov Neural Logic Network (CMNLN) that combines the representation learning and structure learning of logical rules in an end-to-end differentiable manner. Experimental results demonstrate that ExCAR outperforms previous state-of-the-art methods. Adversarial evaluation shows the improved stability of ExCAR over baseline systems. Human evaluation shows that ExCAR can achieve a promising explainable performance.","Causal reasoning aims at understanding the general causal dependency between the cause and effect (Luo et al., 2016). Causality is commonly expressed by humans in the text of natural language, and is of great value for various Artificial Intelligence applications, such as question answering (Oh et al., 2013), event prediction (Li et al., 2018), and decision making (Sun et al., 2018). Previous work mainly learns causal knowledge from manually annotated causal event pairs, and achieves promising performances (Luo et al., 2016; Xie and Mu, 2019a; Li et al., 2019). However, recent works have questioned the seemingly superb performance for some of these studies (McCoy et al., 2019; Poliak et al., 2018; Gururangan et al., 2018). Specifically, training data may contain exploitable superficial cues that are correlative of the expected output. The main concern is that these works have not learned the underlying mechanism of causation so that their inference models are not stable enough and their results are not explainable. While we notice that there is plentiful evidence information outside the given corpus that can provide more clues for understanding the logical law of the causality. Figure 1 (a) exemplifies two clues I1 : Excess Liquidity and I2: Invest Demand Increase for explaining how a: Quantitative Easing gradually leads to b: House Price Increases. Without these important evidence information, on the other hand, as illustrated in Figure 1 (b), the causal relationship between ha, di and between hc, bi could not be deducted from the known causation between ha, bi and between hc, di. In contrast, with intermediate event I in hand, according to the transitivity of causality (Hall, 2000), the logic chain of ha ⇒ i ⇒ di and hc ⇒ i ⇒ bi could be naturally derived from the observed logic chain ha ⇒ i ⇒ bi and hc ⇒ i ⇒ di. To fully exploit the potential of the evidence information, we present an Event graph knowledge enhanced explainable CAusal Reasoning (ExCAR) framework. In particular, as illustrated in Figure 1 (c), given an input event pair hC, Ei, ExCAR firstly retrieves external evidence events such as I1, I2 from a large-scale causal event graph (CEG, a causal knowledge base constructed by us), and defines the causation between C, I1, I2, E as a set of logical rules (e.g., ri = (Ei ⇒ Ii)), which rules are useful representations for the causal reasoning task because they are interpretable and can provide insight to inference results. Pearl (2001) pointed out that the underlying logic of causality is a probabilistic logic. The advantage of using a probabilistic logic is that by equipping logical rules with probability, one can better model statistically complex and noisy data. However, learning such probabilistic logical rules in the causal reasoning scenario is quite difficult —- it requires modeling the superimposed causal effect for each logical rule. Different from firstorder logical rules induced from some knowledge graphs, the probability of the logical rule (i.e. the causal strength of the cause-effect pair) in causal reasoning is uncertain, which varies with different antecedents. For example, as shown in Figure 1 (d), with the antecedent A: Catch a cold, a fever can hardly lead to life danger. While if fever is caused by the antecedent B: Septicemia, it can result in life danger with a high probability. To address this issue, we further propose a Conditional Markov Neural Logic Network (CMNLN) for learning the conditional causal dependency of logical rules in an end-to-end fashion. Specifically, CMNLN first decomposes the logical rules set derived from the CEG into several distinct logic chains and learns a distributed representation for each logic chain in an embedding space. Subsequently, CMNLN estimates the conditional probability of each logical rule by an antecedent-aware potential function. Then CMNLN computes the probability of each logic chain by multiplying the probabilities of logical rules in the chain. Finally, CMNLN predicts the causality score of the input event pair based on the disjunction of chain-level causality information. Experimental results show that our approach can effectively utilize the event graph information to improve the accuracy of causal reasoning by more than 5%. Adversarial evaluation and human evaluation show that ExCAR can achieve stable and explainable performance. The code is released at https://github.com/sjcfr/ExCAR.",How can additional evidence information intermediate to cause and effect be incorporated into causal reasoning models to unveil the logical law behind causality and improve the interpretability and stability of these models?,1.0,1.0,1.0
62,ExCAR: Event Graph Knowledge Enhanced Explainable Causal Reasoning,"Li Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin. 2021. ExCAR: Event Graph Knowledge Enhanced Explainable Causal Reasoning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2354–2363, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.183.pdf,https://aclanthology.org/2021.acl-long.183/,"Prior work infers the causation between events mainly based on the knowledge induced from the annotated causal event pairs. However, additional evidence information intermediate to the cause and effect remains unexploited. By incorporating such information, the logical law behind the causality can be unveiled, and the interpretability and stability of the causal reasoning system can be improved. To facilitate this, we present an Event graph knowledge enhanced explainable CAusal Reasoning framework (ExCAR). ExCAR first acquires additional evidence information from a large-scale causal event graph as logical rules for causal reasoning. To learn the conditional probabilistic of logical rules, we propose the Conditional Markov Neural Logic Network (CMNLN) that combines the representation learning and structure learning of logical rules in an end-to-end differentiable manner. Experimental results demonstrate that ExCAR outperforms previous state-of-the-art methods. Adversarial evaluation shows the improved stability of ExCAR over baseline systems. Human evaluation shows that ExCAR can achieve a promising explainable performance.","Causal reasoning aims at understanding the general causal dependency between the cause and effect (Luo et al., 2016). Causality is commonly expressed by humans in the text of natural language, and is of great value for various Artificial Intelligence applications, such as question answering (Oh et al., 2013), event prediction (Li et al., 2018), and decision making (Sun et al., 2018). Previous work mainly learns causal knowledge from manually annotated causal event pairs, and achieves promising performances (Luo et al., 2016; Xie and Mu, 2019a; Li et al., 2019). However, recent works have questioned the seemingly superb performance for some of these studies (McCoy et al., 2019; Poliak et al., 2018; Gururangan et al., 2018). Specifically, training data may contain exploitable superficial cues that are correlative of the expected output. The main concern is that these works have not learned the underlying mechanism of causation so that their inference models are not stable enough and their results are not explainable. While we notice that there is plentiful evidence information outside the given corpus that can provide more clues for understanding the logical law of the causality. Figure 1 (a) exemplifies two clues I1 : Excess Liquidity and I2: Invest Demand Increase for explaining how a: Quantitative Easing gradually leads to b: House Price Increases. Without these important evidence information, on the other hand, as illustrated in Figure 1 (b), the causal relationship between ha, di and between hc, bi could not be deducted from the known causation between ha, bi and between hc, di. In contrast, with intermediate event I in hand, according to the transitivity of causality (Hall, 2000), the logic chain of ha ⇒ i ⇒ di and hc ⇒ i ⇒ bi could be naturally derived from the observed logic chain ha ⇒ i ⇒ bi and hc ⇒ i ⇒ di. To fully exploit the potential of the evidence information, we present an Event graph knowledge enhanced explainable CAusal Reasoning (ExCAR) framework. In particular, as illustrated in Figure 1 (c), given an input event pair hC, Ei, ExCAR firstly retrieves external evidence events such as I1, I2 from a large-scale causal event graph (CEG, a causal knowledge base constructed by us), and defines the causation between C, I1, I2, E as a set of logical rules (e.g., ri = (Ei ⇒ Ii)), which rules are useful representations for the causal reasoning task because they are interpretable and can provide insight to inference results. Pearl (2001) pointed out that the underlying logic of causality is a probabilistic logic. The advantage of using a probabilistic logic is that by equipping logical rules with probability, one can better model statistically complex and noisy data. However, learning such probabilistic logical rules in the causal reasoning scenario is quite difficult —- it requires modeling the superimposed causal effect for each logical rule. Different from firstorder logical rules induced from some knowledge graphs, the probability of the logical rule (i.e. the causal strength of the cause-effect pair) in causal reasoning is uncertain, which varies with different antecedents. For example, as shown in Figure 1 (d), with the antecedent A: Catch a cold, a fever can hardly lead to life danger. While if fever is caused by the antecedent B: Septicemia, it can result in life danger with a high probability. To address this issue, we further propose a Conditional Markov Neural Logic Network (CMNLN) for learning the conditional causal dependency of logical rules in an end-to-end fashion. Specifically, CMNLN first decomposes the logical rules set derived from the CEG into several distinct logic chains and learns a distributed representation for each logic chain in an embedding space. Subsequently, CMNLN estimates the conditional probability of each logical rule by an antecedent-aware potential function. Then CMNLN computes the probability of each logic chain by multiplying the probabilities of logical rules in the chain. Finally, CMNLN predicts the causality score of the input event pair based on the disjunction of chain-level causality information. Experimental results show that our approach can effectively utilize the event graph information to improve the accuracy of causal reasoning by more than 5%. Adversarial evaluation and human evaluation show that ExCAR can achieve stable and explainable performance. The code is released at https://github.com/sjcfr/ExCAR.",Can causal reasoning be improved by incorporating intermediate evidence information from a large-scale causal event graph and applying a Conditional Markov Neural Logic Network (CMNLN)?,1.0,1.0,1.0
63,ExCAR: Event Graph Knowledge Enhanced Explainable Causal Reasoning,"Li Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin. 2021. ExCAR: Event Graph Knowledge Enhanced Explainable Causal Reasoning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2354–2363, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.183.pdf,https://aclanthology.org/2021.acl-long.183/,"Prior work infers the causation between events mainly based on the knowledge induced from the annotated causal event pairs. However, additional evidence information intermediate to the cause and effect remains unexploited. By incorporating such information, the logical law behind the causality can be unveiled, and the interpretability and stability of the causal reasoning system can be improved. To facilitate this, we present an Event graph knowledge enhanced explainable CAusal Reasoning framework (ExCAR). ExCAR first acquires additional evidence information from a large-scale causal event graph as logical rules for causal reasoning. To learn the conditional probabilistic of logical rules, we propose the Conditional Markov Neural Logic Network (CMNLN) that combines the representation learning and structure learning of logical rules in an end-to-end differentiable manner. Experimental results demonstrate that ExCAR outperforms previous state-of-the-art methods. Adversarial evaluation shows the improved stability of ExCAR over baseline systems. Human evaluation shows that ExCAR can achieve a promising explainable performance.","Causal reasoning aims at understanding the general causal dependency between the cause and effect (Luo et al., 2016). Causality is commonly expressed by humans in the text of natural language, and is of great value for various Artificial Intelligence applications, such as question answering (Oh et al., 2013), event prediction (Li et al., 2018), and decision making (Sun et al., 2018). Previous work mainly learns causal knowledge from manually annotated causal event pairs, and achieves promising performances (Luo et al., 2016; Xie and Mu, 2019a; Li et al., 2019). However, recent works have questioned the seemingly superb performance for some of these studies (McCoy et al., 2019; Poliak et al., 2018; Gururangan et al., 2018). Specifically, training data may contain exploitable superficial cues that are correlative of the expected output. The main concern is that these works have not learned the underlying mechanism of causation so that their inference models are not stable enough and their results are not explainable. While we notice that there is plentiful evidence information outside the given corpus that can provide more clues for understanding the logical law of the causality. Figure 1 (a) exemplifies two clues I1 : Excess Liquidity and I2: Invest Demand Increase for explaining how a: Quantitative Easing gradually leads to b: House Price Increases. Without these important evidence information, on the other hand, as illustrated in Figure 1 (b), the causal relationship between ha, di and between hc, bi could not be deducted from the known causation between ha, bi and between hc, di. In contrast, with intermediate event I in hand, according to the transitivity of causality (Hall, 2000), the logic chain of ha ⇒ i ⇒ di and hc ⇒ i ⇒ bi could be naturally derived from the observed logic chain ha ⇒ i ⇒ bi and hc ⇒ i ⇒ di. To fully exploit the potential of the evidence information, we present an Event graph knowledge enhanced explainable CAusal Reasoning (ExCAR) framework. In particular, as illustrated in Figure 1 (c), given an input event pair hC, Ei, ExCAR firstly retrieves external evidence events such as I1, I2 from a large-scale causal event graph (CEG, a causal knowledge base constructed by us), and defines the causation between C, I1, I2, E as a set of logical rules (e.g., ri = (Ei ⇒ Ii)), which rules are useful representations for the causal reasoning task because they are interpretable and can provide insight to inference results. Pearl (2001) pointed out that the underlying logic of causality is a probabilistic logic. The advantage of using a probabilistic logic is that by equipping logical rules with probability, one can better model statistically complex and noisy data. However, learning such probabilistic logical rules in the causal reasoning scenario is quite difficult —- it requires modeling the superimposed causal effect for each logical rule. Different from firstorder logical rules induced from some knowledge graphs, the probability of the logical rule (i.e. the causal strength of the cause-effect pair) in causal reasoning is uncertain, which varies with different antecedents. For example, as shown in Figure 1 (d), with the antecedent A: Catch a cold, a fever can hardly lead to life danger. While if fever is caused by the antecedent B: Septicemia, it can result in life danger with a high probability. To address this issue, we further propose a Conditional Markov Neural Logic Network (CMNLN) for learning the conditional causal dependency of logical rules in an end-to-end fashion. Specifically, CMNLN first decomposes the logical rules set derived from the CEG into several distinct logic chains and learns a distributed representation for each logic chain in an embedding space. Subsequently, CMNLN estimates the conditional probability of each logical rule by an antecedent-aware potential function. Then CMNLN computes the probability of each logic chain by multiplying the probabilities of logical rules in the chain. Finally, CMNLN predicts the causality score of the input event pair based on the disjunction of chain-level causality information. Experimental results show that our approach can effectively utilize the event graph information to improve the accuracy of causal reasoning by more than 5%. Adversarial evaluation and human evaluation show that ExCAR can achieve stable and explainable performance. The code is released at https://github.com/sjcfr/ExCAR.","Can the lack of interpretability and stability in prior causal reasoning work, due to reliance on annotated causal event pairs without considering additional evidence information, be addressed by incorporating evidence from a large-scale causal event graph using the Event graph knowledge enhanced explainable CAusal Reasoning framework (ExCAR) along with the Conditional Markov Neural Logic Network (CMNLN) to unveil the logical law behind causality?",2.0,2.0,1.0
64,Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering,"Ahjeong Seo, Gi-Cheon Kang, Joonhan Park, and Byoung-Tak Zhang. 2021. Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6167–6177, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.481.pdf,https://aclanthology.org/2021.acl-long.481/,"Video Question Answering is a task which requires an AI agent to answer questions grounded in video. This task entails three key challenges: (1) understand the intention of various questions, (2) capturing various elements of the input video (e.g., object, action, causality), and (3) cross-modal grounding between language and vision information. We propose Motion-Appearance Synergistic Networks (MASN), which embed two crossmodal features grounded on motion and appearance information and selectively utilize them depending on the question’s intentions. MASN consists of a motion module, an appearance module, and a motion-appearance fusion module. The motion module computes the action-oriented cross-modal joint representations, while the appearance module focuses on the appearance aspect of the input video. Finally, the motion-appearance fusion module takes each output of the motion module and the appearance module as input, and performs question-guided fusion. As a result, MASN achieves new state-of-the-art performance on the TGIF-QA and MSVD-QA datasets. We also conduct qualitative analysis by visualizing the inference results of MASN. The code is available at https://github.com/ ahjeongseo/MASN-pytorch.","Recently, research in natural language processing and computer vision has made significant progress in artificial intelligence (AI). Thanks to this, visionlanguage tasks such as image captioning (Xu et al., 2015), visual question answering (VQA) (Antol et al., 2015; Goyal et al., 2017), and visual commonsense reasoning (VCR) (Zellers et al., 2019) have been introduced to the research community, along with some benchmark datasets. In particular, video question answering (video QA) tasks (Xu et al., 2016; Jang et al., 2017; Lei et al., 2018; Yu et al., 2019; Choi et al., 2020) have been proposed with the goal of reasoning over higher-level visionlanguage interactions. In contrast to QA tasks based on static images, the questions presented in the video QA dataset vary from frame-level questions regarding the appearance of objects (e.g., what is the color of the hat?) to questions regarding action and causality (e.g., what does the man do after opening a door?). There are three crucial challenges in video QA: (1) understand the intention of various questions, (2) capturing various elements of the input video (e.g., object, action, and causality), and (3) crossmodal grounding between language and vision information. To tackle these challenges, previous studies (Li et al., 2019; Jiang et al., 2020; Huang et al., 2020) have mainly explored this task by jointly embedding the features from the pre-trained word embedding model (Pennington et al., 2014) and the object detection models (He et al., 2016; Ren et al., 2016). However, as discussed in (Gao et al., 2018), the use of the visual features extracted from the object detection models suffers from motion analysis since the object detection model lacks temporal modeling. To enforce the motion analysis, a few approaches (Xu et al., 2017; Gao et al., 2018) have employed additional visual features (Tran et al., 2015) (i.e., motion features) which were widely used in the action recognition domain, but their reasoning capability is still limited. They typically employed recurrent models (e.g., LSTM) to embed a long sequence of the visual features. Due to the problem of long-term dependency in recurrent models (Bengio et al., 1993), their proposed methods may fail to learn dependencies between distant features. In this paper, we propose Motion-Appearance Synergistic Networks (MASN) for video question answering which consist of three kinds of modules: the motion module, the appearance module, and the motion-appearance fusion module. As shown in Figure 1, the motion module and the appearance module aim to embed rich cross-modal representations. These two modules have the same architecture except that the motion module takes the motion features extracted from I3D as visual features and the appearance module utilizes the appearance features extracted from ResNet. Each of these modules first constructs the object graphs via graph convolutional networks (GCN) to compute the relationships among objects in each visual feature. Then, the vision-question interaction module performs cross-modal grounding between the output of the GCNs and the question features. The motion module and the appearance module each yield cross-modal representations of the motion and the appearance aspects of the input video respectively. The motion-appearance fusion module finally integrates these two features based on the question features. The main contributions of our paper are as follows. First, we propose Motion-Appearance Synergistic Networks (MASN) for video question answering based on three modules, the motion module, the appearance module, and the motionappearance fusion module. Second, we validate MASN on the large-scale video question answering datasets TGIF-QA, MSVD-QA, and MSRVTT-QA. MASN achieves the new state-of-the-art performance on TGIF-QA and MSVD-QA. We perform ablation studies to validate the effectiveness of our proposed methods. Finally, we conduct a qualitative analysis of MASN by visualizing inference results.",How does the Motion-Appearance Synergistic Networks (MASN) approach improve video question answering performance through its integration of motion and appearance information compared to previous models that struggle with motion analysis and long-term dependency issues?,1.0,1.0,1.0
65,Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering,"Ahjeong Seo, Gi-Cheon Kang, Joonhan Park, and Byoung-Tak Zhang. 2021. Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6167–6177, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.481.pdf,https://aclanthology.org/2021.acl-long.481/,"Video Question Answering is a task which requires an AI agent to answer questions grounded in video. This task entails three key challenges: (1) understand the intention of various questions, (2) capturing various elements of the input video (e.g., object, action, causality), and (3) cross-modal grounding between language and vision information. We propose Motion-Appearance Synergistic Networks (MASN), which embed two crossmodal features grounded on motion and appearance information and selectively utilize them depending on the question’s intentions. MASN consists of a motion module, an appearance module, and a motion-appearance fusion module. The motion module computes the action-oriented cross-modal joint representations, while the appearance module focuses on the appearance aspect of the input video. Finally, the motion-appearance fusion module takes each output of the motion module and the appearance module as input, and performs question-guided fusion. As a result, MASN achieves new state-of-the-art performance on the TGIF-QA and MSVD-QA datasets. We also conduct qualitative analysis by visualizing the inference results of MASN. The code is available at https://github.com/ ahjeongseo/MASN-pytorch.","Recently, research in natural language processing and computer vision has made significant progress in artificial intelligence (AI). Thanks to this, visionlanguage tasks such as image captioning (Xu et al., 2015), visual question answering (VQA) (Antol et al., 2015; Goyal et al., 2017), and visual commonsense reasoning (VCR) (Zellers et al., 2019) have been introduced to the research community, along with some benchmark datasets. In particular, video question answering (video QA) tasks (Xu et al., 2016; Jang et al., 2017; Lei et al., 2018; Yu et al., 2019; Choi et al., 2020) have been proposed with the goal of reasoning over higher-level visionlanguage interactions. In contrast to QA tasks based on static images, the questions presented in the video QA dataset vary from frame-level questions regarding the appearance of objects (e.g., what is the color of the hat?) to questions regarding action and causality (e.g., what does the man do after opening a door?). There are three crucial challenges in video QA: (1) understand the intention of various questions, (2) capturing various elements of the input video (e.g., object, action, and causality), and (3) crossmodal grounding between language and vision information. To tackle these challenges, previous studies (Li et al., 2019; Jiang et al., 2020; Huang et al., 2020) have mainly explored this task by jointly embedding the features from the pre-trained word embedding model (Pennington et al., 2014) and the object detection models (He et al., 2016; Ren et al., 2016). However, as discussed in (Gao et al., 2018), the use of the visual features extracted from the object detection models suffers from motion analysis since the object detection model lacks temporal modeling. To enforce the motion analysis, a few approaches (Xu et al., 2017; Gao et al., 2018) have employed additional visual features (Tran et al., 2015) (i.e., motion features) which were widely used in the action recognition domain, but their reasoning capability is still limited. They typically employed recurrent models (e.g., LSTM) to embed a long sequence of the visual features. Due to the problem of long-term dependency in recurrent models (Bengio et al., 1993), their proposed methods may fail to learn dependencies between distant features. In this paper, we propose Motion-Appearance Synergistic Networks (MASN) for video question answering which consist of three kinds of modules: the motion module, the appearance module, and the motion-appearance fusion module. As shown in Figure 1, the motion module and the appearance module aim to embed rich cross-modal representations. These two modules have the same architecture except that the motion module takes the motion features extracted from I3D as visual features and the appearance module utilizes the appearance features extracted from ResNet. Each of these modules first constructs the object graphs via graph convolutional networks (GCN) to compute the relationships among objects in each visual feature. Then, the vision-question interaction module performs cross-modal grounding between the output of the GCNs and the question features. The motion module and the appearance module each yield cross-modal representations of the motion and the appearance aspects of the input video respectively. The motion-appearance fusion module finally integrates these two features based on the question features. The main contributions of our paper are as follows. First, we propose Motion-Appearance Synergistic Networks (MASN) for video question answering based on three modules, the motion module, the appearance module, and the motionappearance fusion module. Second, we validate MASN on the large-scale video question answering datasets TGIF-QA, MSVD-QA, and MSRVTT-QA. MASN achieves the new state-of-the-art performance on TGIF-QA and MSVD-QA. We perform ablation studies to validate the effectiveness of our proposed methods. Finally, we conduct a qualitative analysis of MASN by visualizing inference results.","Can the challenges of understanding question intention, capturing variegated elements of videos, and achieving cross-modal grounding between language and vision in video question answering be solved by Motion-Appearance Synergistic Networks (MASN)?",0.0,1.0,1.0
66,Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering,"Ahjeong Seo, Gi-Cheon Kang, Joonhan Park, and Byoung-Tak Zhang. 2021. Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6167–6177, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.481.pdf,https://aclanthology.org/2021.acl-long.481/,"Video Question Answering is a task which requires an AI agent to answer questions grounded in video. This task entails three key challenges: (1) understand the intention of various questions, (2) capturing various elements of the input video (e.g., object, action, causality), and (3) cross-modal grounding between language and vision information. We propose Motion-Appearance Synergistic Networks (MASN), which embed two crossmodal features grounded on motion and appearance information and selectively utilize them depending on the question’s intentions. MASN consists of a motion module, an appearance module, and a motion-appearance fusion module. The motion module computes the action-oriented cross-modal joint representations, while the appearance module focuses on the appearance aspect of the input video. Finally, the motion-appearance fusion module takes each output of the motion module and the appearance module as input, and performs question-guided fusion. As a result, MASN achieves new state-of-the-art performance on the TGIF-QA and MSVD-QA datasets. We also conduct qualitative analysis by visualizing the inference results of MASN. The code is available at https://github.com/ ahjeongseo/MASN-pytorch.","Recently, research in natural language processing and computer vision has made significant progress in artificial intelligence (AI). Thanks to this, visionlanguage tasks such as image captioning (Xu et al., 2015), visual question answering (VQA) (Antol et al., 2015; Goyal et al., 2017), and visual commonsense reasoning (VCR) (Zellers et al., 2019) have been introduced to the research community, along with some benchmark datasets. In particular, video question answering (video QA) tasks (Xu et al., 2016; Jang et al., 2017; Lei et al., 2018; Yu et al., 2019; Choi et al., 2020) have been proposed with the goal of reasoning over higher-level visionlanguage interactions. In contrast to QA tasks based on static images, the questions presented in the video QA dataset vary from frame-level questions regarding the appearance of objects (e.g., what is the color of the hat?) to questions regarding action and causality (e.g., what does the man do after opening a door?). There are three crucial challenges in video QA: (1) understand the intention of various questions, (2) capturing various elements of the input video (e.g., object, action, and causality), and (3) crossmodal grounding between language and vision information. To tackle these challenges, previous studies (Li et al., 2019; Jiang et al., 2020; Huang et al., 2020) have mainly explored this task by jointly embedding the features from the pre-trained word embedding model (Pennington et al., 2014) and the object detection models (He et al., 2016; Ren et al., 2016). However, as discussed in (Gao et al., 2018), the use of the visual features extracted from the object detection models suffers from motion analysis since the object detection model lacks temporal modeling. To enforce the motion analysis, a few approaches (Xu et al., 2017; Gao et al., 2018) have employed additional visual features (Tran et al., 2015) (i.e., motion features) which were widely used in the action recognition domain, but their reasoning capability is still limited. They typically employed recurrent models (e.g., LSTM) to embed a long sequence of the visual features. Due to the problem of long-term dependency in recurrent models (Bengio et al., 1993), their proposed methods may fail to learn dependencies between distant features. In this paper, we propose Motion-Appearance Synergistic Networks (MASN) for video question answering which consist of three kinds of modules: the motion module, the appearance module, and the motion-appearance fusion module. As shown in Figure 1, the motion module and the appearance module aim to embed rich cross-modal representations. These two modules have the same architecture except that the motion module takes the motion features extracted from I3D as visual features and the appearance module utilizes the appearance features extracted from ResNet. Each of these modules first constructs the object graphs via graph convolutional networks (GCN) to compute the relationships among objects in each visual feature. Then, the vision-question interaction module performs cross-modal grounding between the output of the GCNs and the question features. The motion module and the appearance module each yield cross-modal representations of the motion and the appearance aspects of the input video respectively. The motion-appearance fusion module finally integrates these two features based on the question features. The main contributions of our paper are as follows. First, we propose Motion-Appearance Synergistic Networks (MASN) for video question answering based on three modules, the motion module, the appearance module, and the motionappearance fusion module. Second, we validate MASN on the large-scale video question answering datasets TGIF-QA, MSVD-QA, and MSRVTT-QA. MASN achieves the new state-of-the-art performance on TGIF-QA and MSVD-QA. We perform ablation studies to validate the effectiveness of our proposed methods. Finally, we conduct a qualitative analysis of MASN by visualizing inference results.","Can the challenges of Video Question Answering tasks, which include understanding various question intentions, capturing relevant input video elements, and achieving cross-modal grounding between language and vision information, be addressed effectively by the Motion-Appearance Synergistic Networks (MASN) that integrate motion and appearance information through specialized modules guided by the question's intentions?",0.0,1.0,1.0
67,Translationese as a Language in “Multilingual” NMT,"Parker Riley, Isaac Caswell, Markus Freitag, and David Grangier. 2020. Translationese as a Language in “Multilingual” NMT. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7737–7746, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.691.pdf,https://aclanthology.org/2020.acl-main.691/,"Machine translation has an undesirable propensity to produce “translationese” artifacts, which can lead to higher BLEU scores while being liked less by human raters. Motivated by this, we model translationese and original (i.e. natural) text as separate languages in a multilingual model, and pose the question: can we perform zero-shot translation between original source text and original target text? There is no data with original source and original target, so we train a sentence-level classifier to distinguish translationese from original target text, and use this classifier to tag the training data for an NMT model. Using this technique we bias the model to produce more natural outputs at test time, yielding gains in human evaluation scores on both adequacy and fluency. Additionally, we demonstrate that it is possible to bias the model to produce translationese and game the BLEU score, increasing it while decreasing human-rated quality. We analyze these outputs using metrics measuring the degree of translationese, and present an analysis of the volatility of heuristic-based train-data tagging.","“Translationese” is a term that refers to artifacts present in text that was translated into a given language that distinguish it from text originally written in that language (Gellerstam, 1986). These artifacts include lexical and word order choices that are influenced by the source language (Gellerstam, 1996) as well as the use of more explicit and simpler constructions (Baker et al., 1993). These differences between translated and original text mean that the direction in which parallel data (bitext) was translated is potentially important for machine translation (MT) systems. Most parallel data is either source-original (the source was translated into the target) or target-original (the target was translated into the source), though sometimes neither side is original because both were translated from a third language. Figure 1 illustrates the four possible combinations of translated and original source and target data. Recent work has examined the impact of translationese in MT evaluation, using the WMT evaluation campaign as the most prominent example. From 2014 through 2018, WMT test sets were constructed such that 50% of the sentence pairs are source-original (upper right quadrant of Figure 1) and the rest are target-original (lower left quadrant). Toral et al. (2018), Zhang and Toral (2019), and Graham et al. (2019) have examined the effect of this testing setup on MT evaluation, and have all argued that target-original test data should not be included in future evaluation campaigns because the translationese source is too easy to translate. While target-original test data does have the downside of a translationese source side, recent work has also shown that human raters prefer MT output that is closer in distribution to original target text than translationese (Freitag et al., 2019). This indicates that the target side of test data should also be original (upper left quadrant of Figure 1); however, it is unclear how to produce high-quality test data (let alone training data) that is simultaneously sourceand target-original. Because of this lack of original-to-original sentence pairs, we frame this as a zero-shot translation task, where translationese and original text are distinct languages or domains. We adapt techniques from zero-shot translation with multilingual models (Johnson et al., 2016), where the training pairs are tagged with a reserved token corresponding to the domain of the target side: translationese or original text. Tagging is helpful when the training set mixes data of different types by allowing the model to 1) see each pair’s type in training to preserve distinct behaviors and avoid regressing to a mean/dominant prediction across data types, and 2) elicit different behavior in inference, i.e. providing a tag at test time yields predictions resembling a specific data type. We then investigate what happens when the input is an original sentence in the source language and the model’s output is also biased to be original, a scenario never observed in training. Tagging in this fashion is not trivial, as most MT training sets do not annotate which pairs are sourceoriginal and which are target-original1 , so in order to distinguish them we train binary classifiers to distinguish original and translated target text. Finally, we perform several analyses of tagging these “languages” and demonstrate that tagged back-translation (Caswell et al., 2019) can be framed as a simplified version of our method, and thereby improved by targeted decoding. Our contributions are as follows: 1. We propose two methods to train translationese classifiers using only monolingual text, coupled with synthetic text produced by machine translation. 2. Using only original→translationese and translationese→original training pairs, we apply techniques from zero-shot multilingual MT to enable original→original translation. 3. We demonstrate with human evaluations that this technique improves translation quality, both in terms of fluency and adequacy. 4. We show that biasing the model to instead produce translationese outputs inflates BLEU scores while harming quality as measured by human evaluations.",Can zero-shot translation between original source text and original target text be effectively performed by modeling translationese and original text as distinct languages within a multilingual machine translation model?,0.0,1.0,0.0
68,Translationese as a Language in “Multilingual” NMT,"Parker Riley, Isaac Caswell, Markus Freitag, and David Grangier. 2020. Translationese as a Language in “Multilingual” NMT. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7737–7746, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.691.pdf,https://aclanthology.org/2020.acl-main.691/,"Machine translation has an undesirable propensity to produce “translationese” artifacts, which can lead to higher BLEU scores while being liked less by human raters. Motivated by this, we model translationese and original (i.e. natural) text as separate languages in a multilingual model, and pose the question: can we perform zero-shot translation between original source text and original target text? There is no data with original source and original target, so we train a sentence-level classifier to distinguish translationese from original target text, and use this classifier to tag the training data for an NMT model. Using this technique we bias the model to produce more natural outputs at test time, yielding gains in human evaluation scores on both adequacy and fluency. Additionally, we demonstrate that it is possible to bias the model to produce translationese and game the BLEU score, increasing it while decreasing human-rated quality. We analyze these outputs using metrics measuring the degree of translationese, and present an analysis of the volatility of heuristic-based train-data tagging.","“Translationese” is a term that refers to artifacts present in text that was translated into a given language that distinguish it from text originally written in that language (Gellerstam, 1986). These artifacts include lexical and word order choices that are influenced by the source language (Gellerstam, 1996) as well as the use of more explicit and simpler constructions (Baker et al., 1993). These differences between translated and original text mean that the direction in which parallel data (bitext) was translated is potentially important for machine translation (MT) systems. Most parallel data is either source-original (the source was translated into the target) or target-original (the target was translated into the source), though sometimes neither side is original because both were translated from a third language. Figure 1 illustrates the four possible combinations of translated and original source and target data. Recent work has examined the impact of translationese in MT evaluation, using the WMT evaluation campaign as the most prominent example. From 2014 through 2018, WMT test sets were constructed such that 50% of the sentence pairs are source-original (upper right quadrant of Figure 1) and the rest are target-original (lower left quadrant). Toral et al. (2018), Zhang and Toral (2019), and Graham et al. (2019) have examined the effect of this testing setup on MT evaluation, and have all argued that target-original test data should not be included in future evaluation campaigns because the translationese source is too easy to translate. While target-original test data does have the downside of a translationese source side, recent work has also shown that human raters prefer MT output that is closer in distribution to original target text than translationese (Freitag et al., 2019). This indicates that the target side of test data should also be original (upper left quadrant of Figure 1); however, it is unclear how to produce high-quality test data (let alone training data) that is simultaneously sourceand target-original. Because of this lack of original-to-original sentence pairs, we frame this as a zero-shot translation task, where translationese and original text are distinct languages or domains. We adapt techniques from zero-shot translation with multilingual models (Johnson et al., 2016), where the training pairs are tagged with a reserved token corresponding to the domain of the target side: translationese or original text. Tagging is helpful when the training set mixes data of different types by allowing the model to 1) see each pair’s type in training to preserve distinct behaviors and avoid regressing to a mean/dominant prediction across data types, and 2) elicit different behavior in inference, i.e. providing a tag at test time yields predictions resembling a specific data type. We then investigate what happens when the input is an original sentence in the source language and the model’s output is also biased to be original, a scenario never observed in training. Tagging in this fashion is not trivial, as most MT training sets do not annotate which pairs are sourceoriginal and which are target-original1 , so in order to distinguish them we train binary classifiers to distinguish original and translated target text. Finally, we perform several analyses of tagging these “languages” and demonstrate that tagged back-translation (Caswell et al., 2019) can be framed as a simplified version of our method, and thereby improved by targeted decoding. Our contributions are as follows: 1. We propose two methods to train translationese classifiers using only monolingual text, coupled with synthetic text produced by machine translation. 2. Using only original→translationese and translationese→original training pairs, we apply techniques from zero-shot multilingual MT to enable original→original translation. 3. We demonstrate with human evaluations that this technique improves translation quality, both in terms of fluency and adequacy. 4. We show that biasing the model to instead produce translationese outputs inflates BLEU scores while harming quality as measured by human evaluations.",Can zero-shot translation between original source text and original target text be enabled using a multilingual model that distinguishes translationese from original text?,0.0,1.0,0.0
69,Translationese as a Language in “Multilingual” NMT,"Parker Riley, Isaac Caswell, Markus Freitag, and David Grangier. 2020. Translationese as a Language in “Multilingual” NMT. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7737–7746, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.691.pdf,https://aclanthology.org/2020.acl-main.691/,"Machine translation has an undesirable propensity to produce “translationese” artifacts, which can lead to higher BLEU scores while being liked less by human raters. Motivated by this, we model translationese and original (i.e. natural) text as separate languages in a multilingual model, and pose the question: can we perform zero-shot translation between original source text and original target text? There is no data with original source and original target, so we train a sentence-level classifier to distinguish translationese from original target text, and use this classifier to tag the training data for an NMT model. Using this technique we bias the model to produce more natural outputs at test time, yielding gains in human evaluation scores on both adequacy and fluency. Additionally, we demonstrate that it is possible to bias the model to produce translationese and game the BLEU score, increasing it while decreasing human-rated quality. We analyze these outputs using metrics measuring the degree of translationese, and present an analysis of the volatility of heuristic-based train-data tagging.","“Translationese” is a term that refers to artifacts present in text that was translated into a given language that distinguish it from text originally written in that language (Gellerstam, 1986). These artifacts include lexical and word order choices that are influenced by the source language (Gellerstam, 1996) as well as the use of more explicit and simpler constructions (Baker et al., 1993). These differences between translated and original text mean that the direction in which parallel data (bitext) was translated is potentially important for machine translation (MT) systems. Most parallel data is either source-original (the source was translated into the target) or target-original (the target was translated into the source), though sometimes neither side is original because both were translated from a third language. Figure 1 illustrates the four possible combinations of translated and original source and target data. Recent work has examined the impact of translationese in MT evaluation, using the WMT evaluation campaign as the most prominent example. From 2014 through 2018, WMT test sets were constructed such that 50% of the sentence pairs are source-original (upper right quadrant of Figure 1) and the rest are target-original (lower left quadrant). Toral et al. (2018), Zhang and Toral (2019), and Graham et al. (2019) have examined the effect of this testing setup on MT evaluation, and have all argued that target-original test data should not be included in future evaluation campaigns because the translationese source is too easy to translate. While target-original test data does have the downside of a translationese source side, recent work has also shown that human raters prefer MT output that is closer in distribution to original target text than translationese (Freitag et al., 2019). This indicates that the target side of test data should also be original (upper left quadrant of Figure 1); however, it is unclear how to produce high-quality test data (let alone training data) that is simultaneously sourceand target-original. Because of this lack of original-to-original sentence pairs, we frame this as a zero-shot translation task, where translationese and original text are distinct languages or domains. We adapt techniques from zero-shot translation with multilingual models (Johnson et al., 2016), where the training pairs are tagged with a reserved token corresponding to the domain of the target side: translationese or original text. Tagging is helpful when the training set mixes data of different types by allowing the model to 1) see each pair’s type in training to preserve distinct behaviors and avoid regressing to a mean/dominant prediction across data types, and 2) elicit different behavior in inference, i.e. providing a tag at test time yields predictions resembling a specific data type. We then investigate what happens when the input is an original sentence in the source language and the model’s output is also biased to be original, a scenario never observed in training. Tagging in this fashion is not trivial, as most MT training sets do not annotate which pairs are sourceoriginal and which are target-original1 , so in order to distinguish them we train binary classifiers to distinguish original and translated target text. Finally, we perform several analyses of tagging these “languages” and demonstrate that tagged back-translation (Caswell et al., 2019) can be framed as a simplified version of our method, and thereby improved by targeted decoding. Our contributions are as follows: 1. We propose two methods to train translationese classifiers using only monolingual text, coupled with synthetic text produced by machine translation. 2. Using only original→translationese and translationese→original training pairs, we apply techniques from zero-shot multilingual MT to enable original→original translation. 3. We demonstrate with human evaluations that this technique improves translation quality, both in terms of fluency and adequacy. 4. We show that biasing the model to instead produce translationese outputs inflates BLEU scores while harming quality as measured by human evaluations.","Can the issue of ""translationese"" artifacts reducing the perceived quality of machine-translated text be addressed by modeling translationese and original text as distinct languages within a multilingual model and using domain tagging to train the MT model towards generating more natural, original-like text outputs?",2.0,2.0,1.0
70,Parameter-Efficient Fine-Tuning without Introducing New Latency,"Baohao Liao, Yan Meng, and Christof Monz. 2023. Parameter-Efficient Fine-Tuning without Introducing New Latency. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4242–4260, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.233.pdf,https://aclanthology.org/2023.acl-long.233/,"Parameter-efficient fine-tuning (PEFT) of pretrained language models has recently demonstrated remarkable achievements, effectively matching the performance of full fine-tuning while utilizing significantly fewer trainable parameters, and consequently addressing the storage and communication constraints. Nonetheless, various PEFT methods are limited by their inherent characteristics. In the case of sparse fine-tuning, which involves modifying only a small subset of the existing parameters, the selection of fine-tuned parameters is task- and domain-specific, making it unsuitable for federated learning. On the other hand, PEFT methods with adding new parameters typically introduce additional inference latency. In this paper, we demonstrate the feasibility of generating a sparse mask in a task-agnostic manner, wherein all downstream tasks share a common mask. Our approach, which relies solely on the magnitude information of pre-trained parameters, surpasses existing methodologies by a significant margin when evaluated on the GLUE benchmark. Additionally, we introduce a novel adapter technique that directly applies the adapter to pre-trained parameters instead of the hidden representation, thereby achieving identical inference speed to that of full finetuning. Through extensive experiments, our proposed method attains a new state-of-the-art outcome in terms of both performance and storage efficiency, storing only 0.03% parameters of full fine-tuning.","Pre-trained language models (PLMs) have served as a cornerstone for various natural language processing applications, favoring downstream tasks by offering a robust initialization (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019, 2020; Brown et al., 2020; Liao et al., 2022). Starting with a pre-trained checkpoint, a model can achieve significantly better performance on tasks of interest than the one from scratch. The most historically common way to adapt PLMs to downstream tasks is to update all pre-trained parameters, full fine-tuning. While full fine-tuning produces numerous state-of-the-art results, it is impractical for storage-constrained and communication-frequent cases, like federated learning (McMahan et al., 2017), since it requires a full copy of the fine-tuned model for each task. This issue becomes more severe when PLMs are large-scale (Brown et al., 2020; Zhang et al., 2022; Hoffmann et al., 2022; Raffel et al., 2020; Scao et al., 2022; Touvron et al., 2023), the number of tasks in interest grows, or data are privately saved on hundreds of servers for federated learning. An alternative approach popularized by Houlsby et al. (2019) is parameter-efficient fine-tuning (PEFT), where a small number of task-specific parameters is updated and the majority of PLM’s parameters is frozen. In this way, only one general PLM alongside the modified parameters for each task is saved or transferred. Except for saving memory and training cost, PEFT matches the performance of full fine-tuning with only updating less than 1% of the PLM parameters, quickly adapts to new tasks without catastrophic forgetting (Pfeiffer et al., 2021) and often exhibits robustness in out-ofdistribution evaluation (Li and Liang, 2021). These compelling advantages have sparked considerable interest in the adoption of PEFT. PEFT methods can be split into two categories: sparse and infused fine-tuning. Sparse fine-tuning tunes a small subset of existing parameters without introducing new parameters. One typical example is BitFit (Zaken et al., 2022), where only the biases are updated. Nonetheless, BitFit is not scalable because of the fixed bias terms. Diff Pruning (Guo et al., 2021) and FISH Mask (Sung et al., 2021) alleviate this issue by learning and updating task-specific masked parameters with a specified sparsity ratio. However, different masks are learned under different tasks, making these two methods unsuitable for the federated learning setting, where data is rarely i.i.d. across servers. Infused fine-tuning introduces new parameters to PLMs, and only updates these parameters during training. For example, adapter fine-tuning (Houlsby et al., 2019; Pfeiffer et al., 2021) inserts adapters to each layer of the PLM. Other methods, like Prefix Tuning (Li and Liang, 2021) and Prompt Tuning (Lester et al., 2021), append trainable vectors to input or hidden layers. However, inference latency is typically introduced by the newly added parameters and is nonnegligible for some complex tasks, like machine translation (MT) and summarization that add more than 4% of the PLM parameters (He et al., 2022). In this paper, we address the above-mentioned challenges from sparse and infused fine-tuning by proposing two methods, PaFi and HiWi (illustrated in Figure 2). PaFi is a sparse fine-tuning method that selects trainable parameters in a task-agnostic way. I.e., we have the same mask for various downstream tasks. The mask generation of PaFi is also data-less. It doesn’t require any training on any data. HiWi is an infused fine-tuning method that applies the adapters directly to pre-trained weights or biases instead of to hidden representations. After training, the adapters are abandoned, therefore sharing the same inference speed as full fine-tuning. Our main contributions in this paper are: (1) We introduce two novel transfer learning methods that solve the above-mentioned key challenges of sparse and infused fine-tuning. (2) We empirically evaluate PaFi on the GLUE benchmark and show its effectiveness over existing sparse fine-tuning methods. (3) We compare our methods to a wide range of baselines on a newly constructed benchmark that contains tasks in different types and resources. HiWi outperforms all baselines and full fine-tuning, while requiring the minimum storage (see Figure 1). (4) Our proposed methods still show their effectiveness on a complex task, i.e. machine translation. And all PaFi and HiWi share the same inference speed as full fine-tuning.","How can a parameter-efficient fine-tuning method be designed to achieve task-agnostic sparse fine-tuning and to incorporate adapters directly to pre-trained parameters, thereby maintaining full fine-tuning's inference speed while improving storage efficiency and performance across diverse downstream tasks?",1.0,2.0,1.0
71,Parameter-Efficient Fine-Tuning without Introducing New Latency,"Baohao Liao, Yan Meng, and Christof Monz. 2023. Parameter-Efficient Fine-Tuning without Introducing New Latency. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4242–4260, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.233.pdf,https://aclanthology.org/2023.acl-long.233/,"Parameter-efficient fine-tuning (PEFT) of pretrained language models has recently demonstrated remarkable achievements, effectively matching the performance of full fine-tuning while utilizing significantly fewer trainable parameters, and consequently addressing the storage and communication constraints. Nonetheless, various PEFT methods are limited by their inherent characteristics. In the case of sparse fine-tuning, which involves modifying only a small subset of the existing parameters, the selection of fine-tuned parameters is task- and domain-specific, making it unsuitable for federated learning. On the other hand, PEFT methods with adding new parameters typically introduce additional inference latency. In this paper, we demonstrate the feasibility of generating a sparse mask in a task-agnostic manner, wherein all downstream tasks share a common mask. Our approach, which relies solely on the magnitude information of pre-trained parameters, surpasses existing methodologies by a significant margin when evaluated on the GLUE benchmark. Additionally, we introduce a novel adapter technique that directly applies the adapter to pre-trained parameters instead of the hidden representation, thereby achieving identical inference speed to that of full finetuning. Through extensive experiments, our proposed method attains a new state-of-the-art outcome in terms of both performance and storage efficiency, storing only 0.03% parameters of full fine-tuning.","Pre-trained language models (PLMs) have served as a cornerstone for various natural language processing applications, favoring downstream tasks by offering a robust initialization (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019, 2020; Brown et al., 2020; Liao et al., 2022). Starting with a pre-trained checkpoint, a model can achieve significantly better performance on tasks of interest than the one from scratch. The most historically common way to adapt PLMs to downstream tasks is to update all pre-trained parameters, full fine-tuning. While full fine-tuning produces numerous state-of-the-art results, it is impractical for storage-constrained and communication-frequent cases, like federated learning (McMahan et al., 2017), since it requires a full copy of the fine-tuned model for each task. This issue becomes more severe when PLMs are large-scale (Brown et al., 2020; Zhang et al., 2022; Hoffmann et al., 2022; Raffel et al., 2020; Scao et al., 2022; Touvron et al., 2023), the number of tasks in interest grows, or data are privately saved on hundreds of servers for federated learning. An alternative approach popularized by Houlsby et al. (2019) is parameter-efficient fine-tuning (PEFT), where a small number of task-specific parameters is updated and the majority of PLM’s parameters is frozen. In this way, only one general PLM alongside the modified parameters for each task is saved or transferred. Except for saving memory and training cost, PEFT matches the performance of full fine-tuning with only updating less than 1% of the PLM parameters, quickly adapts to new tasks without catastrophic forgetting (Pfeiffer et al., 2021) and often exhibits robustness in out-ofdistribution evaluation (Li and Liang, 2021). These compelling advantages have sparked considerable interest in the adoption of PEFT. PEFT methods can be split into two categories: sparse and infused fine-tuning. Sparse fine-tuning tunes a small subset of existing parameters without introducing new parameters. One typical example is BitFit (Zaken et al., 2022), where only the biases are updated. Nonetheless, BitFit is not scalable because of the fixed bias terms. Diff Pruning (Guo et al., 2021) and FISH Mask (Sung et al., 2021) alleviate this issue by learning and updating task-specific masked parameters with a specified sparsity ratio. However, different masks are learned under different tasks, making these two methods unsuitable for the federated learning setting, where data is rarely i.i.d. across servers. Infused fine-tuning introduces new parameters to PLMs, and only updates these parameters during training. For example, adapter fine-tuning (Houlsby et al., 2019; Pfeiffer et al., 2021) inserts adapters to each layer of the PLM. Other methods, like Prefix Tuning (Li and Liang, 2021) and Prompt Tuning (Lester et al., 2021), append trainable vectors to input or hidden layers. However, inference latency is typically introduced by the newly added parameters and is nonnegligible for some complex tasks, like machine translation (MT) and summarization that add more than 4% of the PLM parameters (He et al., 2022). In this paper, we address the above-mentioned challenges from sparse and infused fine-tuning by proposing two methods, PaFi and HiWi (illustrated in Figure 2). PaFi is a sparse fine-tuning method that selects trainable parameters in a task-agnostic way. I.e., we have the same mask for various downstream tasks. The mask generation of PaFi is also data-less. It doesn’t require any training on any data. HiWi is an infused fine-tuning method that applies the adapters directly to pre-trained weights or biases instead of to hidden representations. After training, the adapters are abandoned, therefore sharing the same inference speed as full fine-tuning. Our main contributions in this paper are: (1) We introduce two novel transfer learning methods that solve the above-mentioned key challenges of sparse and infused fine-tuning. (2) We empirically evaluate PaFi on the GLUE benchmark and show its effectiveness over existing sparse fine-tuning methods. (3) We compare our methods to a wide range of baselines on a newly constructed benchmark that contains tasks in different types and resources. HiWi outperforms all baselines and full fine-tuning, while requiring the minimum storage (see Figure 1). (4) Our proposed methods still show their effectiveness on a complex task, i.e. machine translation. And all PaFi and HiWi share the same inference speed as full fine-tuning.",Can the limitations of sparse and infused parameter-efficient fine-tuning methods be solved by introducing task-agnostic mask selection and direct application of adapters to pre-trained weights or biases?,1.0,2.0,1.0
72,Parameter-Efficient Fine-Tuning without Introducing New Latency,"Baohao Liao, Yan Meng, and Christof Monz. 2023. Parameter-Efficient Fine-Tuning without Introducing New Latency. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4242–4260, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.233.pdf,https://aclanthology.org/2023.acl-long.233/,"Parameter-efficient fine-tuning (PEFT) of pretrained language models has recently demonstrated remarkable achievements, effectively matching the performance of full fine-tuning while utilizing significantly fewer trainable parameters, and consequently addressing the storage and communication constraints. Nonetheless, various PEFT methods are limited by their inherent characteristics. In the case of sparse fine-tuning, which involves modifying only a small subset of the existing parameters, the selection of fine-tuned parameters is task- and domain-specific, making it unsuitable for federated learning. On the other hand, PEFT methods with adding new parameters typically introduce additional inference latency. In this paper, we demonstrate the feasibility of generating a sparse mask in a task-agnostic manner, wherein all downstream tasks share a common mask. Our approach, which relies solely on the magnitude information of pre-trained parameters, surpasses existing methodologies by a significant margin when evaluated on the GLUE benchmark. Additionally, we introduce a novel adapter technique that directly applies the adapter to pre-trained parameters instead of the hidden representation, thereby achieving identical inference speed to that of full finetuning. Through extensive experiments, our proposed method attains a new state-of-the-art outcome in terms of both performance and storage efficiency, storing only 0.03% parameters of full fine-tuning.","Pre-trained language models (PLMs) have served as a cornerstone for various natural language processing applications, favoring downstream tasks by offering a robust initialization (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019, 2020; Brown et al., 2020; Liao et al., 2022). Starting with a pre-trained checkpoint, a model can achieve significantly better performance on tasks of interest than the one from scratch. The most historically common way to adapt PLMs to downstream tasks is to update all pre-trained parameters, full fine-tuning. While full fine-tuning produces numerous state-of-the-art results, it is impractical for storage-constrained and communication-frequent cases, like federated learning (McMahan et al., 2017), since it requires a full copy of the fine-tuned model for each task. This issue becomes more severe when PLMs are large-scale (Brown et al., 2020; Zhang et al., 2022; Hoffmann et al., 2022; Raffel et al., 2020; Scao et al., 2022; Touvron et al., 2023), the number of tasks in interest grows, or data are privately saved on hundreds of servers for federated learning. An alternative approach popularized by Houlsby et al. (2019) is parameter-efficient fine-tuning (PEFT), where a small number of task-specific parameters is updated and the majority of PLM’s parameters is frozen. In this way, only one general PLM alongside the modified parameters for each task is saved or transferred. Except for saving memory and training cost, PEFT matches the performance of full fine-tuning with only updating less than 1% of the PLM parameters, quickly adapts to new tasks without catastrophic forgetting (Pfeiffer et al., 2021) and often exhibits robustness in out-ofdistribution evaluation (Li and Liang, 2021). These compelling advantages have sparked considerable interest in the adoption of PEFT. PEFT methods can be split into two categories: sparse and infused fine-tuning. Sparse fine-tuning tunes a small subset of existing parameters without introducing new parameters. One typical example is BitFit (Zaken et al., 2022), where only the biases are updated. Nonetheless, BitFit is not scalable because of the fixed bias terms. Diff Pruning (Guo et al., 2021) and FISH Mask (Sung et al., 2021) alleviate this issue by learning and updating task-specific masked parameters with a specified sparsity ratio. However, different masks are learned under different tasks, making these two methods unsuitable for the federated learning setting, where data is rarely i.i.d. across servers. Infused fine-tuning introduces new parameters to PLMs, and only updates these parameters during training. For example, adapter fine-tuning (Houlsby et al., 2019; Pfeiffer et al., 2021) inserts adapters to each layer of the PLM. Other methods, like Prefix Tuning (Li and Liang, 2021) and Prompt Tuning (Lester et al., 2021), append trainable vectors to input or hidden layers. However, inference latency is typically introduced by the newly added parameters and is nonnegligible for some complex tasks, like machine translation (MT) and summarization that add more than 4% of the PLM parameters (He et al., 2022). In this paper, we address the above-mentioned challenges from sparse and infused fine-tuning by proposing two methods, PaFi and HiWi (illustrated in Figure 2). PaFi is a sparse fine-tuning method that selects trainable parameters in a task-agnostic way. I.e., we have the same mask for various downstream tasks. The mask generation of PaFi is also data-less. It doesn’t require any training on any data. HiWi is an infused fine-tuning method that applies the adapters directly to pre-trained weights or biases instead of to hidden representations. After training, the adapters are abandoned, therefore sharing the same inference speed as full fine-tuning. Our main contributions in this paper are: (1) We introduce two novel transfer learning methods that solve the above-mentioned key challenges of sparse and infused fine-tuning. (2) We empirically evaluate PaFi on the GLUE benchmark and show its effectiveness over existing sparse fine-tuning methods. (3) We compare our methods to a wide range of baselines on a newly constructed benchmark that contains tasks in different types and resources. HiWi outperforms all baselines and full fine-tuning, while requiring the minimum storage (see Figure 1). (4) Our proposed methods still show their effectiveness on a complex task, i.e. machine translation. And all PaFi and HiWi share the same inference speed as full fine-tuning.","Can the limitations of existing parameter-efficient fine-tuning methods for pre-trained language models be addressed by the proposed PaFi and HiWi methods, which are task-agnostic and maintain the same inference speed as full fine-tuning?",1.0,1.0,1.0
73,MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization,"Shivam Sharma, Ramaneswaran S, Udit Arora, Md. Shad Akhtar, and Tanmoy Chakraborty. 2023. MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5272–5290, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.289.pdf,https://aclanthology.org/2023.acl-long.289/,"Memes are a powerful tool for communication over social media. Their affinity for evolving across politics, history, and sociocultural phenomena makes them an ideal communication vehicle. To comprehend the subtle message conveyed within a meme, one must understand the background that facilitates its holistic assimilation. Besides digital archiving of memes and their metadata by a few websites like knowyourmeme.com, currently, there is no efficient way to deduce a meme’s context dynamically. In this work, we propose a novel task, MEMEX – given a meme and a related document, the aim is to mine the context that succinctly explains the background of the meme. At first, we develop MCC (Meme Context Corpus), a novel dataset for MEMEX. Further, to benchmark MCC, we propose MIME (MultImodal Meme Explainer), a multimodal neural framework that uses common sense enriched meme representation and a layered approach to capture the cross-modal semantic dependencies between the meme and the context. MIME surpasses several unimodal and multimodal systems and yields an absolute improvement of ⇡ 4% F1-score over the best baseline. Lastly, we conduct detailed analyses of MIME’s performance, highlighting the aspects that could lead to optimal modeling of cross-modal contextual associations.","Social media has become a mainstream communication medium for the masses, redefining how we interact within society. The information shared on social media has diverse forms, like text, audio, and visual messages, or their combinations thereof. A meme is a typical example of such social media artifact that is usually disseminated with the flair of sarcasm or humor. While memes facilitate convenient means for propagating complex social, cultural, or political ideas via visual-linguistic semiotics, they often abstract away the contextual details that would typically be necessary for the uninitiated. Such contextual knowledge is critical for human understanding and computational analysis alike. We aim to address this requirement by contemplating solutions that facilitate the automated derivation of contextual evidence towards making memes more accessible. To this end, we formulate a novel task – MEMEX, which, given a meme and a related context, aims to detect the sentences from within the context that can potentially explain the meme. Table 1 visually explains MEMEX. Memes often camouflage their intended meaning, suggesting MEMEX’s utility for a broader set of multimodal applications having visual-linguistic dissociation. Other use cases include context retrieval for various art forms, news images, abstract graphics for digital media marketing, etc. Table 1 primarily showcases a meme’s figure (left) and an excerpt from the related context (right). This meme is about the revenge killing of an Ottoman Sultan, by the Janissaries (infantry units), in reaction to their disbanding, by the Sultan. The first line conveys the supporting evidence for the meme from the related context, emboldened and highlighted in Table 1. The aim is to model the required cross-modal association that facilitates the detection of such supporting pieces of evidence from a given related contextual document. The recent surge in the dissemination of memes has led to an evolving body of studies on meme analysis in which the primary focus has been on tasks, such as emotion analysis (Sharma et al., 2020), visual-semantic role labeling (Sharma et al., 2022c), detection of phenomena like sarcasm, hatespeech (Kiela et al., 2020), trolling (Hegde et al., 2021) and harmfulness (Pramanick et al., 2021; Sharma et al., 2022b). These studies indicate that off-the-shelf multimodal models, which perform well on several traditional visual-linguistic tasks, struggle when applied to memes (Kiela et al., 2020; Baltrušaitis et al., 2017; Sharma et al., 2022b). The primary reason behind this is the contextual dependency of memes for their accurate assimilation and analysis. Websites like knowyourmeme.com (KYM) facilitate important yet restricted information. MEMEX requires the model to learn the cross-modal analogies shared by the contextual evidence and the meme at various levels of information abstraction, towards detecting the crucial explanatory evidence1. The critical challenge is to represent the abstraction granularity aptly. Therefore, we formulate MEMEX as an “evidence detection” task, which can help deduce pieces of contextual evidence that help bridge the abstraction gap. However, besides including image and text modality, there is a critical need to inject contextual signals that compensate for the constraints due to the visual-linguistic grounding offered by conventional approaches. Even with how effective and convenient memes are to design and disseminate over social media strategically, they are often hard to understand or are easily misinterpreted by the uninitiated, typically without the proper context. Thereby suggesting the importance of addressing a task like MEMEX. Governments or organizations involved in content moderation over social media platforms could use such a utility, underlining the convenience that such a context deduction solution would bring about in assimilating harmful memes and thereby adjudicating their social implications in emergencies like elections or a pandemic. Motivated by this, we first curate MCC, a new dataset that captures various memes and related contextual documents. We also systematically experiment with various multimodal solutions to address MEMEX, which culminates into a novel framework named MIME (MultImodal Meme Explainer). Our model primarily addresses the challenges posed by the knowledge gap and multimodal abstraction and delivers optimal detection of contextual evidence for a given pair of memes and related contexts. In doing so, MIME surpasses several competitive and conventional baselines. To summarize, we make the following main contributions 2.: • A novel task, MEMEX, aimed to identify explanatory evidence for memes from their related contexts. • A novel dataset, MCC, containing 3400 memes and related context, along with gold-standard human annotated evidence sentence-subset. • A novel method, MIME that uses common senseenriched meme representation to identify evidence from the given context. • Empirical analysis establishing MIME’s superiority over various unimodal and multimodal baselines, adapted for the MEMEX task.","What are the most effective methods for automatically identifying the contextual evidence that helps explain the meaning behind a meme, accounting for the cross-modal dependencies and abstraction levels?",0.0,0.0,0.0
74,MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization,"Shivam Sharma, Ramaneswaran S, Udit Arora, Md. Shad Akhtar, and Tanmoy Chakraborty. 2023. MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5272–5290, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.289.pdf,https://aclanthology.org/2023.acl-long.289/,"Memes are a powerful tool for communication over social media. Their affinity for evolving across politics, history, and sociocultural phenomena makes them an ideal communication vehicle. To comprehend the subtle message conveyed within a meme, one must understand the background that facilitates its holistic assimilation. Besides digital archiving of memes and their metadata by a few websites like knowyourmeme.com, currently, there is no efficient way to deduce a meme’s context dynamically. In this work, we propose a novel task, MEMEX – given a meme and a related document, the aim is to mine the context that succinctly explains the background of the meme. At first, we develop MCC (Meme Context Corpus), a novel dataset for MEMEX. Further, to benchmark MCC, we propose MIME (MultImodal Meme Explainer), a multimodal neural framework that uses common sense enriched meme representation and a layered approach to capture the cross-modal semantic dependencies between the meme and the context. MIME surpasses several unimodal and multimodal systems and yields an absolute improvement of ⇡ 4% F1-score over the best baseline. Lastly, we conduct detailed analyses of MIME’s performance, highlighting the aspects that could lead to optimal modeling of cross-modal contextual associations.","Social media has become a mainstream communication medium for the masses, redefining how we interact within society. The information shared on social media has diverse forms, like text, audio, and visual messages, or their combinations thereof. A meme is a typical example of such social media artifact that is usually disseminated with the flair of sarcasm or humor. While memes facilitate convenient means for propagating complex social, cultural, or political ideas via visual-linguistic semiotics, they often abstract away the contextual details that would typically be necessary for the uninitiated. Such contextual knowledge is critical for human understanding and computational analysis alike. We aim to address this requirement by contemplating solutions that facilitate the automated derivation of contextual evidence towards making memes more accessible. To this end, we formulate a novel task – MEMEX, which, given a meme and a related context, aims to detect the sentences from within the context that can potentially explain the meme. Table 1 visually explains MEMEX. Memes often camouflage their intended meaning, suggesting MEMEX’s utility for a broader set of multimodal applications having visual-linguistic dissociation. Other use cases include context retrieval for various art forms, news images, abstract graphics for digital media marketing, etc. Table 1 primarily showcases a meme’s figure (left) and an excerpt from the related context (right). This meme is about the revenge killing of an Ottoman Sultan, by the Janissaries (infantry units), in reaction to their disbanding, by the Sultan. The first line conveys the supporting evidence for the meme from the related context, emboldened and highlighted in Table 1. The aim is to model the required cross-modal association that facilitates the detection of such supporting pieces of evidence from a given related contextual document. The recent surge in the dissemination of memes has led to an evolving body of studies on meme analysis in which the primary focus has been on tasks, such as emotion analysis (Sharma et al., 2020), visual-semantic role labeling (Sharma et al., 2022c), detection of phenomena like sarcasm, hatespeech (Kiela et al., 2020), trolling (Hegde et al., 2021) and harmfulness (Pramanick et al., 2021; Sharma et al., 2022b). These studies indicate that off-the-shelf multimodal models, which perform well on several traditional visual-linguistic tasks, struggle when applied to memes (Kiela et al., 2020; Baltrušaitis et al., 2017; Sharma et al., 2022b). The primary reason behind this is the contextual dependency of memes for their accurate assimilation and analysis. Websites like knowyourmeme.com (KYM) facilitate important yet restricted information. MEMEX requires the model to learn the cross-modal analogies shared by the contextual evidence and the meme at various levels of information abstraction, towards detecting the crucial explanatory evidence1. The critical challenge is to represent the abstraction granularity aptly. Therefore, we formulate MEMEX as an “evidence detection” task, which can help deduce pieces of contextual evidence that help bridge the abstraction gap. However, besides including image and text modality, there is a critical need to inject contextual signals that compensate for the constraints due to the visual-linguistic grounding offered by conventional approaches. Even with how effective and convenient memes are to design and disseminate over social media strategically, they are often hard to understand or are easily misinterpreted by the uninitiated, typically without the proper context. Thereby suggesting the importance of addressing a task like MEMEX. Governments or organizations involved in content moderation over social media platforms could use such a utility, underlining the convenience that such a context deduction solution would bring about in assimilating harmful memes and thereby adjudicating their social implications in emergencies like elections or a pandemic. Motivated by this, we first curate MCC, a new dataset that captures various memes and related contextual documents. We also systematically experiment with various multimodal solutions to address MEMEX, which culminates into a novel framework named MIME (MultImodal Meme Explainer). Our model primarily addresses the challenges posed by the knowledge gap and multimodal abstraction and delivers optimal detection of contextual evidence for a given pair of memes and related contexts. In doing so, MIME surpasses several competitive and conventional baselines. To summarize, we make the following main contributions 2.: • A novel task, MEMEX, aimed to identify explanatory evidence for memes from their related contexts. • A novel dataset, MCC, containing 3400 memes and related context, along with gold-standard human annotated evidence sentence-subset. • A novel method, MIME that uses common senseenriched meme representation to identify evidence from the given context. • Empirical analysis establishing MIME’s superiority over various unimodal and multimodal baselines, adapted for the MEMEX task.",Can the task of identifying explanatory evidence for memes from their related contexts be solved by a common sense-enriched meme representation method (MIME)?,0.0,0.0,0.0
75,MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization,"Shivam Sharma, Ramaneswaran S, Udit Arora, Md. Shad Akhtar, and Tanmoy Chakraborty. 2023. MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5272–5290, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.289.pdf,https://aclanthology.org/2023.acl-long.289/,"Memes are a powerful tool for communication over social media. Their affinity for evolving across politics, history, and sociocultural phenomena makes them an ideal communication vehicle. To comprehend the subtle message conveyed within a meme, one must understand the background that facilitates its holistic assimilation. Besides digital archiving of memes and their metadata by a few websites like knowyourmeme.com, currently, there is no efficient way to deduce a meme’s context dynamically. In this work, we propose a novel task, MEMEX – given a meme and a related document, the aim is to mine the context that succinctly explains the background of the meme. At first, we develop MCC (Meme Context Corpus), a novel dataset for MEMEX. Further, to benchmark MCC, we propose MIME (MultImodal Meme Explainer), a multimodal neural framework that uses common sense enriched meme representation and a layered approach to capture the cross-modal semantic dependencies between the meme and the context. MIME surpasses several unimodal and multimodal systems and yields an absolute improvement of ⇡ 4% F1-score over the best baseline. Lastly, we conduct detailed analyses of MIME’s performance, highlighting the aspects that could lead to optimal modeling of cross-modal contextual associations.","Social media has become a mainstream communication medium for the masses, redefining how we interact within society. The information shared on social media has diverse forms, like text, audio, and visual messages, or their combinations thereof. A meme is a typical example of such social media artifact that is usually disseminated with the flair of sarcasm or humor. While memes facilitate convenient means for propagating complex social, cultural, or political ideas via visual-linguistic semiotics, they often abstract away the contextual details that would typically be necessary for the uninitiated. Such contextual knowledge is critical for human understanding and computational analysis alike. We aim to address this requirement by contemplating solutions that facilitate the automated derivation of contextual evidence towards making memes more accessible. To this end, we formulate a novel task – MEMEX, which, given a meme and a related context, aims to detect the sentences from within the context that can potentially explain the meme. Table 1 visually explains MEMEX. Memes often camouflage their intended meaning, suggesting MEMEX’s utility for a broader set of multimodal applications having visual-linguistic dissociation. Other use cases include context retrieval for various art forms, news images, abstract graphics for digital media marketing, etc. Table 1 primarily showcases a meme’s figure (left) and an excerpt from the related context (right). This meme is about the revenge killing of an Ottoman Sultan, by the Janissaries (infantry units), in reaction to their disbanding, by the Sultan. The first line conveys the supporting evidence for the meme from the related context, emboldened and highlighted in Table 1. The aim is to model the required cross-modal association that facilitates the detection of such supporting pieces of evidence from a given related contextual document. The recent surge in the dissemination of memes has led to an evolving body of studies on meme analysis in which the primary focus has been on tasks, such as emotion analysis (Sharma et al., 2020), visual-semantic role labeling (Sharma et al., 2022c), detection of phenomena like sarcasm, hatespeech (Kiela et al., 2020), trolling (Hegde et al., 2021) and harmfulness (Pramanick et al., 2021; Sharma et al., 2022b). These studies indicate that off-the-shelf multimodal models, which perform well on several traditional visual-linguistic tasks, struggle when applied to memes (Kiela et al., 2020; Baltrušaitis et al., 2017; Sharma et al., 2022b). The primary reason behind this is the contextual dependency of memes for their accurate assimilation and analysis. Websites like knowyourmeme.com (KYM) facilitate important yet restricted information. MEMEX requires the model to learn the cross-modal analogies shared by the contextual evidence and the meme at various levels of information abstraction, towards detecting the crucial explanatory evidence1. The critical challenge is to represent the abstraction granularity aptly. Therefore, we formulate MEMEX as an “evidence detection” task, which can help deduce pieces of contextual evidence that help bridge the abstraction gap. However, besides including image and text modality, there is a critical need to inject contextual signals that compensate for the constraints due to the visual-linguistic grounding offered by conventional approaches. Even with how effective and convenient memes are to design and disseminate over social media strategically, they are often hard to understand or are easily misinterpreted by the uninitiated, typically without the proper context. Thereby suggesting the importance of addressing a task like MEMEX. Governments or organizations involved in content moderation over social media platforms could use such a utility, underlining the convenience that such a context deduction solution would bring about in assimilating harmful memes and thereby adjudicating their social implications in emergencies like elections or a pandemic. Motivated by this, we first curate MCC, a new dataset that captures various memes and related contextual documents. We also systematically experiment with various multimodal solutions to address MEMEX, which culminates into a novel framework named MIME (MultImodal Meme Explainer). Our model primarily addresses the challenges posed by the knowledge gap and multimodal abstraction and delivers optimal detection of contextual evidence for a given pair of memes and related contexts. In doing so, MIME surpasses several competitive and conventional baselines. To summarize, we make the following main contributions 2.: • A novel task, MEMEX, aimed to identify explanatory evidence for memes from their related contexts. • A novel dataset, MCC, containing 3400 memes and related context, along with gold-standard human annotated evidence sentence-subset. • A novel method, MIME that uses common senseenriched meme representation to identify evidence from the given context. • Empirical analysis establishing MIME’s superiority over various unimodal and multimodal baselines, adapted for the MEMEX task.","Can the contextual explanation of a meme's background be dynamically mined from related documents through the MEMEX task, utilizing the MCC dataset and the MIME multimodal neural framework?",0.0,1.0,0.0
76,Modeling Social Norms Evolution for Personalized Sentiment Classification,"Lin Gong, Mohammad Al Boni, and Hongning Wang. 2016. Modeling Social Norms Evolution for Personalized Sentiment Classification. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 855–865, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1081.pdf,https://aclanthology.org/P16-1081/,"Motivated by the findings in social science that people’s opinions are diverse and variable while together they are shaped by evolving social norms, we perform personalized sentiment classification via shared model adaptation over time. In our proposed solution, a global sentiment model is constantly updated to capture the homogeneity in which users express opinions, while personalized models are simultaneously adapted from the global model to recognize the heterogeneity of opinions from individuals. Global model sharing alleviates data sparsity issue, and individualized model adaptation enables efficient online model learning. Extensive experimentations are performed on two large review collections from Amazon and Yelp, and encouraging performance gain is achieved against several state-of-the-art transfer learning and multi-task learning based sentiment classification solutions.","Sentiment is personal; the same sentiment can be expressed in various ways and the same expression might carry distinct polarities across different individuals (Wiebe et al., 2005). Current mainstream solutions of sentiment analysis overlook this fact by focusing on population-level models (Liu, 2012; Pang and Lee, 2008). But the idiosyncratic and variable ways in which individuals communicate their opinions make a global sentiment classifier incompetent and consequently lead to suboptimal opinion mining results. For instance, a shared statistical classifier can hardly recognize that in restaurant reviews, the word “expensive” may indicate some users’ satisfaction with a restaurant’s quality, although it is generally associated with negative attitudes. Hence, a personalized sentiment classification solution is required to achieve fine-grained understanding of individuals’ distinctive and dynamic opinions and benefit downstream opinion mining applications. Sparse observations of individuals’ opinionated data (Max, 2014) prevent straightforward solutions from building personalized sentiment classification models, such as estimating supervised classifiers on a per-user basis. Semi-supervised methods are developed to address the data sparsity issue. For example, leveraging auxiliary information from user-user and user-document relations in transductive learning (Hu et al., 2013; Tan et al., 2011). However, only one global model is estimated there, and the details of how individual users express diverse opinions cannot be captured. More importantly, existing solutions build static sentiment models on historic data; but the means in which a user expresses his/her opinion is changing over time. To capture temporal dynamics in a user’s opinions with existing solutions, repeated model reconstruction is unavoidable, albeit it is prohibitively expensive. As a result, personalized sentiment analysis requires effective exploitation of users’ own opinionated data and efficient execution of model updates across all users. To address these challenges, we propose to build personalized sentiment classification models via shared model adaptation. Our solution roots in the social psychology theories about humans’ dispositional tendencies (Briley et al., 2000). Humans’ behaviors are shaped by social norms, a set of socially shared “feelings” and “display rules” about how one should feel and express opinions (Barsade and Gibson, 1998; Sherif, 1936). In the ¨ context of content-based sentiment classification, we interpret social norms as global model sharing and adaptation across users. Formally, we assume a global sentiment model serves as the basis to capture self-enforcing sentimental regularities across users, and each individual user tailors the shared model to realize his/her personal preference. In addition, social norms also evolve over time (Ehrlich and Levin, 2005), which leads to shifts in individuals’ behaviors. This can again be interpreted as model adaptation: a new global model is adapted from an existing one to reflect the newly adopted sentimental norms. The temporal changes in individuals’ opinions can be efficiently captured via online model adaptation at the levels of both global and personalized models. Our proposed solution can also be understood from the perspective of multi-task learning (Evgeniou and Pontil, 2004; Jacob et al., 2009). Intuitively, personalized model adaptations can be considered as a set of related tasks in individual users, which contribute to a shared global model adaptation. In particular, we assume the distinct ways in which users express their opinions can be characterized by a linear classifier’s parameters, i.e., the weights of textual features. Personalized models are thus achieved via a series of linear transformations over a globally shared classifier’s parameters (Wang et al., 2013), e.g., shifting and scaling the weight vector. This globally shared classifier itself is obtained via another set of linear transformations over a given base classifier, which can be estimated from an isolated collection beforehand and serves as a prior for shared sentiment classification. The shared global model adaptation makes personalized model estimation no longer independent, such that regularity is formed across individualized learning tasks. We empirically evaluated the proposed solution on two large collections of reviews, i.e., Amazon and Yelp reviews. Extensive experiment results confirm its effectiveness: the proposed method outperformed user-independent classification methods, several state-of-the-art model adaption methods, and multi-task learning algorithms.","How can a sentiment classification model be effectively adapted over time to capture both the global homogeneity and personal heterogeneity of user opinions, considering the evolution of social norms and the challenges posed by data sparsity and static models?",2.0,2.0,1.0
77,Modeling Social Norms Evolution for Personalized Sentiment Classification,"Lin Gong, Mohammad Al Boni, and Hongning Wang. 2016. Modeling Social Norms Evolution for Personalized Sentiment Classification. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 855–865, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1081.pdf,https://aclanthology.org/P16-1081/,"Motivated by the findings in social science that people’s opinions are diverse and variable while together they are shaped by evolving social norms, we perform personalized sentiment classification via shared model adaptation over time. In our proposed solution, a global sentiment model is constantly updated to capture the homogeneity in which users express opinions, while personalized models are simultaneously adapted from the global model to recognize the heterogeneity of opinions from individuals. Global model sharing alleviates data sparsity issue, and individualized model adaptation enables efficient online model learning. Extensive experimentations are performed on two large review collections from Amazon and Yelp, and encouraging performance gain is achieved against several state-of-the-art transfer learning and multi-task learning based sentiment classification solutions.","Sentiment is personal; the same sentiment can be expressed in various ways and the same expression might carry distinct polarities across different individuals (Wiebe et al., 2005). Current mainstream solutions of sentiment analysis overlook this fact by focusing on population-level models (Liu, 2012; Pang and Lee, 2008). But the idiosyncratic and variable ways in which individuals communicate their opinions make a global sentiment classifier incompetent and consequently lead to suboptimal opinion mining results. For instance, a shared statistical classifier can hardly recognize that in restaurant reviews, the word “expensive” may indicate some users’ satisfaction with a restaurant’s quality, although it is generally associated with negative attitudes. Hence, a personalized sentiment classification solution is required to achieve fine-grained understanding of individuals’ distinctive and dynamic opinions and benefit downstream opinion mining applications. Sparse observations of individuals’ opinionated data (Max, 2014) prevent straightforward solutions from building personalized sentiment classification models, such as estimating supervised classifiers on a per-user basis. Semi-supervised methods are developed to address the data sparsity issue. For example, leveraging auxiliary information from user-user and user-document relations in transductive learning (Hu et al., 2013; Tan et al., 2011). However, only one global model is estimated there, and the details of how individual users express diverse opinions cannot be captured. More importantly, existing solutions build static sentiment models on historic data; but the means in which a user expresses his/her opinion is changing over time. To capture temporal dynamics in a user’s opinions with existing solutions, repeated model reconstruction is unavoidable, albeit it is prohibitively expensive. As a result, personalized sentiment analysis requires effective exploitation of users’ own opinionated data and efficient execution of model updates across all users. To address these challenges, we propose to build personalized sentiment classification models via shared model adaptation. Our solution roots in the social psychology theories about humans’ dispositional tendencies (Briley et al., 2000). Humans’ behaviors are shaped by social norms, a set of socially shared “feelings” and “display rules” about how one should feel and express opinions (Barsade and Gibson, 1998; Sherif, 1936). In the ¨ context of content-based sentiment classification, we interpret social norms as global model sharing and adaptation across users. Formally, we assume a global sentiment model serves as the basis to capture self-enforcing sentimental regularities across users, and each individual user tailors the shared model to realize his/her personal preference. In addition, social norms also evolve over time (Ehrlich and Levin, 2005), which leads to shifts in individuals’ behaviors. This can again be interpreted as model adaptation: a new global model is adapted from an existing one to reflect the newly adopted sentimental norms. The temporal changes in individuals’ opinions can be efficiently captured via online model adaptation at the levels of both global and personalized models. Our proposed solution can also be understood from the perspective of multi-task learning (Evgeniou and Pontil, 2004; Jacob et al., 2009). Intuitively, personalized model adaptations can be considered as a set of related tasks in individual users, which contribute to a shared global model adaptation. In particular, we assume the distinct ways in which users express their opinions can be characterized by a linear classifier’s parameters, i.e., the weights of textual features. Personalized models are thus achieved via a series of linear transformations over a globally shared classifier’s parameters (Wang et al., 2013), e.g., shifting and scaling the weight vector. This globally shared classifier itself is obtained via another set of linear transformations over a given base classifier, which can be estimated from an isolated collection beforehand and serves as a prior for shared sentiment classification. The shared global model adaptation makes personalized model estimation no longer independent, such that regularity is formed across individualized learning tasks. We empirically evaluated the proposed solution on two large collections of reviews, i.e., Amazon and Yelp reviews. Extensive experiment results confirm its effectiveness: the proposed method outperformed user-independent classification methods, several state-of-the-art model adaption methods, and multi-task learning algorithms.",Can personalized sentiment classification be achieved through shared model adaptation over time?,1.0,1.0,1.0
78,Modeling Social Norms Evolution for Personalized Sentiment Classification,"Lin Gong, Mohammad Al Boni, and Hongning Wang. 2016. Modeling Social Norms Evolution for Personalized Sentiment Classification. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 855–865, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1081.pdf,https://aclanthology.org/P16-1081/,"Motivated by the findings in social science that people’s opinions are diverse and variable while together they are shaped by evolving social norms, we perform personalized sentiment classification via shared model adaptation over time. In our proposed solution, a global sentiment model is constantly updated to capture the homogeneity in which users express opinions, while personalized models are simultaneously adapted from the global model to recognize the heterogeneity of opinions from individuals. Global model sharing alleviates data sparsity issue, and individualized model adaptation enables efficient online model learning. Extensive experimentations are performed on two large review collections from Amazon and Yelp, and encouraging performance gain is achieved against several state-of-the-art transfer learning and multi-task learning based sentiment classification solutions.","Sentiment is personal; the same sentiment can be expressed in various ways and the same expression might carry distinct polarities across different individuals (Wiebe et al., 2005). Current mainstream solutions of sentiment analysis overlook this fact by focusing on population-level models (Liu, 2012; Pang and Lee, 2008). But the idiosyncratic and variable ways in which individuals communicate their opinions make a global sentiment classifier incompetent and consequently lead to suboptimal opinion mining results. For instance, a shared statistical classifier can hardly recognize that in restaurant reviews, the word “expensive” may indicate some users’ satisfaction with a restaurant’s quality, although it is generally associated with negative attitudes. Hence, a personalized sentiment classification solution is required to achieve fine-grained understanding of individuals’ distinctive and dynamic opinions and benefit downstream opinion mining applications. Sparse observations of individuals’ opinionated data (Max, 2014) prevent straightforward solutions from building personalized sentiment classification models, such as estimating supervised classifiers on a per-user basis. Semi-supervised methods are developed to address the data sparsity issue. For example, leveraging auxiliary information from user-user and user-document relations in transductive learning (Hu et al., 2013; Tan et al., 2011). However, only one global model is estimated there, and the details of how individual users express diverse opinions cannot be captured. More importantly, existing solutions build static sentiment models on historic data; but the means in which a user expresses his/her opinion is changing over time. To capture temporal dynamics in a user’s opinions with existing solutions, repeated model reconstruction is unavoidable, albeit it is prohibitively expensive. As a result, personalized sentiment analysis requires effective exploitation of users’ own opinionated data and efficient execution of model updates across all users. To address these challenges, we propose to build personalized sentiment classification models via shared model adaptation. Our solution roots in the social psychology theories about humans’ dispositional tendencies (Briley et al., 2000). Humans’ behaviors are shaped by social norms, a set of socially shared “feelings” and “display rules” about how one should feel and express opinions (Barsade and Gibson, 1998; Sherif, 1936). In the ¨ context of content-based sentiment classification, we interpret social norms as global model sharing and adaptation across users. Formally, we assume a global sentiment model serves as the basis to capture self-enforcing sentimental regularities across users, and each individual user tailors the shared model to realize his/her personal preference. In addition, social norms also evolve over time (Ehrlich and Levin, 2005), which leads to shifts in individuals’ behaviors. This can again be interpreted as model adaptation: a new global model is adapted from an existing one to reflect the newly adopted sentimental norms. The temporal changes in individuals’ opinions can be efficiently captured via online model adaptation at the levels of both global and personalized models. Our proposed solution can also be understood from the perspective of multi-task learning (Evgeniou and Pontil, 2004; Jacob et al., 2009). Intuitively, personalized model adaptations can be considered as a set of related tasks in individual users, which contribute to a shared global model adaptation. In particular, we assume the distinct ways in which users express their opinions can be characterized by a linear classifier’s parameters, i.e., the weights of textual features. Personalized models are thus achieved via a series of linear transformations over a globally shared classifier’s parameters (Wang et al., 2013), e.g., shifting and scaling the weight vector. This globally shared classifier itself is obtained via another set of linear transformations over a given base classifier, which can be estimated from an isolated collection beforehand and serves as a prior for shared sentiment classification. The shared global model adaptation makes personalized model estimation no longer independent, such that regularity is formed across individualized learning tasks. We empirically evaluated the proposed solution on two large collections of reviews, i.e., Amazon and Yelp reviews. Extensive experiment results confirm its effectiveness: the proposed method outperformed user-independent classification methods, several state-of-the-art model adaption methods, and multi-task learning algorithms.",Can personalized sentiment classification via shared model adaptation effectively capture both the homogeneity and heterogeneity of opinions among individuals over time?,1.0,1.0,1.0
79,FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining,"Zhoujun Cheng, Haoyu Dong, Ran Jia, Pengfei Wu, Shi Han, Fan Cheng, and Dongmei Zhang. 2022. FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1150–1166, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.82.pdf,https://aclanthology.org/2022.acl-long.82/,"Tables store rich numerical data, but numerical reasoning over tables is still a challenge. In this paper, we find that the spreadsheet formula, a commonly used language to perform computations on numerical values in spreadsheets, is valuable supervision for numerical reasoning in tables. Considering large amounts of spreadsheets available on the web, we propose FORTAP , the first exploration to leverage spreadsheet formulas for table pretraining. Two novel self-supervised pretraining objectives are derived from formulas, numerical reference prediction (NRP) and numerical calculation prediction (NCP). While our proposed objectives are generic for encoders, to better capture spreadsheet table layouts and structures, we build FORTAP upon TUTA, the first transformer-based method for spreadsheet&web table pretraining with tree attention. FORTAP outperforms state-of-the-art methods by large margins on three representative datasets of formula prediction, question answering, and cell type classification, showing the great potential of leveraging formulas for table pretraining. The code will be released at https://github.com/microsoft/TUTA_ table_understanding.","Tables store rich numerical data, so a wide range of tasks require numerical reasoning over (semi- )structured tabular context, such as question answering over tables (Chen et al., 2021b; Zhu et al., 2021; Cheng et al., 2021), table-to-text (Suadaa et al., 2021; Moosavi et al., 2021; Cheng et al., 2021), spreadsheet formula prediction (Chen et al., 2021a), and table structure understanding (Koci et al., 2019). Take Table#2 in Figure 1 as an example, both suggesting the formula (C4-B4)/B4 for cell D4 and answering “0.61%” to the question require numerical reasoning capabilities of (1) understanding the contextual meaning of individual numerical cells, e.g., “11.49” at B4 and “11.56” at C4 are “population”s of “Belgium” in “2019” and “2020”; (2) inferring calculational relationships of numerical cells, e.g., percentage change from “11.49” to “11.56”. As Figure 1 shows, same capabilities also benefit table structure recognition and table-to-text. So it’s a fundamental need to empower table modeling with stronger numerical reasoning capabilities. However, it is challenging to endow a tabular model with robust numerical reasoning capabilities. First, understanding a local numerical cell needs dimension inference (Chambers and Erwig, 2008), unit inference (Shbita et al., 2019), and index inference (Dong et al., 2019a), e.g., “population” (dimension), “million” (unit), “2020” (index), and “Belgium” (index) jointly describe “11.56” in Figure 1. It is non-trivial concerning the great flexibility of table semantic structures (Wang et al.,2021b). Second, calculational relationships among two or more numerical cells are various and often compositional, e.g., “F1 Score = 2 × (Recall × Precision) / (Recall + Precision)” in machine learning papers and “Profit Margin = Net Income / Sales” in financial reports. To make matters more challenging, human labeling for numerical reasoning in relevant tasks (Chen et al., 2020; Suadaa et al., 2021; Koci et al., 2019) is labor-intensive and error-prone, largely restricting the generalization ability of large models that are rather data-hungry. Recently, table pretraining on large amount of unlabeled tables shows promising results on table understanding and reasoning. Self-supervised objectives are derived from tables and text such as Masked Language Models (MLM) (Herzig et al., 2020), masked column prediction (Yin et al., 2020), masked entity recovery (Deng et al., 2020b), cell cloze and corrupt detection (Wang et al., 2021b; Tang et al., 2020; Iida et al., 2021), table-text matching and alignment (Wang et al., 2021a,b; Deng et al., 2020a). However, numerical and calculational relationships of cells lack sufficient attention. Then (Yoran et al., 2021) and (Liu et al., 2021; Yu et al., 2020) synthesize questions and SQL queries, respectively, as training corpus for reasoning purpose, but SQL is only applicable to database-like relational tables, and importantly, it’s challenging to ensure synthesized questions and SQLs be realistic, meaningful, and diverse. Gladly, tens of millions of real spreadsheet formulas are publicly available on the web and can be valuable for numerical reasoning in tables. The spreadsheet formula is an expressive yet simple language consisting of operators (e.g., +,/,%), functions (e.g., SUM,MAX,COUNT), referenced cells (e.g., B4), and constant values (e.g., 100) (Aivaloglou et al., 2015). Since writing the formula does not require formal programming education, it’s widely used by non-programmers such as business professionals or other kinds of domain specialists whose jobs involve computational tasks. So spreadsheet formulas cover real numerical calculations in a great variety of domains. To this end, we propose FORmula-driven TAble Pretraining (FORTAP ) for numerical reasoning. One should master two basic concepts to use the formula language: cells as variables and operators/functions as relationships between variables. So we explicitly decompose information in formulas into numerical reference and numerical calculation and devise two complementary tasks. Given a table as well as a formula cell in it, we mask the formula and then (1) the model classifies whether “header A references header B” (we consider that “header A references header B” if the formula cell belonging to header A references a numerical cell belonging to header B, as illustrated in Figure 2); (2) the model predicts the operator/function of two or more referenced numerical cells. Furthermore, to better encode and represent formulas, we also apply MLM to the token sequence of formulas. Considering the flexibility of table structures in spreadsheets, we base FORTAP on TUTA (Wang et al., 2021b), the first transformer-based method for spreadsheet tables with carefully-designed textual, numerical, positional, and formatting embedding layers. Importantly, its tree-based position encoding and attention are highly effective in representing generally structured tables. TUTA is pretrained with MLM, cell cloze, and table-text matching. Experiment results on three tasks demonstrate that the significance of leveraging formulas for table pretraining. For formula prediction, FORTAP achieves 55.8% top-1 accuracy, significantly surpassing TUTA (48.5%), TaPEx (43.2%), and SpreadsheetCoder (40.4%) on Enron. For table question answering, TUTA achieves comparable accuracy with the best system on HiTab. After pretraining with formulas, FORTAP delivers a huge improvement of +6.3% as over previous SOTA, comparable to TaPEx. For cell type classification, on dataset DeEx, FORTAP largely improves TUTA by +6.6% on derived type and +3.2% on overall Macro-F1.","How can spreadsheet formulas be leveraged for enhancing numerical reasoning capabilities in table pretraining to improve performance on tasks like formula prediction, question answering, and cell type classification?",2.0,1.0,1.0
80,FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining,"Zhoujun Cheng, Haoyu Dong, Ran Jia, Pengfei Wu, Shi Han, Fan Cheng, and Dongmei Zhang. 2022. FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1150–1166, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.82.pdf,https://aclanthology.org/2022.acl-long.82/,"Tables store rich numerical data, but numerical reasoning over tables is still a challenge. In this paper, we find that the spreadsheet formula, a commonly used language to perform computations on numerical values in spreadsheets, is valuable supervision for numerical reasoning in tables. Considering large amounts of spreadsheets available on the web, we propose FORTAP , the first exploration to leverage spreadsheet formulas for table pretraining. Two novel self-supervised pretraining objectives are derived from formulas, numerical reference prediction (NRP) and numerical calculation prediction (NCP). While our proposed objectives are generic for encoders, to better capture spreadsheet table layouts and structures, we build FORTAP upon TUTA, the first transformer-based method for spreadsheet&web table pretraining with tree attention. FORTAP outperforms state-of-the-art methods by large margins on three representative datasets of formula prediction, question answering, and cell type classification, showing the great potential of leveraging formulas for table pretraining. The code will be released at https://github.com/microsoft/TUTA_ table_understanding.","Tables store rich numerical data, so a wide range of tasks require numerical reasoning over (semi- )structured tabular context, such as question answering over tables (Chen et al., 2021b; Zhu et al., 2021; Cheng et al., 2021), table-to-text (Suadaa et al., 2021; Moosavi et al., 2021; Cheng et al., 2021), spreadsheet formula prediction (Chen et al., 2021a), and table structure understanding (Koci et al., 2019). Take Table#2 in Figure 1 as an example, both suggesting the formula (C4-B4)/B4 for cell D4 and answering “0.61%” to the question require numerical reasoning capabilities of (1) understanding the contextual meaning of individual numerical cells, e.g., “11.49” at B4 and “11.56” at C4 are “population”s of “Belgium” in “2019” and “2020”; (2) inferring calculational relationships of numerical cells, e.g., percentage change from “11.49” to “11.56”. As Figure 1 shows, same capabilities also benefit table structure recognition and table-to-text. So it’s a fundamental need to empower table modeling with stronger numerical reasoning capabilities. However, it is challenging to endow a tabular model with robust numerical reasoning capabilities. First, understanding a local numerical cell needs dimension inference (Chambers and Erwig, 2008), unit inference (Shbita et al., 2019), and index inference (Dong et al., 2019a), e.g., “population” (dimension), “million” (unit), “2020” (index), and “Belgium” (index) jointly describe “11.56” in Figure 1. It is non-trivial concerning the great flexibility of table semantic structures (Wang et al.,2021b). Second, calculational relationships among two or more numerical cells are various and often compositional, e.g., “F1 Score = 2 × (Recall × Precision) / (Recall + Precision)” in machine learning papers and “Profit Margin = Net Income / Sales” in financial reports. To make matters more challenging, human labeling for numerical reasoning in relevant tasks (Chen et al., 2020; Suadaa et al., 2021; Koci et al., 2019) is labor-intensive and error-prone, largely restricting the generalization ability of large models that are rather data-hungry. Recently, table pretraining on large amount of unlabeled tables shows promising results on table understanding and reasoning. Self-supervised objectives are derived from tables and text such as Masked Language Models (MLM) (Herzig et al., 2020), masked column prediction (Yin et al., 2020), masked entity recovery (Deng et al., 2020b), cell cloze and corrupt detection (Wang et al., 2021b; Tang et al., 2020; Iida et al., 2021), table-text matching and alignment (Wang et al., 2021a,b; Deng et al., 2020a). However, numerical and calculational relationships of cells lack sufficient attention. Then (Yoran et al., 2021) and (Liu et al., 2021; Yu et al., 2020) synthesize questions and SQL queries, respectively, as training corpus for reasoning purpose, but SQL is only applicable to database-like relational tables, and importantly, it’s challenging to ensure synthesized questions and SQLs be realistic, meaningful, and diverse. Gladly, tens of millions of real spreadsheet formulas are publicly available on the web and can be valuable for numerical reasoning in tables. The spreadsheet formula is an expressive yet simple language consisting of operators (e.g., +,/,%), functions (e.g., SUM,MAX,COUNT), referenced cells (e.g., B4), and constant values (e.g., 100) (Aivaloglou et al., 2015). Since writing the formula does not require formal programming education, it’s widely used by non-programmers such as business professionals or other kinds of domain specialists whose jobs involve computational tasks. So spreadsheet formulas cover real numerical calculations in a great variety of domains. To this end, we propose FORmula-driven TAble Pretraining (FORTAP ) for numerical reasoning. One should master two basic concepts to use the formula language: cells as variables and operators/functions as relationships between variables. So we explicitly decompose information in formulas into numerical reference and numerical calculation and devise two complementary tasks. Given a table as well as a formula cell in it, we mask the formula and then (1) the model classifies whether “header A references header B” (we consider that “header A references header B” if the formula cell belonging to header A references a numerical cell belonging to header B, as illustrated in Figure 2); (2) the model predicts the operator/function of two or more referenced numerical cells. Furthermore, to better encode and represent formulas, we also apply MLM to the token sequence of formulas. Considering the flexibility of table structures in spreadsheets, we base FORTAP on TUTA (Wang et al., 2021b), the first transformer-based method for spreadsheet tables with carefully-designed textual, numerical, positional, and formatting embedding layers. Importantly, its tree-based position encoding and attention are highly effective in representing generally structured tables. TUTA is pretrained with MLM, cell cloze, and table-text matching. Experiment results on three tasks demonstrate that the significance of leveraging formulas for table pretraining. For formula prediction, FORTAP achieves 55.8% top-1 accuracy, significantly surpassing TUTA (48.5%), TaPEx (43.2%), and SpreadsheetCoder (40.4%) on Enron. For table question answering, TUTA achieves comparable accuracy with the best system on HiTab. After pretraining with formulas, FORTAP delivers a huge improvement of +6.3% as over previous SOTA, comparable to TaPEx. For cell type classification, on dataset DeEx, FORTAP largely improves TUTA by +6.6% on derived type and +3.2% on overall Macro-F1.",Can numerical reasoning in tables be improved by leveraging spreadsheet formulas for table pretraining?,2.0,1.0,1.0
81,FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining,"Zhoujun Cheng, Haoyu Dong, Ran Jia, Pengfei Wu, Shi Han, Fan Cheng, and Dongmei Zhang. 2022. FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1150–1166, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.82.pdf,https://aclanthology.org/2022.acl-long.82/,"Tables store rich numerical data, but numerical reasoning over tables is still a challenge. In this paper, we find that the spreadsheet formula, a commonly used language to perform computations on numerical values in spreadsheets, is valuable supervision for numerical reasoning in tables. Considering large amounts of spreadsheets available on the web, we propose FORTAP , the first exploration to leverage spreadsheet formulas for table pretraining. Two novel self-supervised pretraining objectives are derived from formulas, numerical reference prediction (NRP) and numerical calculation prediction (NCP). While our proposed objectives are generic for encoders, to better capture spreadsheet table layouts and structures, we build FORTAP upon TUTA, the first transformer-based method for spreadsheet&web table pretraining with tree attention. FORTAP outperforms state-of-the-art methods by large margins on three representative datasets of formula prediction, question answering, and cell type classification, showing the great potential of leveraging formulas for table pretraining. The code will be released at https://github.com/microsoft/TUTA_ table_understanding.","Tables store rich numerical data, so a wide range of tasks require numerical reasoning over (semi- )structured tabular context, such as question answering over tables (Chen et al., 2021b; Zhu et al., 2021; Cheng et al., 2021), table-to-text (Suadaa et al., 2021; Moosavi et al., 2021; Cheng et al., 2021), spreadsheet formula prediction (Chen et al., 2021a), and table structure understanding (Koci et al., 2019). Take Table#2 in Figure 1 as an example, both suggesting the formula (C4-B4)/B4 for cell D4 and answering “0.61%” to the question require numerical reasoning capabilities of (1) understanding the contextual meaning of individual numerical cells, e.g., “11.49” at B4 and “11.56” at C4 are “population”s of “Belgium” in “2019” and “2020”; (2) inferring calculational relationships of numerical cells, e.g., percentage change from “11.49” to “11.56”. As Figure 1 shows, same capabilities also benefit table structure recognition and table-to-text. So it’s a fundamental need to empower table modeling with stronger numerical reasoning capabilities. However, it is challenging to endow a tabular model with robust numerical reasoning capabilities. First, understanding a local numerical cell needs dimension inference (Chambers and Erwig, 2008), unit inference (Shbita et al., 2019), and index inference (Dong et al., 2019a), e.g., “population” (dimension), “million” (unit), “2020” (index), and “Belgium” (index) jointly describe “11.56” in Figure 1. It is non-trivial concerning the great flexibility of table semantic structures (Wang et al.,2021b). Second, calculational relationships among two or more numerical cells are various and often compositional, e.g., “F1 Score = 2 × (Recall × Precision) / (Recall + Precision)” in machine learning papers and “Profit Margin = Net Income / Sales” in financial reports. To make matters more challenging, human labeling for numerical reasoning in relevant tasks (Chen et al., 2020; Suadaa et al., 2021; Koci et al., 2019) is labor-intensive and error-prone, largely restricting the generalization ability of large models that are rather data-hungry. Recently, table pretraining on large amount of unlabeled tables shows promising results on table understanding and reasoning. Self-supervised objectives are derived from tables and text such as Masked Language Models (MLM) (Herzig et al., 2020), masked column prediction (Yin et al., 2020), masked entity recovery (Deng et al., 2020b), cell cloze and corrupt detection (Wang et al., 2021b; Tang et al., 2020; Iida et al., 2021), table-text matching and alignment (Wang et al., 2021a,b; Deng et al., 2020a). However, numerical and calculational relationships of cells lack sufficient attention. Then (Yoran et al., 2021) and (Liu et al., 2021; Yu et al., 2020) synthesize questions and SQL queries, respectively, as training corpus for reasoning purpose, but SQL is only applicable to database-like relational tables, and importantly, it’s challenging to ensure synthesized questions and SQLs be realistic, meaningful, and diverse. Gladly, tens of millions of real spreadsheet formulas are publicly available on the web and can be valuable for numerical reasoning in tables. The spreadsheet formula is an expressive yet simple language consisting of operators (e.g., +,/,%), functions (e.g., SUM,MAX,COUNT), referenced cells (e.g., B4), and constant values (e.g., 100) (Aivaloglou et al., 2015). Since writing the formula does not require formal programming education, it’s widely used by non-programmers such as business professionals or other kinds of domain specialists whose jobs involve computational tasks. So spreadsheet formulas cover real numerical calculations in a great variety of domains. To this end, we propose FORmula-driven TAble Pretraining (FORTAP ) for numerical reasoning. One should master two basic concepts to use the formula language: cells as variables and operators/functions as relationships between variables. So we explicitly decompose information in formulas into numerical reference and numerical calculation and devise two complementary tasks. Given a table as well as a formula cell in it, we mask the formula and then (1) the model classifies whether “header A references header B” (we consider that “header A references header B” if the formula cell belonging to header A references a numerical cell belonging to header B, as illustrated in Figure 2); (2) the model predicts the operator/function of two or more referenced numerical cells. Furthermore, to better encode and represent formulas, we also apply MLM to the token sequence of formulas. Considering the flexibility of table structures in spreadsheets, we base FORTAP on TUTA (Wang et al., 2021b), the first transformer-based method for spreadsheet tables with carefully-designed textual, numerical, positional, and formatting embedding layers. Importantly, its tree-based position encoding and attention are highly effective in representing generally structured tables. TUTA is pretrained with MLM, cell cloze, and table-text matching. Experiment results on three tasks demonstrate that the significance of leveraging formulas for table pretraining. For formula prediction, FORTAP achieves 55.8% top-1 accuracy, significantly surpassing TUTA (48.5%), TaPEx (43.2%), and SpreadsheetCoder (40.4%) on Enron. For table question answering, TUTA achieves comparable accuracy with the best system on HiTab. After pretraining with formulas, FORTAP delivers a huge improvement of +6.3% as over previous SOTA, comparable to TaPEx. For cell type classification, on dataset DeEx, FORTAP largely improves TUTA by +6.6% on derived type and +3.2% on overall Macro-F1.","Can the challenge of numerical reasoning over tables be addressed by leveraging real spreadsheet formulas for table pretraining through novel self-supervised pretraining objectives, based on a transformer method with tree attention?",2.0,2.0,1.0
82,Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in Pretrained Embeddings,"Vihari Piratla, Sunita Sarawagi, and Soumen Chakrabarti. 2019. Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in Pretrained Embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1717–1726, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1168.pdf,https://aclanthology.org/P19-1168/,"Given a small corpus DT pertaining to a limited set of focused topics, our goal is to train embeddings that accurately capture the sense of words in the topic in spite of the limited size of DT . These embeddings may be used in various tasks involving DT . A popular strategy in limited data settings is to adapt pretrained embeddings E trained on a large corpus. To correct for sense drift, fine-tuning, regularization, projection, and pivoting have been proposed recently. Among these, regularization informed by a word’s corpus frequency performed well, but we improve upon it using a new regularizer based on the stability of its cooccurrence with other words. However, a thorough comparison across ten topics, spanning three tasks, with standardized settings of hyper-parameters, reveals that even the best embedding adaptation strategies provide small gains beyond well-tuned baselines, which many earlier comparisons ignored. In a bold departure from adapting pretrained embeddings, we propose using DT to probe, attend to, and borrow fragments from any large, topic-rich source corpus (such as Wikipedia), which need not be the corpus used to pretrain embeddings. This step is made scalable and practical by suitable indexing. We reach the surprising conclusion that even limited corpus augmentation is more useful than adapting embeddings, which suggests that non-dominant sense information may be irrevocably obliterated from pretrained embeddings and cannot be salvaged by adaptation.","Word embeddings (Mikolov et al., 2013; Pennington et al., 2014) benefit many natural language processing (NLP) tasks. Often, a group of tasks may involve a limited corpus DT pertaining to a few focused topics, e.g., discussion boards on Physics, video games, or Unix, or a forum for discussing medical literature. Because DT may be too small to train word embeddings to sufficient quality, a prevalent practice is to harness general-purpose embeddings E pretrained on a broad-coverage corpus, not tailored to the topics of interest. The pretrained embeddings are sometimes used as-is (‘pinned’). Even if E is trained on a ‘universal’ corpus, considerable sense shift may exist in the meaning of polysemous words and their cooccurrences and similarities with other words. In a corpus about Unix, ‘cat’ and ‘print’ are more similar than in Wikipedia. ‘Charge’ and ‘potential’ are more related in a Physics corpus than in Wikipedia. Thus, pinning can lead to poor target task performance in case of serious sense mismatch. Another popular practice is to initialize the target embeddings to the pretrained vectors, but then “fine-tune” using DT to improve performance in the target (Mou et al., 2015; Min et al., 2017; Howard and Ruder, 2018). As we shall see, the number of epochs of fine-tuning is a sensitive knob — excessive fine-tuning might lead to “catastrophic forgetting” (Kirkpatrick et al., 2017) of useful word similarities in E, and too little finetuning may not adapt to target sense. Even if we are given development (‘dev’) sets for target tasks, the best balancing act between a pretrained E and a topic-focused DT is far from clear. Should we fine-tune (all word vectors) in epochs and stop when dev performance deteriorates? Or should we keep some words close to their pretrained embeddings (a form of regularization) and allow others to tune more aggressively? On what properties of E and DT should the regularization strength of each word depend? Our first contribution is a new measure of semantic drift of a word from E to DT , which can be used to control the regularization strength. In terms of perplexity, we show that this is superior to both epoch-based tuning, as well as regularization based on simple corpus frequencies of words (Yang et al., 2017). Yet another option is to learn projections to align generic embeddings to the target sense (Bollegala et al., 2015; Barnes et al., 2018; K Sarma et al., 2018), or to a shared common space (Yin and Schutze ¨ , 2016; Coates and Bollegala, 2018; Bollegala and Bao, 2018) However, in carefully controlled experiments, none of the proposed approaches to adapting pretrained embeddings consistently beats the trivial baseline of discarding them and training afresh on DT ! Our second contribution is to explore other techniques beyond adapting generic embeddings E. Often, we might additionally have easy access to a broad corpus DS like Wikipedia. DS may span many diverse topics, while DT focuses on one or few, so there may be large overall drift from DS to DT too. However, a judicious subset DcS ⊂ DS may exist that would be excellent for augmenting DT . The large size of DS is not a problem: we use an inverted index that we probe with documents from DT to efficiently identify DcS. Then we apply a novel perplexity-based joint loss over DcS ∪ DT to fit adapted word embeddings. While most of recent research focus has been on designing better methods of adapting pretrained embeddings, we show that retraining with selected source text is significantly more accurate than the best of embeddings-only strategy, while runtime overheads are within practical limits. An important lesson is that non-dominant sense information may be irrevocably obliterated from generic embeddings; it may not be possible to salvage this information by post-facto adaptation. Summarizing, our contributions are: • We propose new formulations for training topicspecific embeddings on a limited target corpus DT by (1) adapting generic pre-trained word embeddings E, and/or (2) selecting from any available broad-coverage corpus DS. • We perform a systematic comparison of our and several recent methods on three tasks spanning ten topics and offer many insights. • Our selection of DcS from DS and joint perplexity minimization on DcS ∪ DT perform better than pure embedding adaptation methods, at the (practical) cost of processing DS. • We evaluate our method even with contextual embeddings. The relative performance of the adaptation alternatives remain fairly stable whether the adapted embeddings are used on their own, or concatenated with contextsensitive embeddings (Peters et al., 2018; Cer et al., 2018).",How can incorporating a carefully selected subset of a broad-coverage corpus (like Wikipedia) for corpus augmentation compare with adapting pre-trained word embeddings in terms of improving the accuracy of topic-specific embeddings trained on a limited target corpus?,1.0,1.0,1.0
83,Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in Pretrained Embeddings,"Vihari Piratla, Sunita Sarawagi, and Soumen Chakrabarti. 2019. Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in Pretrained Embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1717–1726, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1168.pdf,https://aclanthology.org/P19-1168/,"Given a small corpus DT pertaining to a limited set of focused topics, our goal is to train embeddings that accurately capture the sense of words in the topic in spite of the limited size of DT . These embeddings may be used in various tasks involving DT . A popular strategy in limited data settings is to adapt pretrained embeddings E trained on a large corpus. To correct for sense drift, fine-tuning, regularization, projection, and pivoting have been proposed recently. Among these, regularization informed by a word’s corpus frequency performed well, but we improve upon it using a new regularizer based on the stability of its cooccurrence with other words. However, a thorough comparison across ten topics, spanning three tasks, with standardized settings of hyper-parameters, reveals that even the best embedding adaptation strategies provide small gains beyond well-tuned baselines, which many earlier comparisons ignored. In a bold departure from adapting pretrained embeddings, we propose using DT to probe, attend to, and borrow fragments from any large, topic-rich source corpus (such as Wikipedia), which need not be the corpus used to pretrain embeddings. This step is made scalable and practical by suitable indexing. We reach the surprising conclusion that even limited corpus augmentation is more useful than adapting embeddings, which suggests that non-dominant sense information may be irrevocably obliterated from pretrained embeddings and cannot be salvaged by adaptation.","Word embeddings (Mikolov et al., 2013; Pennington et al., 2014) benefit many natural language processing (NLP) tasks. Often, a group of tasks may involve a limited corpus DT pertaining to a few focused topics, e.g., discussion boards on Physics, video games, or Unix, or a forum for discussing medical literature. Because DT may be too small to train word embeddings to sufficient quality, a prevalent practice is to harness general-purpose embeddings E pretrained on a broad-coverage corpus, not tailored to the topics of interest. The pretrained embeddings are sometimes used as-is (‘pinned’). Even if E is trained on a ‘universal’ corpus, considerable sense shift may exist in the meaning of polysemous words and their cooccurrences and similarities with other words. In a corpus about Unix, ‘cat’ and ‘print’ are more similar than in Wikipedia. ‘Charge’ and ‘potential’ are more related in a Physics corpus than in Wikipedia. Thus, pinning can lead to poor target task performance in case of serious sense mismatch. Another popular practice is to initialize the target embeddings to the pretrained vectors, but then “fine-tune” using DT to improve performance in the target (Mou et al., 2015; Min et al., 2017; Howard and Ruder, 2018). As we shall see, the number of epochs of fine-tuning is a sensitive knob — excessive fine-tuning might lead to “catastrophic forgetting” (Kirkpatrick et al., 2017) of useful word similarities in E, and too little finetuning may not adapt to target sense. Even if we are given development (‘dev’) sets for target tasks, the best balancing act between a pretrained E and a topic-focused DT is far from clear. Should we fine-tune (all word vectors) in epochs and stop when dev performance deteriorates? Or should we keep some words close to their pretrained embeddings (a form of regularization) and allow others to tune more aggressively? On what properties of E and DT should the regularization strength of each word depend? Our first contribution is a new measure of semantic drift of a word from E to DT , which can be used to control the regularization strength. In terms of perplexity, we show that this is superior to both epoch-based tuning, as well as regularization based on simple corpus frequencies of words (Yang et al., 2017). Yet another option is to learn projections to align generic embeddings to the target sense (Bollegala et al., 2015; Barnes et al., 2018; K Sarma et al., 2018), or to a shared common space (Yin and Schutze ¨ , 2016; Coates and Bollegala, 2018; Bollegala and Bao, 2018) However, in carefully controlled experiments, none of the proposed approaches to adapting pretrained embeddings consistently beats the trivial baseline of discarding them and training afresh on DT ! Our second contribution is to explore other techniques beyond adapting generic embeddings E. Often, we might additionally have easy access to a broad corpus DS like Wikipedia. DS may span many diverse topics, while DT focuses on one or few, so there may be large overall drift from DS to DT too. However, a judicious subset DcS ⊂ DS may exist that would be excellent for augmenting DT . The large size of DS is not a problem: we use an inverted index that we probe with documents from DT to efficiently identify DcS. Then we apply a novel perplexity-based joint loss over DcS ∪ DT to fit adapted word embeddings. While most of recent research focus has been on designing better methods of adapting pretrained embeddings, we show that retraining with selected source text is significantly more accurate than the best of embeddings-only strategy, while runtime overheads are within practical limits. An important lesson is that non-dominant sense information may be irrevocably obliterated from generic embeddings; it may not be possible to salvage this information by post-facto adaptation. Summarizing, our contributions are: • We propose new formulations for training topicspecific embeddings on a limited target corpus DT by (1) adapting generic pre-trained word embeddings E, and/or (2) selecting from any available broad-coverage corpus DS. • We perform a systematic comparison of our and several recent methods on three tasks spanning ten topics and offer many insights. • Our selection of DcS from DS and joint perplexity minimization on DcS ∪ DT perform better than pure embedding adaptation methods, at the (practical) cost of processing DS. • We evaluate our method even with contextual embeddings. The relative performance of the adaptation alternatives remain fairly stable whether the adapted embeddings are used on their own, or concatenated with contextsensitive embeddings (Peters et al., 2018; Cer et al., 2018).","Can the quality of topic-specific word embeddings for a limited target corpus DT be improved by selecting relevant text fragments from a broad-coverage corpus DS and retraining, rather than solely adapting generic pretrained embeddings E?",1.0,1.0,1.0
84,Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in Pretrained Embeddings,"Vihari Piratla, Sunita Sarawagi, and Soumen Chakrabarti. 2019. Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in Pretrained Embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1717–1726, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1168.pdf,https://aclanthology.org/P19-1168/,"Given a small corpus DT pertaining to a limited set of focused topics, our goal is to train embeddings that accurately capture the sense of words in the topic in spite of the limited size of DT . These embeddings may be used in various tasks involving DT . A popular strategy in limited data settings is to adapt pretrained embeddings E trained on a large corpus. To correct for sense drift, fine-tuning, regularization, projection, and pivoting have been proposed recently. Among these, regularization informed by a word’s corpus frequency performed well, but we improve upon it using a new regularizer based on the stability of its cooccurrence with other words. However, a thorough comparison across ten topics, spanning three tasks, with standardized settings of hyper-parameters, reveals that even the best embedding adaptation strategies provide small gains beyond well-tuned baselines, which many earlier comparisons ignored. In a bold departure from adapting pretrained embeddings, we propose using DT to probe, attend to, and borrow fragments from any large, topic-rich source corpus (such as Wikipedia), which need not be the corpus used to pretrain embeddings. This step is made scalable and practical by suitable indexing. We reach the surprising conclusion that even limited corpus augmentation is more useful than adapting embeddings, which suggests that non-dominant sense information may be irrevocably obliterated from pretrained embeddings and cannot be salvaged by adaptation.","Word embeddings (Mikolov et al., 2013; Pennington et al., 2014) benefit many natural language processing (NLP) tasks. Often, a group of tasks may involve a limited corpus DT pertaining to a few focused topics, e.g., discussion boards on Physics, video games, or Unix, or a forum for discussing medical literature. Because DT may be too small to train word embeddings to sufficient quality, a prevalent practice is to harness general-purpose embeddings E pretrained on a broad-coverage corpus, not tailored to the topics of interest. The pretrained embeddings are sometimes used as-is (‘pinned’). Even if E is trained on a ‘universal’ corpus, considerable sense shift may exist in the meaning of polysemous words and their cooccurrences and similarities with other words. In a corpus about Unix, ‘cat’ and ‘print’ are more similar than in Wikipedia. ‘Charge’ and ‘potential’ are more related in a Physics corpus than in Wikipedia. Thus, pinning can lead to poor target task performance in case of serious sense mismatch. Another popular practice is to initialize the target embeddings to the pretrained vectors, but then “fine-tune” using DT to improve performance in the target (Mou et al., 2015; Min et al., 2017; Howard and Ruder, 2018). As we shall see, the number of epochs of fine-tuning is a sensitive knob — excessive fine-tuning might lead to “catastrophic forgetting” (Kirkpatrick et al., 2017) of useful word similarities in E, and too little finetuning may not adapt to target sense. Even if we are given development (‘dev’) sets for target tasks, the best balancing act between a pretrained E and a topic-focused DT is far from clear. Should we fine-tune (all word vectors) in epochs and stop when dev performance deteriorates? Or should we keep some words close to their pretrained embeddings (a form of regularization) and allow others to tune more aggressively? On what properties of E and DT should the regularization strength of each word depend? Our first contribution is a new measure of semantic drift of a word from E to DT , which can be used to control the regularization strength. In terms of perplexity, we show that this is superior to both epoch-based tuning, as well as regularization based on simple corpus frequencies of words (Yang et al., 2017). Yet another option is to learn projections to align generic embeddings to the target sense (Bollegala et al., 2015; Barnes et al., 2018; K Sarma et al., 2018), or to a shared common space (Yin and Schutze ¨ , 2016; Coates and Bollegala, 2018; Bollegala and Bao, 2018) However, in carefully controlled experiments, none of the proposed approaches to adapting pretrained embeddings consistently beats the trivial baseline of discarding them and training afresh on DT ! Our second contribution is to explore other techniques beyond adapting generic embeddings E. Often, we might additionally have easy access to a broad corpus DS like Wikipedia. DS may span many diverse topics, while DT focuses on one or few, so there may be large overall drift from DS to DT too. However, a judicious subset DcS ⊂ DS may exist that would be excellent for augmenting DT . The large size of DS is not a problem: we use an inverted index that we probe with documents from DT to efficiently identify DcS. Then we apply a novel perplexity-based joint loss over DcS ∪ DT to fit adapted word embeddings. While most of recent research focus has been on designing better methods of adapting pretrained embeddings, we show that retraining with selected source text is significantly more accurate than the best of embeddings-only strategy, while runtime overheads are within practical limits. An important lesson is that non-dominant sense information may be irrevocably obliterated from generic embeddings; it may not be possible to salvage this information by post-facto adaptation. Summarizing, our contributions are: • We propose new formulations for training topicspecific embeddings on a limited target corpus DT by (1) adapting generic pre-trained word embeddings E, and/or (2) selecting from any available broad-coverage corpus DS. • We perform a systematic comparison of our and several recent methods on three tasks spanning ten topics and offer many insights. • Our selection of DcS from DS and joint perplexity minimization on DcS ∪ DT perform better than pure embedding adaptation methods, at the (practical) cost of processing DS. • We evaluate our method even with contextual embeddings. The relative performance of the adaptation alternatives remain fairly stable whether the adapted embeddings are used on their own, or concatenated with contextsensitive embeddings (Peters et al., 2018; Cer et al., 2018).","Can the problem of accurately capturing the specific sense of words within a small, focused corpus (DT) despite its limited size be solved by using DT to probe, attend to, and borrow fragments from any large, topic-rich source corpus for corpus augmentation, providing a scalable and practical solution through suitable indexing?",2.0,1.0,1.0
85,MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations,"Tao Shi and Shao-Lun Huang. 2023. MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14752–14766, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.824.pdf,https://aclanthology.org/2023.acl-long.824/,"Emotion Recognition in Conversations (ERC) is an increasingly popular task in the Natural Language Processing community, which seeks to achieve accurate emotion classifications of utterances expressed by speakers during a conversation. Most existing approaches focus on modeling speaker and contextual information based on the textual modality, while the complementarity of multimodal information has not been well leveraged, few current methods have sufficiently captured the complex correlations and mapping relationships across different modalities. Furthermore, existing state-ofthe-art ERC models have difficulty classifying minority and semantically similar emotion categories. To address these challenges, we propose a novel attention-based correlation-aware multimodal fusion framework named MultiEMO, which effectively integrates multimodal cues by capturing cross-modal mapping relationships across textual, audio and visual modalities based on bidirectional multi-head crossattention layers. The difficulty of recognizing minority and semantically hard-to-distinguish emotion classes is alleviated by our proposed Sample-Weighted Focal Contrastive (SWFC) loss. Extensive experiments on two benchmark ERC datasets demonstrate that our MultiEMO framework consistently outperforms existing state-of-the-art approaches in all emotion categories on both datasets, the improvements in minority and semantically similar emotions are especially significant.","Emotion Recognition in Conversations (ERC) is an emerging task in the field of Natural Language Processing (NLP), which aims to identify the emotion of each utterance in a conversation based on textual, audio and visual cues of the speaker. ERC has attracted an enormous amount of attention from both academia and industry, due to its widespread potentials in social media analysis (Chatterjee et al., 2019), health care services (Hu et al., 2021b), empathetic systems (Jiao et al., 2020), and so on. To solve the problem of ERC, numerous approaches have been proposed. The majority of existing works concentrate on modeling speaker dependencies and conversational contexts (Poria et al., 2017; Hazarika et al., 2018a,c; Majumder et al., 2019; Ghosal et al., 2019, 2020; Shen et al., 2021; Hu et al., 2021a,b; Li et al., 2021a; Joshi et al., 2022; Lee and Lee, 2022), while there still exist several unsolved challenges: (1) The complementarity of multimodal information has not been well exploited. Apart from rich information contained in the textual modality, the tone and intonation of the speaker can indicate the intensity of the emotion, facial expressions of interlocutors are also able to explicitly reveal emotional tendencies (Li et al., 2022). Figure 1 shows an example where the complementarity of acoustic and visual signals in addition to the textual modality is essential for an accurate emotion classification. Nevertheless, most existing approaches focus on the textual modality of utterances or simply utilize feature concatenation as the multimodal fusion mechanism (Poria et al., 2017; Hazarika et al., 2018a,c; Majumder et al., 2019; Zhang and Chai, 2021; Li et al., 2022) without modeling the complicated correlations and mapping relationships across textual, audio and visual modalities, which results in an inadequate integration of multimodal cues. (2) Unsatisfactory performances in minority emotion classes. Existing benchmark datasets in ERC, such as IEMOCAP (Busso et al., 2008) and MELD (Poria et al., 2019), suffer from the problem of imbalanced classes. As illustrated in Figure 2, both MELD and IEMOCAP are class-imbalanced, especially in MELD, where the majority class neutral takes up a much larger proportion than minority classes disgust and fear. Current state-of-the-art approaches fail to solve the class imbalance problem and have poor performances in minority emotions. (3) The difficulty of distinguishing between semantically similar emotions. It remains to be a challenging task to correctly classify different emotions that are semantically related, such as disgust and anger in MELD, since they share similar underlying cognitive, affective and physiological features, and tend to be expressed by speakers in similar contexts. To address the above problems, in this paper, we propose a novel attention-based correlationaware multimodal fusion framework named MultiEMO. Firstly, unimodal feature extraction and context modeling are performed for each modality, in which we introduce a visual feature extractor named VisExtNet based on a Multi-task Cascaded Convolutional Network (MTCNN) (Zhang et al., 2016) and a VGGFace2 (Cao et al., 2018) pretrained ResNet-101 (He et al., 2016). VisExtNet accurately captures visual cues of utterance videos by extracting emotion-rich facial expressions of interlocutors without modeling redundant scenerelated visual information. Secondly, we propose a multimodal fusion model called MultiAttn to effectively integrate multimodal information based on bidirectional multi-head cross-attention layers (Vaswani et al., 2017), which successfully captures complex cross-modal correlations and mapping relationships across contextualized textual, audio and visual features. Thirdly, in order to mitigate the difficulty of classifying minority and semantically similar emotion classes, enlightened by Focal Contrastive loss (Zhang et al., 2021), a Sample-Weighted Focal Contrastive (SWFC) loss is proposed, in which we assign more focus to hard-to-classify minority classes and make sample pairs with different emotion labels mutually exclusive with each other such that semantically similar emotions can be better distinguished. In addition, we utilize a Soft Hirschfeld-GebeleinRényi (Soft-HGR) loss (Wang et al., 2019) to maximize the correlations across multimodal-fused textual, audio and visual feature representations extracted from MultiAttn. Finally, extensive experiments are conducted on two ERC benchmark datasets, MELD and IEMOCAP. Experimental results demonstrate the effectiveness and superiority of our proposed MultiEMO framework compared with existing state-of-the-art approaches, the improvements in minority and semantically similar emotion categories are especially remarkable. The main contributions of this work can be summarized as follows: • We propose a novel visual feature extraction network named VisExtNet, which effectively captures visual cues of interlocutors without modeling redundant scene information. • We design a multimodal fusion model called MultiAttn based on bidirectional multi-head cross-attention layers, which successfully models the complicated correlations across textual, audio and visual modalities. • We innovatively introduce a SWFC loss to address the difficulty of classifying minority and semantically similar emotion classes. • We conduct extensive experiments on MELD and IEMOCAP, results show that our proposed MultiEMO framework achieves stateof-the-art performances on both datasets, the improvements in minority and semantically similar emotions are especially notable.","How can the integration of bidirectional multi-head cross-attention layers and a Sample-Weighted Focal Contrastive loss within a multimodal fusion framework enhance the accuracy of emotion recognition in conversations, especially for minority and semantically similar emotion categories?",2.0,1.0,1.0
86,MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations,"Tao Shi and Shao-Lun Huang. 2023. MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14752–14766, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.824.pdf,https://aclanthology.org/2023.acl-long.824/,"Emotion Recognition in Conversations (ERC) is an increasingly popular task in the Natural Language Processing community, which seeks to achieve accurate emotion classifications of utterances expressed by speakers during a conversation. Most existing approaches focus on modeling speaker and contextual information based on the textual modality, while the complementarity of multimodal information has not been well leveraged, few current methods have sufficiently captured the complex correlations and mapping relationships across different modalities. Furthermore, existing state-ofthe-art ERC models have difficulty classifying minority and semantically similar emotion categories. To address these challenges, we propose a novel attention-based correlation-aware multimodal fusion framework named MultiEMO, which effectively integrates multimodal cues by capturing cross-modal mapping relationships across textual, audio and visual modalities based on bidirectional multi-head crossattention layers. The difficulty of recognizing minority and semantically hard-to-distinguish emotion classes is alleviated by our proposed Sample-Weighted Focal Contrastive (SWFC) loss. Extensive experiments on two benchmark ERC datasets demonstrate that our MultiEMO framework consistently outperforms existing state-of-the-art approaches in all emotion categories on both datasets, the improvements in minority and semantically similar emotions are especially significant.","Emotion Recognition in Conversations (ERC) is an emerging task in the field of Natural Language Processing (NLP), which aims to identify the emotion of each utterance in a conversation based on textual, audio and visual cues of the speaker. ERC has attracted an enormous amount of attention from both academia and industry, due to its widespread potentials in social media analysis (Chatterjee et al., 2019), health care services (Hu et al., 2021b), empathetic systems (Jiao et al., 2020), and so on. To solve the problem of ERC, numerous approaches have been proposed. The majority of existing works concentrate on modeling speaker dependencies and conversational contexts (Poria et al., 2017; Hazarika et al., 2018a,c; Majumder et al., 2019; Ghosal et al., 2019, 2020; Shen et al., 2021; Hu et al., 2021a,b; Li et al., 2021a; Joshi et al., 2022; Lee and Lee, 2022), while there still exist several unsolved challenges: (1) The complementarity of multimodal information has not been well exploited. Apart from rich information contained in the textual modality, the tone and intonation of the speaker can indicate the intensity of the emotion, facial expressions of interlocutors are also able to explicitly reveal emotional tendencies (Li et al., 2022). Figure 1 shows an example where the complementarity of acoustic and visual signals in addition to the textual modality is essential for an accurate emotion classification. Nevertheless, most existing approaches focus on the textual modality of utterances or simply utilize feature concatenation as the multimodal fusion mechanism (Poria et al., 2017; Hazarika et al., 2018a,c; Majumder et al., 2019; Zhang and Chai, 2021; Li et al., 2022) without modeling the complicated correlations and mapping relationships across textual, audio and visual modalities, which results in an inadequate integration of multimodal cues. (2) Unsatisfactory performances in minority emotion classes. Existing benchmark datasets in ERC, such as IEMOCAP (Busso et al., 2008) and MELD (Poria et al., 2019), suffer from the problem of imbalanced classes. As illustrated in Figure 2, both MELD and IEMOCAP are class-imbalanced, especially in MELD, where the majority class neutral takes up a much larger proportion than minority classes disgust and fear. Current state-of-the-art approaches fail to solve the class imbalance problem and have poor performances in minority emotions. (3) The difficulty of distinguishing between semantically similar emotions. It remains to be a challenging task to correctly classify different emotions that are semantically related, such as disgust and anger in MELD, since they share similar underlying cognitive, affective and physiological features, and tend to be expressed by speakers in similar contexts. To address the above problems, in this paper, we propose a novel attention-based correlationaware multimodal fusion framework named MultiEMO. Firstly, unimodal feature extraction and context modeling are performed for each modality, in which we introduce a visual feature extractor named VisExtNet based on a Multi-task Cascaded Convolutional Network (MTCNN) (Zhang et al., 2016) and a VGGFace2 (Cao et al., 2018) pretrained ResNet-101 (He et al., 2016). VisExtNet accurately captures visual cues of utterance videos by extracting emotion-rich facial expressions of interlocutors without modeling redundant scenerelated visual information. Secondly, we propose a multimodal fusion model called MultiAttn to effectively integrate multimodal information based on bidirectional multi-head cross-attention layers (Vaswani et al., 2017), which successfully captures complex cross-modal correlations and mapping relationships across contextualized textual, audio and visual features. Thirdly, in order to mitigate the difficulty of classifying minority and semantically similar emotion classes, enlightened by Focal Contrastive loss (Zhang et al., 2021), a Sample-Weighted Focal Contrastive (SWFC) loss is proposed, in which we assign more focus to hard-to-classify minority classes and make sample pairs with different emotion labels mutually exclusive with each other such that semantically similar emotions can be better distinguished. In addition, we utilize a Soft Hirschfeld-GebeleinRényi (Soft-HGR) loss (Wang et al., 2019) to maximize the correlations across multimodal-fused textual, audio and visual feature representations extracted from MultiAttn. Finally, extensive experiments are conducted on two ERC benchmark datasets, MELD and IEMOCAP. Experimental results demonstrate the effectiveness and superiority of our proposed MultiEMO framework compared with existing state-of-the-art approaches, the improvements in minority and semantically similar emotion categories are especially remarkable. The main contributions of this work can be summarized as follows: • We propose a novel visual feature extraction network named VisExtNet, which effectively captures visual cues of interlocutors without modeling redundant scene information. • We design a multimodal fusion model called MultiAttn based on bidirectional multi-head cross-attention layers, which successfully models the complicated correlations across textual, audio and visual modalities. • We innovatively introduce a SWFC loss to address the difficulty of classifying minority and semantically similar emotion classes. • We conduct extensive experiments on MELD and IEMOCAP, results show that our proposed MultiEMO framework achieves stateof-the-art performances on both datasets, the improvements in minority and semantically similar emotions are especially notable.","Can the challenges of emotion recognition in conversations, specifically integrating multimodal information effectively and classifying minority and semantically similar emotions, be solved by a novel attention-based correlation-aware multimodal fusion framework named MultiEMO?",2.0,1.0,1.0
87,MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations,"Tao Shi and Shao-Lun Huang. 2023. MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14752–14766, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.824.pdf,https://aclanthology.org/2023.acl-long.824/,"Emotion Recognition in Conversations (ERC) is an increasingly popular task in the Natural Language Processing community, which seeks to achieve accurate emotion classifications of utterances expressed by speakers during a conversation. Most existing approaches focus on modeling speaker and contextual information based on the textual modality, while the complementarity of multimodal information has not been well leveraged, few current methods have sufficiently captured the complex correlations and mapping relationships across different modalities. Furthermore, existing state-ofthe-art ERC models have difficulty classifying minority and semantically similar emotion categories. To address these challenges, we propose a novel attention-based correlation-aware multimodal fusion framework named MultiEMO, which effectively integrates multimodal cues by capturing cross-modal mapping relationships across textual, audio and visual modalities based on bidirectional multi-head crossattention layers. The difficulty of recognizing minority and semantically hard-to-distinguish emotion classes is alleviated by our proposed Sample-Weighted Focal Contrastive (SWFC) loss. Extensive experiments on two benchmark ERC datasets demonstrate that our MultiEMO framework consistently outperforms existing state-of-the-art approaches in all emotion categories on both datasets, the improvements in minority and semantically similar emotions are especially significant.","Emotion Recognition in Conversations (ERC) is an emerging task in the field of Natural Language Processing (NLP), which aims to identify the emotion of each utterance in a conversation based on textual, audio and visual cues of the speaker. ERC has attracted an enormous amount of attention from both academia and industry, due to its widespread potentials in social media analysis (Chatterjee et al., 2019), health care services (Hu et al., 2021b), empathetic systems (Jiao et al., 2020), and so on. To solve the problem of ERC, numerous approaches have been proposed. The majority of existing works concentrate on modeling speaker dependencies and conversational contexts (Poria et al., 2017; Hazarika et al., 2018a,c; Majumder et al., 2019; Ghosal et al., 2019, 2020; Shen et al., 2021; Hu et al., 2021a,b; Li et al., 2021a; Joshi et al., 2022; Lee and Lee, 2022), while there still exist several unsolved challenges: (1) The complementarity of multimodal information has not been well exploited. Apart from rich information contained in the textual modality, the tone and intonation of the speaker can indicate the intensity of the emotion, facial expressions of interlocutors are also able to explicitly reveal emotional tendencies (Li et al., 2022). Figure 1 shows an example where the complementarity of acoustic and visual signals in addition to the textual modality is essential for an accurate emotion classification. Nevertheless, most existing approaches focus on the textual modality of utterances or simply utilize feature concatenation as the multimodal fusion mechanism (Poria et al., 2017; Hazarika et al., 2018a,c; Majumder et al., 2019; Zhang and Chai, 2021; Li et al., 2022) without modeling the complicated correlations and mapping relationships across textual, audio and visual modalities, which results in an inadequate integration of multimodal cues. (2) Unsatisfactory performances in minority emotion classes. Existing benchmark datasets in ERC, such as IEMOCAP (Busso et al., 2008) and MELD (Poria et al., 2019), suffer from the problem of imbalanced classes. As illustrated in Figure 2, both MELD and IEMOCAP are class-imbalanced, especially in MELD, where the majority class neutral takes up a much larger proportion than minority classes disgust and fear. Current state-of-the-art approaches fail to solve the class imbalance problem and have poor performances in minority emotions. (3) The difficulty of distinguishing between semantically similar emotions. It remains to be a challenging task to correctly classify different emotions that are semantically related, such as disgust and anger in MELD, since they share similar underlying cognitive, affective and physiological features, and tend to be expressed by speakers in similar contexts. To address the above problems, in this paper, we propose a novel attention-based correlationaware multimodal fusion framework named MultiEMO. Firstly, unimodal feature extraction and context modeling are performed for each modality, in which we introduce a visual feature extractor named VisExtNet based on a Multi-task Cascaded Convolutional Network (MTCNN) (Zhang et al., 2016) and a VGGFace2 (Cao et al., 2018) pretrained ResNet-101 (He et al., 2016). VisExtNet accurately captures visual cues of utterance videos by extracting emotion-rich facial expressions of interlocutors without modeling redundant scenerelated visual information. Secondly, we propose a multimodal fusion model called MultiAttn to effectively integrate multimodal information based on bidirectional multi-head cross-attention layers (Vaswani et al., 2017), which successfully captures complex cross-modal correlations and mapping relationships across contextualized textual, audio and visual features. Thirdly, in order to mitigate the difficulty of classifying minority and semantically similar emotion classes, enlightened by Focal Contrastive loss (Zhang et al., 2021), a Sample-Weighted Focal Contrastive (SWFC) loss is proposed, in which we assign more focus to hard-to-classify minority classes and make sample pairs with different emotion labels mutually exclusive with each other such that semantically similar emotions can be better distinguished. In addition, we utilize a Soft Hirschfeld-GebeleinRényi (Soft-HGR) loss (Wang et al., 2019) to maximize the correlations across multimodal-fused textual, audio and visual feature representations extracted from MultiAttn. Finally, extensive experiments are conducted on two ERC benchmark datasets, MELD and IEMOCAP. Experimental results demonstrate the effectiveness and superiority of our proposed MultiEMO framework compared with existing state-of-the-art approaches, the improvements in minority and semantically similar emotion categories are especially remarkable. The main contributions of this work can be summarized as follows: • We propose a novel visual feature extraction network named VisExtNet, which effectively captures visual cues of interlocutors without modeling redundant scene information. • We design a multimodal fusion model called MultiAttn based on bidirectional multi-head cross-attention layers, which successfully models the complicated correlations across textual, audio and visual modalities. • We innovatively introduce a SWFC loss to address the difficulty of classifying minority and semantically similar emotion classes. • We conduct extensive experiments on MELD and IEMOCAP, results show that our proposed MultiEMO framework achieves stateof-the-art performances on both datasets, the improvements in minority and semantically similar emotions are especially notable.","Can the accuracy of emotion recognition in conversations be improved by effectively integrating and exploiting multimodal information through the MultiEMO framework, which incorporates an attention-based, correlation-aware multimodal fusion approach alongside innovative loss functions?",2.0,2.0,1.0
88,Graph-based Dependency Parsing with Bidirectional LSTM,"Wenhui Wang and Baobao Chang. 2016. Graph-based Dependency Parsing with Bidirectional LSTM. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2306–2315, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1218.pdf,https://aclanthology.org/P16-1218/,"In this paper, we propose a neural network model for graph-based dependency parsing which utilizes Bidirectional LSTM (BLSTM) to capture richer contextual information instead of using high-order factorization, and enable our model to use much fewer features than previous work. In addition, we propose an effective way to learn sentence segment embedding on sentence-level based on an extra forward LSTM network. Although our model uses only first-order factorization, experiments on English Peen Treebank and Chinese Penn Treebank show that our model could be competitive with previous higher-order graph-based dependency parsing models and state-of-the-art models.","Dependency parsing is a fundamental task for language processing which has been investigated for decades. It has been applied in a wide range of applications such as information extraction and machine translation. Among a variety of dependency parsing models, graph-based models are attractive for their ability of scoring the parsing decisions on a whole-tree basis. Typical graph-based models factor the dependency tree into subgraphs, including single arcs (McDonald et al., 2005), sibling or grandparent arcs (McDonald and Pereira, 2006; Carreras, 2007) or higher-order substructures (Koo and Collins, 2010; Ma and Zhao, 2012) and then score the whole tree by summing scores of the subgraphs. In these models, subgraphs are usually represented as high-dimensional feature vectors which are then fed into a linear model to learn the feature weights. However, conventional graph-based models heavily rely on feature engineering and their performance is restricted by the design of features. In addition, standard decoding algorithm (Eisner, 2000) only works for the first-order model which limits the scope of feature selection. To incorporate high-order features, Eisner algorithm must be somehow extended or modified, which is usually done at high cost in terms of efficiency. The fourth-order graph-based model (Ma and Zhao, 2012), which seems the highest-order model so far to our knowledge, requires O(n 5 ) time and O(n 4 ) space. Due to the high computational cost, highorder models are normally restricted to producing only unlabeled parses to avoid extra cost introduced by inclusion of arc-labels into the parse trees. To alleviate the burden of feature engineering, Pei et al. (2015) presented an effective neural network model for graph-based dependency parsing. They only use atomic features such as word unigrams and POS tag unigrams and leave the model to automatically learn the feature combinations. However, their model requires many atomic features and still relies on high-order factorization strategy to further improve the accuracy. Different from previous work, we propose an LSTM-based dependency parsing model in this paper and aim to use LSTM network to capture richer contextual information to support parsing decisions, instead of adopting a high-order factorization. The main advantages of our model are as follows: • By introducing Bidirectional LSTM, our model shows strong ability to capture potential long range contextual information and exhibits improved accuracy in recovering long distance dependencies. It is different to previous work in which a similar effect is usually achieved by high-order factorization. More over, our model also eliminates the need for setting feature selection windows and reduces the number of features to a minimum level. • We propose an LSTM-based sentence segment embedding method named LSTMMinus, in which distributed representation of sentence segment is learned by using subtraction between LSTM hidden vectors. Experiment shows this further enhances our model’s ability to access to sentence-level information. • Last but important, our model is a first-order model using standard Eisner algorithm for decoding, the computational cost remains at the lowest level among graph-based models. Our model does not trade-off efficiency for accuracy. We evaluate our model on the English Penn Treebank and Chinese Penn Treebank, experiments show that our model achieves competitive parsing accuracy compared with conventional high-order models, however, with a much lower computational cost.",What is the impact of utilizing a Bidirectional LSTM-based model with reduced feature requirements on the accuracy and computational efficiency of graph-based dependency parsing compared to traditional high-order factorization approaches?,1.0,1.0,1.0
89,Graph-based Dependency Parsing with Bidirectional LSTM,"Wenhui Wang and Baobao Chang. 2016. Graph-based Dependency Parsing with Bidirectional LSTM. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2306–2315, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1218.pdf,https://aclanthology.org/P16-1218/,"In this paper, we propose a neural network model for graph-based dependency parsing which utilizes Bidirectional LSTM (BLSTM) to capture richer contextual information instead of using high-order factorization, and enable our model to use much fewer features than previous work. In addition, we propose an effective way to learn sentence segment embedding on sentence-level based on an extra forward LSTM network. Although our model uses only first-order factorization, experiments on English Peen Treebank and Chinese Penn Treebank show that our model could be competitive with previous higher-order graph-based dependency parsing models and state-of-the-art models.","Dependency parsing is a fundamental task for language processing which has been investigated for decades. It has been applied in a wide range of applications such as information extraction and machine translation. Among a variety of dependency parsing models, graph-based models are attractive for their ability of scoring the parsing decisions on a whole-tree basis. Typical graph-based models factor the dependency tree into subgraphs, including single arcs (McDonald et al., 2005), sibling or grandparent arcs (McDonald and Pereira, 2006; Carreras, 2007) or higher-order substructures (Koo and Collins, 2010; Ma and Zhao, 2012) and then score the whole tree by summing scores of the subgraphs. In these models, subgraphs are usually represented as high-dimensional feature vectors which are then fed into a linear model to learn the feature weights. However, conventional graph-based models heavily rely on feature engineering and their performance is restricted by the design of features. In addition, standard decoding algorithm (Eisner, 2000) only works for the first-order model which limits the scope of feature selection. To incorporate high-order features, Eisner algorithm must be somehow extended or modified, which is usually done at high cost in terms of efficiency. The fourth-order graph-based model (Ma and Zhao, 2012), which seems the highest-order model so far to our knowledge, requires O(n 5 ) time and O(n 4 ) space. Due to the high computational cost, highorder models are normally restricted to producing only unlabeled parses to avoid extra cost introduced by inclusion of arc-labels into the parse trees. To alleviate the burden of feature engineering, Pei et al. (2015) presented an effective neural network model for graph-based dependency parsing. They only use atomic features such as word unigrams and POS tag unigrams and leave the model to automatically learn the feature combinations. However, their model requires many atomic features and still relies on high-order factorization strategy to further improve the accuracy. Different from previous work, we propose an LSTM-based dependency parsing model in this paper and aim to use LSTM network to capture richer contextual information to support parsing decisions, instead of adopting a high-order factorization. The main advantages of our model are as follows: • By introducing Bidirectional LSTM, our model shows strong ability to capture potential long range contextual information and exhibits improved accuracy in recovering long distance dependencies. It is different to previous work in which a similar effect is usually achieved by high-order factorization. More over, our model also eliminates the need for setting feature selection windows and reduces the number of features to a minimum level. • We propose an LSTM-based sentence segment embedding method named LSTMMinus, in which distributed representation of sentence segment is learned by using subtraction between LSTM hidden vectors. Experiment shows this further enhances our model’s ability to access to sentence-level information. • Last but important, our model is a first-order model using standard Eisner algorithm for decoding, the computational cost remains at the lowest level among graph-based models. Our model does not trade-off efficiency for accuracy. We evaluate our model on the English Penn Treebank and Chinese Penn Treebank, experiments show that our model achieves competitive parsing accuracy compared with conventional high-order models, however, with a much lower computational cost.",Can dependency parsing be effectively performed by a neural network model that utilizes Bidirectional LSTM for capturing contextual information and a sentence segment embedding method based on an extra forward LSTM network?,1.0,1.0,1.0
90,Graph-based Dependency Parsing with Bidirectional LSTM,"Wenhui Wang and Baobao Chang. 2016. Graph-based Dependency Parsing with Bidirectional LSTM. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2306–2315, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1218.pdf,https://aclanthology.org/P16-1218/,"In this paper, we propose a neural network model for graph-based dependency parsing which utilizes Bidirectional LSTM (BLSTM) to capture richer contextual information instead of using high-order factorization, and enable our model to use much fewer features than previous work. In addition, we propose an effective way to learn sentence segment embedding on sentence-level based on an extra forward LSTM network. Although our model uses only first-order factorization, experiments on English Peen Treebank and Chinese Penn Treebank show that our model could be competitive with previous higher-order graph-based dependency parsing models and state-of-the-art models.","Dependency parsing is a fundamental task for language processing which has been investigated for decades. It has been applied in a wide range of applications such as information extraction and machine translation. Among a variety of dependency parsing models, graph-based models are attractive for their ability of scoring the parsing decisions on a whole-tree basis. Typical graph-based models factor the dependency tree into subgraphs, including single arcs (McDonald et al., 2005), sibling or grandparent arcs (McDonald and Pereira, 2006; Carreras, 2007) or higher-order substructures (Koo and Collins, 2010; Ma and Zhao, 2012) and then score the whole tree by summing scores of the subgraphs. In these models, subgraphs are usually represented as high-dimensional feature vectors which are then fed into a linear model to learn the feature weights. However, conventional graph-based models heavily rely on feature engineering and their performance is restricted by the design of features. In addition, standard decoding algorithm (Eisner, 2000) only works for the first-order model which limits the scope of feature selection. To incorporate high-order features, Eisner algorithm must be somehow extended or modified, which is usually done at high cost in terms of efficiency. The fourth-order graph-based model (Ma and Zhao, 2012), which seems the highest-order model so far to our knowledge, requires O(n 5 ) time and O(n 4 ) space. Due to the high computational cost, highorder models are normally restricted to producing only unlabeled parses to avoid extra cost introduced by inclusion of arc-labels into the parse trees. To alleviate the burden of feature engineering, Pei et al. (2015) presented an effective neural network model for graph-based dependency parsing. They only use atomic features such as word unigrams and POS tag unigrams and leave the model to automatically learn the feature combinations. However, their model requires many atomic features and still relies on high-order factorization strategy to further improve the accuracy. Different from previous work, we propose an LSTM-based dependency parsing model in this paper and aim to use LSTM network to capture richer contextual information to support parsing decisions, instead of adopting a high-order factorization. The main advantages of our model are as follows: • By introducing Bidirectional LSTM, our model shows strong ability to capture potential long range contextual information and exhibits improved accuracy in recovering long distance dependencies. It is different to previous work in which a similar effect is usually achieved by high-order factorization. More over, our model also eliminates the need for setting feature selection windows and reduces the number of features to a minimum level. • We propose an LSTM-based sentence segment embedding method named LSTMMinus, in which distributed representation of sentence segment is learned by using subtraction between LSTM hidden vectors. Experiment shows this further enhances our model’s ability to access to sentence-level information. • Last but important, our model is a first-order model using standard Eisner algorithm for decoding, the computational cost remains at the lowest level among graph-based models. Our model does not trade-off efficiency for accuracy. We evaluate our model on the English Penn Treebank and Chinese Penn Treebank, experiments show that our model achieves competitive parsing accuracy compared with conventional high-order models, however, with a much lower computational cost.","Can the limitations in traditional graph-based models for dependency parsing, such as heavy reliance on feature engineering and high computational costs of high-order feature incorporation, be overcome by a new neural network model that utilizes Bidirectional LSTM to capture richer contextual information and introduces an efficient way to learn sentence segment embedding, thereby enhancing performance with minimal feature use and maintained computational efficiency?",2.0,2.0,1.0
91,Improving the Robustness of Summarization Systems with Dual Augmentation,"Xiuying Chen, Guodong Long, Chongyang Tao, Mingzhe Li, Xin Gao, Chengqi Zhang, and Xiangliang Zhang. 2023. Improving the Robustness of Summarization Systems with Dual Augmentation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6846–6857, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.378.pdf,https://aclanthology.org/2023.acl-long.378/,"A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models’ robustness against perturbations including word-level synonym substitution and noise. To create semanticconsistent substitutes, we propose a SummAttacker, which is an efficient approach to generating adversarial samples based on language models. Experimental results show that stateof-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first brittleness factor we found is the poor understanding of infrequent words in the input. Correspondingly, we feed the encoder with more diverse cases created by SummAttacker in the input space. The other factor is in the latent space, where the attacked inputs bring more variations to the hidden states. Hence, we construct adversarial decoder input and devise manifold softmixing operation in hidden space to introduce more diversity. Experimental results on Gigaword and CNN/DM datasets demonstrate that our approach achieves significant improvements over strong baselines and exhibits higher robustness on noisy, attacked, and clean datasets1 .","Humans have robust summarization processing systems that can easily understand diverse expressions and various wording, and overcome typos, misspellings, and the complete omission of letters when reading (Rawlinson, 2007). However, studies reveal that small changes in the input can lead to significant performance drops and fool state-ofthe-art neural networks (Goodfellow et al., 2015; Belinkov and Bisk, 2018; Cheng et al., 2018). In text generation fields such as machine translation, Belinkov and Bisk (2018) showed that state-ofthe-art models fail to translate even moderately noisy texts, Cheng et al. (2018) found that the generated translation is completely distorted by only replacing a source word with its synonym. However, the robustness on summarization models is less explored. Here, we show three summarization examples from the Gigaword dataset in Table 1. A fine-tuned BART model will generate a worse summary for a minor change in the input including misspelling errors and synonym substitution, which often happen in practice due to the carelessness and habit of word usage in writing. Take the second case for example, an English user and an American user who use barrister or attorney will obtain summaries of different qualities. In the third case, a synonym word replacement even changes the subject of canvassing. Such weakness of summarization systems can lead to serious consequences in practice. Despite its importance, robustness in summarization has been less explored. Jung et al. (2019) and Krysci ´ nski et al. ´ (2019) examined positional bias and layout bias in summarization. Liu et al. (2021) introduced multiple noise signals in self-knowledge distillation to improve the performance of student models on benchmark datasets, but they did not explicitly evaluate the robustness of summarization models against noise. Hence, in this work, we first evaluate the robustness of the existing state-of-the-art summarization systems against word-level perturbations including noise and adversarial attacks. The noise consists of natural human errors such as typos and misspellings. To create the adversarial attack test set, we come up with a model named SummAttacker. The core algorithm of SummAttacker is to find vulnerable words in a given document for the target model and then apply language models to find substituted words adjacent in the opposite direction of the gradient to maximize perturbations. We validate the effectiveness of SummAttacker on benchmark datasets with different attributes, i.e., Gigaword and CNN/DailyMail. Experiment results show that by only attacking one word (1% token) in Gigaword and 5% tokens in CNN/DailyMail, the existing summarization models have drastically lower performance. We next conduct a vulnerability analysis and propose two corresponding solutions to improve robustness. Our first conjecture is that worse summaries can be caused by replacing common words with uncommon and infrequently-used words, which the model might not understand well. Hence, we employ the outputs from SummAttacker as inputs for the encoder, so as to improve the diversity in the discrete input space. The second influencing factor is that the attacked inputs introduce more variations in the latent space. Correspondingly, we aim to expose the model to more diverse hidden states in the training process. Specifically, we build soft pseudo tokens by multiplying the decoder output probability with target token embeddings. These soft pseudo tokens and original tokens are then manifold softmixed on a randomly selected decoder layer to enlarge the training distribution. The interpolations leveraged in deeper hidden layers help capture higher-level information, improve semantic diversity, and provide additional training signal (Zeiler and Fergus, 2014). Experiments show that our dual augmentation for both encoder and decoder improves the robustness of summarization models on noisy and attacked test datasets. Our main contributions are as follows: • We empirically evaluate the robustness of recent summarization models against perturbations including noise and synonym substitutions. • To improve the robustness of summarization models, we propose a dual data augmentation method that introduces diversity in the input and latent semantic spaces. • Experimental results demonstrate that our augmentation method brings substantial improvements over state-of-the-art baselines on benchmark datasets and attacked test datasets.",How can the robustness of machine learning models for text summarization be improved against perturbations such as noise and synonym substitutions?,1.0,0.0,1.0
92,Improving the Robustness of Summarization Systems with Dual Augmentation,"Xiuying Chen, Guodong Long, Chongyang Tao, Mingzhe Li, Xin Gao, Chengqi Zhang, and Xiangliang Zhang. 2023. Improving the Robustness of Summarization Systems with Dual Augmentation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6846–6857, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.378.pdf,https://aclanthology.org/2023.acl-long.378/,"A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models’ robustness against perturbations including word-level synonym substitution and noise. To create semanticconsistent substitutes, we propose a SummAttacker, which is an efficient approach to generating adversarial samples based on language models. Experimental results show that stateof-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first brittleness factor we found is the poor understanding of infrequent words in the input. Correspondingly, we feed the encoder with more diverse cases created by SummAttacker in the input space. The other factor is in the latent space, where the attacked inputs bring more variations to the hidden states. Hence, we construct adversarial decoder input and devise manifold softmixing operation in hidden space to introduce more diversity. Experimental results on Gigaword and CNN/DM datasets demonstrate that our approach achieves significant improvements over strong baselines and exhibits higher robustness on noisy, attacked, and clean datasets1 .","Humans have robust summarization processing systems that can easily understand diverse expressions and various wording, and overcome typos, misspellings, and the complete omission of letters when reading (Rawlinson, 2007). However, studies reveal that small changes in the input can lead to significant performance drops and fool state-ofthe-art neural networks (Goodfellow et al., 2015; Belinkov and Bisk, 2018; Cheng et al., 2018). In text generation fields such as machine translation, Belinkov and Bisk (2018) showed that state-ofthe-art models fail to translate even moderately noisy texts, Cheng et al. (2018) found that the generated translation is completely distorted by only replacing a source word with its synonym. However, the robustness on summarization models is less explored. Here, we show three summarization examples from the Gigaword dataset in Table 1. A fine-tuned BART model will generate a worse summary for a minor change in the input including misspelling errors and synonym substitution, which often happen in practice due to the carelessness and habit of word usage in writing. Take the second case for example, an English user and an American user who use barrister or attorney will obtain summaries of different qualities. In the third case, a synonym word replacement even changes the subject of canvassing. Such weakness of summarization systems can lead to serious consequences in practice. Despite its importance, robustness in summarization has been less explored. Jung et al. (2019) and Krysci ´ nski et al. ´ (2019) examined positional bias and layout bias in summarization. Liu et al. (2021) introduced multiple noise signals in self-knowledge distillation to improve the performance of student models on benchmark datasets, but they did not explicitly evaluate the robustness of summarization models against noise. Hence, in this work, we first evaluate the robustness of the existing state-of-the-art summarization systems against word-level perturbations including noise and adversarial attacks. The noise consists of natural human errors such as typos and misspellings. To create the adversarial attack test set, we come up with a model named SummAttacker. The core algorithm of SummAttacker is to find vulnerable words in a given document for the target model and then apply language models to find substituted words adjacent in the opposite direction of the gradient to maximize perturbations. We validate the effectiveness of SummAttacker on benchmark datasets with different attributes, i.e., Gigaword and CNN/DailyMail. Experiment results show that by only attacking one word (1% token) in Gigaword and 5% tokens in CNN/DailyMail, the existing summarization models have drastically lower performance. We next conduct a vulnerability analysis and propose two corresponding solutions to improve robustness. Our first conjecture is that worse summaries can be caused by replacing common words with uncommon and infrequently-used words, which the model might not understand well. Hence, we employ the outputs from SummAttacker as inputs for the encoder, so as to improve the diversity in the discrete input space. The second influencing factor is that the attacked inputs introduce more variations in the latent space. Correspondingly, we aim to expose the model to more diverse hidden states in the training process. Specifically, we build soft pseudo tokens by multiplying the decoder output probability with target token embeddings. These soft pseudo tokens and original tokens are then manifold softmixed on a randomly selected decoder layer to enlarge the training distribution. The interpolations leveraged in deeper hidden layers help capture higher-level information, improve semantic diversity, and provide additional training signal (Zeiler and Fergus, 2014). Experiments show that our dual augmentation for both encoder and decoder improves the robustness of summarization models on noisy and attacked test datasets. Our main contributions are as follows: • We empirically evaluate the robustness of recent summarization models against perturbations including noise and synonym substitutions. • To improve the robustness of summarization models, we propose a dual data augmentation method that introduces diversity in the input and latent semantic spaces. • Experimental results demonstrate that our augmentation method brings substantial improvements over state-of-the-art baselines on benchmark datasets and attacked test datasets.",Can the robustness of summarization models against perturbations including noise and synonym substitutions be improved by introducing diversity in the input and latent semantic spaces through a dual data augmentation method?,1.0,1.0,1.0
93,Improving the Robustness of Summarization Systems with Dual Augmentation,"Xiuying Chen, Guodong Long, Chongyang Tao, Mingzhe Li, Xin Gao, Chengqi Zhang, and Xiangliang Zhang. 2023. Improving the Robustness of Summarization Systems with Dual Augmentation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6846–6857, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.378.pdf,https://aclanthology.org/2023.acl-long.378/,"A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models’ robustness against perturbations including word-level synonym substitution and noise. To create semanticconsistent substitutes, we propose a SummAttacker, which is an efficient approach to generating adversarial samples based on language models. Experimental results show that stateof-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first brittleness factor we found is the poor understanding of infrequent words in the input. Correspondingly, we feed the encoder with more diverse cases created by SummAttacker in the input space. The other factor is in the latent space, where the attacked inputs bring more variations to the hidden states. Hence, we construct adversarial decoder input and devise manifold softmixing operation in hidden space to introduce more diversity. Experimental results on Gigaword and CNN/DM datasets demonstrate that our approach achieves significant improvements over strong baselines and exhibits higher robustness on noisy, attacked, and clean datasets1 .","Humans have robust summarization processing systems that can easily understand diverse expressions and various wording, and overcome typos, misspellings, and the complete omission of letters when reading (Rawlinson, 2007). However, studies reveal that small changes in the input can lead to significant performance drops and fool state-ofthe-art neural networks (Goodfellow et al., 2015; Belinkov and Bisk, 2018; Cheng et al., 2018). In text generation fields such as machine translation, Belinkov and Bisk (2018) showed that state-ofthe-art models fail to translate even moderately noisy texts, Cheng et al. (2018) found that the generated translation is completely distorted by only replacing a source word with its synonym. However, the robustness on summarization models is less explored. Here, we show three summarization examples from the Gigaword dataset in Table 1. A fine-tuned BART model will generate a worse summary for a minor change in the input including misspelling errors and synonym substitution, which often happen in practice due to the carelessness and habit of word usage in writing. Take the second case for example, an English user and an American user who use barrister or attorney will obtain summaries of different qualities. In the third case, a synonym word replacement even changes the subject of canvassing. Such weakness of summarization systems can lead to serious consequences in practice. Despite its importance, robustness in summarization has been less explored. Jung et al. (2019) and Krysci ´ nski et al. ´ (2019) examined positional bias and layout bias in summarization. Liu et al. (2021) introduced multiple noise signals in self-knowledge distillation to improve the performance of student models on benchmark datasets, but they did not explicitly evaluate the robustness of summarization models against noise. Hence, in this work, we first evaluate the robustness of the existing state-of-the-art summarization systems against word-level perturbations including noise and adversarial attacks. The noise consists of natural human errors such as typos and misspellings. To create the adversarial attack test set, we come up with a model named SummAttacker. The core algorithm of SummAttacker is to find vulnerable words in a given document for the target model and then apply language models to find substituted words adjacent in the opposite direction of the gradient to maximize perturbations. We validate the effectiveness of SummAttacker on benchmark datasets with different attributes, i.e., Gigaword and CNN/DailyMail. Experiment results show that by only attacking one word (1% token) in Gigaword and 5% tokens in CNN/DailyMail, the existing summarization models have drastically lower performance. We next conduct a vulnerability analysis and propose two corresponding solutions to improve robustness. Our first conjecture is that worse summaries can be caused by replacing common words with uncommon and infrequently-used words, which the model might not understand well. Hence, we employ the outputs from SummAttacker as inputs for the encoder, so as to improve the diversity in the discrete input space. The second influencing factor is that the attacked inputs introduce more variations in the latent space. Correspondingly, we aim to expose the model to more diverse hidden states in the training process. Specifically, we build soft pseudo tokens by multiplying the decoder output probability with target token embeddings. These soft pseudo tokens and original tokens are then manifold softmixed on a randomly selected decoder layer to enlarge the training distribution. The interpolations leveraged in deeper hidden layers help capture higher-level information, improve semantic diversity, and provide additional training signal (Zeiler and Fergus, 2014). Experiments show that our dual augmentation for both encoder and decoder improves the robustness of summarization models on noisy and attacked test datasets. Our main contributions are as follows: • We empirically evaluate the robustness of recent summarization models against perturbations including noise and synonym substitutions. • To improve the robustness of summarization models, we propose a dual data augmentation method that introduces diversity in the input and latent semantic spaces. • Experimental results demonstrate that our augmentation method brings substantial improvements over state-of-the-art baselines on benchmark datasets and attacked test datasets.","Can the vulnerability of summarization models to perturbations, leading to significant performance decreases, be addressed by a dual data augmentation method that involves SummAttacker for generating adversarial samples to improve model diversity in both the input and latent spaces?",1.0,1.0,1.0
94,Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic Change,"Haim Dubossarsky, Simon Hengchen, Nina Tahmasebi, and Dominik Schlechtweg. 2019. Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic Change. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 457–470, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1044.pdf,https://aclanthology.org/P19-1044/,"State-of-the-art models of lexical semantic change detection suffer from noise stemming from vector space alignment. We have empirically tested the Temporal Referencing method for lexical semantic change and show that, by avoiding alignment, it is less affected by this noise. We show that, trained on a diachronic corpus, the skip-gram with negative sampling architecture with temporal referencing outperforms alignment models on a synthetic task as well as a manual testset. We introduce a principled way to simulate lexical semantic change and systematically control for possible biases.","These past years have seen the rise of computational methods to detect, track, qualify, and quantify how a word’s sense – or senses – change over time. These tasks are critical challenges that are relevant to a range of NLP fields, including the study of historical semantic change. The successful outcome of semantic change detection is relevant to any diachronic textual analysis, including machine translation or normalization of historical texts (Tjong Kim Sang et al., 2017), the detection of cultural semantic shifts (Kutuzov et al., 2017) or applications in digital humanities (Tahmasebi and Risse, 2017a). However, currently, the best-performing models (Hamilton et al., 2016b; Kulkarni et al., 2015; Schlechtweg et al., 2019) require a complex alignment procedure and have been shown to suffer from biases (Dubossarsky et al., 2017). This exposes them to various sources of noise influencing their predictions; a fact which has long gone unnoticed because of the lack of standard evaluation procedures in the field. We examine the modeling approach of Temporal Referencing (TR) which avoids post hoc alignment and is applicable to any vector space learning technique. We show that it (i) is less affected by noise and (ii) clearly outperforms state-of-the-art alignment models on a synthetic change detection task. The task is based on data from a synchronic corpus into which we artificially inject lexical semantic change (LSC) in a controlled and semantically principled way. We further evaluate the models on a manual testset of diachronic LSC and examine their properties. In this paper, we focus on skip-gram with negative sampling (SGNS) models (Mikolov et al., 2013) and PPMI (Levy et al., 2015) and make use of TR to share context information across time periods, while learning individual embeddings for a target word in each time period. We evaluate models in two ways: on the one hand, through the comparison of model performance between semantically changing and stable words. This is achieved through the synthetic introduction (and removal) of polysemy, mimicking Schutze ¨ (1998); Kulkarni et al. (2015); Rosenfeld and Erk (2018). We differ from previous work by creating those changes in a more structured way, and for many time points. The second type of evaluation put forward is a study built on a smaller number of words manually classified as changed or stable. Our contributions are the following: • Noise Reduction: We avoid post hoc alignment by TR and show that it outperforms other models and is robust to noise. • LSC Simulation: We propose a systematic and principled method of injecting semantic change in a controlled fashion. • Evaluation: We evaluate (i) by testing for noise reduction in a control condition, (ii) on large and controlled artificial data and (iii) on a manually annotated LSC testset. • Framework: The above comprises a framework to test any model of semantic change for their levels of noise and sensitivity in detecting simulated semantic change.",Can lexical semantic change detection be improved by employing the Temporal Referencing method to avoid vector space alignment noise?,1.0,1.0,1.0
95,Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic Change,"Haim Dubossarsky, Simon Hengchen, Nina Tahmasebi, and Dominik Schlechtweg. 2019. Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic Change. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 457–470, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1044.pdf,https://aclanthology.org/P19-1044/,"State-of-the-art models of lexical semantic change detection suffer from noise stemming from vector space alignment. We have empirically tested the Temporal Referencing method for lexical semantic change and show that, by avoiding alignment, it is less affected by this noise. We show that, trained on a diachronic corpus, the skip-gram with negative sampling architecture with temporal referencing outperforms alignment models on a synthetic task as well as a manual testset. We introduce a principled way to simulate lexical semantic change and systematically control for possible biases.","These past years have seen the rise of computational methods to detect, track, qualify, and quantify how a word’s sense – or senses – change over time. These tasks are critical challenges that are relevant to a range of NLP fields, including the study of historical semantic change. The successful outcome of semantic change detection is relevant to any diachronic textual analysis, including machine translation or normalization of historical texts (Tjong Kim Sang et al., 2017), the detection of cultural semantic shifts (Kutuzov et al., 2017) or applications in digital humanities (Tahmasebi and Risse, 2017a). However, currently, the best-performing models (Hamilton et al., 2016b; Kulkarni et al., 2015; Schlechtweg et al., 2019) require a complex alignment procedure and have been shown to suffer from biases (Dubossarsky et al., 2017). This exposes them to various sources of noise influencing their predictions; a fact which has long gone unnoticed because of the lack of standard evaluation procedures in the field. We examine the modeling approach of Temporal Referencing (TR) which avoids post hoc alignment and is applicable to any vector space learning technique. We show that it (i) is less affected by noise and (ii) clearly outperforms state-of-the-art alignment models on a synthetic change detection task. The task is based on data from a synchronic corpus into which we artificially inject lexical semantic change (LSC) in a controlled and semantically principled way. We further evaluate the models on a manual testset of diachronic LSC and examine their properties. In this paper, we focus on skip-gram with negative sampling (SGNS) models (Mikolov et al., 2013) and PPMI (Levy et al., 2015) and make use of TR to share context information across time periods, while learning individual embeddings for a target word in each time period. We evaluate models in two ways: on the one hand, through the comparison of model performance between semantically changing and stable words. This is achieved through the synthetic introduction (and removal) of polysemy, mimicking Schutze ¨ (1998); Kulkarni et al. (2015); Rosenfeld and Erk (2018). We differ from previous work by creating those changes in a more structured way, and for many time points. The second type of evaluation put forward is a study built on a smaller number of words manually classified as changed or stable. Our contributions are the following: • Noise Reduction: We avoid post hoc alignment by TR and show that it outperforms other models and is robust to noise. • LSC Simulation: We propose a systematic and principled method of injecting semantic change in a controlled fashion. • Evaluation: We evaluate (i) by testing for noise reduction in a control condition, (ii) on large and controlled artificial data and (iii) on a manually annotated LSC testset. • Framework: The above comprises a framework to test any model of semantic change for their levels of noise and sensitivity in detecting simulated semantic change.","Can the problem of noise in lexical semantic change detection, stemming from vector space alignment, be mitigated by employing the Temporal Referencing method which avoids alignment and thereby outperforms existing alignment models on synthetic tasks and manual testsets?",1.0,1.0,1.0
96,Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding,"Haoli Bai, Zhiguang Liu, Xiaojun Meng, Li Wentao, Shuang Liu, Yifeng Luo, Nian Xie, Rongfu Zheng, Liangwei Wang, Lu Hou, Jiansheng Wei, Xin Jiang, and Qun Liu. 2023. Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 13386–13401, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.748.pdf,https://aclanthology.org/2023.acl-long.748/,"Unsupervised pre-training on millions of digital-born or scanned documents has shown promising advances in visual document understanding (VDU). While various visionlanguage pre-training objectives are studied in existing solutions, the document textline, as an intrinsic granularity in VDU, has seldom been explored so far. A document textline usually contains words that are spatially and semantically correlated, which can be easily obtained from OCR engines. In this paper, we propose WUKONG-READER, trained with new pre-training objectives to leverage the structural knowledge nested in document textlines. We introduce textline-region contrastive learning to achieve fine-grained alignment between the visual regions and texts of document textlines. Furthermore, masked region modeling and textline-grid matching are also designed to enhance the visual and layout representations of textlines. Experiments show that WUKONGREADER brings superior performance on various VDU tasks in both English and Chinese. The fine-grained alignment over textlines also empowers WUKONG-READER with promising localization ability.","Visual document understanding (VDU) handles various types of digital-born or scanned documents like forms, tables, reports, or research papers, and is becoming increasingly important for real-world industrial practices [7]. Multi-modal pre-training on millions of documents is a popular solution for visual document understanding [12, 33, 35, 34, 14, 27]. Unlike the conventional vision-language pre-training over natural images and their paired short and abstractive descriptions [29, 22, 21], the document texts are usually long and highly correlated with the images, since they can be easily obtained from accurate Optical Character Recognition (OCR) engines from the scanned images. Therefore, it is crucial to strengthen the connection between vision and language for VDU with more fine-grained alignment across the two modalities. Towards that end, existing efforts seek to align the visual and textual knowledge of documents at different levels. A commonly used pre-training objective for documents is masked language modeling [8] over document text tokens [35, 34, 14, 33, 12, 27], often accompanied by the layout information encoded via the positional embedding. Besides, various visual and vision-language multimodal pre-training objectives are also proposed, leveraging the patch-level features [34, 14], objectlevel features from object detectors [23, 11], or the whole image feature through a global text-image matching loss [34]. However, as an intrinsic granularity for VDU, document textlines have been mostly neglected in past efforts. Intuitively, a textline contains a set of words that are spatially and semantically related. For instance of information extraction, the desired text span (e.g., the names on letters and addresses on receipts in Figure 1) often appears in a single textline. Therefore, the document textline serves as an appealing fine-grained granularity for VDU tasks. While StructualLM [19] similarly considers textlines as cell layout information, they only use the textual features of these textlines in language modeling. Instead, in this work, we seek to enhance the multi-modal representation of a document by aligning the visual region and text span corresponding to the same textline. In this work, we propose WUKONG-READER, a pre-trained document model with a hybrid dualand single-stream multimodal architecture. To learn fine-grained document representation, we propose the Textline-Region Contrastive Learning to align the visual and textual features of document textlines from the dual-stream encoders. The objective thus connects the spatial and semantic information among document textlines for various VDU tasks. Additionally, we also introduce two other objectives to further improve the textline representation. We design the Masked Region Modeling to recover the masked textline regions, so as to enhance the visual features of textline. We also propose the Textline Grid Matching to strengthen the layout information of textlines, which localizes each word of textlines to the pre-defined image grids. Similar to previous works [35, 34, 14], the classic masked language modeling objective is also applied over document texts. Experimental results show that our WUKONGREADER notably improves various document understanding tasks across both English and Chinese. For instance, WUKONG-READERlarge with 470M parameters achieves the weighted F1 score of 93.62 on FUNSD [16] and 98.15 on SROIE [15], leading the new state-of-the-art records on information extraction tasks. We also demonstrate that the textline-based pre-training objectives empower the model with meaningful textline features with promising localization ability.","How can leveraging the structural knowledge nested in document textlines, through novel pre-training objectives, enhance the multi-modal representation of a document for improved performance on visual document understanding tasks?",0.0,1.0,0.0
97,Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding,"Haoli Bai, Zhiguang Liu, Xiaojun Meng, Li Wentao, Shuang Liu, Yifeng Luo, Nian Xie, Rongfu Zheng, Liangwei Wang, Lu Hou, Jiansheng Wei, Xin Jiang, and Qun Liu. 2023. Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 13386–13401, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.748.pdf,https://aclanthology.org/2023.acl-long.748/,"Unsupervised pre-training on millions of digital-born or scanned documents has shown promising advances in visual document understanding (VDU). While various visionlanguage pre-training objectives are studied in existing solutions, the document textline, as an intrinsic granularity in VDU, has seldom been explored so far. A document textline usually contains words that are spatially and semantically correlated, which can be easily obtained from OCR engines. In this paper, we propose WUKONG-READER, trained with new pre-training objectives to leverage the structural knowledge nested in document textlines. We introduce textline-region contrastive learning to achieve fine-grained alignment between the visual regions and texts of document textlines. Furthermore, masked region modeling and textline-grid matching are also designed to enhance the visual and layout representations of textlines. Experiments show that WUKONGREADER brings superior performance on various VDU tasks in both English and Chinese. The fine-grained alignment over textlines also empowers WUKONG-READER with promising localization ability.","Visual document understanding (VDU) handles various types of digital-born or scanned documents like forms, tables, reports, or research papers, and is becoming increasingly important for real-world industrial practices [7]. Multi-modal pre-training on millions of documents is a popular solution for visual document understanding [12, 33, 35, 34, 14, 27]. Unlike the conventional vision-language pre-training over natural images and their paired short and abstractive descriptions [29, 22, 21], the document texts are usually long and highly correlated with the images, since they can be easily obtained from accurate Optical Character Recognition (OCR) engines from the scanned images. Therefore, it is crucial to strengthen the connection between vision and language for VDU with more fine-grained alignment across the two modalities. Towards that end, existing efforts seek to align the visual and textual knowledge of documents at different levels. A commonly used pre-training objective for documents is masked language modeling [8] over document text tokens [35, 34, 14, 33, 12, 27], often accompanied by the layout information encoded via the positional embedding. Besides, various visual and vision-language multimodal pre-training objectives are also proposed, leveraging the patch-level features [34, 14], objectlevel features from object detectors [23, 11], or the whole image feature through a global text-image matching loss [34]. However, as an intrinsic granularity for VDU, document textlines have been mostly neglected in past efforts. Intuitively, a textline contains a set of words that are spatially and semantically related. For instance of information extraction, the desired text span (e.g., the names on letters and addresses on receipts in Figure 1) often appears in a single textline. Therefore, the document textline serves as an appealing fine-grained granularity for VDU tasks. While StructualLM [19] similarly considers textlines as cell layout information, they only use the textual features of these textlines in language modeling. Instead, in this work, we seek to enhance the multi-modal representation of a document by aligning the visual region and text span corresponding to the same textline. In this work, we propose WUKONG-READER, a pre-trained document model with a hybrid dualand single-stream multimodal architecture. To learn fine-grained document representation, we propose the Textline-Region Contrastive Learning to align the visual and textual features of document textlines from the dual-stream encoders. The objective thus connects the spatial and semantic information among document textlines for various VDU tasks. Additionally, we also introduce two other objectives to further improve the textline representation. We design the Masked Region Modeling to recover the masked textline regions, so as to enhance the visual features of textline. We also propose the Textline Grid Matching to strengthen the layout information of textlines, which localizes each word of textlines to the pre-defined image grids. Similar to previous works [35, 34, 14], the classic masked language modeling objective is also applied over document texts. Experimental results show that our WUKONGREADER notably improves various document understanding tasks across both English and Chinese. For instance, WUKONG-READERlarge with 470M parameters achieves the weighted F1 score of 93.62 on FUNSD [16] and 98.15 on SROIE [15], leading the new state-of-the-art records on information extraction tasks. We also demonstrate that the textline-based pre-training objectives empower the model with meaningful textline features with promising localization ability.",Can the alignment of visual and textual features of document textlines be enhanced by Textline-Region Contrastive Learning along with Masked Region Modeling and Textline Grid Matching?,1.0,1.0,1.0
98,Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding,"Haoli Bai, Zhiguang Liu, Xiaojun Meng, Li Wentao, Shuang Liu, Yifeng Luo, Nian Xie, Rongfu Zheng, Liangwei Wang, Lu Hou, Jiansheng Wei, Xin Jiang, and Qun Liu. 2023. Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 13386–13401, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.748.pdf,https://aclanthology.org/2023.acl-long.748/,"Unsupervised pre-training on millions of digital-born or scanned documents has shown promising advances in visual document understanding (VDU). While various visionlanguage pre-training objectives are studied in existing solutions, the document textline, as an intrinsic granularity in VDU, has seldom been explored so far. A document textline usually contains words that are spatially and semantically correlated, which can be easily obtained from OCR engines. In this paper, we propose WUKONG-READER, trained with new pre-training objectives to leverage the structural knowledge nested in document textlines. We introduce textline-region contrastive learning to achieve fine-grained alignment between the visual regions and texts of document textlines. Furthermore, masked region modeling and textline-grid matching are also designed to enhance the visual and layout representations of textlines. Experiments show that WUKONGREADER brings superior performance on various VDU tasks in both English and Chinese. The fine-grained alignment over textlines also empowers WUKONG-READER with promising localization ability.","Visual document understanding (VDU) handles various types of digital-born or scanned documents like forms, tables, reports, or research papers, and is becoming increasingly important for real-world industrial practices [7]. Multi-modal pre-training on millions of documents is a popular solution for visual document understanding [12, 33, 35, 34, 14, 27]. Unlike the conventional vision-language pre-training over natural images and their paired short and abstractive descriptions [29, 22, 21], the document texts are usually long and highly correlated with the images, since they can be easily obtained from accurate Optical Character Recognition (OCR) engines from the scanned images. Therefore, it is crucial to strengthen the connection between vision and language for VDU with more fine-grained alignment across the two modalities. Towards that end, existing efforts seek to align the visual and textual knowledge of documents at different levels. A commonly used pre-training objective for documents is masked language modeling [8] over document text tokens [35, 34, 14, 33, 12, 27], often accompanied by the layout information encoded via the positional embedding. Besides, various visual and vision-language multimodal pre-training objectives are also proposed, leveraging the patch-level features [34, 14], objectlevel features from object detectors [23, 11], or the whole image feature through a global text-image matching loss [34]. However, as an intrinsic granularity for VDU, document textlines have been mostly neglected in past efforts. Intuitively, a textline contains a set of words that are spatially and semantically related. For instance of information extraction, the desired text span (e.g., the names on letters and addresses on receipts in Figure 1) often appears in a single textline. Therefore, the document textline serves as an appealing fine-grained granularity for VDU tasks. While StructualLM [19] similarly considers textlines as cell layout information, they only use the textual features of these textlines in language modeling. Instead, in this work, we seek to enhance the multi-modal representation of a document by aligning the visual region and text span corresponding to the same textline. In this work, we propose WUKONG-READER, a pre-trained document model with a hybrid dualand single-stream multimodal architecture. To learn fine-grained document representation, we propose the Textline-Region Contrastive Learning to align the visual and textual features of document textlines from the dual-stream encoders. The objective thus connects the spatial and semantic information among document textlines for various VDU tasks. Additionally, we also introduce two other objectives to further improve the textline representation. We design the Masked Region Modeling to recover the masked textline regions, so as to enhance the visual features of textline. We also propose the Textline Grid Matching to strengthen the layout information of textlines, which localizes each word of textlines to the pre-defined image grids. Similar to previous works [35, 34, 14], the classic masked language modeling objective is also applied over document texts. Experimental results show that our WUKONGREADER notably improves various document understanding tasks across both English and Chinese. For instance, WUKONG-READERlarge with 470M parameters achieves the weighted F1 score of 93.62 on FUNSD [16] and 98.15 on SROIE [15], leading the new state-of-the-art records on information extraction tasks. We also demonstrate that the textline-based pre-training objectives empower the model with meaningful textline features with promising localization ability.","Can the inadequacy in exploring document textlines for visual document understanding be addressed by leveraging their spatial and semantic correlation using WUKONG-READER, trained with specific pre-training objectives?",2.0,1.0,1.0
99,ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation,"Kuan-Hao Huang, Varun Iyer, I-Hung Hsu, Anoop Kumar, Kai-Wei Chang, and Aram Galstyan. 2023. ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8047–8061, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.447.pdf,https://aclanthology.org/2023.acl-long.447/,"Paraphrase generation is a long-standing task in natural language processing (NLP). Supervised paraphrase generation models, which rely on human-annotated paraphrase pairs, are costinefficient and hard to scale up. On the other hand, automatically annotated paraphrase pairs (e.g., by machine back-translation), usually suffer from the lack of syntactic diversity — the generated paraphrase sentences are very similar to the source sentences in terms of syntax. In this work, we present PARAAMR, a large-scale syntactically diverse paraphrase dataset created by abstract meaning representation backtranslation. Our quantitative analysis, qualitative examples, and human evaluation demonstrate that the paraphrases of PARAAMR are syntactically more diverse compared to existing large-scale paraphrase datasets while preserving good semantic similarity. In addition, we show that PARAAMR can be used to improve on three NLP tasks: learning sentence embeddings, syntactically controlled paraphrase generation, and data augmentation for few-shot learning. Our results thus showcase the potential of PARAAMR for improving various NLP applications.","Paraphrase generation is a long-standing task in natural language processing (NLP) (McKeown, 1983; Barzilay and Lee, 2003; Kauchak and Barzilay, 2006). It has been applied to various downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), creative generation (Tian et al., 2021), and improving model robustness (Huang and Chang, 2021). Most existing paraphrase generation models require a large amount of annotated paraphrase pairs (Li et al., 2019; Gupta et al., 2018; Kumar et al., 2020). Since human-labeled instances are expensive and hard to scale up (Dolan et al., 2004; Madnani et al., 2012; Iyer et al., 2017), recent research has explored the possibility of generating paraphrase pairs automatically. One popular approach is back-translation (Wieting and Gimpel, 2018; Hu et al., 2019a,b), which generates paraphrases of a source sentence by translating it to another language and translating back to the original language. Although backtranslation creates large-scale automatically annotated paraphrase pairs, the generated paraphrases usually suffer from the lack of syntactic diversity — they are very similar to the source sentences, especially in syntactic features. Consequently, supervised paraphrase models trained with those datasets are also limited in their ability to generate syntactically diverse paraphrases. Furthermore, not all words can be perfectly translated into another language. As we will show in Section 4.3, this mismatch may produce subpar paraphrases. In this work, we leverage abstract meaning representation (AMR) (Banarescu et al., 2013) to generate syntactically diverse paraphrase pairs. We present PARAAMR, a large-scale syntactically diverse paraphrase dataset based on AMR backtranslation. As illustrated by Figure 1, our approach works by encoding a source sentence to an AMR graph, modifying the focus of the AMR graph that represents the main assertion, linearizing the modified AMR graph, and finally decoding the linearized graph back to a sentence. Since the new sentence shares the same AMR graph structure as the source sentence, it preserves similar semantics to the source sentence. At the same time, the change of focus makes the new main assertion different from that source sentence. When linearizing the AMR graph, a different concept will be emphasized at the beginning of the string. Therefore, the decoded sentence may have a much different syntax from the source sentence. Our quantitative analysis (Section 4.2) and qualitative examples (Section 4.3) show that the paraphrases of PARAAMR are syntactically more diverse than existing datasets (Wieting and Gimpel, 2018; Hu et al., 2019a,b), while at the same time preserving good semantic similarity between paraphrased sentences. In addition, our human evaluation results (Section 4.4) confirm that PARAAMR is indeed more syntactically diverse than prior datasets. To showcase the benefits of syntactically diverse paraphrases, we conduct experiments on three downstream tasks: learning sentence embeddings (Section 5.1), syntactically controlled paraphrase generation (Section 5.2), and data augmentation for few-shot learning (Section 5.3). We observe that models trained on PARAAMR achieve better performance on all three downstream tasks compared to other datasets, thus indicating its potential value for various NLP applications.1","How does leveraging abstract meaning representation (AMR) for generating paraphrase pairs improve the syntactic diversity of paraphrases while maintaining semantic similarity, and what impact does this have on various NLP applications?",0.0,2.0,0.0
100,ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation,"Kuan-Hao Huang, Varun Iyer, I-Hung Hsu, Anoop Kumar, Kai-Wei Chang, and Aram Galstyan. 2023. ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR Back-Translation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8047–8061, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.447.pdf,https://aclanthology.org/2023.acl-long.447/,"Paraphrase generation is a long-standing task in natural language processing (NLP). Supervised paraphrase generation models, which rely on human-annotated paraphrase pairs, are costinefficient and hard to scale up. On the other hand, automatically annotated paraphrase pairs (e.g., by machine back-translation), usually suffer from the lack of syntactic diversity — the generated paraphrase sentences are very similar to the source sentences in terms of syntax. In this work, we present PARAAMR, a large-scale syntactically diverse paraphrase dataset created by abstract meaning representation backtranslation. Our quantitative analysis, qualitative examples, and human evaluation demonstrate that the paraphrases of PARAAMR are syntactically more diverse compared to existing large-scale paraphrase datasets while preserving good semantic similarity. In addition, we show that PARAAMR can be used to improve on three NLP tasks: learning sentence embeddings, syntactically controlled paraphrase generation, and data augmentation for few-shot learning. Our results thus showcase the potential of PARAAMR for improving various NLP applications.","Paraphrase generation is a long-standing task in natural language processing (NLP) (McKeown, 1983; Barzilay and Lee, 2003; Kauchak and Barzilay, 2006). It has been applied to various downstream applications, such as question answering (Yu et al., 2018), chatbot engines (Yan et al., 2016), creative generation (Tian et al., 2021), and improving model robustness (Huang and Chang, 2021). Most existing paraphrase generation models require a large amount of annotated paraphrase pairs (Li et al., 2019; Gupta et al., 2018; Kumar et al., 2020). Since human-labeled instances are expensive and hard to scale up (Dolan et al., 2004; Madnani et al., 2012; Iyer et al., 2017), recent research has explored the possibility of generating paraphrase pairs automatically. One popular approach is back-translation (Wieting and Gimpel, 2018; Hu et al., 2019a,b), which generates paraphrases of a source sentence by translating it to another language and translating back to the original language. Although backtranslation creates large-scale automatically annotated paraphrase pairs, the generated paraphrases usually suffer from the lack of syntactic diversity — they are very similar to the source sentences, especially in syntactic features. Consequently, supervised paraphrase models trained with those datasets are also limited in their ability to generate syntactically diverse paraphrases. Furthermore, not all words can be perfectly translated into another language. As we will show in Section 4.3, this mismatch may produce subpar paraphrases. In this work, we leverage abstract meaning representation (AMR) (Banarescu et al., 2013) to generate syntactically diverse paraphrase pairs. We present PARAAMR, a large-scale syntactically diverse paraphrase dataset based on AMR backtranslation. As illustrated by Figure 1, our approach works by encoding a source sentence to an AMR graph, modifying the focus of the AMR graph that represents the main assertion, linearizing the modified AMR graph, and finally decoding the linearized graph back to a sentence. Since the new sentence shares the same AMR graph structure as the source sentence, it preserves similar semantics to the source sentence. At the same time, the change of focus makes the new main assertion different from that source sentence. When linearizing the AMR graph, a different concept will be emphasized at the beginning of the string. Therefore, the decoded sentence may have a much different syntax from the source sentence. Our quantitative analysis (Section 4.2) and qualitative examples (Section 4.3) show that the paraphrases of PARAAMR are syntactically more diverse than existing datasets (Wieting and Gimpel, 2018; Hu et al., 2019a,b), while at the same time preserving good semantic similarity between paraphrased sentences. In addition, our human evaluation results (Section 4.4) confirm that PARAAMR is indeed more syntactically diverse than prior datasets. To showcase the benefits of syntactically diverse paraphrases, we conduct experiments on three downstream tasks: learning sentence embeddings (Section 5.1), syntactically controlled paraphrase generation (Section 5.2), and data augmentation for few-shot learning (Section 5.3). We observe that models trained on PARAAMR achieve better performance on all three downstream tasks compared to other datasets, thus indicating its potential value for various NLP applications.1",Can the problem of automated paraphrase generation suffering from a lack of syntactic diversity and limited efficacy in various NLP tasks be solved by creating a large-scale syntactically diverse paraphrase dataset using abstract meaning representation (AMR) backtranslation and testing its effectiveness in improving various NLP applications?,2.0,2.0,1.0
101,Feature Projection for Improved Text Classification,"Qi Qin, Wenpeng Hu, and Bing Liu. 2020. Feature Projection for Improved Text Classification. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8161–8171, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.726.pdf,https://aclanthology.org/2020.acl-main.726/,"In classification, there are usually some good features that are indicative of class labels. For example, in sentiment classification, words like good and nice are indicative of the positive sentiment and words like bad and terrible are indicative of the negative sentiment. However, there are also many common features (e.g., words) that are not indicative of any specific class (e.g., voice and screen, which are common to both sentiment classes and are not discriminative for classification). Although deep learning has made significant progresses in generating discriminative features through its powerful representation learning, we believe there is still room for improvement. In this paper, we propose a novel angle to further improve this representation learning, i.e., feature projection. This method projects existing features into the orthogonal space of the common features. The resulting projection is thus perpendicular to the common features and more discriminative for classification. We apply this new method to improve CNN, RNN, Transformer, and Bert based text classification and obtain markedly better results.","Text classification is an important task in natural language processing and text mining. It has a very wide range of applications, such as sentiment classification (Liu, 2012), question classification (Li and Roth, 2002), and deception detection (Liu, 2012; Feng et al., 2012). In recent years, deep learning models have been shown to outperform traditional classification methods (Kim, 2014; Iyyer et al., 2015; Tang et al., 2015; Dai and Le, 2015; Jin et al., 2016; Joulin et al., 2017; Shen et al., 2018). Given the input document, the system applies a mapping function (e.g., averaging or summation, a convolution neural network (CNN), recurrent neural network (RNN), and so on) to learn a dense representation of the document and then uses this representation to perform the final classification. Representation learning is one of the key strengthes of deep learning. In this paper, we propose to further improve the representation learning, i.e., to make the representation more discriminative for classification. Note that throughout the paper we will use sentence sentiment classification as an example to explain different ideas, but in our experiments, non-sentiment classification datasets are also used to show the generality of the proposed method. For text classification, many neural networks and embedding techniques have been devised and applied, e.g., RNN, CNN, Transformer (Vaswani et al., 2017) and Bert (Devlin et al., 2018). For example, RNN can model the whole sentence and also capture the long-term dependencies within the sentence. However, modeling the entire sequence may neglect some key local contexts that are important for classification (Yin et al., 2017). CNN is able to extract more local and position-invariant features (Scherer et al., 2010; Collobert et al., 2011). However, these methods may not give enough weights to some special or discriminative words. To solve this problem, the attention mechanism was introduced. For example, by exploiting attention, Transformer and Bert (which maximizes Transformer’s ability to extract sentence semantic information) can achieve even better results than both CNN and RNN on many tasks. We will see some other related methods to produce effective representations in the related work section. Although the existing models are already able to produce excellent representations, we will show that these representations can still be improved. This paper explores in an entirely different direction, i.e., feature projection. In a typical sentence or document, there are usually some words or features that are correlated with some class labels, but there are also many other common features that cannot distinguish different classes. For example, in sentiment classification, words like Good and Nice are indicative of the positive sentiment, and words like Bad and Terrible are indicative of the negative sentiment. Words like picture, price, and battery are not indicative of any sentiment, i.e., they are not discriminative. However, they may still interfere the representation learning to produce sub-optimal feature representations for the final classification. Even though the attention mechanism can alleviate this problem to some extent by giving higher weights to words associated with classes and lower weights to the other words that are not indicative of any specific classes. However, due to the idiosyncrasy of the data and the inaccuracy of the attention mechanism, the problem remains. In this paper, we propose a novel feature projection method to improve feature representation learning to make it more discriminative for classification. The proposed method is called Feature Purification Network (FP-Net). Specifically, FPNet consists of two sub-networks, a common feature learning network referred to as the C-net and a projection network referred to as the P-net. Cnet uses a Gradient Reverse Layer (GRL) (Ganin and Lempitsky, 2014; Zhang et al., 2019) to extract common features ~b (i.e., invariant features (Zhang et al., 2019)) that are shared by multiple classes and have little discriminative power for classification. At the same time, P-net uses a traditional feature extractor to learn the feature vector ~a for the input sentence or document. Then the feature (or representation) vector ~a is projected onto the vector of the common features ~b (i.e., vector ~b) to get a projection vector ~c, which represents the input sentence’s own common features. Then, we project the feature vector ~a onto the orthogonal direction of the vector of the common features ~c to produce the final purer features for classification. It is quite clear and intuitive that this orthogonal project is to get rid of the common features and make the system focusing on those discriminative features only. We will explain why two projections are used in Section 3. In summary, the key contribution of this paper is the improvement to representation learning through feature vector projection. To the best of our knowledge, this is the first such technique. Specifically, an Orthogonal Projection Layer (OPL) is proposed to map the features obtained by a traditional feature extractor to the classification-specific semantic space, which is orthogonal to the common features such that we obtain a more relevant and discriminative (or purer) feature representation from the original document for classification. Extensive experiments have been conducted to verify the effectiveness of the proposed method on two sentence sentiment classification datasets MR and SST2, a natural language inference dataset SNLI, and a question classification dataset TREC. The results show that the proposed method can improve the classification accuracy of RNN, CNN, Transformer and Bert based classification methods markedly, which shows that feature projection is a highly promising direction to explore.","How can the novel feature projection method, specifically the Orthogonal Projection Layer (OPL) within the Feature Purification Network (FP-Net), improve deep learning-based text classification by enhancing feature representation learning to be more discriminative for classification tasks?",1.0,2.0,1.0
102,Feature Projection for Improved Text Classification,"Qi Qin, Wenpeng Hu, and Bing Liu. 2020. Feature Projection for Improved Text Classification. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8161–8171, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.726.pdf,https://aclanthology.org/2020.acl-main.726/,"In classification, there are usually some good features that are indicative of class labels. For example, in sentiment classification, words like good and nice are indicative of the positive sentiment and words like bad and terrible are indicative of the negative sentiment. However, there are also many common features (e.g., words) that are not indicative of any specific class (e.g., voice and screen, which are common to both sentiment classes and are not discriminative for classification). Although deep learning has made significant progresses in generating discriminative features through its powerful representation learning, we believe there is still room for improvement. In this paper, we propose a novel angle to further improve this representation learning, i.e., feature projection. This method projects existing features into the orthogonal space of the common features. The resulting projection is thus perpendicular to the common features and more discriminative for classification. We apply this new method to improve CNN, RNN, Transformer, and Bert based text classification and obtain markedly better results.","Text classification is an important task in natural language processing and text mining. It has a very wide range of applications, such as sentiment classification (Liu, 2012), question classification (Li and Roth, 2002), and deception detection (Liu, 2012; Feng et al., 2012). In recent years, deep learning models have been shown to outperform traditional classification methods (Kim, 2014; Iyyer et al., 2015; Tang et al., 2015; Dai and Le, 2015; Jin et al., 2016; Joulin et al., 2017; Shen et al., 2018). Given the input document, the system applies a mapping function (e.g., averaging or summation, a convolution neural network (CNN), recurrent neural network (RNN), and so on) to learn a dense representation of the document and then uses this representation to perform the final classification. Representation learning is one of the key strengthes of deep learning. In this paper, we propose to further improve the representation learning, i.e., to make the representation more discriminative for classification. Note that throughout the paper we will use sentence sentiment classification as an example to explain different ideas, but in our experiments, non-sentiment classification datasets are also used to show the generality of the proposed method. For text classification, many neural networks and embedding techniques have been devised and applied, e.g., RNN, CNN, Transformer (Vaswani et al., 2017) and Bert (Devlin et al., 2018). For example, RNN can model the whole sentence and also capture the long-term dependencies within the sentence. However, modeling the entire sequence may neglect some key local contexts that are important for classification (Yin et al., 2017). CNN is able to extract more local and position-invariant features (Scherer et al., 2010; Collobert et al., 2011). However, these methods may not give enough weights to some special or discriminative words. To solve this problem, the attention mechanism was introduced. For example, by exploiting attention, Transformer and Bert (which maximizes Transformer’s ability to extract sentence semantic information) can achieve even better results than both CNN and RNN on many tasks. We will see some other related methods to produce effective representations in the related work section. Although the existing models are already able to produce excellent representations, we will show that these representations can still be improved. This paper explores in an entirely different direction, i.e., feature projection. In a typical sentence or document, there are usually some words or features that are correlated with some class labels, but there are also many other common features that cannot distinguish different classes. For example, in sentiment classification, words like Good and Nice are indicative of the positive sentiment, and words like Bad and Terrible are indicative of the negative sentiment. Words like picture, price, and battery are not indicative of any sentiment, i.e., they are not discriminative. However, they may still interfere the representation learning to produce sub-optimal feature representations for the final classification. Even though the attention mechanism can alleviate this problem to some extent by giving higher weights to words associated with classes and lower weights to the other words that are not indicative of any specific classes. However, due to the idiosyncrasy of the data and the inaccuracy of the attention mechanism, the problem remains. In this paper, we propose a novel feature projection method to improve feature representation learning to make it more discriminative for classification. The proposed method is called Feature Purification Network (FP-Net). Specifically, FPNet consists of two sub-networks, a common feature learning network referred to as the C-net and a projection network referred to as the P-net. Cnet uses a Gradient Reverse Layer (GRL) (Ganin and Lempitsky, 2014; Zhang et al., 2019) to extract common features ~b (i.e., invariant features (Zhang et al., 2019)) that are shared by multiple classes and have little discriminative power for classification. At the same time, P-net uses a traditional feature extractor to learn the feature vector ~a for the input sentence or document. Then the feature (or representation) vector ~a is projected onto the vector of the common features ~b (i.e., vector ~b) to get a projection vector ~c, which represents the input sentence’s own common features. Then, we project the feature vector ~a onto the orthogonal direction of the vector of the common features ~c to produce the final purer features for classification. It is quite clear and intuitive that this orthogonal project is to get rid of the common features and make the system focusing on those discriminative features only. We will explain why two projections are used in Section 3. In summary, the key contribution of this paper is the improvement to representation learning through feature vector projection. To the best of our knowledge, this is the first such technique. Specifically, an Orthogonal Projection Layer (OPL) is proposed to map the features obtained by a traditional feature extractor to the classification-specific semantic space, which is orthogonal to the common features such that we obtain a more relevant and discriminative (or purer) feature representation from the original document for classification. Extensive experiments have been conducted to verify the effectiveness of the proposed method on two sentence sentiment classification datasets MR and SST2, a natural language inference dataset SNLI, and a question classification dataset TREC. The results show that the proposed method can improve the classification accuracy of RNN, CNN, Transformer and Bert based classification methods markedly, which shows that feature projection is a highly promising direction to explore.",Can the discriminative power of feature representations for text classification be improved by projecting existing features into the orthogonal space of common features?,1.0,1.0,1.0
103,Feature Projection for Improved Text Classification,"Qi Qin, Wenpeng Hu, and Bing Liu. 2020. Feature Projection for Improved Text Classification. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8161–8171, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.726.pdf,https://aclanthology.org/2020.acl-main.726/,"In classification, there are usually some good features that are indicative of class labels. For example, in sentiment classification, words like good and nice are indicative of the positive sentiment and words like bad and terrible are indicative of the negative sentiment. However, there are also many common features (e.g., words) that are not indicative of any specific class (e.g., voice and screen, which are common to both sentiment classes and are not discriminative for classification). Although deep learning has made significant progresses in generating discriminative features through its powerful representation learning, we believe there is still room for improvement. In this paper, we propose a novel angle to further improve this representation learning, i.e., feature projection. This method projects existing features into the orthogonal space of the common features. The resulting projection is thus perpendicular to the common features and more discriminative for classification. We apply this new method to improve CNN, RNN, Transformer, and Bert based text classification and obtain markedly better results.","Text classification is an important task in natural language processing and text mining. It has a very wide range of applications, such as sentiment classification (Liu, 2012), question classification (Li and Roth, 2002), and deception detection (Liu, 2012; Feng et al., 2012). In recent years, deep learning models have been shown to outperform traditional classification methods (Kim, 2014; Iyyer et al., 2015; Tang et al., 2015; Dai and Le, 2015; Jin et al., 2016; Joulin et al., 2017; Shen et al., 2018). Given the input document, the system applies a mapping function (e.g., averaging or summation, a convolution neural network (CNN), recurrent neural network (RNN), and so on) to learn a dense representation of the document and then uses this representation to perform the final classification. Representation learning is one of the key strengthes of deep learning. In this paper, we propose to further improve the representation learning, i.e., to make the representation more discriminative for classification. Note that throughout the paper we will use sentence sentiment classification as an example to explain different ideas, but in our experiments, non-sentiment classification datasets are also used to show the generality of the proposed method. For text classification, many neural networks and embedding techniques have been devised and applied, e.g., RNN, CNN, Transformer (Vaswani et al., 2017) and Bert (Devlin et al., 2018). For example, RNN can model the whole sentence and also capture the long-term dependencies within the sentence. However, modeling the entire sequence may neglect some key local contexts that are important for classification (Yin et al., 2017). CNN is able to extract more local and position-invariant features (Scherer et al., 2010; Collobert et al., 2011). However, these methods may not give enough weights to some special or discriminative words. To solve this problem, the attention mechanism was introduced. For example, by exploiting attention, Transformer and Bert (which maximizes Transformer’s ability to extract sentence semantic information) can achieve even better results than both CNN and RNN on many tasks. We will see some other related methods to produce effective representations in the related work section. Although the existing models are already able to produce excellent representations, we will show that these representations can still be improved. This paper explores in an entirely different direction, i.e., feature projection. In a typical sentence or document, there are usually some words or features that are correlated with some class labels, but there are also many other common features that cannot distinguish different classes. For example, in sentiment classification, words like Good and Nice are indicative of the positive sentiment, and words like Bad and Terrible are indicative of the negative sentiment. Words like picture, price, and battery are not indicative of any sentiment, i.e., they are not discriminative. However, they may still interfere the representation learning to produce sub-optimal feature representations for the final classification. Even though the attention mechanism can alleviate this problem to some extent by giving higher weights to words associated with classes and lower weights to the other words that are not indicative of any specific classes. However, due to the idiosyncrasy of the data and the inaccuracy of the attention mechanism, the problem remains. In this paper, we propose a novel feature projection method to improve feature representation learning to make it more discriminative for classification. The proposed method is called Feature Purification Network (FP-Net). Specifically, FPNet consists of two sub-networks, a common feature learning network referred to as the C-net and a projection network referred to as the P-net. Cnet uses a Gradient Reverse Layer (GRL) (Ganin and Lempitsky, 2014; Zhang et al., 2019) to extract common features ~b (i.e., invariant features (Zhang et al., 2019)) that are shared by multiple classes and have little discriminative power for classification. At the same time, P-net uses a traditional feature extractor to learn the feature vector ~a for the input sentence or document. Then the feature (or representation) vector ~a is projected onto the vector of the common features ~b (i.e., vector ~b) to get a projection vector ~c, which represents the input sentence’s own common features. Then, we project the feature vector ~a onto the orthogonal direction of the vector of the common features ~c to produce the final purer features for classification. It is quite clear and intuitive that this orthogonal project is to get rid of the common features and make the system focusing on those discriminative features only. We will explain why two projections are used in Section 3. In summary, the key contribution of this paper is the improvement to representation learning through feature vector projection. To the best of our knowledge, this is the first such technique. Specifically, an Orthogonal Projection Layer (OPL) is proposed to map the features obtained by a traditional feature extractor to the classification-specific semantic space, which is orthogonal to the common features such that we obtain a more relevant and discriminative (or purer) feature representation from the original document for classification. Extensive experiments have been conducted to verify the effectiveness of the proposed method on two sentence sentiment classification datasets MR and SST2, a natural language inference dataset SNLI, and a question classification dataset TREC. The results show that the proposed method can improve the classification accuracy of RNN, CNN, Transformer and Bert based classification methods markedly, which shows that feature projection is a highly promising direction to explore.",Can the interference of common features in the representation learning of text classification tasks be mitigated by a feature projection technique to improve the discriminativeness of feature representation?,2.0,1.0,1.0
104,KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling,"Xindi Wang, Robert Mercer, and Frank Rudzicz. 2022. KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2941–2951, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.210.pdf,https://aclanthology.org/2022.acl-long.210/,"Currently, Medical Subject Headings (MeSH) are manually assigned to every biomedical article published and subsequently recorded in the PubMed database to facilitate retrieving relevant information. With the rapid growth of the PubMed database, large-scale biomedical document indexing becomes increasingly important. MeSH indexing is a challenging task for machine learning, as it needs to assign multiple labels to each article from an extremely large hierachically organized collection. To address this challenge, we propose KenMeSH, an end-to-end model that combines new text features and a dynamic Knowledge-enhanced mask attention that integrates document features with MeSH label hierarchy and journal correlation features to index MeSH terms. Experimental results show the proposed method achieves state-of-the-art performance on a number of measures.","The PubMed1 database is a resource that provides access to the MEDLINE bibliographic database of references and abstracts together with the full text articles of some of these citations which are available in the PubMed Central2 (PMC) repository. MEDLINE3 contains more than 28 million references (as of Feb. 2021) to journal articles in the biomedical, health, and related disciplines. Journal articles in MEDLINE are indexed according to Medical Subject Headings (MeSH)4 , an hierarchically organized vocabulary that has been developed and maintained by the National Library of Medicine (NLM)5 . Currently, there are 29,369 main MeSH headings, and each MEDLINE citation has 13 MeSH indices, on average. MeSH terms are distinctive features of MEDLINE and can be used in many applications in biomedical text mining and information retrieval (Lu et al., 2008; Huang et al., 2011; Gu et al., 2013), being recognized as important tools for research (e.g., knowledge discovery and hypothesis generation). Currently, MeSH indexing is done by human annotators who examine full articles and assign MeSH terms to each article according to rules set by NLM6 . Human annotation is time consuming and costly – the average cost of annotating one article in MEDLINE is about $9.40 (Mork et al., 2013). Nearly 1 million citations were added to MEDLINE in 2020 (approximately 2,600 on a daily basis)7 . The rate of articles being added to the MEDLINE database is constantly increasing, so there is a huge financial and time-consuming cost for the status quo. Therefore, it is imperative to develop an automatic annotation system that can assist MeSH indexing of large-scale biomedical articles efficiently and accurately. Automatic MeSH indexing can be regarded as an extreme multi-label text classification (XMC) problem, where each article can be labeled with multiple MeSH terms. Compared with standard multilabel problems, XMC finds relevant labels from an enormous set of candidate labels. The challenge of large-scale MeSH indexing comes from both the label and article sides. Currently, there are more than 29,000 distinct MeSH terms, and new MeSH terms are updated to the vocabulary every year. The frequency of different MeSH terms appearing in documents are quite imbalanced. For instance, the most frequent MeSH term, ‘humans’, appears in more than 8 million citations; ‘Pandanaceae’, on the other hand, appears in only 31 documents (Zhai et al., 2015). In addition, the MeSH terms that have been assigned to each article varies greatly, ranging from more than 30 to fewer than 5. Furthermore, semantic features of the biomedical literature are complicated to capture, as they contain many domain-specific concepts, phrases, and abbreviations. The aforementioned difficulties make the task more complicated to generate an effective and efficient prediction model for MeSH indexing. In this work, inspired by the rapid development of deep learning, we propose a novel neural architecture called KenMeSH (Knowledge-enhanced MeSH labelling) which is suitable for handling XMC problems where the labels are arrayed hierarchically and could capture useful information as a directed graph. Our method uses a dynamic knowledge-enhanced mask attention mechanism and incorporates document features together with label features to index biomedical articles. Our major contributions are: 1. We design a multi-channel document representation module to extract document features from the title and the abstract using a bidirectional LSTM. We use multi-level dilated convolution to capture semantic units in the abstract channel. This module combines a hybrid of information, at the levels of words and the latent representations of the semantic units, to capture local correlations and longterm dependencies from text. 2. Our proposed method appears to be the first to employ graph convolutional neural networks that integrate information from the complete MeSH hierarchy to map label representations. 3. We propose a novel dynamic knowledgeenhanced mask attention mechanism which incorporates external journal-MeSH cooccurrence information and document similarity in the PubMed database to constrain the large universe of possible labels in the MeSH indexing task. 4. We evaluate our model on a corpus of PMC articles. Our proposed method consistently achieves superior performance over previous approaches on a number of measures.","What is the efficacy of the KenMeSH model, which employs a dynamic knowledge-enhanced mask attention mechanism and integrates document and MeSH label hierarchy features, in improving the accuracy and efficiency of automatic MeSH indexing of biomedical articles in comparison to previous approaches?",1.0,2.0,1.0
105,Predicate-Argument Based Bi-Encoder for Paraphrase Identification,"Qiwei Peng, David Weir, Julie Weeds, and Yekun Chai. 2022. Predicate-Argument Based Bi-Encoder for Paraphrase Identification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5579–5589, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.382.pdf,https://aclanthology.org/2022.acl-long.382/,"Paraphrase identification involves identifying whether a pair of sentences express the same or similar meanings. While cross-encoders have achieved high performances across several benchmarks, bi-encoders such as SBERT have been widely applied to sentence pair tasks. They exhibit substantially lower computation complexity and are better suited to symmetric tasks. In this work, we adopt a biencoder approach to the paraphrase identification task, and investigate the impact of explicitly incorporating predicate-argument information into SBERT through weighted aggregation. Experiments on six paraphrase identification datasets demonstrate that, with a minimal increase in parameters, the proposed model is able to outperform SBERT/SRoBERTa significantly. Further, ablation studies reveal that the predicate-argument based component plays a significant role in the performance gain.","Paraphrases are sentences that express the same or similar meanings with different wording (Bhagat and Hovy, 2013). Paraphrase pairs are either fully or largely semantically equivalent. For example: a) Marriage equality law passed in Rhode Island b) Rhode Island becomes the 10th state to enact marriage equality It is generally considered to be a symmetric task where the paraphrase relation holds in both directions (Bhagat and Hovy, 2013; Yang et al., 2019). Since word order and sentence structure are crucial in determining sentence meaning, effective paraphrase models must be structure-aware and word order sensitive. In light of this, paraphrase datasets have been created that are specifically designed to encourage models to consider structural differences (Xu et al., 2015; Zhang et al., 2019b). For example, PIT2015 (Xu et al., 2015) consists of paraphrase pairs that are lexically diverse and non-paraphrase pairs that are lexically similar but semantically dissimilar. There are generally two pre-trained based approaches for sentence pair tasks such as paraphrase identification. The first is the cross-encoder approach, which involves concatenating the two input sentences and performing full-attention over the input. The second is the bi-encoder approach, which adopts a conjoined twin network structure and maps each sentence onto separate representations, which can then be compared using similarity measures such as cosine. Though typical cross-encoders like BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have set stateof-the-art performance on various sentence pair tasks (Zhang et al., 2021; Xia et al., 2021), they still face challenges from both extreme computational overhead for many use cases (Reimers and Gurevych, 2019; Thakur et al., 2021) and inconsistent predictions (ranging from 2.66% to 8.46% depending on specific datasets) when dealing with symmetric tasks (Chen et al., 2020). In contrast, a bi-encoder approach such as Sentence-BERT (SBERT) (Reimers and Gurevych, 2019) encodes sentences separately and generates high-quality embeddings for each of them. This architecture enables sentence embeddings to be pre-computed, supporting efficient indexing and comparison between different sequences. Due to the nature of bi-encoders, the symmetry property will be preserved as long as no asymmetry is introduced in subsequent layers. These properties make bi-encoders appealing for the paraphrase identification task. Accordingly, here, we focus on biencoders rather than cross-encoders. One downside of SBERT is that it only adopts a very simple strategy, which is mean-pooling over all tokens, to generate sentence embeddings. As previously discussed, models should ideally be sensitive to any structural differences between two sentences. Relational Graph Convolutional Networks (RGCNs) (Schlichtkrull et al., 2018) have been used to introduce structural information (e.g. dependency/semantic parse trees) into SBERT and improvements have been reported on unsupervised similarity comparison tasks (Peng et al., 2021). One drawback of RGCNs is the size of the parameter space. For example, a single-layer RGCN can involve more than 30 million parameters. Furthermore, as we will demonstrate, the performance gain on different paraphrase identification datasets is not consistent. An important aspect of sentence meaning concerns its predicate-argument structure. This has been utilised to generate paraphrases (Kozlowski et al., 2003) and to compare sentence meanings (Shan et al., 2009). Inspired by the Self-Explain model (Sun et al., 2020) which uses a span-based framework to generate sentence embeddings, we propose a method that effectively introduces sentence structure into SBERT via the aggregation of predicate-argument spans. This self-attention based aggregation allows us to gain benefits with minimal increased cost in terms of additional parameters. Empirical results indicate that the proposed model yields improvements on six benchmarks for paraphrase identification. Upon closer investigation, we find the predicate-argument span (PAS) component plays a crucial role in the performance gains and can be easily generalised to other models.",How does explicitly incorporating predicate-argument information into SBERT through weighted aggregation impact the performance of bi-encoders in paraphrase identification tasks compared to traditional SBERT/SRoBERTa models?,0.0,2.0,0.0
106,Predicate-Argument Based Bi-Encoder for Paraphrase Identification,"Qiwei Peng, David Weir, Julie Weeds, and Yekun Chai. 2022. Predicate-Argument Based Bi-Encoder for Paraphrase Identification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5579–5589, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.382.pdf,https://aclanthology.org/2022.acl-long.382/,"Paraphrase identification involves identifying whether a pair of sentences express the same or similar meanings. While cross-encoders have achieved high performances across several benchmarks, bi-encoders such as SBERT have been widely applied to sentence pair tasks. They exhibit substantially lower computation complexity and are better suited to symmetric tasks. In this work, we adopt a biencoder approach to the paraphrase identification task, and investigate the impact of explicitly incorporating predicate-argument information into SBERT through weighted aggregation. Experiments on six paraphrase identification datasets demonstrate that, with a minimal increase in parameters, the proposed model is able to outperform SBERT/SRoBERTa significantly. Further, ablation studies reveal that the predicate-argument based component plays a significant role in the performance gain.","Paraphrases are sentences that express the same or similar meanings with different wording (Bhagat and Hovy, 2013). Paraphrase pairs are either fully or largely semantically equivalent. For example: a) Marriage equality law passed in Rhode Island b) Rhode Island becomes the 10th state to enact marriage equality It is generally considered to be a symmetric task where the paraphrase relation holds in both directions (Bhagat and Hovy, 2013; Yang et al., 2019). Since word order and sentence structure are crucial in determining sentence meaning, effective paraphrase models must be structure-aware and word order sensitive. In light of this, paraphrase datasets have been created that are specifically designed to encourage models to consider structural differences (Xu et al., 2015; Zhang et al., 2019b). For example, PIT2015 (Xu et al., 2015) consists of paraphrase pairs that are lexically diverse and non-paraphrase pairs that are lexically similar but semantically dissimilar. There are generally two pre-trained based approaches for sentence pair tasks such as paraphrase identification. The first is the cross-encoder approach, which involves concatenating the two input sentences and performing full-attention over the input. The second is the bi-encoder approach, which adopts a conjoined twin network structure and maps each sentence onto separate representations, which can then be compared using similarity measures such as cosine. Though typical cross-encoders like BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have set stateof-the-art performance on various sentence pair tasks (Zhang et al., 2021; Xia et al., 2021), they still face challenges from both extreme computational overhead for many use cases (Reimers and Gurevych, 2019; Thakur et al., 2021) and inconsistent predictions (ranging from 2.66% to 8.46% depending on specific datasets) when dealing with symmetric tasks (Chen et al., 2020). In contrast, a bi-encoder approach such as Sentence-BERT (SBERT) (Reimers and Gurevych, 2019) encodes sentences separately and generates high-quality embeddings for each of them. This architecture enables sentence embeddings to be pre-computed, supporting efficient indexing and comparison between different sequences. Due to the nature of bi-encoders, the symmetry property will be preserved as long as no asymmetry is introduced in subsequent layers. These properties make bi-encoders appealing for the paraphrase identification task. Accordingly, here, we focus on biencoders rather than cross-encoders. One downside of SBERT is that it only adopts a very simple strategy, which is mean-pooling over all tokens, to generate sentence embeddings. As previously discussed, models should ideally be sensitive to any structural differences between two sentences. Relational Graph Convolutional Networks (RGCNs) (Schlichtkrull et al., 2018) have been used to introduce structural information (e.g. dependency/semantic parse trees) into SBERT and improvements have been reported on unsupervised similarity comparison tasks (Peng et al., 2021). One drawback of RGCNs is the size of the parameter space. For example, a single-layer RGCN can involve more than 30 million parameters. Furthermore, as we will demonstrate, the performance gain on different paraphrase identification datasets is not consistent. An important aspect of sentence meaning concerns its predicate-argument structure. This has been utilised to generate paraphrases (Kozlowski et al., 2003) and to compare sentence meanings (Shan et al., 2009). Inspired by the Self-Explain model (Sun et al., 2020) which uses a span-based framework to generate sentence embeddings, we propose a method that effectively introduces sentence structure into SBERT via the aggregation of predicate-argument spans. This self-attention based aggregation allows us to gain benefits with minimal increased cost in terms of additional parameters. Empirical results indicate that the proposed model yields improvements on six benchmarks for paraphrase identification. Upon closer investigation, we find the predicate-argument span (PAS) component plays a crucial role in the performance gains and can be easily generalised to other models.",Can paraphrase identification be improved by incorporating predicate-argument information into Sentence-BERT (SBERT) through weighted aggregation?,0.0,1.0,0.0
107,Predicate-Argument Based Bi-Encoder for Paraphrase Identification,"Qiwei Peng, David Weir, Julie Weeds, and Yekun Chai. 2022. Predicate-Argument Based Bi-Encoder for Paraphrase Identification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5579–5589, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.382.pdf,https://aclanthology.org/2022.acl-long.382/,"Paraphrase identification involves identifying whether a pair of sentences express the same or similar meanings. While cross-encoders have achieved high performances across several benchmarks, bi-encoders such as SBERT have been widely applied to sentence pair tasks. They exhibit substantially lower computation complexity and are better suited to symmetric tasks. In this work, we adopt a biencoder approach to the paraphrase identification task, and investigate the impact of explicitly incorporating predicate-argument information into SBERT through weighted aggregation. Experiments on six paraphrase identification datasets demonstrate that, with a minimal increase in parameters, the proposed model is able to outperform SBERT/SRoBERTa significantly. Further, ablation studies reveal that the predicate-argument based component plays a significant role in the performance gain.","Paraphrases are sentences that express the same or similar meanings with different wording (Bhagat and Hovy, 2013). Paraphrase pairs are either fully or largely semantically equivalent. For example: a) Marriage equality law passed in Rhode Island b) Rhode Island becomes the 10th state to enact marriage equality It is generally considered to be a symmetric task where the paraphrase relation holds in both directions (Bhagat and Hovy, 2013; Yang et al., 2019). Since word order and sentence structure are crucial in determining sentence meaning, effective paraphrase models must be structure-aware and word order sensitive. In light of this, paraphrase datasets have been created that are specifically designed to encourage models to consider structural differences (Xu et al., 2015; Zhang et al., 2019b). For example, PIT2015 (Xu et al., 2015) consists of paraphrase pairs that are lexically diverse and non-paraphrase pairs that are lexically similar but semantically dissimilar. There are generally two pre-trained based approaches for sentence pair tasks such as paraphrase identification. The first is the cross-encoder approach, which involves concatenating the two input sentences and performing full-attention over the input. The second is the bi-encoder approach, which adopts a conjoined twin network structure and maps each sentence onto separate representations, which can then be compared using similarity measures such as cosine. Though typical cross-encoders like BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have set stateof-the-art performance on various sentence pair tasks (Zhang et al., 2021; Xia et al., 2021), they still face challenges from both extreme computational overhead for many use cases (Reimers and Gurevych, 2019; Thakur et al., 2021) and inconsistent predictions (ranging from 2.66% to 8.46% depending on specific datasets) when dealing with symmetric tasks (Chen et al., 2020). In contrast, a bi-encoder approach such as Sentence-BERT (SBERT) (Reimers and Gurevych, 2019) encodes sentences separately and generates high-quality embeddings for each of them. This architecture enables sentence embeddings to be pre-computed, supporting efficient indexing and comparison between different sequences. Due to the nature of bi-encoders, the symmetry property will be preserved as long as no asymmetry is introduced in subsequent layers. These properties make bi-encoders appealing for the paraphrase identification task. Accordingly, here, we focus on biencoders rather than cross-encoders. One downside of SBERT is that it only adopts a very simple strategy, which is mean-pooling over all tokens, to generate sentence embeddings. As previously discussed, models should ideally be sensitive to any structural differences between two sentences. Relational Graph Convolutional Networks (RGCNs) (Schlichtkrull et al., 2018) have been used to introduce structural information (e.g. dependency/semantic parse trees) into SBERT and improvements have been reported on unsupervised similarity comparison tasks (Peng et al., 2021). One drawback of RGCNs is the size of the parameter space. For example, a single-layer RGCN can involve more than 30 million parameters. Furthermore, as we will demonstrate, the performance gain on different paraphrase identification datasets is not consistent. An important aspect of sentence meaning concerns its predicate-argument structure. This has been utilised to generate paraphrases (Kozlowski et al., 2003) and to compare sentence meanings (Shan et al., 2009). Inspired by the Self-Explain model (Sun et al., 2020) which uses a span-based framework to generate sentence embeddings, we propose a method that effectively introduces sentence structure into SBERT via the aggregation of predicate-argument spans. This self-attention based aggregation allows us to gain benefits with minimal increased cost in terms of additional parameters. Empirical results indicate that the proposed model yields improvements on six benchmarks for paraphrase identification. Upon closer investigation, we find the predicate-argument span (PAS) component plays a crucial role in the performance gains and can be easily generalised to other models.","Can the inadequacy of current bi-encoder strategies, like SBERT, in effectively considering structural differences in paraphrase identification tasks, be addressed by enhancing SBERT with a method that integrates predicate-argument structure into sentence embeddings through weighted aggregation?",1.0,2.0,1.0
108,TDNN: A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring,"Cancan Jin, Ben He, Kai Hui, and Le Sun. 2018. TDNN: A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1088–1097, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1100.pdf,https://aclanthology.org/P18-1100/,"Existing automated essay scoring (AES) models rely on rated essays for the target prompt as training data. Despite their successes in prompt-dependent AES, how to effectively predict essay ratings under a prompt-independent setting remains a challenge, where the rated essays for the target prompt are not available. To close this gap, a two-stage deep neural network (TDNN) is proposed. In particular, in the first stage, using the rated essays for nontarget prompts as the training data, a shallow model is learned to select essays with an extreme quality for the target prompt, serving as pseudo training data; in the second stage, an end-to-end hybrid deep model is proposed to learn a prompt-dependent rating model consuming the pseudo training data from the first step. Evaluation of the proposed TDNN on the standard ASAP dataset demonstrates a promising improvement for the prompt-independent AES task.","Automated essay scoring (AES) utilizes natural language processing and machine learning techniques to automatically rate essays written for a target prompt (Dikli, 2006). Currently, the AES systems have been widely used in large-scale English writing tests, e.g. Graduate Record Examination (GRE), to reduce the human efforts in the writing assessments (Attali and Burstein, 2006). Existing AES approaches are promptdependent, where, given a target prompt, rated essays for this particular prompt are required for training (Dikli, 2006; Williamson, 2009; Foltz et al., 1999). While the established models are effective (Chen and He, 2013; Taghipour and Ng, 2016; Alikaniotis et al., 2016; Cummins et al., 2016; Dong et al., 2017), we argue that the models for prompt-independent AES are also desirable to allow for better feasibility and flexibility of AES systems especially when the rated essays for a target prompt are difficult to obtain or even unaccessible. For example, in a writing test within a small class, students are asked to write essays for a target prompt without any rated examples, where the prompt-dependent methods are unlikely to provide effective AES due to the lack of training data. Prompt-independent AES, however, has drawn little attention in the literature, where there only exists unrated essays written for the target prompt, as well as the rated essays for several non-target prompts. We argue that it is not straightforward, if possible, to apply the established promptdependent AES methods for the mentioned prompt-independent scenario. On one hand, essays for different prompts may differ a lot in the uses of vocabulary, the structure, and the grammatic characteristics; on the other hand, however, established prompt-dependent AES models are designed to learn from these prompt-specific features, including the on/off-topic degree, the tf - idf weights of topical terms (Attali and Burstein, 2006; Dikli, 2006), and the n-gram features extracted from word semantic embeddings (Dong and Zhang, 2016; Alikaniotis et al., 2016). Consequently, the prompt-dependent models can hardly learn generalized rules from rated essays for nontarget prompts, and are not suitable for the promptindependent AES. Being aware of this difficulty, to this end, a twostage deep neural network, coined as TDNN, is proposed to tackle the prompt-independent AES problem. In particular, to mitigate the lack of the prompt-dependent labeled data, at the first stage, a shallow model is trained on a number of rated essays for several non-target prompts; given a target prompt and a set of essays to rate, the trained model is employed to generate pseudo training data by selecting essays with the extreme quality. At the second stage, a novel end-to-end hybrid deep neural network learns prompt-dependent features from these selected training data, by considering semantic, part-of-speech, and syntactic features. The contributions in this paper are threefold: 1) a two-stage learning framework is proposed to bridge the gap between the target and non-target prompts, by only consuming rated essays for nontarget prompts as training data; 2) a novel deep model is proposed to learn from pseudo labels by considering semantic, part-of-speech, and syntactic features; and most importantly, 3) to the best of our knowledge, the proposed TDNN is actually the first approach dedicated to addressing the prompt-independent AES. Evaluation on the standard ASAP dataset demonstrates the effectiveness of the proposed method. The rest of this paper is organized as follows. In Section 2, we describe our novel TDNN model, including the two-stage framework and the proposed deep model. Following that, we describe the setup of our empirical study in Section 3, thereafter present the results and provide analyzes in Section 4. Section 5 recaps existing literature and put our work in context, before drawing final conclusions in Section 6.","How can a two-stage deep neural network be effectively utilized to predict essay ratings under a prompt-independent setting, where rated essays for the target prompt are not available?",2.0,1.0,1.0
109,TDNN: A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring,"Cancan Jin, Ben He, Kai Hui, and Le Sun. 2018. TDNN: A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1088–1097, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1100.pdf,https://aclanthology.org/P18-1100/,"Existing automated essay scoring (AES) models rely on rated essays for the target prompt as training data. Despite their successes in prompt-dependent AES, how to effectively predict essay ratings under a prompt-independent setting remains a challenge, where the rated essays for the target prompt are not available. To close this gap, a two-stage deep neural network (TDNN) is proposed. In particular, in the first stage, using the rated essays for nontarget prompts as the training data, a shallow model is learned to select essays with an extreme quality for the target prompt, serving as pseudo training data; in the second stage, an end-to-end hybrid deep model is proposed to learn a prompt-dependent rating model consuming the pseudo training data from the first step. Evaluation of the proposed TDNN on the standard ASAP dataset demonstrates a promising improvement for the prompt-independent AES task.","Automated essay scoring (AES) utilizes natural language processing and machine learning techniques to automatically rate essays written for a target prompt (Dikli, 2006). Currently, the AES systems have been widely used in large-scale English writing tests, e.g. Graduate Record Examination (GRE), to reduce the human efforts in the writing assessments (Attali and Burstein, 2006). Existing AES approaches are promptdependent, where, given a target prompt, rated essays for this particular prompt are required for training (Dikli, 2006; Williamson, 2009; Foltz et al., 1999). While the established models are effective (Chen and He, 2013; Taghipour and Ng, 2016; Alikaniotis et al., 2016; Cummins et al., 2016; Dong et al., 2017), we argue that the models for prompt-independent AES are also desirable to allow for better feasibility and flexibility of AES systems especially when the rated essays for a target prompt are difficult to obtain or even unaccessible. For example, in a writing test within a small class, students are asked to write essays for a target prompt without any rated examples, where the prompt-dependent methods are unlikely to provide effective AES due to the lack of training data. Prompt-independent AES, however, has drawn little attention in the literature, where there only exists unrated essays written for the target prompt, as well as the rated essays for several non-target prompts. We argue that it is not straightforward, if possible, to apply the established promptdependent AES methods for the mentioned prompt-independent scenario. On one hand, essays for different prompts may differ a lot in the uses of vocabulary, the structure, and the grammatic characteristics; on the other hand, however, established prompt-dependent AES models are designed to learn from these prompt-specific features, including the on/off-topic degree, the tf - idf weights of topical terms (Attali and Burstein, 2006; Dikli, 2006), and the n-gram features extracted from word semantic embeddings (Dong and Zhang, 2016; Alikaniotis et al., 2016). Consequently, the prompt-dependent models can hardly learn generalized rules from rated essays for nontarget prompts, and are not suitable for the promptindependent AES. Being aware of this difficulty, to this end, a twostage deep neural network, coined as TDNN, is proposed to tackle the prompt-independent AES problem. In particular, to mitigate the lack of the prompt-dependent labeled data, at the first stage, a shallow model is trained on a number of rated essays for several non-target prompts; given a target prompt and a set of essays to rate, the trained model is employed to generate pseudo training data by selecting essays with the extreme quality. At the second stage, a novel end-to-end hybrid deep neural network learns prompt-dependent features from these selected training data, by considering semantic, part-of-speech, and syntactic features. The contributions in this paper are threefold: 1) a two-stage learning framework is proposed to bridge the gap between the target and non-target prompts, by only consuming rated essays for nontarget prompts as training data; 2) a novel deep model is proposed to learn from pseudo labels by considering semantic, part-of-speech, and syntactic features; and most importantly, 3) to the best of our knowledge, the proposed TDNN is actually the first approach dedicated to addressing the prompt-independent AES. Evaluation on the standard ASAP dataset demonstrates the effectiveness of the proposed method. The rest of this paper is organized as follows. In Section 2, we describe our novel TDNN model, including the two-stage framework and the proposed deep model. Following that, we describe the setup of our empirical study in Section 3, thereafter present the results and provide analyzes in Section 4. Section 5 recaps existing literature and put our work in context, before drawing final conclusions in Section 6.",Can prompt-independent automated essay scoring be effectively achieved by using a two-stage deep neural network that leverages pseudo training data from rated essays of non-target prompts?,1.0,1.0,1.0
110,Probing for Predicate Argument Structures in Pretrained Language Models,"Simone Conia and Roberto Navigli. 2022. Probing for Predicate Argument Structures in Pretrained Language Models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4622–4632, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.316.pdf,https://aclanthology.org/2022.acl-long.316/,"Thanks to the effectiveness and wide availability of modern pretrained language models (PLMs), recently proposed approaches have achieved remarkable results in dependencyand span-based, multilingual and cross-lingual Semantic Role Labeling (SRL). These results have prompted researchers to investigate the inner workings of modern PLMs with the aim of understanding how, where, and to what extent they encode information about SRL. In this paper, we follow this line of research and probe for predicate argument structures in PLMs. Our study shows that PLMs do encode semantic structures directly into the contextualized representation of a predicate, and also provides insights into the correlation between predicate senses and their structures, the degree of transferability between nominal and verbal structures, and how such structures are encoded across languages. Finally, we look at the practical implications of such insights and demonstrate the benefits of embedding predicate argument structure information into an SRL model.","Semantic Role Labeling (SRL) is often defined informally as the task of automatically answering the question “Who did What to Whom, Where, When and How?” (Màrquez et al., 2008) and is, therefore, thought to be a fundamental step towards Natural Language Understanding (Navigli, 2018). Over the past few years, SRL has started to gain renewed traction, thanks mainly to the effectiveness and wide availability of modern pretrained language models (PLMs), such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2019) and BART (Lewis et al., 2020). Current approaches have, indeed, attained impressive results on standard evaluation benchmarks for dependency- and span-based, multilingual and cross-lingual SRL (He et al., 2019; Li et al., 2019; Cai and Lapata, 2020; Conia and Navigli, 2020; Blloshmi et al., 2021; Conia et al., 2021). Despite the remarkable benefits provided by the rich contextualized word representations coming from PLMs, the novelties introduced in recent stateof-the-art models for SRL revolve primarily around developing complexities on top of such word representations, rather than investigating what happens inside a PLM. For example, the SRL systems of He et al. (2019) and Conia and Navigli (2020) take advantage only of BERT’s uppermost hidden layers to build their input word representations. However, the revolution that PLMs have sparked in numerous areas of Natural Language Processing (NLP) has motivated researchers in the community to investigate the inner workings of such models, with the aim of understanding how, where, and to what extent they encode information about specific tasks. This research has revealed that different layers encode significantly different features (Tenney et al., 2019; Vulic et al. ´ , 2020). In perhaps one of the most notable studies in this direction, Tenney et al. (2019) demonstrated empirically that BERT “rediscovers” the classical NLP pipeline, highlighting that the lower layers tend to encode mostly lexicallevel information while upper layers seem to favor sentence-level information. Although recent analyses have already provided important insights into which layers of a PLM are more relevant for SRL and how their relative importance is affected by the linguistic formalism of choice (Kuznetsov and Gurevych, 2020), not only do these analyses treat SRL as an atomic task but they also do not explore taking advantage of their insights to improve current state-of-the-art SRL systems. Indeed, the SRL pipeline is usually divided into four main steps: predicate identification and disambiguation, and argument identification and classification. To address this gap, in this paper we therefore take an in-depth look at how predicate senses and their predicate argument structures (PASs) are encoded across different layers of different PLMs. On the one hand, we provide new insights into the capability of these models to capture complex linguistic features, while on the other, we show the benefits of embedding such features into SRL systems to improve their performance. Our contributions can be summarized as follows: • We probe PLMs for PASs: do PLMs encode the argument structure of a predicate in its contextual representation? • We show that, even though a PAS is defined according to a predicate sense, senses and argument structures are encoded at different layers in PLMs; • We demonstrate empirically that verbal and nominal PASs are represented differently across the layers of a PLM; • Current SRL systems do not discriminate between nominal and verbal PASs: we demonstrate that, although there exists some degree of transferability between the two, an SRL system benefits from treating them separately; • We find that PAS information is encoded similarly across two very different languages, English and Chinese, in multilingual PLMs; • We corroborate our findings by proposing a simple approach for integrating predicateargument structure knowledge into an SRL architecture, attaining improved results on standard gold benchmarks. We hope that our work will contribute both to the understanding of the inner workings of modern pretrained language models and to the development of more effective SRL systems. We release our software for research purposes at https://github. com/SapienzaNLP/srl-pas-probing.","How do modern pretrained language models (PLMs) encode predicate argument structures (PASs) across different layers, and how can this knowledge improve the performance of semantic role labeling (SRL) systems?",0.0,0.0,0.0
111,Probing for Predicate Argument Structures in Pretrained Language Models,"Simone Conia and Roberto Navigli. 2022. Probing for Predicate Argument Structures in Pretrained Language Models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4622–4632, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.316.pdf,https://aclanthology.org/2022.acl-long.316/,"Thanks to the effectiveness and wide availability of modern pretrained language models (PLMs), recently proposed approaches have achieved remarkable results in dependencyand span-based, multilingual and cross-lingual Semantic Role Labeling (SRL). These results have prompted researchers to investigate the inner workings of modern PLMs with the aim of understanding how, where, and to what extent they encode information about SRL. In this paper, we follow this line of research and probe for predicate argument structures in PLMs. Our study shows that PLMs do encode semantic structures directly into the contextualized representation of a predicate, and also provides insights into the correlation between predicate senses and their structures, the degree of transferability between nominal and verbal structures, and how such structures are encoded across languages. Finally, we look at the practical implications of such insights and demonstrate the benefits of embedding predicate argument structure information into an SRL model.","Semantic Role Labeling (SRL) is often defined informally as the task of automatically answering the question “Who did What to Whom, Where, When and How?” (Màrquez et al., 2008) and is, therefore, thought to be a fundamental step towards Natural Language Understanding (Navigli, 2018). Over the past few years, SRL has started to gain renewed traction, thanks mainly to the effectiveness and wide availability of modern pretrained language models (PLMs), such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2019) and BART (Lewis et al., 2020). Current approaches have, indeed, attained impressive results on standard evaluation benchmarks for dependency- and span-based, multilingual and cross-lingual SRL (He et al., 2019; Li et al., 2019; Cai and Lapata, 2020; Conia and Navigli, 2020; Blloshmi et al., 2021; Conia et al., 2021). Despite the remarkable benefits provided by the rich contextualized word representations coming from PLMs, the novelties introduced in recent stateof-the-art models for SRL revolve primarily around developing complexities on top of such word representations, rather than investigating what happens inside a PLM. For example, the SRL systems of He et al. (2019) and Conia and Navigli (2020) take advantage only of BERT’s uppermost hidden layers to build their input word representations. However, the revolution that PLMs have sparked in numerous areas of Natural Language Processing (NLP) has motivated researchers in the community to investigate the inner workings of such models, with the aim of understanding how, where, and to what extent they encode information about specific tasks. This research has revealed that different layers encode significantly different features (Tenney et al., 2019; Vulic et al. ´ , 2020). In perhaps one of the most notable studies in this direction, Tenney et al. (2019) demonstrated empirically that BERT “rediscovers” the classical NLP pipeline, highlighting that the lower layers tend to encode mostly lexicallevel information while upper layers seem to favor sentence-level information. Although recent analyses have already provided important insights into which layers of a PLM are more relevant for SRL and how their relative importance is affected by the linguistic formalism of choice (Kuznetsov and Gurevych, 2020), not only do these analyses treat SRL as an atomic task but they also do not explore taking advantage of their insights to improve current state-of-the-art SRL systems. Indeed, the SRL pipeline is usually divided into four main steps: predicate identification and disambiguation, and argument identification and classification. To address this gap, in this paper we therefore take an in-depth look at how predicate senses and their predicate argument structures (PASs) are encoded across different layers of different PLMs. On the one hand, we provide new insights into the capability of these models to capture complex linguistic features, while on the other, we show the benefits of embedding such features into SRL systems to improve their performance. Our contributions can be summarized as follows: • We probe PLMs for PASs: do PLMs encode the argument structure of a predicate in its contextual representation? • We show that, even though a PAS is defined according to a predicate sense, senses and argument structures are encoded at different layers in PLMs; • We demonstrate empirically that verbal and nominal PASs are represented differently across the layers of a PLM; • Current SRL systems do not discriminate between nominal and verbal PASs: we demonstrate that, although there exists some degree of transferability between the two, an SRL system benefits from treating them separately; • We find that PAS information is encoded similarly across two very different languages, English and Chinese, in multilingual PLMs; • We corroborate our findings by proposing a simple approach for integrating predicateargument structure knowledge into an SRL architecture, attaining improved results on standard gold benchmarks. We hope that our work will contribute both to the understanding of the inner workings of modern pretrained language models and to the development of more effective SRL systems. We release our software for research purposes at https://github. com/SapienzaNLP/srl-pas-probing.",Can the encoding of argument structures of a predicate in its contextual representation by pretrained language models (PLMs) be probed to improve Semantic Role Labeling (SRL) systems?,0.0,1.0,0.0
112,Probing for Predicate Argument Structures in Pretrained Language Models,"Simone Conia and Roberto Navigli. 2022. Probing for Predicate Argument Structures in Pretrained Language Models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4622–4632, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.316.pdf,https://aclanthology.org/2022.acl-long.316/,"Thanks to the effectiveness and wide availability of modern pretrained language models (PLMs), recently proposed approaches have achieved remarkable results in dependencyand span-based, multilingual and cross-lingual Semantic Role Labeling (SRL). These results have prompted researchers to investigate the inner workings of modern PLMs with the aim of understanding how, where, and to what extent they encode information about SRL. In this paper, we follow this line of research and probe for predicate argument structures in PLMs. Our study shows that PLMs do encode semantic structures directly into the contextualized representation of a predicate, and also provides insights into the correlation between predicate senses and their structures, the degree of transferability between nominal and verbal structures, and how such structures are encoded across languages. Finally, we look at the practical implications of such insights and demonstrate the benefits of embedding predicate argument structure information into an SRL model.","Semantic Role Labeling (SRL) is often defined informally as the task of automatically answering the question “Who did What to Whom, Where, When and How?” (Màrquez et al., 2008) and is, therefore, thought to be a fundamental step towards Natural Language Understanding (Navigli, 2018). Over the past few years, SRL has started to gain renewed traction, thanks mainly to the effectiveness and wide availability of modern pretrained language models (PLMs), such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2019) and BART (Lewis et al., 2020). Current approaches have, indeed, attained impressive results on standard evaluation benchmarks for dependency- and span-based, multilingual and cross-lingual SRL (He et al., 2019; Li et al., 2019; Cai and Lapata, 2020; Conia and Navigli, 2020; Blloshmi et al., 2021; Conia et al., 2021). Despite the remarkable benefits provided by the rich contextualized word representations coming from PLMs, the novelties introduced in recent stateof-the-art models for SRL revolve primarily around developing complexities on top of such word representations, rather than investigating what happens inside a PLM. For example, the SRL systems of He et al. (2019) and Conia and Navigli (2020) take advantage only of BERT’s uppermost hidden layers to build their input word representations. However, the revolution that PLMs have sparked in numerous areas of Natural Language Processing (NLP) has motivated researchers in the community to investigate the inner workings of such models, with the aim of understanding how, where, and to what extent they encode information about specific tasks. This research has revealed that different layers encode significantly different features (Tenney et al., 2019; Vulic et al. ´ , 2020). In perhaps one of the most notable studies in this direction, Tenney et al. (2019) demonstrated empirically that BERT “rediscovers” the classical NLP pipeline, highlighting that the lower layers tend to encode mostly lexicallevel information while upper layers seem to favor sentence-level information. Although recent analyses have already provided important insights into which layers of a PLM are more relevant for SRL and how their relative importance is affected by the linguistic formalism of choice (Kuznetsov and Gurevych, 2020), not only do these analyses treat SRL as an atomic task but they also do not explore taking advantage of their insights to improve current state-of-the-art SRL systems. Indeed, the SRL pipeline is usually divided into four main steps: predicate identification and disambiguation, and argument identification and classification. To address this gap, in this paper we therefore take an in-depth look at how predicate senses and their predicate argument structures (PASs) are encoded across different layers of different PLMs. On the one hand, we provide new insights into the capability of these models to capture complex linguistic features, while on the other, we show the benefits of embedding such features into SRL systems to improve their performance. Our contributions can be summarized as follows: • We probe PLMs for PASs: do PLMs encode the argument structure of a predicate in its contextual representation? • We show that, even though a PAS is defined according to a predicate sense, senses and argument structures are encoded at different layers in PLMs; • We demonstrate empirically that verbal and nominal PASs are represented differently across the layers of a PLM; • Current SRL systems do not discriminate between nominal and verbal PASs: we demonstrate that, although there exists some degree of transferability between the two, an SRL system benefits from treating them separately; • We find that PAS information is encoded similarly across two very different languages, English and Chinese, in multilingual PLMs; • We corroborate our findings by proposing a simple approach for integrating predicateargument structure knowledge into an SRL architecture, attaining improved results on standard gold benchmarks. We hope that our work will contribute both to the understanding of the inner workings of modern pretrained language models and to the development of more effective SRL systems. We release our software for research purposes at https://github. com/SapienzaNLP/srl-pas-probing.","Can the understanding of how modern pretrained language models (PLMs) encode information relevant to Semantic Role Labeling (SRL), particularly predicate argument structures (PASs), be leveraged to improve SRL models?",0.0,0.0,0.0
113,Language Modeling with Shared Grammar,"Yuyu Zhang and Le Song. 2019. Language Modeling with Shared Grammar. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4442–4453, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1437.pdf,https://aclanthology.org/P19-1437/,"Sequential recurrent neural networks have achieved superior performance on language modeling, but overlook the structure information in natural language. Recent works on structure-aware models have shown promising results on language modeling. However, how to incorporate structure knowledge on corpus without syntactic annotations remains an open problem. In this work, we propose neural variational language model (NVLM), which enables the sharing of grammar knowledge among different corpora. Experimental results demonstrate the effectiveness of our framework on two popular benchmark datasets. With the help of shared grammar, our language model converges significantly faster to a lower perplexity on new training corpus.","Language modeling has been a long-standing fundamental task in natural language processing. In recent years, sequential recurrent neural networks (RNNs) based language models have made astonishing progress, which achieve remarkable results on various benchmark datasets (Mikolov et al., 2010a; Jozefowicz et al., 2016; Melis et al., 2017; Elbayad et al., 2018; Gong et al., 2018; Takase et al., 2018; Dai et al., 2019). Despite the huge success, the structure information in natural language is largely overlooked due to the structural limit of sequential RNN-based language models. Recently, researchers have explored to explicitly exploit the latent structures in natural language, such as recurrent neural network grammars (RNNGs; Dyer et al., 2016; Kuncoro et al., 2017) and parsing-reading-predict networks (PRPNs; Shen et al., 2017). These structureaware models have shown promising results on language modeling, demonstrating that the latent nested structure in language indeed helps improve sequential language models. Models like RNNG exploit treebank data with syntactic annotations to learn grammar, which is then used to improve language model performance by a significant margin. This is definitely intriguing, but we have to pay the cost: accurate syntactic annotation is very costly, and treebank data such as the Penn Treebank (Marcus et al., 1993) is typically small-scale and not open to the public for free. On new corpus which has no syntactic annotations, how to improve language modeling with grammar knowledge? This is an important and challenging open problem. As a motivating example, we conduct a simple experiment by training a RNN language model on one corpus and testing it on another, and report the results in Table 1. The RNN language model performs terribly when training and testing on different datasets, which is reasonable since the data distribution may vary dramatically on different corpora. Training from scratch on every new corpus is obviously not good enough: 1) it is computationally expensive and not data-efficient; 2) the size of target corpus may be too small to train a decent RNN-based language model; 3) the common grammar is not leveraged. Some recent works on transfer learning have made attempts on language model adaptation (Yoon et al., 2017; Ma et al., 2017; Chen et al., 2015), however, none of them explicitly exploits the common grammar knowledge shared between corpora. To bridge the gap of language modeling on different corpora, we believe that grammar is the key since all corpora are in the same language and should share the same grammar. Motivated by that, we propose neural variational language model (NVLM). Specifically, our framework consists of two probabilistic components: a constituency parser and a joint generative model of sentence and parse tree. When treebank data is available, we can separately train both components. On new corpus without tree annotations, we fix the pre-trained parser and train the generative model either from scratch or with warmup. The pre-trained parser is armed with grammar knowledge, thus it boosts up our language model to land on new corpus. Our proposed framework also supports end-to-end joint training of the two components, so that we can fine-tune the language model. Experimental results show that our proposed framework is effective in all leaning schemes, which achieves good performance on two popular benchmark datasets. With the help of shared grammar, our language model converges significantly faster to a lower perplexity on new corpus. Our contributions in this paper are summarized as follows: • Grammar-sharing framework: We propose a framework for grammar-sharing language modeling, which incorporates the common grammar knowledge into language modeling. With the shared grammar, our framework helps language model efficiently transfer to new corpus with better performance and using shorter time. • End-to-end learning: Our framework can be end-to-end trained without syntactic annotations. To tackle the technical challenges in end-to-end learning, we use variational methods that exploit policy gradient algorithm for joint training. • Efficient software package: We provide a highly efficient implementation of our work on GPUs. Our parser is capable of parsing one million sentences per hour on a single GPU. See Appendix D for details.","How can structure knowledge, specifically shared grammar, be incorporated into language models to improve performance on new corpora without requiring syntactic annotations?",0.0,1.0,0.0
114,Language Modeling with Shared Grammar,"Yuyu Zhang and Le Song. 2019. Language Modeling with Shared Grammar. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4442–4453, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1437.pdf,https://aclanthology.org/P19-1437/,"Sequential recurrent neural networks have achieved superior performance on language modeling, but overlook the structure information in natural language. Recent works on structure-aware models have shown promising results on language modeling. However, how to incorporate structure knowledge on corpus without syntactic annotations remains an open problem. In this work, we propose neural variational language model (NVLM), which enables the sharing of grammar knowledge among different corpora. Experimental results demonstrate the effectiveness of our framework on two popular benchmark datasets. With the help of shared grammar, our language model converges significantly faster to a lower perplexity on new training corpus.","Language modeling has been a long-standing fundamental task in natural language processing. In recent years, sequential recurrent neural networks (RNNs) based language models have made astonishing progress, which achieve remarkable results on various benchmark datasets (Mikolov et al., 2010a; Jozefowicz et al., 2016; Melis et al., 2017; Elbayad et al., 2018; Gong et al., 2018; Takase et al., 2018; Dai et al., 2019). Despite the huge success, the structure information in natural language is largely overlooked due to the structural limit of sequential RNN-based language models. Recently, researchers have explored to explicitly exploit the latent structures in natural language, such as recurrent neural network grammars (RNNGs; Dyer et al., 2016; Kuncoro et al., 2017) and parsing-reading-predict networks (PRPNs; Shen et al., 2017). These structureaware models have shown promising results on language modeling, demonstrating that the latent nested structure in language indeed helps improve sequential language models. Models like RNNG exploit treebank data with syntactic annotations to learn grammar, which is then used to improve language model performance by a significant margin. This is definitely intriguing, but we have to pay the cost: accurate syntactic annotation is very costly, and treebank data such as the Penn Treebank (Marcus et al., 1993) is typically small-scale and not open to the public for free. On new corpus which has no syntactic annotations, how to improve language modeling with grammar knowledge? This is an important and challenging open problem. As a motivating example, we conduct a simple experiment by training a RNN language model on one corpus and testing it on another, and report the results in Table 1. The RNN language model performs terribly when training and testing on different datasets, which is reasonable since the data distribution may vary dramatically on different corpora. Training from scratch on every new corpus is obviously not good enough: 1) it is computationally expensive and not data-efficient; 2) the size of target corpus may be too small to train a decent RNN-based language model; 3) the common grammar is not leveraged. Some recent works on transfer learning have made attempts on language model adaptation (Yoon et al., 2017; Ma et al., 2017; Chen et al., 2015), however, none of them explicitly exploits the common grammar knowledge shared between corpora. To bridge the gap of language modeling on different corpora, we believe that grammar is the key since all corpora are in the same language and should share the same grammar. Motivated by that, we propose neural variational language model (NVLM). Specifically, our framework consists of two probabilistic components: a constituency parser and a joint generative model of sentence and parse tree. When treebank data is available, we can separately train both components. On new corpus without tree annotations, we fix the pre-trained parser and train the generative model either from scratch or with warmup. The pre-trained parser is armed with grammar knowledge, thus it boosts up our language model to land on new corpus. Our proposed framework also supports end-to-end joint training of the two components, so that we can fine-tune the language model. Experimental results show that our proposed framework is effective in all leaning schemes, which achieves good performance on two popular benchmark datasets. With the help of shared grammar, our language model converges significantly faster to a lower perplexity on new corpus. Our contributions in this paper are summarized as follows: • Grammar-sharing framework: We propose a framework for grammar-sharing language modeling, which incorporates the common grammar knowledge into language modeling. With the shared grammar, our framework helps language model efficiently transfer to new corpus with better performance and using shorter time. • End-to-end learning: Our framework can be end-to-end trained without syntactic annotations. To tackle the technical challenges in end-to-end learning, we use variational methods that exploit policy gradient algorithm for joint training. • Efficient software package: We provide a highly efficient implementation of our work on GPUs. Our parser is capable of parsing one million sentences per hour on a single GPU. See Appendix D for details.",Can language modeling performance be improved on a new corpus without syntactic annotations by sharing grammar knowledge among different corpora through a neural variational language model (NVLM)?,0.0,1.0,0.0
115,UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective,"Yang Ping, JunYu Lu, Ruyi Gan, Junjie Wang, Yuxiang Zhang, Pingjian Zhang, and Jiaxing Zhang. 2023. UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 16424–16440, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.907.pdf,https://aclanthology.org/2023.acl-long.907/,"We propose a new paradigm for universal information extraction (IE) that is compatible with any schema format and applicable to a list of IE tasks, such as named entity recognition, relation extraction, event extraction and sentiment analysis. Our approach converts the text-based IE tasks as the token-pair problem, which uniformly disassembles all extraction targets into joint span detection, classification and association problems with a unified extractive framework, namely UniEX. UniEX can synchronously encode schema-based prompt and textual information, and collaboratively learn the generalized knowledge from pre-defined information using the auto-encoder language models. We develop a traffine attention mechanism to integrate heterogeneous factors including tasks, labels and inside tokens, and obtain the extraction target via a scoring matrix. Experiment results show that UniEX can outperform generative universal IE models in terms of performance and inference-speed on 14 benchmarks IE datasets with the supervised setting. The state-of-the-art performance in low-resource scenarios also verifies the transferability and effectiveness of UniEX.","Information extraction (IE) aims at automatically extracting structured information from unstructured textual sources, covering a wide range of subtasks such as named entity recognition, relation extraction, semantic role labeling, and sentiment analysis (Muslea et al., 1999; Grishman, 2019). However, the variety of subtasks build the isolation zones between each other and form their own dedicated models. Fig 1 (a) presents that the popular IE approaches handle structured extraction by the addition of task-specific layers on top of pretrained language models (LMs) and a subsequent fine-tuning of the conjoined model (Lample et al., 2016; Luo et al., 2020; Wei et al., 2020; Ye et al., 2022). The isolated architectures and chaotic situation prevents enhancements from one task from being applied to another, which hinders the effective latent semantics sharing such as label names, and suffer from inductive bias in transfer learning (Paolini et al., 2020). With powerful capabilities in knowledge sharing and semantic generalization, large-scale LMs bring the opportunity to handle multiple IE tasks using a single framework. As shown in Fig 1 (b), by developing sophisticated schema-based prompt and structural generation specification, the IE tasks can be transformed into text-to-text and text-to-structure formats via large-scale generative LMs (Dong et al., 2019; Paolini et al., 2020; Lu et al., 2022) such as T5 (Raffel et al., 2020a). Moreover, the universal IE frameworks can learn general knowledge from multi-source prompts, which is beneficial for perceiving unseen content in lowresource scenarios. Despite their success, these generative frameworks suffer from their inherent problems, which limit their potential and performance in universal modeling. Firstly, the schemabased prompt and contextual information are synthetically encoded for generating the target structure, which is not conducive to directly leveraging the position information among different tokens. Secondly, the generative architecture utilizes the token-wise decoder to obtain the target structure, which is extremely time-consuming. The aforementioned issues prompt us to rethink the foundation of IE tasks. Fundamentally, we discover that the extraction targets of different IE tasks involve the determination of semantic roles and semantic types, both of which can be converted into span formats by the correlation of the inside tokens in the passage. For instance, an entity type is the boundary detection and label classification of a semantic role, while a relation type can be regarded as the semantic association between specific semantic roles. From this perspective, the IE tasks can be decoded using a span-extractive framework, which can be uniformly decomposed as several atomic operations: i) Span Detection, which locates the boundaries of the mentioned semantic roles; ii) Span Classification, which recognizes the semantic types of the semantic roles; iii) Span Association, which establishes and measures the correlation between semantic roles to determine semantic types. According to the above observation, we propose a new paradigm for universal IE, called Unified Extraction model (UniEX) as Figure 1 (c). Specifically, we first introduce a rule-based transformation to bridge various extraction targets and unified input formats, which leverages task-specific labels with identifiers as the schema-based prompt to learn general IE knowledge. Then, recent works (Liu et al., 2019a; Yang et al., 2022) state that the auto-encoder LMs with bidirectional context representations are more suitable for natural language understanding. Therefore, We employ BERT-like LMs to construct an extractive architecture for underlying semantic encoding. Finally, inspired by the successful application of span-decoder and biaffine network to decode entity and relation with a scoring matrix (Yu et al., 2020b; Li et al., 2020; Yuan et al., 2022), we introduce a triaffine attention mechanism for structural decoding, which jointly considers high-order interactions among multiple factors, including tasks, labels and inside tokens. Each triaffine scoring matrix is assigned to a demand-specific prompt for obtaining span-extractive objectives. Through extensive experiments on several challenging benchmarks of 4 main IE tasks (entity/relation/event/sentiment extraction), we demonstrate that compared with the state-of-the-art universal IE models and task-specific low-resource approaches, our UniEX achieves a substantial improvement in performance and efficiency with supervised, few-shot and zero-shot settings. Our main contributions are summarized as: • We develop an efficient and effective universal IE paradigm by converting all IE tasks into joint span classification, detection and association problem. • We introduce UniEX, a new unified extractive framework that utilizes the extractive structures to encode the underlying information and control the schema-based span decoding via the triaffine attention mechanism. • We apply our approach in low-resource scenarios, and significant performance improvements suggest that our approach is potential for attaching label information to generalized objects and transfer learning. Our code will be made publicly available.",What is the effectiveness of the UniEX framework in enhancing performance and efficiency across various information extraction tasks compared to state-of-the-art universal IE models and task-specific approaches in both low-resource and supervised settings?,0.0,0.0,0.0
116,UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective,"Yang Ping, JunYu Lu, Ruyi Gan, Junjie Wang, Yuxiang Zhang, Pingjian Zhang, and Jiaxing Zhang. 2023. UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 16424–16440, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.907.pdf,https://aclanthology.org/2023.acl-long.907/,"We propose a new paradigm for universal information extraction (IE) that is compatible with any schema format and applicable to a list of IE tasks, such as named entity recognition, relation extraction, event extraction and sentiment analysis. Our approach converts the text-based IE tasks as the token-pair problem, which uniformly disassembles all extraction targets into joint span detection, classification and association problems with a unified extractive framework, namely UniEX. UniEX can synchronously encode schema-based prompt and textual information, and collaboratively learn the generalized knowledge from pre-defined information using the auto-encoder language models. We develop a traffine attention mechanism to integrate heterogeneous factors including tasks, labels and inside tokens, and obtain the extraction target via a scoring matrix. Experiment results show that UniEX can outperform generative universal IE models in terms of performance and inference-speed on 14 benchmarks IE datasets with the supervised setting. The state-of-the-art performance in low-resource scenarios also verifies the transferability and effectiveness of UniEX.","Information extraction (IE) aims at automatically extracting structured information from unstructured textual sources, covering a wide range of subtasks such as named entity recognition, relation extraction, semantic role labeling, and sentiment analysis (Muslea et al., 1999; Grishman, 2019). However, the variety of subtasks build the isolation zones between each other and form their own dedicated models. Fig 1 (a) presents that the popular IE approaches handle structured extraction by the addition of task-specific layers on top of pretrained language models (LMs) and a subsequent fine-tuning of the conjoined model (Lample et al., 2016; Luo et al., 2020; Wei et al., 2020; Ye et al., 2022). The isolated architectures and chaotic situation prevents enhancements from one task from being applied to another, which hinders the effective latent semantics sharing such as label names, and suffer from inductive bias in transfer learning (Paolini et al., 2020). With powerful capabilities in knowledge sharing and semantic generalization, large-scale LMs bring the opportunity to handle multiple IE tasks using a single framework. As shown in Fig 1 (b), by developing sophisticated schema-based prompt and structural generation specification, the IE tasks can be transformed into text-to-text and text-to-structure formats via large-scale generative LMs (Dong et al., 2019; Paolini et al., 2020; Lu et al., 2022) such as T5 (Raffel et al., 2020a). Moreover, the universal IE frameworks can learn general knowledge from multi-source prompts, which is beneficial for perceiving unseen content in lowresource scenarios. Despite their success, these generative frameworks suffer from their inherent problems, which limit their potential and performance in universal modeling. Firstly, the schemabased prompt and contextual information are synthetically encoded for generating the target structure, which is not conducive to directly leveraging the position information among different tokens. Secondly, the generative architecture utilizes the token-wise decoder to obtain the target structure, which is extremely time-consuming. The aforementioned issues prompt us to rethink the foundation of IE tasks. Fundamentally, we discover that the extraction targets of different IE tasks involve the determination of semantic roles and semantic types, both of which can be converted into span formats by the correlation of the inside tokens in the passage. For instance, an entity type is the boundary detection and label classification of a semantic role, while a relation type can be regarded as the semantic association between specific semantic roles. From this perspective, the IE tasks can be decoded using a span-extractive framework, which can be uniformly decomposed as several atomic operations: i) Span Detection, which locates the boundaries of the mentioned semantic roles; ii) Span Classification, which recognizes the semantic types of the semantic roles; iii) Span Association, which establishes and measures the correlation between semantic roles to determine semantic types. According to the above observation, we propose a new paradigm for universal IE, called Unified Extraction model (UniEX) as Figure 1 (c). Specifically, we first introduce a rule-based transformation to bridge various extraction targets and unified input formats, which leverages task-specific labels with identifiers as the schema-based prompt to learn general IE knowledge. Then, recent works (Liu et al., 2019a; Yang et al., 2022) state that the auto-encoder LMs with bidirectional context representations are more suitable for natural language understanding. Therefore, We employ BERT-like LMs to construct an extractive architecture for underlying semantic encoding. Finally, inspired by the successful application of span-decoder and biaffine network to decode entity and relation with a scoring matrix (Yu et al., 2020b; Li et al., 2020; Yuan et al., 2022), we introduce a triaffine attention mechanism for structural decoding, which jointly considers high-order interactions among multiple factors, including tasks, labels and inside tokens. Each triaffine scoring matrix is assigned to a demand-specific prompt for obtaining span-extractive objectives. Through extensive experiments on several challenging benchmarks of 4 main IE tasks (entity/relation/event/sentiment extraction), we demonstrate that compared with the state-of-the-art universal IE models and task-specific low-resource approaches, our UniEX achieves a substantial improvement in performance and efficiency with supervised, few-shot and zero-shot settings. Our main contributions are summarized as: • We develop an efficient and effective universal IE paradigm by converting all IE tasks into joint span classification, detection and association problem. • We introduce UniEX, a new unified extractive framework that utilizes the extractive structures to encode the underlying information and control the schema-based span decoding via the triaffine attention mechanism. • We apply our approach in low-resource scenarios, and significant performance improvements suggest that our approach is potential for attaching label information to generalized objects and transfer learning. Our code will be made publicly available.","Can the inefficiency and ineffectiveness of current isolated model approaches to information extraction across various subtasks be addressed by a universally applicable, unified extractive framework (UniEX), which treats IE tasks uniformly as token-pair problems involving span detection, classification, and association and integrates schema-based prompts with textual information through auto-encoder language models?",2.0,1.0,1.0
117,AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction,"Yanzeng Li, Bingcong Xue, Ruoyu Zhang, and Lei Zou. 2023. AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2139–2152, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.119.pdf,https://aclanthology.org/2023.acl-long.119/,"Attribute extraction aims to identify attribute names and the corresponding values from descriptive texts, which is the foundation for extensive downstream applications such as knowledge graph construction, search engines, and e-Commerce. In previous studies, attribute extraction is generally treated as a classification problem for predicting attribute types or a sequence tagging problem for labeling attribute values, where two paradigms, i.e., closed-world and open-world assumption, are involved. However, both of these paradigms have limitations in terms of real-world applications. And prior studies attempting to integrate these paradigms through ensemble, pipeline, and co-training models, still face challenges like cascading errors, high computational overhead, and difficulty in training. To address these existing problems, this paper presents Attribute Tree, a unified formulation for realworld attribute extraction application, where closed-world, open-world, and semi-open attribute extraction tasks are modeled uniformly. Then a text-to-tree generation model, AtTGen, is proposed to learn annotations from different scenarios efficiently and consistently. Experiments demonstrate that our proposed paradigm well covers various scenarios for real-world applications, and the model achieves state-ofthe-art, outperforming existing methods by a large margin on three datasets. Our code, pretrained model, and datasets are available at https://github.com/lsvih/AtTGen.","Attribute Extraction (AE) is a practical application of the Information Extraction (IE) task, aiming to identify the attribute name and the corresponding attribute value from unstructured or semistructured text fragments (Ghani et al., 2006; Ravi and Pasca, 2008; More, 2016). Figure 1 shows a typical product profile with extracted attribute tags. As the foundation for various downstream applications such as knowledge graph construction, search engines, e-Commerce and recommender systems, AE has attracted extensive research interest in recent years (Zheng et al., 2018; Xu et al., 2019; Zhu et al., 2020; Jain et al., 2021; Zhang et al., 2022; Li and Zou, 2022). There are two basic subtasks in the research of AE, namely, attribute name extraction and attribute value extraction. And we use the RDF-style triple1 <e, n, v> to denote the entity, attribute name, and attribute value respectively. According to whether the attribute name set is pre-defined, AE can be divided into two paradigms, i.e., the Closed-World Assumption (CWA) and the Open-World Assumption (OWA). For CWA AE, the attribute name n is limited to a finite set of the pre-defined schema, where attribute name extraction is typically modeled as a classification task (Zeng et al., 2014; Zhou et al., 2016), and attribute value extraction models are trained for each target attribute (Zheng et al., 2018; Zhu et al., 2020; Yan et al., 2021). While for OWA AE, which is also known as “New Attribute Discover” (Wong and Lam, 2010; Zhang et al., 2022) and “Open Information Extraction” (Cui et al., 2018), the attribute name is schema-free and can be extracted from the text. Sequence tagging methods are broadly employed to extract those attributes (Xu et al., 2019). Recently, researchers also explore novel paradigms such as Question Answering (QA) models (Wang et al., 2020; Shinzato et al., 2022; Yang et al., 2022) and generative models (Roy et al., 2022) to generalize the ability of attribute extraction. However, AE in the real world is far more complicated. On the one hand, in closely related fields like e-commerce, new types of products with new sets of attributes are so constantly arising that the pre-defined schema is never enough. For example, an analysis in Zhang et al. (2022) has shown that only 30 / 51 attributes are found in existing structured product profiles of Amazon’s 10 product types. On the other hand, however, attribute extraction methods shouldn’t overlook the huge value and commonalities behind known attributes, and it is inherent that not all attributes can be fully identified by open extraction methods due to the lack of literal name mentions, e.g. name and size in Figure 1. It is possible to carry out both CWA and OWA methods when needed, just as Zhang et al. (2021) attempts preliminarily. But apart from the fragmentation of the problem form and the unnecessary computing overhead, a more prominent issue is that such simple integration neglects the natural connections between the CWA vocabulary and the OWA ability in attribute extraction, and thus cannot achieve satisfactory results. In this paper, we, for the first time, explicitly unify the different AE paradigms in the form of Attribute Tree, and present a text-to-tree based generative model called AtTGen to solve the real-world attribute joint extraction task. Specifically, our proposed AtTGen successfully implements the unification of attribute tagging and classification tasks by generating the Attribute Tree, and congenitally circumvents the problem of “null”-value that troubles pioneers (Xu et al., 2019; Wang et al., 2020). Further, the head entity is optional as the root node on Attribute Tree to meet the actual situation, as well as to enhance the extraction performance with the help of the subject guidance (Yu et al., 2021; Zhang et al., 2021). AtTGen reduces the length of the generated sequence and thus shrinks the search space by conducting the tree generation model. And it can accurately mark out the span of attribute values and extract unseen attributes with the pointer-copy mechanism (Zhou et al., 2018). Moreover, the teacher forcing manner (Williams and Zipser, 1989) and the converted path-generation training objective further reduce the exposure bias (Zhang et al., 2020) to improve the generalization and effectiveness. In short, the major contributions of this paper can be summarized as follows: • We are the first to define different attribute extraction paradigms like CWA, OWA and semi-open as the attribute tree generation problem, formally unifying multiple tasks and fully capturing the internal connections. • We design a novel text-to-attribute tree generation model with a pointer-based copy mechanism for extracting both literal mentions and category labels. • We evaluate our model on several benchmark datasets. Experimental results show that our method achieves state-of-the-art (SOTA) and outperforms existing works by a large margin in all scenarios including open, semi-open and closedworld attribute extraction.","How can a unified model effectively address the challenges of attribute extraction in real-world applications by incorporating closed-world, open-world, and semi-open paradigms into a single attribute tree generation approach, while overcoming limitations such as cascading errors, high computational costs, and training difficulties associated with previous methods?",2.0,2.0,1.0
118,AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction,"Yanzeng Li, Bingcong Xue, Ruoyu Zhang, and Lei Zou. 2023. AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2139–2152, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.119.pdf,https://aclanthology.org/2023.acl-long.119/,"Attribute extraction aims to identify attribute names and the corresponding values from descriptive texts, which is the foundation for extensive downstream applications such as knowledge graph construction, search engines, and e-Commerce. In previous studies, attribute extraction is generally treated as a classification problem for predicting attribute types or a sequence tagging problem for labeling attribute values, where two paradigms, i.e., closed-world and open-world assumption, are involved. However, both of these paradigms have limitations in terms of real-world applications. And prior studies attempting to integrate these paradigms through ensemble, pipeline, and co-training models, still face challenges like cascading errors, high computational overhead, and difficulty in training. To address these existing problems, this paper presents Attribute Tree, a unified formulation for realworld attribute extraction application, where closed-world, open-world, and semi-open attribute extraction tasks are modeled uniformly. Then a text-to-tree generation model, AtTGen, is proposed to learn annotations from different scenarios efficiently and consistently. Experiments demonstrate that our proposed paradigm well covers various scenarios for real-world applications, and the model achieves state-ofthe-art, outperforming existing methods by a large margin on three datasets. Our code, pretrained model, and datasets are available at https://github.com/lsvih/AtTGen.","Attribute Extraction (AE) is a practical application of the Information Extraction (IE) task, aiming to identify the attribute name and the corresponding attribute value from unstructured or semistructured text fragments (Ghani et al., 2006; Ravi and Pasca, 2008; More, 2016). Figure 1 shows a typical product profile with extracted attribute tags. As the foundation for various downstream applications such as knowledge graph construction, search engines, e-Commerce and recommender systems, AE has attracted extensive research interest in recent years (Zheng et al., 2018; Xu et al., 2019; Zhu et al., 2020; Jain et al., 2021; Zhang et al., 2022; Li and Zou, 2022). There are two basic subtasks in the research of AE, namely, attribute name extraction and attribute value extraction. And we use the RDF-style triple1 <e, n, v> to denote the entity, attribute name, and attribute value respectively. According to whether the attribute name set is pre-defined, AE can be divided into two paradigms, i.e., the Closed-World Assumption (CWA) and the Open-World Assumption (OWA). For CWA AE, the attribute name n is limited to a finite set of the pre-defined schema, where attribute name extraction is typically modeled as a classification task (Zeng et al., 2014; Zhou et al., 2016), and attribute value extraction models are trained for each target attribute (Zheng et al., 2018; Zhu et al., 2020; Yan et al., 2021). While for OWA AE, which is also known as “New Attribute Discover” (Wong and Lam, 2010; Zhang et al., 2022) and “Open Information Extraction” (Cui et al., 2018), the attribute name is schema-free and can be extracted from the text. Sequence tagging methods are broadly employed to extract those attributes (Xu et al., 2019). Recently, researchers also explore novel paradigms such as Question Answering (QA) models (Wang et al., 2020; Shinzato et al., 2022; Yang et al., 2022) and generative models (Roy et al., 2022) to generalize the ability of attribute extraction. However, AE in the real world is far more complicated. On the one hand, in closely related fields like e-commerce, new types of products with new sets of attributes are so constantly arising that the pre-defined schema is never enough. For example, an analysis in Zhang et al. (2022) has shown that only 30 / 51 attributes are found in existing structured product profiles of Amazon’s 10 product types. On the other hand, however, attribute extraction methods shouldn’t overlook the huge value and commonalities behind known attributes, and it is inherent that not all attributes can be fully identified by open extraction methods due to the lack of literal name mentions, e.g. name and size in Figure 1. It is possible to carry out both CWA and OWA methods when needed, just as Zhang et al. (2021) attempts preliminarily. But apart from the fragmentation of the problem form and the unnecessary computing overhead, a more prominent issue is that such simple integration neglects the natural connections between the CWA vocabulary and the OWA ability in attribute extraction, and thus cannot achieve satisfactory results. In this paper, we, for the first time, explicitly unify the different AE paradigms in the form of Attribute Tree, and present a text-to-tree based generative model called AtTGen to solve the real-world attribute joint extraction task. Specifically, our proposed AtTGen successfully implements the unification of attribute tagging and classification tasks by generating the Attribute Tree, and congenitally circumvents the problem of “null”-value that troubles pioneers (Xu et al., 2019; Wang et al., 2020). Further, the head entity is optional as the root node on Attribute Tree to meet the actual situation, as well as to enhance the extraction performance with the help of the subject guidance (Yu et al., 2021; Zhang et al., 2021). AtTGen reduces the length of the generated sequence and thus shrinks the search space by conducting the tree generation model. And it can accurately mark out the span of attribute values and extract unseen attributes with the pointer-copy mechanism (Zhou et al., 2018). Moreover, the teacher forcing manner (Williams and Zipser, 1989) and the converted path-generation training objective further reduce the exposure bias (Zhang et al., 2020) to improve the generalization and effectiveness. In short, the major contributions of this paper can be summarized as follows: • We are the first to define different attribute extraction paradigms like CWA, OWA and semi-open as the attribute tree generation problem, formally unifying multiple tasks and fully capturing the internal connections. • We design a novel text-to-attribute tree generation model with a pointer-based copy mechanism for extracting both literal mentions and category labels. • We evaluate our model on several benchmark datasets. Experimental results show that our method achieves state-of-the-art (SOTA) and outperforms existing works by a large margin in all scenarios including open, semi-open and closedworld attribute extraction.",Can real-world attribute joint extraction tasks be solved by a text-to-tree based generative model called AtTGen?,0.0,1.0,0.0
119,AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction,"Yanzeng Li, Bingcong Xue, Ruoyu Zhang, and Lei Zou. 2023. AtTGen: Attribute Tree Generation for Real-World Attribute Joint Extraction. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2139–2152, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.119.pdf,https://aclanthology.org/2023.acl-long.119/,"Attribute extraction aims to identify attribute names and the corresponding values from descriptive texts, which is the foundation for extensive downstream applications such as knowledge graph construction, search engines, and e-Commerce. In previous studies, attribute extraction is generally treated as a classification problem for predicting attribute types or a sequence tagging problem for labeling attribute values, where two paradigms, i.e., closed-world and open-world assumption, are involved. However, both of these paradigms have limitations in terms of real-world applications. And prior studies attempting to integrate these paradigms through ensemble, pipeline, and co-training models, still face challenges like cascading errors, high computational overhead, and difficulty in training. To address these existing problems, this paper presents Attribute Tree, a unified formulation for realworld attribute extraction application, where closed-world, open-world, and semi-open attribute extraction tasks are modeled uniformly. Then a text-to-tree generation model, AtTGen, is proposed to learn annotations from different scenarios efficiently and consistently. Experiments demonstrate that our proposed paradigm well covers various scenarios for real-world applications, and the model achieves state-ofthe-art, outperforming existing methods by a large margin on three datasets. Our code, pretrained model, and datasets are available at https://github.com/lsvih/AtTGen.","Attribute Extraction (AE) is a practical application of the Information Extraction (IE) task, aiming to identify the attribute name and the corresponding attribute value from unstructured or semistructured text fragments (Ghani et al., 2006; Ravi and Pasca, 2008; More, 2016). Figure 1 shows a typical product profile with extracted attribute tags. As the foundation for various downstream applications such as knowledge graph construction, search engines, e-Commerce and recommender systems, AE has attracted extensive research interest in recent years (Zheng et al., 2018; Xu et al., 2019; Zhu et al., 2020; Jain et al., 2021; Zhang et al., 2022; Li and Zou, 2022). There are two basic subtasks in the research of AE, namely, attribute name extraction and attribute value extraction. And we use the RDF-style triple1 <e, n, v> to denote the entity, attribute name, and attribute value respectively. According to whether the attribute name set is pre-defined, AE can be divided into two paradigms, i.e., the Closed-World Assumption (CWA) and the Open-World Assumption (OWA). For CWA AE, the attribute name n is limited to a finite set of the pre-defined schema, where attribute name extraction is typically modeled as a classification task (Zeng et al., 2014; Zhou et al., 2016), and attribute value extraction models are trained for each target attribute (Zheng et al., 2018; Zhu et al., 2020; Yan et al., 2021). While for OWA AE, which is also known as “New Attribute Discover” (Wong and Lam, 2010; Zhang et al., 2022) and “Open Information Extraction” (Cui et al., 2018), the attribute name is schema-free and can be extracted from the text. Sequence tagging methods are broadly employed to extract those attributes (Xu et al., 2019). Recently, researchers also explore novel paradigms such as Question Answering (QA) models (Wang et al., 2020; Shinzato et al., 2022; Yang et al., 2022) and generative models (Roy et al., 2022) to generalize the ability of attribute extraction. However, AE in the real world is far more complicated. On the one hand, in closely related fields like e-commerce, new types of products with new sets of attributes are so constantly arising that the pre-defined schema is never enough. For example, an analysis in Zhang et al. (2022) has shown that only 30 / 51 attributes are found in existing structured product profiles of Amazon’s 10 product types. On the other hand, however, attribute extraction methods shouldn’t overlook the huge value and commonalities behind known attributes, and it is inherent that not all attributes can be fully identified by open extraction methods due to the lack of literal name mentions, e.g. name and size in Figure 1. It is possible to carry out both CWA and OWA methods when needed, just as Zhang et al. (2021) attempts preliminarily. But apart from the fragmentation of the problem form and the unnecessary computing overhead, a more prominent issue is that such simple integration neglects the natural connections between the CWA vocabulary and the OWA ability in attribute extraction, and thus cannot achieve satisfactory results. In this paper, we, for the first time, explicitly unify the different AE paradigms in the form of Attribute Tree, and present a text-to-tree based generative model called AtTGen to solve the real-world attribute joint extraction task. Specifically, our proposed AtTGen successfully implements the unification of attribute tagging and classification tasks by generating the Attribute Tree, and congenitally circumvents the problem of “null”-value that troubles pioneers (Xu et al., 2019; Wang et al., 2020). Further, the head entity is optional as the root node on Attribute Tree to meet the actual situation, as well as to enhance the extraction performance with the help of the subject guidance (Yu et al., 2021; Zhang et al., 2021). AtTGen reduces the length of the generated sequence and thus shrinks the search space by conducting the tree generation model. And it can accurately mark out the span of attribute values and extract unseen attributes with the pointer-copy mechanism (Zhou et al., 2018). Moreover, the teacher forcing manner (Williams and Zipser, 1989) and the converted path-generation training objective further reduce the exposure bias (Zhang et al., 2020) to improve the generalization and effectiveness. In short, the major contributions of this paper can be summarized as follows: • We are the first to define different attribute extraction paradigms like CWA, OWA and semi-open as the attribute tree generation problem, formally unifying multiple tasks and fully capturing the internal connections. • We design a novel text-to-attribute tree generation model with a pointer-based copy mechanism for extracting both literal mentions and category labels. • We evaluate our model on several benchmark datasets. Experimental results show that our method achieves state-of-the-art (SOTA) and outperforms existing works by a large margin in all scenarios including open, semi-open and closedworld attribute extraction.","Can the limitations of existing attribute extraction methods under the closed-world and open-world assumptions, along with the integration difficulties of these paradigms for real-world applications, be addressed by a unified formulation like the Attribute Tree and the text-to-tree generation model (AtTGen)?",1.0,1.0,1.0
120,Improving the Faithfulness of Attention-based Explanations with Task-specific Information for Text Classification,"George Chrysostomou and Nikolaos Aletras. 2021. Improving the Faithfulness of Attention-based Explanations with Task-specific Information for Text Classification. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 477–488, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.40.pdf,https://aclanthology.org/2021.acl-long.40/,"Neural network architectures in natural language processing often use attention mechanisms to produce probability distributions over input token representations. Attention has empirically been demonstrated to improve performance in various tasks, while its weights have been extensively used as explanations for model predictions. Recent studies (Jain and Wallace, 2019; Serrano and Smith, 2019; Wiegreffe and Pinter, 2019) have showed that it cannot generally be considered as a faithful explanation (Jacovi and Goldberg, 2020) across encoders and tasks. In this paper, we seek to improve the faithfulness of attention-based explanations for text classification. We achieve this by proposing a new family of Task-Scaling (TaSc) mechanisms that learn task-specific non-contextualised information to scale the original attention weights. Evaluation tests for explanation faithfulness, show that the three proposed variants of TaSc improve attentionbased explanations across two attention mechanisms, five encoders and five text classification datasets without sacrificing predictive performance. Finally, we demonstrate that TaSc consistently provides more faithful attentionbased explanations compared to three widelyused interpretability techniques.","Natural Language Processing (NLP) approaches for text classification are often underpinned by large neural network models (Cho et al., 2014; Devlin et al., 2019). Despite the high accuracy and efficiency of these models in dealing with large amounts of data, an important problem is their increased complexity that makes them opaque and hard to interpret by humans which usually treat them as black boxes (Zhang et al., 2018; Linzen et al., 2019). Attention mechanisms (Bahdanau et al., 2015) produce a probability distribution over the input to compute a vector representation of the entire token sequence as the weighted sum of its constituent vectors. A common practice is to provide explanations for a given prediction and qualitative model analysis by assigning importance to input tokens using scores provided by attention mechanisms (Chen et al., 2017; Wang et al., 2016; Jain et al., 2020; Sun and Lu, 2020) as a mean towards model interpretability (Lipton, 2016; Miller, 2019). A faithful explanation is one that accurately represents the true reasoning behind a model’s prediction (Jacovi and Goldberg, 2020). A series of recent studies illustrate that explanations obtained by attention weights do not always provide faithful explanations (Serrano and Smith, 2019) while different text encoders can affect attention interpretability, e.g. results can differ when using a recurrent or non-recurrent encoder (Wiegreffe and Pinter, 2019). A limitation of attention as an indicator of input importance is that it refers to the word in context due to information mixing in the model (Tutek and Snajder, 2020). Motivated by this, we aim to improve the effectiveness of neural models in providing more faithful attention-based explanations for text classification, by introducing noncontextualised information in the model. Our contributions are as follows: • We introduce three Task-Scaling (TaSc) mechanisms (§4), a family of encoder-independent components that learn task-specific noncontextualised importance scores for each word in the vocabulary to scale the original attention weights which can be easily ported to any neural architecture; We show that TaSc variants offer more robust, consistent and faithful attention-based explanations compared to using vanilla attention in a set of standard interpretability benchmarks, without sacrificing predictive performance (§6); • We demonstrate that attention-based explanations with TaSc consistently outperform explanations obtained from two gradient-based and a word-erasure explanation approaches (§7).",Can the introduction of Task-Scaling mechanisms improve the faithfulness of attention-based explanations for text classification decisions by scaling original attention weights with task-specific non-contextualized information?,1.0,2.0,1.0
121,Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting,"Yen-Chun Chen and Mohit Bansal. 2018. Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 675–686, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1063.pdf,https://aclanthology.org/P18-1063/,"Inspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the nondifferentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency. Empirically, we achieve the new state-of-theart on all metrics (including human evaluation) on the CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores. Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models. We also demonstrate the generalization of our model on the test-only DUC2002 dataset, where we achieve higher scores than a state-of-the-art model.","The task of document summarization has two main paradigms: extractive and abstractive. The former method directly chooses and outputs the salient sentences (or phrases) in the original document (Jing and McKeown, 2000; Knight and Marcu, 2000; Martins and Smith, 2009; BergKirkpatrick et al., 2011). The latter abstractive approach involves rewriting the summary (Banko et al., 2000; Zajic et al., 2004), and has seen substantial recent gains due to neural sequence-tosequence models (Chopra et al., 2016; Nallapati et al., 2016; See et al., 2017; Paulus et al., 2018). Abstractive models can be more concise by performing generation from scratch, but they suffer from slow and inaccurate encoding of very long documents, with the attention model being required to look at all encoded words (in long paragraphs) for decoding each generated summary word (slow, one by one sequentially). Abstractive models also suffer from redundancy (repetitions), especially when generating multi-sentence summary. To address both these issues and combine the advantages of both paradigms, we propose a hybrid extractive-abstractive architecture, with policy-based reinforcement learning (RL) to bridge together the two networks. Similar to how humans summarize long documents, our model first uses an extractor agent to select salient sentences or highlights, and then employs an abstractor network to rewrite (i.e., compress and paraphrase) each of these extracted sentences. To overcome the non-differentiable behavior of our extractor and train on available document-summary pairs without saliency label, we next use actorcritic policy gradient with sentence-level metric rewards to connect these two neural networks and to learn sentence saliency. We also avoid common language fluency issues (Paulus et al., 2018) by preventing the policy gradients from affecting the abstractive summarizer’s word-level training, which is supported by our human evaluation study. Our sentence-level reinforcement learning takes into account the word-sentence hierarchy, which better models the language structure and makes parallelization possible. Our extractor combines reinforcement learning and pointer networks, which is inspired by Bello et al. (2017)’s attempt to solve the Traveling Salesman Problem. Our abstractor is a simple encoder-aligner-decoder model (with copying) and is trained on pseudo document-summary sentence pairs obtained via simple automatic matching criteria. Thus, our method incorporates the abstractive paradigm’s advantages of concisely rewriting sentences and generating novel words from the full vocabulary, yet it adopts intermediate extractive behavior to improve the overall model’s quality, speed, and stability. Instead of encoding and attending to every word in the long input document sequentially, our model adopts a human-inspired coarse-to-fine approach that first extracts all the salient sentences and then decodes (rewrites) them (in parallel). This also avoids almost all redundancy issues because the model has already chosen non-redundant salient sentences to abstractively summarize (but adding an optional final reranker component does give additional gains by removing the fewer across-sentence repetitions). Empirically, our approach is the new state-ofthe-art on all ROUGE metrics (Lin, 2004) as well as on METEOR (Denkowski and Lavie, 2014) of the CNN/Daily Mail dataset, achieving statistically significant improvements over previous models that use complex long-encoder, copy, and coverage mechanisms (See et al., 2017). The test-only DUC-2002 improvement also shows our model’s better generalization than this strong abstractive system. In addition, we surpass the popular lead-3 baseline on all ROUGE scores with an abstractive model. Moreover, our sentence-level abstractive rewriting module also produces substantially more (3x) novel N-grams that are not seen in the input document, as compared to the strong flat-structured model of See et al. (2017). This empirically justifies that our RL-guided extractor has learned sentence saliency, rather than benefiting from simply copying longer sentences. We also show that our model maintains the same level of fluency as a conventional RNN-based model because the reward does not leak to our abstractor’s word-level training. Finally, our model’s training is 4x and inference is more than 20x faster than the previous state-of-the-art. The optional final reranker gives further improvements while maintaining a 7x speedup. Overall, our contribution is three fold: First we propose a novel sentence-level RL technique for the well-known task of abstractive summarization, effectively utilizing the word-then-sentence hierarchical structure without annotated matching sentence-pairs between the document and ground truth summary. Next, our model achieves the new state-of-the-art on all metrics of multiple versions of a popular summarization dataset (as well as a test-only dataset) both extractively and abstractively, without loss in language fluency (also demonstrated via human evaluation and abstractiveness scores). Finally, our parallel decoding results in a significant 10-20x speed-up over the previous best neural abstractive summarization system with even better accuracy.","What is the key research question addressed by introducing a novel sentence-level reinforcement learning technique in a hybrid extractive-abstractive document summarization model to bridge the gap between salient sentence selection and abstractive rewriting, while maintaining language fluency and improving summarization speed and accuracy?",0.0,2.0,0.0
122,Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting,"Yen-Chun Chen and Mohit Bansal. 2018. Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 675–686, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1063.pdf,https://aclanthology.org/P18-1063/,"Inspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the nondifferentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency. Empirically, we achieve the new state-of-theart on all metrics (including human evaluation) on the CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores. Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models. We also demonstrate the generalization of our model on the test-only DUC2002 dataset, where we achieve higher scores than a state-of-the-art model.","The task of document summarization has two main paradigms: extractive and abstractive. The former method directly chooses and outputs the salient sentences (or phrases) in the original document (Jing and McKeown, 2000; Knight and Marcu, 2000; Martins and Smith, 2009; BergKirkpatrick et al., 2011). The latter abstractive approach involves rewriting the summary (Banko et al., 2000; Zajic et al., 2004), and has seen substantial recent gains due to neural sequence-tosequence models (Chopra et al., 2016; Nallapati et al., 2016; See et al., 2017; Paulus et al., 2018). Abstractive models can be more concise by performing generation from scratch, but they suffer from slow and inaccurate encoding of very long documents, with the attention model being required to look at all encoded words (in long paragraphs) for decoding each generated summary word (slow, one by one sequentially). Abstractive models also suffer from redundancy (repetitions), especially when generating multi-sentence summary. To address both these issues and combine the advantages of both paradigms, we propose a hybrid extractive-abstractive architecture, with policy-based reinforcement learning (RL) to bridge together the two networks. Similar to how humans summarize long documents, our model first uses an extractor agent to select salient sentences or highlights, and then employs an abstractor network to rewrite (i.e., compress and paraphrase) each of these extracted sentences. To overcome the non-differentiable behavior of our extractor and train on available document-summary pairs without saliency label, we next use actorcritic policy gradient with sentence-level metric rewards to connect these two neural networks and to learn sentence saliency. We also avoid common language fluency issues (Paulus et al., 2018) by preventing the policy gradients from affecting the abstractive summarizer’s word-level training, which is supported by our human evaluation study. Our sentence-level reinforcement learning takes into account the word-sentence hierarchy, which better models the language structure and makes parallelization possible. Our extractor combines reinforcement learning and pointer networks, which is inspired by Bello et al. (2017)’s attempt to solve the Traveling Salesman Problem. Our abstractor is a simple encoder-aligner-decoder model (with copying) and is trained on pseudo document-summary sentence pairs obtained via simple automatic matching criteria. Thus, our method incorporates the abstractive paradigm’s advantages of concisely rewriting sentences and generating novel words from the full vocabulary, yet it adopts intermediate extractive behavior to improve the overall model’s quality, speed, and stability. Instead of encoding and attending to every word in the long input document sequentially, our model adopts a human-inspired coarse-to-fine approach that first extracts all the salient sentences and then decodes (rewrites) them (in parallel). This also avoids almost all redundancy issues because the model has already chosen non-redundant salient sentences to abstractively summarize (but adding an optional final reranker component does give additional gains by removing the fewer across-sentence repetitions). Empirically, our approach is the new state-ofthe-art on all ROUGE metrics (Lin, 2004) as well as on METEOR (Denkowski and Lavie, 2014) of the CNN/Daily Mail dataset, achieving statistically significant improvements over previous models that use complex long-encoder, copy, and coverage mechanisms (See et al., 2017). The test-only DUC-2002 improvement also shows our model’s better generalization than this strong abstractive system. In addition, we surpass the popular lead-3 baseline on all ROUGE scores with an abstractive model. Moreover, our sentence-level abstractive rewriting module also produces substantially more (3x) novel N-grams that are not seen in the input document, as compared to the strong flat-structured model of See et al. (2017). This empirically justifies that our RL-guided extractor has learned sentence saliency, rather than benefiting from simply copying longer sentences. We also show that our model maintains the same level of fluency as a conventional RNN-based model because the reward does not leak to our abstractor’s word-level training. Finally, our model’s training is 4x and inference is more than 20x faster than the previous state-of-the-art. The optional final reranker gives further improvements while maintaining a 7x speedup. Overall, our contribution is three fold: First we propose a novel sentence-level RL technique for the well-known task of abstractive summarization, effectively utilizing the word-then-sentence hierarchical structure without annotated matching sentence-pairs between the document and ground truth summary. Next, our model achieves the new state-of-the-art on all metrics of multiple versions of a popular summarization dataset (as well as a test-only dataset) both extractively and abstractively, without loss in language fluency (also demonstrated via human evaluation and abstractiveness scores). Finally, our parallel decoding results in a significant 10-20x speed-up over the previous best neural abstractive summarization system with even better accuracy.","Can the problem of slow and inaccurate encoding of long documents by existing abstractive summarization models, along with issues of redundancy in multi-sentence summaries, be effectively addressed by a novel hybrid extractive-abstractive model that uses a sentence-level policy gradient approach to hierarchically integrate two neural networks while maintaining language fluency, aims at faster training and inference speeds, and enhances summary abstractiveness?",2.0,2.0,1.0
123,R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling,"Xiang Hu, Haitao Mi, Zujie Wen, Yafang Wang, Yi Su, Jing Zheng, and Gerard de Melo. 2021. R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4897–4908, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.379.pdf,https://aclanthology.org/2021.acl-long.379/,"Human language understanding operates at multiple levels of granularity (e.g., words, phrases, and sentences) with increasing levels of abstraction that can be hierarchically combined. However, existing deep models with stacked layers do not explicitly model any sort of hierarchical process. This paper proposes a recursive Transformer model based on differentiable CKY style binary trees to emulate the composition process. We extend the bidirectional language model pre-training objective to this architecture, attempting to predict each word given its left and right abstraction nodes. To scale up our approach, we also introduce an efficient pruned tree induction algorithm to enable encoding in just a linear number of composition steps. Experimental results on language modeling and unsupervised parsing show the effectiveness of our approach.","The idea of devising a structural model of language capable of learning both representations and meaningful syntactic structure without any humanannotated trees has been a long-standing but challenging goal. Across a diverse range of linguistic theories, human language is assumed to possess a recursive hierarchical structure (Chomsky, 1956, 2014; de Marneffe et al., 2006) such that lowerlevel meaning is combined to infer higher-level semantics. Humans possess notions of characters, words, phrases, and sentences, which children naturally learn to segment and combine. Pretrained language models such as BERT (Devlin et al., 2019) have achieved substantial gains across a range of tasks. However, they simply apply layer-stacking with a fixed depth to increase the modeling power (Bengio, 2009; Salakhutdinov, 2014). Moreover, as the core Transformer component (Vaswani et al., 2017) does not capture positional information, one also needs to incorporate additional positional embeddings. Thus, pretrained language models do not explicitly reflect the hierarchical structure of linguistic understanding. Inspired by Le and Zuidema (2015), Maillard et al. (2017) proposed a fully differentiable CKY parser to model the hierarchical process explicitly. To make their parser differentiable, they primarily introduce an energy function to combine all possible derivations when constructing each cell representation. However, their model is based on Tree-LSTMs (Tai et al., 2015; Zhu et al., 2015) and requires O(n^3) time complexity. Hence, it is hard to scale up to large training data. In this paper, we revisit these ideas, and propose a model applying recursive Transformers along differentiable trees (R2D2). To obtain differentiability, we adopt Gumbel-Softmax estimation (Jang et al., 2017) as an elegant solution. Our encoder parser operates in a bottom-up fashion akin to CKY parsing, yet runs in linear time with regard to the number of composition steps, thanks to a novel pruned tree induction algorithm. As a training objective, the model seeks to recover each word in a sentence given its left and right syntax nodes. Thus, our model does not require any positional embedding and does not need to mask any words during training. Figure 1 presents an example binary tree induced by our method: Without any syntactic supervision, it acquires a model of hierarchical construction from the word-piece level to words, phrases, and finally the sentence level. We make the following contributions: • Our novel CKY-based recursive Transformer on differentiable trees model is able to learn both representations and tree structure (Section 2.1). • We propose an efficient optimization algorithm to scale up our approach to a linear number of composition steps (Section 2.2). • We design an effective pre-training objective, which predicts each word given its left and right syntactic nodes (Section 2.3). For simplicity and efficiency reasons, in this paper we conduct experiments only on the tasks of language modeling and unsupervised tree induction. The experimental results on language modeling show that our model significantly outperforms baseline models with same parameter size even in fewer training epochs. At unsupervised parsing, our model as well obtains competitive results.","How can a machine learning model be designed to emulate the recursive hierarchical structure of human language understanding without requiring human-annotated trees, and in a way that is both computationally efficient and effective in language modeling and unsupervised parsing tasks?",0.0,0.0,0.0
124,R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling,"Xiang Hu, Haitao Mi, Zujie Wen, Yafang Wang, Yi Su, Jing Zheng, and Gerard de Melo. 2021. R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4897–4908, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.379.pdf,https://aclanthology.org/2021.acl-long.379/,"Human language understanding operates at multiple levels of granularity (e.g., words, phrases, and sentences) with increasing levels of abstraction that can be hierarchically combined. However, existing deep models with stacked layers do not explicitly model any sort of hierarchical process. This paper proposes a recursive Transformer model based on differentiable CKY style binary trees to emulate the composition process. We extend the bidirectional language model pre-training objective to this architecture, attempting to predict each word given its left and right abstraction nodes. To scale up our approach, we also introduce an efficient pruned tree induction algorithm to enable encoding in just a linear number of composition steps. Experimental results on language modeling and unsupervised parsing show the effectiveness of our approach.","The idea of devising a structural model of language capable of learning both representations and meaningful syntactic structure without any humanannotated trees has been a long-standing but challenging goal. Across a diverse range of linguistic theories, human language is assumed to possess a recursive hierarchical structure (Chomsky, 1956, 2014; de Marneffe et al., 2006) such that lowerlevel meaning is combined to infer higher-level semantics. Humans possess notions of characters, words, phrases, and sentences, which children naturally learn to segment and combine. Pretrained language models such as BERT (Devlin et al., 2019) have achieved substantial gains across a range of tasks. However, they simply apply layer-stacking with a fixed depth to increase the modeling power (Bengio, 2009; Salakhutdinov, 2014). Moreover, as the core Transformer component (Vaswani et al., 2017) does not capture positional information, one also needs to incorporate additional positional embeddings. Thus, pretrained language models do not explicitly reflect the hierarchical structure of linguistic understanding. Inspired by Le and Zuidema (2015), Maillard et al. (2017) proposed a fully differentiable CKY parser to model the hierarchical process explicitly. To make their parser differentiable, they primarily introduce an energy function to combine all possible derivations when constructing each cell representation. However, their model is based on Tree-LSTMs (Tai et al., 2015; Zhu et al., 2015) and requires O(n^3) time complexity. Hence, it is hard to scale up to large training data. In this paper, we revisit these ideas, and propose a model applying recursive Transformers along differentiable trees (R2D2). To obtain differentiability, we adopt Gumbel-Softmax estimation (Jang et al., 2017) as an elegant solution. Our encoder parser operates in a bottom-up fashion akin to CKY parsing, yet runs in linear time with regard to the number of composition steps, thanks to a novel pruned tree induction algorithm. As a training objective, the model seeks to recover each word in a sentence given its left and right syntax nodes. Thus, our model does not require any positional embedding and does not need to mask any words during training. Figure 1 presents an example binary tree induced by our method: Without any syntactic supervision, it acquires a model of hierarchical construction from the word-piece level to words, phrases, and finally the sentence level. We make the following contributions: • Our novel CKY-based recursive Transformer on differentiable trees model is able to learn both representations and tree structure (Section 2.1). • We propose an efficient optimization algorithm to scale up our approach to a linear number of composition steps (Section 2.2). • We design an effective pre-training objective, which predicts each word given its left and right syntactic nodes (Section 2.3). For simplicity and efficiency reasons, in this paper we conduct experiments only on the tasks of language modeling and unsupervised tree induction. The experimental results on language modeling show that our model significantly outperforms baseline models with same parameter size even in fewer training epochs. At unsupervised parsing, our model as well obtains competitive results.",Can the problem of existing deep learning models not explicitly modeling the hierarchical composition process inherent in human language understanding be addressed by developing a recursive Transformer model based on differentiable CKY style binary trees?,1.0,2.0,1.0
125,Identifying Moments of Change from Longitudinal User Text,"Adam Tsakalidis, Federico Nanni, Anthony Hills, Jenny Chim, Jiayu Song, and Maria Liakata. 2022. Identifying Moments of Change from Longitudinal User Text. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4647–4660, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.318.pdf,https://aclanthology.org/2022.acl-long.318/,"Identifying changes in individuals’ behaviour and mood, as observed via content shared on online platforms, is increasingly gaining importance. Most research to-date on this topic focuses on either: (a) identifying individuals at risk or with a certain mental health condition given a batch of posts or (b) providing equivalent labels at the post level. A disadvantage of such work is the lack of a strong temporal component and the inability to make longitudinal assessments following an individual’s trajectory and allowing timely interventions. Here we define a new task, that of identifying moments of change in individuals on the basis of their shared content online. The changes we consider are sudden shifts in mood (switches) or gradual mood progression (escalations). We have created detailed guidelines for capturing moments of change and a corpus of 500 manually annotated user timelines (18.7K posts). We have developed a variety of baseline models drawing inspiration from related tasks and show that the best performance is obtained through context aware sequential modelling. We also introduce new metrics for capturing rare events in temporal windows.","Linguistic and other content from social media data has been used in a number of different studies to obtain biomarkers for mental health. This is gaining importance given the global increase in mental health disorders, the limited access to support services and the prioritisation of mental health as an area by the World Health Organization (2019). Studies using linguistic data for mental health focus on recognising specific conditions related to mental health (e.g., depression, bipolar disorder) (Husseini Orabi et al., 2018), or identifying self-harm ideation in user posts (Yates et al., 2017; Zirikly et al., 2019). However, none of these works, even when incorporating a notion of time (Lynn et al., 2018; Losada et al., 2020), identify how an individual’s mental health changes over time. Yet being able to make assessments on a longitudinal level from linguistic and other digital content is important for clinical outcomes, and especially in mental health (Velupillai et al., 2018). The ability to detect changes in individual’s mental health over time is also important in enabling platform moderators to prioritise interventions for vulnerable individuals (Wadden et al., 2021). Users who currently engage with platforms and apps for mental health support (Neary and Schueller, 2018) would also benefit from being able to monitor their well-being in a longitudinal manner. Motivated by the lack of longitudinal approaches we introduce the task of identifying ‘Moments of Change’ (MoC) from individuals’ shared online content. We focus in particular on two types of changes: Switches – mood shifts from positive to negative, or vice versa – and Escalations – gradual mood progression (see Fig. 1, detailed in § 3). Specifically we make the following contributions: • We present the novel task of identifying moments of change in an individual’s mood by analysing linguistic content shared online over time, along with a longitudinal dataset of 500 user timelines (18.7K posts, English language) from 500 users of an online platform. • We propose a number of baseline models for automatically capturing Switches/Escalations, inspired by sentence- and sequence-level stateof-the-art NLP approaches in related tasks. • We introduce a range of temporally sensitive evaluation metrics for longitudinal NLP tasks adapted from the fields of change point detection (van den Burg and Williams, 2020) and image segmentation (Arbelaez et al., 2010). • We provide a thorough qualitative linguistic analysis of model performance.","Can the problem of the lack of longitudinal approaches in existing research for monitoring individuals' mental health changes over time through their online content be solved by defining the new task of identifying Moments of Change in an individualвЂ™s mood from their online content, developing baseline models for this task, and introducing new evaluation metrics suitable for longitudinal assessments?",2.0,2.0,1.0
126,Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?,"Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, and Kentaro Inui. 2020. Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6105–6117, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.543.pdf,https://aclanthology.org/2020.acl-main.543/,"Despite the success of language models using neural networks, it remains unclear to what extent neural models have the generalization ability to perform inferences. In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition. We consider four aspects of monotonicity inferences and test whether the models can systematically interpret lexical and logical phenomena on different training/test splits. A series of experiments show that three neural models systematically draw inferences on unseen combinations of lexical and logical phenomena when the syntactic structures of the sentences are similar between the training and test sets. However, the performance of the models significantly decreases when the structures are slightly changed in the test set while retaining all vocabularies and constituents already appearing in the training set. This indicates that the generalization ability of neural models is limited to cases where the syntactic structures are nearly the same as those in the training set.","Natural language inference (NLI), a task whereby a system judges whether given a set of premises P semantically entails a hypothesis H (Dagan et al., 2013; Bowman et al., 2015), is a fundamental task for natural language understanding. As with other NLP tasks, recent studies have shown a remarkable impact of deep neural networks in NLI (Williams et al., 2018; Wang et al., 2019; Devlin et al., 2019). However, it remains unclear to what extent DNN-based models are capable of learning the compositional generalization underlying NLI from given labeled training instances. Systematicity of inference (or inferential systematicity) (Fodor and Pylyshyn, 1988; Aydede, 1997) in natural language has been intensively studied in the field of formal semantics. From among the various aspects of inferential systematicity, in the context of NLI, we focus on monotonicity (van Benthem, 1983; Icard and Moss, 2014) and its productivity. Consider the following premise–hypothesis pairs (1)–(3), which have the target label entailment: (1) P: Some [puppies ↑] ran. H: Some dogs ran. (2) P: No [cats ↓] ran. H: No small cats ran. (3) P: Some [puppies which chased no [cats ↓]] ran. H: Some dogs which chased no small cats ran. As in (1), for example, quantifiers such as some exhibit upward monotone (shown as [... ↑]), and replacing a phrase in an upward-entailing context in a sentence with a more general phrase (replacing puppies in P with dogs as in H) yields a sentence inferable from the original sentence. In contrast, as in (2), quantifiers such as no exhibit downward monotone (shown as [... ↓]), and replacing a phrase in a downward-entailing context with a more specific phrase (replacing cats in P with small cats as in H) yields a sentence inferable from the original sentence. Such primitive inference patterns combine recursively as in (3). This manner of monotonicity and its productivity produces a potentially infinite number of inferential patterns. Therefore, NLI models must be capable of systematically interpreting such primitive patterns and reasoning over unseen combinations of patterns. Although many studies have addressed this issue by modeling logical reasoning in formal semantics (Abzianidze, 2015; Mineshima et al., 2015; Hu et al., 2019) and testing DNN-based models on monotonicity inference (Yanaka et al., 2019a,b; Richardson et al., 2020), the ability of DNN-based models to generalize to unseen combinations of patterns is still underexplored. Given this background, we investigate the systematic generalization ability of DNN-based models on four aspects of monotonicity: (i) systematicity of predicate replacements (i.e., replacements with a more general or specific phrase), (ii) systematicity of embedding quantifiers, (iii) productivity, and (iv) localism (see Section 2.2). To this aim, we introduce a new evaluation protocol where we (i) synthesize training instances from sampled sentences and (ii) systematically control which patterns are shown to the models in the training phase and which are left unseen. The rationale behind this protocol is twofold. First, patterns of monotonicity inference are highly systematic, so we can create training data with arbitrary combinations of patterns, as in examples (1)–(3). Second, evaluating the performance of the models trained with well-known NLI datasets such as MultiNLI (Williams et al., 2018) might severely underestimate the ability of the models because such datasets tend to contain only a limited number of training instances that exhibit the inferential patterns of interest. Furthermore, using such datasets would prevent us from identifying which combinations of patterns the models can infer from which patterns in the training data. This paper makes two primary contributions. First, we introduce an evaluation protocol1 using the systematic control of the training/test split under various combinations of semantic properties to evaluate whether models learn inferential systematicity in natural language. Second, we apply our evaluation protocol to three NLI models and present evidence suggesting that, while all models generalize to unseen combinations of lexical and logical phenomena, their generalization ability is limited to cases where sentence structures are nearly the same as those in the training set.","What is the extent of deep neural network-based models' ability to learn and generalize inferential systematicity, specifically monotonicity inference in natural language, across unseen combinations of lexical and logical patterns when varying sentence structures?",0.0,0.0,0.0
127,Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?,"Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, and Kentaro Inui. 2020. Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6105–6117, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.543.pdf,https://aclanthology.org/2020.acl-main.543/,"Despite the success of language models using neural networks, it remains unclear to what extent neural models have the generalization ability to perform inferences. In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition. We consider four aspects of monotonicity inferences and test whether the models can systematically interpret lexical and logical phenomena on different training/test splits. A series of experiments show that three neural models systematically draw inferences on unseen combinations of lexical and logical phenomena when the syntactic structures of the sentences are similar between the training and test sets. However, the performance of the models significantly decreases when the structures are slightly changed in the test set while retaining all vocabularies and constituents already appearing in the training set. This indicates that the generalization ability of neural models is limited to cases where the syntactic structures are nearly the same as those in the training set.","Natural language inference (NLI), a task whereby a system judges whether given a set of premises P semantically entails a hypothesis H (Dagan et al., 2013; Bowman et al., 2015), is a fundamental task for natural language understanding. As with other NLP tasks, recent studies have shown a remarkable impact of deep neural networks in NLI (Williams et al., 2018; Wang et al., 2019; Devlin et al., 2019). However, it remains unclear to what extent DNN-based models are capable of learning the compositional generalization underlying NLI from given labeled training instances. Systematicity of inference (or inferential systematicity) (Fodor and Pylyshyn, 1988; Aydede, 1997) in natural language has been intensively studied in the field of formal semantics. From among the various aspects of inferential systematicity, in the context of NLI, we focus on monotonicity (van Benthem, 1983; Icard and Moss, 2014) and its productivity. Consider the following premise–hypothesis pairs (1)–(3), which have the target label entailment: (1) P: Some [puppies ↑] ran. H: Some dogs ran. (2) P: No [cats ↓] ran. H: No small cats ran. (3) P: Some [puppies which chased no [cats ↓]] ran. H: Some dogs which chased no small cats ran. As in (1), for example, quantifiers such as some exhibit upward monotone (shown as [... ↑]), and replacing a phrase in an upward-entailing context in a sentence with a more general phrase (replacing puppies in P with dogs as in H) yields a sentence inferable from the original sentence. In contrast, as in (2), quantifiers such as no exhibit downward monotone (shown as [... ↓]), and replacing a phrase in a downward-entailing context with a more specific phrase (replacing cats in P with small cats as in H) yields a sentence inferable from the original sentence. Such primitive inference patterns combine recursively as in (3). This manner of monotonicity and its productivity produces a potentially infinite number of inferential patterns. Therefore, NLI models must be capable of systematically interpreting such primitive patterns and reasoning over unseen combinations of patterns. Although many studies have addressed this issue by modeling logical reasoning in formal semantics (Abzianidze, 2015; Mineshima et al., 2015; Hu et al., 2019) and testing DNN-based models on monotonicity inference (Yanaka et al., 2019a,b; Richardson et al., 2020), the ability of DNN-based models to generalize to unseen combinations of patterns is still underexplored. Given this background, we investigate the systematic generalization ability of DNN-based models on four aspects of monotonicity: (i) systematicity of predicate replacements (i.e., replacements with a more general or specific phrase), (ii) systematicity of embedding quantifiers, (iii) productivity, and (iv) localism (see Section 2.2). To this aim, we introduce a new evaluation protocol where we (i) synthesize training instances from sampled sentences and (ii) systematically control which patterns are shown to the models in the training phase and which are left unseen. The rationale behind this protocol is twofold. First, patterns of monotonicity inference are highly systematic, so we can create training data with arbitrary combinations of patterns, as in examples (1)–(3). Second, evaluating the performance of the models trained with well-known NLI datasets such as MultiNLI (Williams et al., 2018) might severely underestimate the ability of the models because such datasets tend to contain only a limited number of training instances that exhibit the inferential patterns of interest. Furthermore, using such datasets would prevent us from identifying which combinations of patterns the models can infer from which patterns in the training data. This paper makes two primary contributions. First, we introduce an evaluation protocol1 using the systematic control of the training/test split under various combinations of semantic properties to evaluate whether models learn inferential systematicity in natural language. Second, we apply our evaluation protocol to three NLI models and present evidence suggesting that, while all models generalize to unseen combinations of lexical and logical phenomena, their generalization ability is limited to cases where sentence structures are nearly the same as those in the training set.","Can the unclear extent of DNN-based models' abilities to generalize and learn compositional generalization underlying natural language inference, with a focus on monotonicity inference, be resolved by a new evaluation protocol that systematically controls training and test splits to assess models' inferential systematicity on four aspects of monotonicity?",2.0,2.0,1.0
128,Joint Modeling of Content and Discourse Relations in Dialogues,"Kechen Qin, Lu Wang, and Joseph Kim. 2017. Joint Modeling of Content and Discourse Relations in Dialogues. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 974–984, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1090.pdf,https://aclanthology.org/P17-1090/,We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrasebased content selection and discourse relation prediction tasks. We also evaluate our model on predicting the consistency among team members’ understanding of their group decisions. Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.,"Goal-oriented dialogues, such as meetings, negotiations, or customer service transcripts, play an important role in our daily life. Automatically extracting the critical points and important outcomes from dialogues would facilitate generating summaries for complicated conversations, understanding the decision-making process of meetings, or analyzing the effectiveness of collaborations. We are interested in a specific type of dialogues — spoken meetings, which is a common way for collaboration and idea sharing. Previous work (Kirschner et al., 2012) has shown that discourse structure can be used to capture the main discussion points and arguments put forward during problem-solving and decision-making processes in meetings. Indeed, content of different speaker turns do not occur in isolation, and should be interpreted within the context of discourse. Meanwhile, content can also reflect the purpose of speaker turns, thus facilitate with discourse relation understanding. Take the meeting snippet from AMI corpus (Carletta et al., 2006) in Figure 1 as an example. This discussion is annotated with discourse structure based on the Twente Argumentation Schema (TAS) by Rienks et al. (2005), which focuses on argumentative discourse information. As can be seen, meeting participants evaluate different options by showing doubt (UNCERTAIN), bringing up alternative solution (OPTION), or giving feedback. The discourse information helps with the identification of the key discussion point, i.e., “which type of battery to use”, by revealing the discussion flow. To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training (Murray et al., 2006; Galley, 2006; McKeown et al., 2007; Bui et al., 2009). However, automatic discourse parsing in dialogues is still a challenging problem (Perret et al., 2016). Moreover, acquiring human annotation on discourse relations is a timeconsuming and expensive process, and does not scale for large datasets. In this paper, we propose a joint modeling approach to select salient phrases reflecting key discussion points as well as label the discourse relations between speaker turns in spoken meetings. We hypothesize that leveraging the interaction between content and discourse has the potential to yield better prediction performance on both phrase-based content selection and discourse relation prediction. Specifically, we utilize argumentative discourse relations as defined in Twente Argument Schema (TAS) (Rienks et al., 2005), where discussions are organized into tree structures with discourse relations labeled between nodes (as shown in Figure 1). Algorithms for joint learning and joint inference are proposed for our model. We also present a variation of our model to treat discourse relations as latent variables when true labels are not available for learning. We envision that the extracted salient phrases by our model can be used as input to abstractive meeting summarization systems (Wang and Cardie, 2013; Mehdad et al., 2014). Combined with the predicted discourse structure, a visualization tool can be exploited to display conversation flow to support intelligent meeting assistant systems. To the best of our knowledge, our work is the first to jointly model content and discourse relations in meetings. We test our model with two meeting corpora — the AMI corpus (Carletta et al., 2006) and the ICSI corpus (Janin et al., 2003). Experimental results show that our model yields an accuracy of 63.2 on phrase selection, which is significantly better than a classifier based on Support Vector Machines (SVM). Our discourse prediction component also obtains better accuracy than a state-of-the-art neural networkbased approach (59.2 vs. 54.2). Moreover, our model trained with latent discourse outperforms SVMs on both AMI and ICSI corpora for phrase selection. We further evaluate the usage of selected phrases as extractive meeting summaries. Results evaluated by ROUGE (Lin and Hovy, 2003) demonstrate that our system summaries obtain a ROUGE-SU4 F1 score of 21.3 on AMI corpus, which outperforms non-trivial extractive summarization baselines and a keyword selection algorithm proposed in Liu et al. (2009). Moreover, since both content and discourse structure are critical for building shared understanding among participants (Mulder et al., 2002; Mercer, 2004), we further investigate whether our learned model can be utilized to predict the consistency among team members’ understanding of their group decisions. This task is first defined as consistency of understanding (COU) prediction by Kim and Shah (2016), who have labeled a portion of AMI discussions with consistency or inconsistency labels. We construct features from our model predictions to capture different discourse patterns and word entrainment scores for discussion with different COU level. Results on AMI discussions show that SVM classifiers trained with our features significantly outperform the state-ofthe-art results (Kim and Shah, 2016) (F1: 63.1 vs. 50.5) and non-trivial baselines. The rest of the paper is structured as follows: we first summarize related work in Section 2. The joint model is presented in Section 3. Datasets and experimental setup are described in Section 4, which is followed by experimental results (Section 5). We then study the usage of our model for predicting consistency of understanding in groups in Section 6. We finally conclude in Section 7.",Can salient discussion points and discourse relations between speaker turns in spoken meetings be identified and labeled through a joint modeling approach?,1.0,1.0,1.0
129,Joint Modeling of Content and Discourse Relations in Dialogues,"Kechen Qin, Lu Wang, and Joseph Kim. 2017. Joint Modeling of Content and Discourse Relations in Dialogues. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 974–984, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1090.pdf,https://aclanthology.org/P17-1090/,We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrasebased content selection and discourse relation prediction tasks. We also evaluate our model on predicting the consistency among team members’ understanding of their group decisions. Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.,"Goal-oriented dialogues, such as meetings, negotiations, or customer service transcripts, play an important role in our daily life. Automatically extracting the critical points and important outcomes from dialogues would facilitate generating summaries for complicated conversations, understanding the decision-making process of meetings, or analyzing the effectiveness of collaborations. We are interested in a specific type of dialogues — spoken meetings, which is a common way for collaboration and idea sharing. Previous work (Kirschner et al., 2012) has shown that discourse structure can be used to capture the main discussion points and arguments put forward during problem-solving and decision-making processes in meetings. Indeed, content of different speaker turns do not occur in isolation, and should be interpreted within the context of discourse. Meanwhile, content can also reflect the purpose of speaker turns, thus facilitate with discourse relation understanding. Take the meeting snippet from AMI corpus (Carletta et al., 2006) in Figure 1 as an example. This discussion is annotated with discourse structure based on the Twente Argumentation Schema (TAS) by Rienks et al. (2005), which focuses on argumentative discourse information. As can be seen, meeting participants evaluate different options by showing doubt (UNCERTAIN), bringing up alternative solution (OPTION), or giving feedback. The discourse information helps with the identification of the key discussion point, i.e., “which type of battery to use”, by revealing the discussion flow. To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training (Murray et al., 2006; Galley, 2006; McKeown et al., 2007; Bui et al., 2009). However, automatic discourse parsing in dialogues is still a challenging problem (Perret et al., 2016). Moreover, acquiring human annotation on discourse relations is a timeconsuming and expensive process, and does not scale for large datasets. In this paper, we propose a joint modeling approach to select salient phrases reflecting key discussion points as well as label the discourse relations between speaker turns in spoken meetings. We hypothesize that leveraging the interaction between content and discourse has the potential to yield better prediction performance on both phrase-based content selection and discourse relation prediction. Specifically, we utilize argumentative discourse relations as defined in Twente Argument Schema (TAS) (Rienks et al., 2005), where discussions are organized into tree structures with discourse relations labeled between nodes (as shown in Figure 1). Algorithms for joint learning and joint inference are proposed for our model. We also present a variation of our model to treat discourse relations as latent variables when true labels are not available for learning. We envision that the extracted salient phrases by our model can be used as input to abstractive meeting summarization systems (Wang and Cardie, 2013; Mehdad et al., 2014). Combined with the predicted discourse structure, a visualization tool can be exploited to display conversation flow to support intelligent meeting assistant systems. To the best of our knowledge, our work is the first to jointly model content and discourse relations in meetings. We test our model with two meeting corpora — the AMI corpus (Carletta et al., 2006) and the ICSI corpus (Janin et al., 2003). Experimental results show that our model yields an accuracy of 63.2 on phrase selection, which is significantly better than a classifier based on Support Vector Machines (SVM). Our discourse prediction component also obtains better accuracy than a state-of-the-art neural networkbased approach (59.2 vs. 54.2). Moreover, our model trained with latent discourse outperforms SVMs on both AMI and ICSI corpora for phrase selection. We further evaluate the usage of selected phrases as extractive meeting summaries. Results evaluated by ROUGE (Lin and Hovy, 2003) demonstrate that our system summaries obtain a ROUGE-SU4 F1 score of 21.3 on AMI corpus, which outperforms non-trivial extractive summarization baselines and a keyword selection algorithm proposed in Liu et al. (2009). Moreover, since both content and discourse structure are critical for building shared understanding among participants (Mulder et al., 2002; Mercer, 2004), we further investigate whether our learned model can be utilized to predict the consistency among team members’ understanding of their group decisions. This task is first defined as consistency of understanding (COU) prediction by Kim and Shah (2016), who have labeled a portion of AMI discussions with consistency or inconsistency labels. We construct features from our model predictions to capture different discourse patterns and word entrainment scores for discussion with different COU level. Results on AMI discussions show that SVM classifiers trained with our features significantly outperform the state-ofthe-art results (Kim and Shah, 2016) (F1: 63.1 vs. 50.5) and non-trivial baselines. The rest of the paper is structured as follows: we first summarize related work in Section 2. The joint model is presented in Section 3. Datasets and experimental setup are described in Section 4, which is followed by experimental results (Section 5). We then study the usage of our model for predicting consistency of understanding in groups in Section 6. We finally conclude in Section 7.","Can the automatic extraction of critical points and decision outcomes from spoken meetings be effectively accomplished by a joint modeling approach that considers both the content and discourse relations between speaker turns, with a variation to treat discourse relations as latent variables?",1.0,2.0,1.0
130,Multi-Domain Dialogue Acts and Response Co-Generation,"Kai Wang, Junfeng Tian, Rui Wang, Xiaojun Quan, and Jianxing Yu. 2020. Multi-Domain Dialogue Acts and Response Co-Generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7125–7134, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.638.pdf,https://aclanthology.org/2020.acl-main.638/,"Generating fluent and informative responses is of critical importance for task-oriented dialogue systems. Existing pipeline approaches generally predict multiple dialogue acts first and use them to assist response generation. There are at least two shortcomings with such approaches. First, the inherent structures of multi-domain dialogue acts are neglected. Second, the semantic associations between acts and responses are not taken into account for response generation. To address these issues, we propose a neural co-generation model that generates dialogue acts and responses concurrently. Unlike those pipeline approaches, our act generation module preserves the semantic structures of multi-domain dialogue acts and our response generation module dynamically attends to different acts as needed. We train the two modules jointly using an uncertainty loss to adjust their task weights adaptively. Extensive experiments are conducted on the largescale MultiWOZ dataset and the results show that our model achieves very favorable improvement over several state-of-the-art models in both automatic and human evaluations.","Task-oriented dialogue systems aim to facilitate people with such services as hotel reservation and ticket booking through natural language conversations. Recent years have seen a rapid proliferation of interests in this task from both academia and industry (Bordes et al., 2017; Budzianowski et al., 2018; Wu et al., 2019). A standard architecture of these systems generally decomposes this task into several subtasks, including natural language understanding (Gupta et al., 2018), dialogue state tracking (Zhong et al., 2018) and natural language generation (Su et al., 2018). They can be modeled separately and combined into a pipeline system. Figure 1 shows a dialogue example, from which we can notice that the natural language generation subtask can be further divided into dialogue act prediction and response generation (Chen et al., 2019; Zhao et al., 2019; Wen et al., 2017). While the former is intended to predict the next action(s) based on current conversational state and database information, response generation is used to produce a natural language response based on the action(s). In order for dialogues to be natural and effective, responses should be fluent, informative, and relevant. Nevertheless, current sequence-to-sequence models often generate uninformative responses like “I don’t know” (Li et al., 2016a), hindering the dialogues to continue or even leading to a failure. Some researchers (Pei et al., 2019; Mehri et al., 2019) sought to combine multiple decoders into a stronger one to avoid such responses, while others (Chen et al., 2019; Wen et al., 2015; Zhao et al., 2019; Wen et al., 2017) represent dialogue acts in a global, static vector to assist response generation. As pointed out by Chen et al. (2019), dialogue acts can be naturally organized in hierarchical structures, which has yet to be explored seriously. Take two acts station-request-stars and restaurantinform-address as an example. While the first act rarely appears in real-world dialogues, the second is more often. Moreover, there can be multiple dialogue acts mentioned in a single dialogue turn, which requires the model to attend to different acts for different sub-sequences. Thus, a global vector is unable to capture the inter-relationships among acts, nor is it flexible for response generation especially when more than one act is mentioned. To overcome the above issues, we treat dialogue act prediction as another sequence generation problem like response generation and propose a co-generation model to generate them concurrently. Unlike those classification approaches, act sequence generation not only preserves the interrelationships among dialogue acts but also allows close interactions with response generation. By attending to different acts, the response generation module can dynamically capture salient acts and produce higher-quality responses. Figure 2 demonstrates the difference between the classification and the generation approaches for act prediction. As for training, most joint learning models rely on hand-crafted or tunable weights on development sets (Liu and Lane, 2017; Mrksiˇ c et al. ´ , 2017; Rastogi et al., 2018). The challenge here is to combine two sequence generators with varied vocabularies and sequence lengths. The model is sensitive during training and nontrivial to generate an optimal weight. To address this issue, we opt for an uncertainty loss (Kendall et al., 2018) to adaptively adjust the weight according to task-specific uncertainty. We conduct extensive studies on a largescale task-oriented dataset to evaluate the model. The experimental results confirm the effectiveness of our model with very favorable performance over several state-of-the-art methods. The contributions of this work include: • We model dialogue act prediction as a sequence generation problem that allows to exploit act structures for the prediction. • We propose a co-generation model to generate act and response sequences jointly, with an uncertainty loss used for adaptive weighting. • Experiments on MultiWOZ verify that our model outperforms several state-of-the-art methods in automatic and human evaluations.","How can a neural co-generation model that concurrently generates dialogue acts and responses, while preserving multi-domain dialogue act structures and dynamically attending to different acts, improve the fluency, informativeness, and relevance of responses in task-oriented dialogue systems?",1.0,2.0,1.0
131,Multi-Domain Dialogue Acts and Response Co-Generation,"Kai Wang, Junfeng Tian, Rui Wang, Xiaojun Quan, and Jianxing Yu. 2020. Multi-Domain Dialogue Acts and Response Co-Generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7125–7134, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.638.pdf,https://aclanthology.org/2020.acl-main.638/,"Generating fluent and informative responses is of critical importance for task-oriented dialogue systems. Existing pipeline approaches generally predict multiple dialogue acts first and use them to assist response generation. There are at least two shortcomings with such approaches. First, the inherent structures of multi-domain dialogue acts are neglected. Second, the semantic associations between acts and responses are not taken into account for response generation. To address these issues, we propose a neural co-generation model that generates dialogue acts and responses concurrently. Unlike those pipeline approaches, our act generation module preserves the semantic structures of multi-domain dialogue acts and our response generation module dynamically attends to different acts as needed. We train the two modules jointly using an uncertainty loss to adjust their task weights adaptively. Extensive experiments are conducted on the largescale MultiWOZ dataset and the results show that our model achieves very favorable improvement over several state-of-the-art models in both automatic and human evaluations.","Task-oriented dialogue systems aim to facilitate people with such services as hotel reservation and ticket booking through natural language conversations. Recent years have seen a rapid proliferation of interests in this task from both academia and industry (Bordes et al., 2017; Budzianowski et al., 2018; Wu et al., 2019). A standard architecture of these systems generally decomposes this task into several subtasks, including natural language understanding (Gupta et al., 2018), dialogue state tracking (Zhong et al., 2018) and natural language generation (Su et al., 2018). They can be modeled separately and combined into a pipeline system. Figure 1 shows a dialogue example, from which we can notice that the natural language generation subtask can be further divided into dialogue act prediction and response generation (Chen et al., 2019; Zhao et al., 2019; Wen et al., 2017). While the former is intended to predict the next action(s) based on current conversational state and database information, response generation is used to produce a natural language response based on the action(s). In order for dialogues to be natural and effective, responses should be fluent, informative, and relevant. Nevertheless, current sequence-to-sequence models often generate uninformative responses like “I don’t know” (Li et al., 2016a), hindering the dialogues to continue or even leading to a failure. Some researchers (Pei et al., 2019; Mehri et al., 2019) sought to combine multiple decoders into a stronger one to avoid such responses, while others (Chen et al., 2019; Wen et al., 2015; Zhao et al., 2019; Wen et al., 2017) represent dialogue acts in a global, static vector to assist response generation. As pointed out by Chen et al. (2019), dialogue acts can be naturally organized in hierarchical structures, which has yet to be explored seriously. Take two acts station-request-stars and restaurantinform-address as an example. While the first act rarely appears in real-world dialogues, the second is more often. Moreover, there can be multiple dialogue acts mentioned in a single dialogue turn, which requires the model to attend to different acts for different sub-sequences. Thus, a global vector is unable to capture the inter-relationships among acts, nor is it flexible for response generation especially when more than one act is mentioned. To overcome the above issues, we treat dialogue act prediction as another sequence generation problem like response generation and propose a co-generation model to generate them concurrently. Unlike those classification approaches, act sequence generation not only preserves the interrelationships among dialogue acts but also allows close interactions with response generation. By attending to different acts, the response generation module can dynamically capture salient acts and produce higher-quality responses. Figure 2 demonstrates the difference between the classification and the generation approaches for act prediction. As for training, most joint learning models rely on hand-crafted or tunable weights on development sets (Liu and Lane, 2017; Mrksiˇ c et al. ´ , 2017; Rastogi et al., 2018). The challenge here is to combine two sequence generators with varied vocabularies and sequence lengths. The model is sensitive during training and nontrivial to generate an optimal weight. To address this issue, we opt for an uncertainty loss (Kendall et al., 2018) to adaptively adjust the weight according to task-specific uncertainty. We conduct extensive studies on a largescale task-oriented dataset to evaluate the model. The experimental results confirm the effectiveness of our model with very favorable performance over several state-of-the-art methods. The contributions of this work include: • We model dialogue act prediction as a sequence generation problem that allows to exploit act structures for the prediction. • We propose a co-generation model to generate act and response sequences jointly, with an uncertainty loss used for adaptive weighting. • Experiments on MultiWOZ verify that our model outperforms several state-of-the-art methods in automatic and human evaluations.","Can the challenge of generating fluent and informative responses in task-oriented dialogue systems be addressed by a neural co-generation model that dynamically integrates dialogue act generation with response generation, incorporating semantic structures of dialogue acts and using an uncertainty loss for adaptive task weighting?",1.0,2.0,1.0
132,Unsupervised Opinion Summarization as Copycat-Review Generation,"Arthur Bražinskas, Mirella Lapata, and Ivan Titov. 2020. Unsupervised Opinion Summarization as Copycat-Review Generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5151–5169, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.461.pdf,https://aclanthology.org/2020.acl-main.461/,"Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (“decoder”) has direct access to the text of input reviews through the pointergenerator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review’s latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.","Summarization of user opinions expressed in online resources, such as blogs, reviews, social media, or internet forums, has drawn much attention due to its potential for various information access applications, such as creating digests, search, and report generation (Hu and Liu, 2004; Angelidis and Lapata, 2018; Medhat et al., 2014). Although there has been significant progress recently in summarizing non-subjective context (Rush et al., 2015; Nallapati et al., 2016; Paulus et al., 2017; See et al., 2017; Liu et al., 2018), modern deep learning methods rely on large amounts of annotated data that are not readily available in the opinion-summarization domain and expensive to produce. Moreover, annotation efforts would have to be undertaken for multiple domains as online reviews are inherently multi-domain (Blitzer et al., 2007) and summarization systems highly domain-sensitive (Isonuma et al., 2017). Thus, perhaps unsurprisingly, there is a long history of applying unsupervised and weakly-supervised methods to opinion summarization (e.g., Mei et al. 2007; Titov and McDonald 2008; Angelidis and Lapata 2018), however, these approaches have primarily focused on extractive summarization, i.e., producing summaries by copying parts of the input reviews. In this work, we instead consider abstractive summarization which involves generating new phrases, possibly rephrasing or using words that were not in the original text. Abstractive summaries are often preferable to extractive ones as they can synthesize content across documents avoiding redundancy (Barzilay et al., 1999; Carenini and Cheung, 2008; Di Fabbrizio et al., 2014). In addition, we focus on the unsupervised setting and do not use any summaries for training. Unlike aspect-based summarization (Liu, 2012), which rewards the diversity of opinions, we aim to generate summaries that represent consensus (i.e., dominant opinons in reviews). We argue that such summaries can be useful for quick decision making, and to get an overall feel for a product or business (see the example in Table 1). More specifically, we assume we are provided with a large collection of reviews for various products and businesses and define a generative model of this collection. Intuitively, we want to design such a model that, when generating a review for a product1 relying on a set of other reviews, we can control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, we can force the novelty to be minimal, and generate summaries representing consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder (VAE) model. Both products and individual reviews are associated with latent representations. Product representations can store, for example, overall sentiment, common topics, and opinions expressed about the product. In contrast, latent representations of reviews depend on the product representations and capture the content of individual reviews. While at training time the latent representations are random variables, we fix them to their respective means at test time. As desired for summarization, these ‘average’ (or ‘copycat’) reviews differ in writing style from a typical review. For example, they do not contain irrelevant details that are common in customer reviews, such as mentioning the occasion or saying how many family members accompanied the reviewer. In order to encourage the summaries to include specific details, the review generator (‘decoder’) has direct access to the text of input reviews through the pointer-generator mechanism (See et al., 2017). In the example in Table 1, the model included specific information about the restaurant type and its location in the generated summary. As we will see in ablation experiments, without this conditioning, model performance drops substantially, as the summaries become more generic. We evaluate our approach on two datasets, Amazon product reviews and Yelp reviews of businesses. The only previous method dealing with unsupervised multi-document opinion summarization, as far as we are aware of, is MeanSum (Chu and Liu, 2019). Similarly to our work, they generate consensus summaries and consider the Yelp benchmark. Whereas we rely on continuous latent representations, they treat the summary itself as a discrete latent representation of a product. Although this captures the intuition that a summary should relay key information about a product, using discrete latent sequences makes optimization challenging; (Miao and Blunsom, 2016; Baziotis et al., 2019; Chu and Liu, 2019) all have to use an extra training loss term and biased gradient estimators. Our contributions can be summarized as follows: • we introduce a simple end-to-end approach to unsupervised abstractive summarization; • we demonstrate that the approach substantially outperforms the previous method, both when measured with automatic metrics and in human evaluation; • we provide a dataset of abstractive summaries for Amazon products.2",How does using a hierarchical variational autoencoder model with minimal novelty at test time for generating abstractive summaries from a collection of product reviews compare in effectiveness to previous methods in terms of fluency and coherence of the summarized consensus opinions?,0.0,1.0,1.0
133,Unsupervised Opinion Summarization as Copycat-Review Generation,"Arthur Bražinskas, Mirella Lapata, and Ivan Titov. 2020. Unsupervised Opinion Summarization as Copycat-Review Generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5151–5169, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.461.pdf,https://aclanthology.org/2020.acl-main.461/,"Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (“decoder”) has direct access to the text of input reviews through the pointergenerator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review’s latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.","Summarization of user opinions expressed in online resources, such as blogs, reviews, social media, or internet forums, has drawn much attention due to its potential for various information access applications, such as creating digests, search, and report generation (Hu and Liu, 2004; Angelidis and Lapata, 2018; Medhat et al., 2014). Although there has been significant progress recently in summarizing non-subjective context (Rush et al., 2015; Nallapati et al., 2016; Paulus et al., 2017; See et al., 2017; Liu et al., 2018), modern deep learning methods rely on large amounts of annotated data that are not readily available in the opinion-summarization domain and expensive to produce. Moreover, annotation efforts would have to be undertaken for multiple domains as online reviews are inherently multi-domain (Blitzer et al., 2007) and summarization systems highly domain-sensitive (Isonuma et al., 2017). Thus, perhaps unsurprisingly, there is a long history of applying unsupervised and weakly-supervised methods to opinion summarization (e.g., Mei et al. 2007; Titov and McDonald 2008; Angelidis and Lapata 2018), however, these approaches have primarily focused on extractive summarization, i.e., producing summaries by copying parts of the input reviews. In this work, we instead consider abstractive summarization which involves generating new phrases, possibly rephrasing or using words that were not in the original text. Abstractive summaries are often preferable to extractive ones as they can synthesize content across documents avoiding redundancy (Barzilay et al., 1999; Carenini and Cheung, 2008; Di Fabbrizio et al., 2014). In addition, we focus on the unsupervised setting and do not use any summaries for training. Unlike aspect-based summarization (Liu, 2012), which rewards the diversity of opinions, we aim to generate summaries that represent consensus (i.e., dominant opinons in reviews). We argue that such summaries can be useful for quick decision making, and to get an overall feel for a product or business (see the example in Table 1). More specifically, we assume we are provided with a large collection of reviews for various products and businesses and define a generative model of this collection. Intuitively, we want to design such a model that, when generating a review for a product1 relying on a set of other reviews, we can control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, we can force the novelty to be minimal, and generate summaries representing consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder (VAE) model. Both products and individual reviews are associated with latent representations. Product representations can store, for example, overall sentiment, common topics, and opinions expressed about the product. In contrast, latent representations of reviews depend on the product representations and capture the content of individual reviews. While at training time the latent representations are random variables, we fix them to their respective means at test time. As desired for summarization, these ‘average’ (or ‘copycat’) reviews differ in writing style from a typical review. For example, they do not contain irrelevant details that are common in customer reviews, such as mentioning the occasion or saying how many family members accompanied the reviewer. In order to encourage the summaries to include specific details, the review generator (‘decoder’) has direct access to the text of input reviews through the pointer-generator mechanism (See et al., 2017). In the example in Table 1, the model included specific information about the restaurant type and its location in the generated summary. As we will see in ablation experiments, without this conditioning, model performance drops substantially, as the summaries become more generic. We evaluate our approach on two datasets, Amazon product reviews and Yelp reviews of businesses. The only previous method dealing with unsupervised multi-document opinion summarization, as far as we are aware of, is MeanSum (Chu and Liu, 2019). Similarly to our work, they generate consensus summaries and consider the Yelp benchmark. Whereas we rely on continuous latent representations, they treat the summary itself as a discrete latent representation of a product. Although this captures the intuition that a summary should relay key information about a product, using discrete latent sequences makes optimization challenging; (Miao and Blunsom, 2016; Baziotis et al., 2019; Chu and Liu, 2019) all have to use an extra training loss term and biased gradient estimators. Our contributions can be summarized as follows: • we introduce a simple end-to-end approach to unsupervised abstractive summarization; • we demonstrate that the approach substantially outperforms the previous method, both when measured with automatic metrics and in human evaluation; • we provide a dataset of abstractive summaries for Amazon products.2",Can the problem of generating accurate and coherent abstractive summaries of opinions expressed in product reviews without using trained summarization datasets be solved by a hierarchical variational autoencoder model that can control the novelty of the generated reviews to focus on consensus opinions?,1.0,2.0,1.0
134,It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations,"Samson Tan, Shafiq Joty, Min-Yen Kan, and Richard Socher. 2020. It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2920–2935, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.263.pdf,https://aclanthology.org/2020.acl-main.263/,"Training on only perfect Standard English corpora predisposes pre-trained neural networks to discriminate against minorities from nonstandard linguistic backgrounds (e.g., African American Vernacular English, Colloquial Singapore English, etc.). We perturb the inflectional morphology of words to craft plausible and semantically similar adversarial examples that expose these biases in popular NLP models, e.g., BERT and Transformer, and show that adversarially fine-tuning them for a single epoch significantly improves robustness without sacrificing performance on clean data.","In recent years, Natural Language Processing (NLP) systems have gotten increasingly better at learning complex patterns in language by pretraining large language models like BERT, GPT-2, and CTRL (Devlin et al., 2019; Radford et al., 2019; Keskar et al., 2019), and fine-tuning them on taskspecific data to achieve state of the art results has become a norm. However, deep learning models are only as good as the data they are trained on. Existing work on societal bias in NLP primarily focuses on attributes like race and gender (Bolukbasi et al., 2016; May et al., 2019). In contrast, we investigate a uniquely NLP attribute that has been largely ignored: linguistic background. Current NLP models seem to be trained with the implicit assumption that everyone speaks fluent (often U.S.) Standard English, even though twothirds (>700 million) of the English speakers in the world speak it as a second language (L2) (Eberhard et al., 2019). Even among native speakers, a significant number speak a dialect like African American Vernacular English (AAVE) rather than Standard English (Crystal, 2003). In addition, these World Englishes exhibit variation at multiple levels of linguistic analysis (Kachru et al., 2009). Therefore, putting these models directly into production without addressing this inherent bias puts them at risk of committing linguistic discrimination by performing poorly for many speech communities (e.g., AAVE and L2 speakers). This could take the form of either failing to understand these speakers (Rickford and King, 2016; Tatman, 2017), or misinterpreting them. For example, the recent mistranslation of a minority speaker’s social media post resulted in his wrongful arrest (Hern, 2017). Since L2 (and many L1 dialect) speakers often exhibit variability in their production of inflectional morphology2 (Lardiere, 1998; Prevost and ´ White, 2000; Haznedar, 2002; White, 2003; Seymour, 2004), we argue that NLP models should be robust to inflectional perturbations in order to minimize their chances of propagating linguistic discrimination. Hence, in this paper, we: Propose MORPHEUS, a method for generating plausible and semantically similar adversaries by perturbing the inflections in the clean examples (Figure 1). In contrast to recent work on adversarial examples in NLP (Belinkov and Bisk, 2018; Ebrahimi et al., 2018; Ribeiro et al., 2018), we exploit morphology to craft our adversaries. • Demonstrate its effectiveness on multiple machine comprehension and translation models, including BERT and Transformer (Tables 1 & 2). • Show that adversarially fine-tuning the model on an adversarial training set generated via weighted random sampling is sufficient for it to acquire significant robustness, while preserving performance on clean examples (Table 5). To the best of our knowledge, we are the first to investigate the robustness of NLP models to inflectional perturbations and its ethical implications.",How can perturbing the inflectional morphology of words in training examples improve the robustness of NLP models to biases against nonstandard linguistic backgrounds without sacrificing their performance on clean data?,2.0,2.0,1.0
135,It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations,"Samson Tan, Shafiq Joty, Min-Yen Kan, and Richard Socher. 2020. It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2920–2935, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.263.pdf,https://aclanthology.org/2020.acl-main.263/,"Training on only perfect Standard English corpora predisposes pre-trained neural networks to discriminate against minorities from nonstandard linguistic backgrounds (e.g., African American Vernacular English, Colloquial Singapore English, etc.). We perturb the inflectional morphology of words to craft plausible and semantically similar adversarial examples that expose these biases in popular NLP models, e.g., BERT and Transformer, and show that adversarially fine-tuning them for a single epoch significantly improves robustness without sacrificing performance on clean data.","In recent years, Natural Language Processing (NLP) systems have gotten increasingly better at learning complex patterns in language by pretraining large language models like BERT, GPT-2, and CTRL (Devlin et al., 2019; Radford et al., 2019; Keskar et al., 2019), and fine-tuning them on taskspecific data to achieve state of the art results has become a norm. However, deep learning models are only as good as the data they are trained on. Existing work on societal bias in NLP primarily focuses on attributes like race and gender (Bolukbasi et al., 2016; May et al., 2019). In contrast, we investigate a uniquely NLP attribute that has been largely ignored: linguistic background. Current NLP models seem to be trained with the implicit assumption that everyone speaks fluent (often U.S.) Standard English, even though twothirds (>700 million) of the English speakers in the world speak it as a second language (L2) (Eberhard et al., 2019). Even among native speakers, a significant number speak a dialect like African American Vernacular English (AAVE) rather than Standard English (Crystal, 2003). In addition, these World Englishes exhibit variation at multiple levels of linguistic analysis (Kachru et al., 2009). Therefore, putting these models directly into production without addressing this inherent bias puts them at risk of committing linguistic discrimination by performing poorly for many speech communities (e.g., AAVE and L2 speakers). This could take the form of either failing to understand these speakers (Rickford and King, 2016; Tatman, 2017), or misinterpreting them. For example, the recent mistranslation of a minority speaker’s social media post resulted in his wrongful arrest (Hern, 2017). Since L2 (and many L1 dialect) speakers often exhibit variability in their production of inflectional morphology2 (Lardiere, 1998; Prevost and ´ White, 2000; Haznedar, 2002; White, 2003; Seymour, 2004), we argue that NLP models should be robust to inflectional perturbations in order to minimize their chances of propagating linguistic discrimination. Hence, in this paper, we: Propose MORPHEUS, a method for generating plausible and semantically similar adversaries by perturbing the inflections in the clean examples (Figure 1). In contrast to recent work on adversarial examples in NLP (Belinkov and Bisk, 2018; Ebrahimi et al., 2018; Ribeiro et al., 2018), we exploit morphology to craft our adversaries. • Demonstrate its effectiveness on multiple machine comprehension and translation models, including BERT and Transformer (Tables 1 & 2). • Show that adversarially fine-tuning the model on an adversarial training set generated via weighted random sampling is sufficient for it to acquire significant robustness, while preserving performance on clean examples (Table 5). To the best of our knowledge, we are the first to investigate the robustness of NLP models to inflectional perturbations and its ethical implications.",Can linguistic discrimination in NLP models against speakers of nonstandard English dialects and L2 English speakers be mitigated by adversarially fine-tuning the models with inflectionally perturbed examples?,2.0,2.0,1.0
136,It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations,"Samson Tan, Shafiq Joty, Min-Yen Kan, and Richard Socher. 2020. It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2920–2935, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.263.pdf,https://aclanthology.org/2020.acl-main.263/,"Training on only perfect Standard English corpora predisposes pre-trained neural networks to discriminate against minorities from nonstandard linguistic backgrounds (e.g., African American Vernacular English, Colloquial Singapore English, etc.). We perturb the inflectional morphology of words to craft plausible and semantically similar adversarial examples that expose these biases in popular NLP models, e.g., BERT and Transformer, and show that adversarially fine-tuning them for a single epoch significantly improves robustness without sacrificing performance on clean data.","In recent years, Natural Language Processing (NLP) systems have gotten increasingly better at learning complex patterns in language by pretraining large language models like BERT, GPT-2, and CTRL (Devlin et al., 2019; Radford et al., 2019; Keskar et al., 2019), and fine-tuning them on taskspecific data to achieve state of the art results has become a norm. However, deep learning models are only as good as the data they are trained on. Existing work on societal bias in NLP primarily focuses on attributes like race and gender (Bolukbasi et al., 2016; May et al., 2019). In contrast, we investigate a uniquely NLP attribute that has been largely ignored: linguistic background. Current NLP models seem to be trained with the implicit assumption that everyone speaks fluent (often U.S.) Standard English, even though twothirds (>700 million) of the English speakers in the world speak it as a second language (L2) (Eberhard et al., 2019). Even among native speakers, a significant number speak a dialect like African American Vernacular English (AAVE) rather than Standard English (Crystal, 2003). In addition, these World Englishes exhibit variation at multiple levels of linguistic analysis (Kachru et al., 2009). Therefore, putting these models directly into production without addressing this inherent bias puts them at risk of committing linguistic discrimination by performing poorly for many speech communities (e.g., AAVE and L2 speakers). This could take the form of either failing to understand these speakers (Rickford and King, 2016; Tatman, 2017), or misinterpreting them. For example, the recent mistranslation of a minority speaker’s social media post resulted in his wrongful arrest (Hern, 2017). Since L2 (and many L1 dialect) speakers often exhibit variability in their production of inflectional morphology2 (Lardiere, 1998; Prevost and ´ White, 2000; Haznedar, 2002; White, 2003; Seymour, 2004), we argue that NLP models should be robust to inflectional perturbations in order to minimize their chances of propagating linguistic discrimination. Hence, in this paper, we: Propose MORPHEUS, a method for generating plausible and semantically similar adversaries by perturbing the inflections in the clean examples (Figure 1). In contrast to recent work on adversarial examples in NLP (Belinkov and Bisk, 2018; Ebrahimi et al., 2018; Ribeiro et al., 2018), we exploit morphology to craft our adversaries. • Demonstrate its effectiveness on multiple machine comprehension and translation models, including BERT and Transformer (Tables 1 & 2). • Show that adversarially fine-tuning the model on an adversarial training set generated via weighted random sampling is sufficient for it to acquire significant robustness, while preserving performance on clean examples (Table 5). To the best of our knowledge, we are the first to investigate the robustness of NLP models to inflectional perturbations and its ethical implications.",Can the problem of linguistic discrimination in NLP models against nonstandard linguistic backgrounds be mitigated by adversarially fine-tuning the models with perturbed inflectional morphology of words?,2.0,2.0,1.0
137,A Unified Multi-task Adversarial Learning Framework for Pharmacovigilance Mining,"Shweta Yadav, Asif Ekbal, Sriparna Saha, and Pushpak Bhattacharyya. 2019. A Unified Multi-task Adversarial Learning Framework for Pharmacovigilance Mining. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5234–5245, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1516.pdf,https://aclanthology.org/P19-1516/,"The mining of adverse drug reaction (ADR) has a crucial role in the pharmacovigilance. The traditional ways of identifying ADR are reliable but time-consuming, non-scalable and offer a very limited amount of ADR relevant information. With the unprecedented growth of information sources in the forms of social media texts (Twitter, Blogs, Reviews etc.), biomedical literature, and Electronic Medical Records (EMR), it has become crucial to extract the most pertinent ADR related information from these free-form texts. In this paper, we propose a neural network inspired multitask learning framework that can simultaneously extract ADRs from various sources. We adopt a novel adversarial learning-based approach to learn features across multiple ADR information sources. Unlike the other existing techniques, our approach is capable to extracting fine-grained information (such as ‘Indications’, ‘Symptoms’, ‘Finding’, ‘Disease’, ‘Drug’) which provide important cues in pharmacovigilance. We evaluate our proposed approach on three publicly available realworld benchmark pharmacovigilance datasets, a Twitter dataset from PSB 2016 Social Media Shared Task, CADEC corpus and Medline ADR corpus. Experiments show that our unified framework achieves state-of-the-art performance on individual tasks associated with the different benchmark datasets. This establishes the fact that our proposed approach is generic, which enables it to achieve high performance on the diverse datasets. The source code is available here.","Early detection and monitoring of adverse drug reactions (ADRs) can minimize the deleterious impact on patients and health-care systems (Hakkarainen et al., 2012; Sultana et al., 2013). For prevention, the drug safety organizations known as pharmacovigilance agencies conduct post-market surveillance to identify the drug’s side effects post-release. However, the majority of the existing ADE surveillance systems utilizes passive spontaneous reporting system databases, such as the Federal Drug Administration’s Adverse Event Reporting System (FAERS) (Li et al., 2014). These systems are often under-reported, biased and delayed. To overcome the limitation of a passive reporting system, active methods to ADR monitoring continuously explores frequently updated ADR data sources (Behrman et al., 2011). The quantity and near-instantaneous nature of social media provide potential opportunities for real-time monitoring of Adverse Drug Reaction (ADR). The fact that this data is up-to-date and is generated by patients overcomes the weaknesses of traditional ADR surveillance techniques (Leaman et al., 2010). Thus, social media could complement traditional information sources for more effective pharmacovigilance studies, as well as potentially serve as an early warning system for unknown ADR, which may be important for a clinical decision. Additionally, the high statistically significant correlation (p < 0.001, ρ = 0.75) between FAERS and ADRs (extracted through Twitter data) shows that Twitter is a viable pharmacovigilance data source (Freifeld et al., 2014). With the enormous amount of data generated every day, it is desirable to have an automated ADR extraction system that can ease the work of domain experts to quickly investigate the vast amount of unstructured text and identify emerging trends. This may correspond to mapping previously undiscovered adverse effect with a given drug, or discovering an unforeseen impact to a change in the manufacturing process. However, extracting this information from the unstructured text poses several challenges as follows: Multiple Context: Context carries an essential role in determining the semantic labels of the medical concepts. For example, consider the following tweets: Tweet 1: “Advil cured my horrific pain, but made my stomach upset” Tweet 2: “Advil cured my upset stomach but gave me a horrific pain” The above tweets, although have a similar medical concept, their contexts specify the associated class types. In Tweet 1, ‘pain’ refers to the class type Symptom, while in Tweet 2, it refers to ADR. • Multiple word form: Social media text offers some inherently distinct challenges such as containing short word-forms ( eg,“need to sleep 24/7”), misspelled wordforms (eg, “fluoxetine, it just make me so tiered ’), abbreviated words (eg, CIT for Citopram), slangs (eg, “seroquel knocked me out”), implicit sense (eg, “hard time getting some Z’s”), symbols (such as emoticons), and figurative languages (eg, “quetiapine zombie”). This arbitrariness increases the difficulty level in capturing the semantic relationships between the different types. To overcome these limitations, several machine learning and deep learning models are introduced for ADR mining. However, these models are very task-specific and often fail to show reasonable accuracies when these evaluated for some other domains or other annotation schemes. In this paper, we propose a unified multi-task learning (MTL) framework that works on the concept of adversarial learning. Our model is capable of learning several tasks associated with ADR monitoring with different levels of supervisions collectively. The proposed approach differs from the previous studies in two aspects: Firstly, most of the existing methods in multi-task learning attempt to divide the features of different tasks based on task-specific and task-invariant feature space, considering only component-wise parameters. The major drawback of this mechanism is that the common feature space often incorporates the task-specific feature space, leading to feature redundancy. Given this issue in multitask learning (MTL), in our proposed framework we employ adversarial learning (Goodfellow et al., 2014), which helps in eliminating redundant features from the feature space and prevent the contamination between shared and task-specific features. Secondly, we also employ the highway and residual connection whenever necessary to avoid the vanishing gradient problem and improve the performance of our deep neural model (multiheaded attention based stacked recurrent and convolutional neural network). Contributions: Contributions of our current work can be summarized as follows: (1) We propose a unified multi-task learning (MTL) framework for pharmacovigilance mining that exploits the capabilities of adversarial learning to learn the shared complementary features across the multiple ADR datasets. To our best knowledge, this is the very first attempt to study the effect of adversarial learning method in MTL environment, especially for pharmacovigilance mining. (2) Our proposed model is capable of automatically identifying the various information (such as Symptom, Finding, Disease, Drug), in addition to the ADR. (3) We validate our proposed framework on three popular benchmark datasets, namely Twitter (Sarker et al., 2016), CADEC (Karimi et al., 2015) and MEDLINE (Gurulingappa et al., 2012a) for pharmacovigilance mining, having different annotation schemes. We extract the following tags: ADR, Drugs, and Indications from the Twitter dataset, ADR, Disease, Drug, Finding; and Symptom from the CADEC dataset; and Drug and ADR mentions from the MEDLINE dataset. Figure-1 shows exemplary sentences from each dataset. (4) Our unified multi-task model achieves the state-of-the-art performance in the ADR labeling and outperforms the strong baseline models for all the other pharmacovigilance labels.","How can a unified multi-task learning framework employing adversarial learning improve the extraction of Adverse Drug Reactions (ADRs) from diverse data sources such as social media, biomedical literature, and Electronic Medical Records (EMR) while addressing issues like feature redundancy and vanishing gradient problems?",1.0,2.0,1.0
138,A Unified Multi-task Adversarial Learning Framework for Pharmacovigilance Mining,"Shweta Yadav, Asif Ekbal, Sriparna Saha, and Pushpak Bhattacharyya. 2019. A Unified Multi-task Adversarial Learning Framework for Pharmacovigilance Mining. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5234–5245, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1516.pdf,https://aclanthology.org/P19-1516/,"The mining of adverse drug reaction (ADR) has a crucial role in the pharmacovigilance. The traditional ways of identifying ADR are reliable but time-consuming, non-scalable and offer a very limited amount of ADR relevant information. With the unprecedented growth of information sources in the forms of social media texts (Twitter, Blogs, Reviews etc.), biomedical literature, and Electronic Medical Records (EMR), it has become crucial to extract the most pertinent ADR related information from these free-form texts. In this paper, we propose a neural network inspired multitask learning framework that can simultaneously extract ADRs from various sources. We adopt a novel adversarial learning-based approach to learn features across multiple ADR information sources. Unlike the other existing techniques, our approach is capable to extracting fine-grained information (such as ‘Indications’, ‘Symptoms’, ‘Finding’, ‘Disease’, ‘Drug’) which provide important cues in pharmacovigilance. We evaluate our proposed approach on three publicly available realworld benchmark pharmacovigilance datasets, a Twitter dataset from PSB 2016 Social Media Shared Task, CADEC corpus and Medline ADR corpus. Experiments show that our unified framework achieves state-of-the-art performance on individual tasks associated with the different benchmark datasets. This establishes the fact that our proposed approach is generic, which enables it to achieve high performance on the diverse datasets. The source code is available here.","Early detection and monitoring of adverse drug reactions (ADRs) can minimize the deleterious impact on patients and health-care systems (Hakkarainen et al., 2012; Sultana et al., 2013). For prevention, the drug safety organizations known as pharmacovigilance agencies conduct post-market surveillance to identify the drug’s side effects post-release. However, the majority of the existing ADE surveillance systems utilizes passive spontaneous reporting system databases, such as the Federal Drug Administration’s Adverse Event Reporting System (FAERS) (Li et al., 2014). These systems are often under-reported, biased and delayed. To overcome the limitation of a passive reporting system, active methods to ADR monitoring continuously explores frequently updated ADR data sources (Behrman et al., 2011). The quantity and near-instantaneous nature of social media provide potential opportunities for real-time monitoring of Adverse Drug Reaction (ADR). The fact that this data is up-to-date and is generated by patients overcomes the weaknesses of traditional ADR surveillance techniques (Leaman et al., 2010). Thus, social media could complement traditional information sources for more effective pharmacovigilance studies, as well as potentially serve as an early warning system for unknown ADR, which may be important for a clinical decision. Additionally, the high statistically significant correlation (p < 0.001, ρ = 0.75) between FAERS and ADRs (extracted through Twitter data) shows that Twitter is a viable pharmacovigilance data source (Freifeld et al., 2014). With the enormous amount of data generated every day, it is desirable to have an automated ADR extraction system that can ease the work of domain experts to quickly investigate the vast amount of unstructured text and identify emerging trends. This may correspond to mapping previously undiscovered adverse effect with a given drug, or discovering an unforeseen impact to a change in the manufacturing process. However, extracting this information from the unstructured text poses several challenges as follows: Multiple Context: Context carries an essential role in determining the semantic labels of the medical concepts. For example, consider the following tweets: Tweet 1: “Advil cured my horrific pain, but made my stomach upset” Tweet 2: “Advil cured my upset stomach but gave me a horrific pain” The above tweets, although have a similar medical concept, their contexts specify the associated class types. In Tweet 1, ‘pain’ refers to the class type Symptom, while in Tweet 2, it refers to ADR. • Multiple word form: Social media text offers some inherently distinct challenges such as containing short word-forms ( eg,“need to sleep 24/7”), misspelled wordforms (eg, “fluoxetine, it just make me so tiered ’), abbreviated words (eg, CIT for Citopram), slangs (eg, “seroquel knocked me out”), implicit sense (eg, “hard time getting some Z’s”), symbols (such as emoticons), and figurative languages (eg, “quetiapine zombie”). This arbitrariness increases the difficulty level in capturing the semantic relationships between the different types. To overcome these limitations, several machine learning and deep learning models are introduced for ADR mining. However, these models are very task-specific and often fail to show reasonable accuracies when these evaluated for some other domains or other annotation schemes. In this paper, we propose a unified multi-task learning (MTL) framework that works on the concept of adversarial learning. Our model is capable of learning several tasks associated with ADR monitoring with different levels of supervisions collectively. The proposed approach differs from the previous studies in two aspects: Firstly, most of the existing methods in multi-task learning attempt to divide the features of different tasks based on task-specific and task-invariant feature space, considering only component-wise parameters. The major drawback of this mechanism is that the common feature space often incorporates the task-specific feature space, leading to feature redundancy. Given this issue in multitask learning (MTL), in our proposed framework we employ adversarial learning (Goodfellow et al., 2014), which helps in eliminating redundant features from the feature space and prevent the contamination between shared and task-specific features. Secondly, we also employ the highway and residual connection whenever necessary to avoid the vanishing gradient problem and improve the performance of our deep neural model (multiheaded attention based stacked recurrent and convolutional neural network). Contributions: Contributions of our current work can be summarized as follows: (1) We propose a unified multi-task learning (MTL) framework for pharmacovigilance mining that exploits the capabilities of adversarial learning to learn the shared complementary features across the multiple ADR datasets. To our best knowledge, this is the very first attempt to study the effect of adversarial learning method in MTL environment, especially for pharmacovigilance mining. (2) Our proposed model is capable of automatically identifying the various information (such as Symptom, Finding, Disease, Drug), in addition to the ADR. (3) We validate our proposed framework on three popular benchmark datasets, namely Twitter (Sarker et al., 2016), CADEC (Karimi et al., 2015) and MEDLINE (Gurulingappa et al., 2012a) for pharmacovigilance mining, having different annotation schemes. We extract the following tags: ADR, Drugs, and Indications from the Twitter dataset, ADR, Disease, Drug, Finding; and Symptom from the CADEC dataset; and Drug and ADR mentions from the MEDLINE dataset. Figure-1 shows exemplary sentences from each dataset. (4) Our unified multi-task model achieves the state-of-the-art performance in the ADR labeling and outperforms the strong baseline models for all the other pharmacovigilance labels.","Can the challenge of mining adverse drug reactions (ADR) from diverse and unstructured data sources be effectively addressed by a neural network inspired multitask learning framework that employs an adversarial learning-based approach, thus overcoming the limitations of traditional and task-specific identification methods?",1.0,2.0,1.0
139,Simplify the Usage of Lexicon in Chinese NER,"Ruotian Ma, Minlong Peng, Qi Zhang, Zhongyu Wei, and Xuanjing Huang. 2020. Simplify the Usage of Lexicon in Chinese NER. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5951–5960, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.528.pdf,https://aclanthology.org/2020.acl-main.528/,"Recently, many works have tried to augment the performance of Chinese named entity recognition (NER) using word lexicons. As a representative, Lattice-LSTM (Zhang and Yang, 2018) has achieved new benchmark results on several public Chinese NER datasets. However, Lattice-LSTM has a complex model architecture. This limits its application in many industrial areas where real-time NER responses are needed. In this work, we propose a simple but effective method for incorporating the word lexicon into the character representations. This method avoids designing a complicated sequence modeling architecture, and for any neural NER model, it requires only subtle adjustment of the character representation layer to introduce the lexicon information. Experimental studies on four benchmark Chinese NER datasets show that our method achieves an inference speed up to 6.15 times faster than those of state-ofthe-art methods, along with a better performance. The experimental results also show that the proposed method can be easily incorporated with pre-trained models like BERT.","Named Entity Recognition (NER) is concerned with the identification of named entities, such as persons, locations, and organizations, in unstructured text. NER plays an important role in many downstream tasks, including knowledge base construction (Riedel et al., 2013), information retrieval (Chen et al., 2015), and question answering (Diefenbach et al., 2018). In languages where words are naturally separated (e.g., English), NER has been conventionally formulated as a sequence labeling problem, and the state-of-the-art results have been achieved using neural-network-based models (Huang et al., 2015; Chiu and Nichols, 2016; Liu et al., 2018). Compared with NER in English, Chinese NER is more difficult since sentences in Chinese are not naturally segmented. Thus, a common practice for Chinese NER is to first perform word segmentation using an existing CWS system and then apply a word-level sequence labeling model to the segmented sentence (Yang et al., 2016; He and Sun, 2017b). However, it is inevitable that the CWS system will incorrectly segment query sentences. This will result in errors in the detection of entity boundary and the prediction of entity category in NER. Therefore, some approaches resort to performing Chinese NER directly at the character level, which has been empirically proven to be effective (He and Wang, 2008; Liu et al., 2010; Li et al., 2014; Liu et al., 2019; Sui et al., 2019; Gui et al., 2019b; Ding et al., 2019). A drawback of the purely character-based NER method is that the word information is not fully exploited. With this consideration, Zhang and Yang, (2018) proposed Lattice-LSTM for incorporating word lexicons into the character-based NER model. Moreover, rather than heuristically choosing a word for the character when it matches multiple words in the lexicon, the authors proposed to preserve all words that match the character, leaving the subsequent NER model to determine which word to apply. To realize this idea, they introduced an elaborate modification to the sequence modeling layer of the LSTM-CRF model (Huang et al., 2015). Experimental studies on four Chinese NER datasets have verified the effectiveness of Lattice-LSTM. However, the model architecture of LatticeLSTM is quite complicated. In order to introduce lexicon information, Lattice-LSTM adds several additional edges between nonadjacent characters in the input sequence, which significantly slows its training and inference speeds. In addition, it is difficult to transfer the structure of LatticeLSTM to other neural-network architectures (e.g., convolutional neural networks and transformers) that may be more suitable for some specific tasks. In this work, we propose a simpler method to realize the idea of Lattice-LSTM, i.e., incorporating all the matched words for each character to a character-based NER model. The first principle of our model design is to achieve a fast inference speed. To this end, we propose to encode lexicon information in the character representations, and we design the encoding scheme to preserve as much of the lexicon matching results as possible. Compared with Lattice-LSTM, our method avoids the need for a complicated model architecture, is easier to implement, and can be quickly adapted to any appropriate neural NER model by adjusting the character representation layer. In addition, ablation studies show the superiority of our method in incorporating more complete and distinct lexicon information, as well as introducing a more effective word-weighting strategy. The contributions of this work can be summarized as follows: • We propose a simple but effective method for incorporating word lexicons into the character representations for Chinese NER. • The proposed method is transferable to different sequence-labeling architectures and can be easily incorporated with pre-trained models like BERT (Devlin et al., 2018). We performed experiments on four public Chinese NER datasets. The experimental results show that when implementing the sequence modeling layer with a single-layer Bi-LSTM, our method achieves considerable improvements over the state-of-theart methods in both inference speed and sequence labeling performance.",Can the performance of Chinese named entity recognition (NER) be improved by simplifying the incorporation of word lexicon into character representations?,0.0,1.0,1.0
140,More Diverse Dialogue Datasets via Diversity-Informed Data Collection,"Katherine Stasaski, Grace Hui Yang, and Marti A. Hearst. 2020. More Diverse Dialogue Datasets via Diversity-Informed Data Collection. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4958–4968, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.446.pdf,https://aclanthology.org/2020.acl-main.446/,"Automated generation of conversational dialogue using modern neural architectures has made notable advances. However, these models are known to have a drawback of often producing uninteresting, predictable responses; this is known as the diversity problem. We introduce a new strategy to address this problem, called Diversity-Informed Data Collection. Unlike prior approaches, which modify model architectures to solve the problem, this method uses dynamically computed corpuslevel statistics to determine which conversational participants to collect data from. Diversity-Informed Data Collection produces significantly more diverse data than baseline data collection methods, and better results on two downstream tasks: emotion classification and dialogue generation. This method is generalizable and can be used with other corpuslevel metrics.","It is well-documented that neural dialogue models struggle with generating engaging, relevant responses (Li et al., 2016a) and often produce banal responses such as “Yeah.” While this may be an appropriate response to a chitchat conversation, to keep a human participant engaged, diversity of responses is important. Diverse models vary the language used and the content referenced, and the generated utterances differ from the most typical conversation responses some proportion of the time. A model which only generates “Yeah,” “No,” and “I don’t know” is not diverse and is not be engaging to converse with. Past work has improved model diversity with innovation on model architectures and decoding strategies (Li et al., 2016a; Baheti et al., 2018; Li et al., 2017; Shao et al., 2017; Cao and Clark, 2017; Serban et al., 2017; Zhao et al., 2017). We build upon this work to propose a novel method to collect and determine more diverse data to train these models with. Our method can be used in conjunction with existing generation-specific model innovations. Some prior work on data collection processes has prioritized diversity. For instance, Rashkin et al. (2019) prompts crowdworkers to choose an underused emotion class to generate dialogue. This work encourages coverage of emotion classes, but does not consider the likelihood that some crowdworkers are better at producing certain types of data than others. This paper introduces Diversity-Informed Data Collection (DIDC), a new strategy for creating a dataset of conversational utterances via selecting which participants’ data to include in the collection. The strategy progressively builds up a more diverse sub-corpus from an existing larger collection. The main idea is to grow the sub-corpus by adding conversations sequentially and to assess the contribution of a new participant’s utterances to the diversity of the entire sub-corpus. This strategy is also applicable to on-the-fly collection of new datasets via crowdworking or similar methods. We implement DIDC with three diversity metrics: Outlier, Entropy, and Mean-IDF. Diversity-Informed Data Collection also provides a new method for finding an upper bound on a current corpus’s diversity via a Corpus-Wide Oracle which has access to information about which utterances are most diverse across the corpus. Prior work has not used corpus-level statistics to enhance the diversity of the collected data. Instead, when collecting data with crowdworkers, researchers have sought more diverse responses by altering the task (Kang et al., 2018) or by altering the stimulus (Larson et al., 2019). Prior work that trains neural dialogue models has not made use of subsets of existing datasets that exhibit properties of diversity. Our experiments show this strategy yields significantly more diverse data than baseline collection processes. It also yields better, more diverse model output on two downstream tasks. Additionally, this method can be implemented for other metrics which are defined relative to the corpus.",What is the efficacy of the Diversity-Informed Data Collection method compared to baseline data collection methods in producing more diverse conversational data and improving the performance of neural dialogue models on emotion classification and dialogue generation tasks?,1.0,1.0,1.0
141,More Diverse Dialogue Datasets via Diversity-Informed Data Collection,"Katherine Stasaski, Grace Hui Yang, and Marti A. Hearst. 2020. More Diverse Dialogue Datasets via Diversity-Informed Data Collection. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4958–4968, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.446.pdf,https://aclanthology.org/2020.acl-main.446/,"Automated generation of conversational dialogue using modern neural architectures has made notable advances. However, these models are known to have a drawback of often producing uninteresting, predictable responses; this is known as the diversity problem. We introduce a new strategy to address this problem, called Diversity-Informed Data Collection. Unlike prior approaches, which modify model architectures to solve the problem, this method uses dynamically computed corpuslevel statistics to determine which conversational participants to collect data from. Diversity-Informed Data Collection produces significantly more diverse data than baseline data collection methods, and better results on two downstream tasks: emotion classification and dialogue generation. This method is generalizable and can be used with other corpuslevel metrics.","It is well-documented that neural dialogue models struggle with generating engaging, relevant responses (Li et al., 2016a) and often produce banal responses such as “Yeah.” While this may be an appropriate response to a chitchat conversation, to keep a human participant engaged, diversity of responses is important. Diverse models vary the language used and the content referenced, and the generated utterances differ from the most typical conversation responses some proportion of the time. A model which only generates “Yeah,” “No,” and “I don’t know” is not diverse and is not be engaging to converse with. Past work has improved model diversity with innovation on model architectures and decoding strategies (Li et al., 2016a; Baheti et al., 2018; Li et al., 2017; Shao et al., 2017; Cao and Clark, 2017; Serban et al., 2017; Zhao et al., 2017). We build upon this work to propose a novel method to collect and determine more diverse data to train these models with. Our method can be used in conjunction with existing generation-specific model innovations. Some prior work on data collection processes has prioritized diversity. For instance, Rashkin et al. (2019) prompts crowdworkers to choose an underused emotion class to generate dialogue. This work encourages coverage of emotion classes, but does not consider the likelihood that some crowdworkers are better at producing certain types of data than others. This paper introduces Diversity-Informed Data Collection (DIDC), a new strategy for creating a dataset of conversational utterances via selecting which participants’ data to include in the collection. The strategy progressively builds up a more diverse sub-corpus from an existing larger collection. The main idea is to grow the sub-corpus by adding conversations sequentially and to assess the contribution of a new participant’s utterances to the diversity of the entire sub-corpus. This strategy is also applicable to on-the-fly collection of new datasets via crowdworking or similar methods. We implement DIDC with three diversity metrics: Outlier, Entropy, and Mean-IDF. Diversity-Informed Data Collection also provides a new method for finding an upper bound on a current corpus’s diversity via a Corpus-Wide Oracle which has access to information about which utterances are most diverse across the corpus. Prior work has not used corpus-level statistics to enhance the diversity of the collected data. Instead, when collecting data with crowdworkers, researchers have sought more diverse responses by altering the task (Kang et al., 2018) or by altering the stimulus (Larson et al., 2019). Prior work that trains neural dialogue models has not made use of subsets of existing datasets that exhibit properties of diversity. Our experiments show this strategy yields significantly more diverse data than baseline collection processes. It also yields better, more diverse model output on two downstream tasks. Additionally, this method can be implemented for other metrics which are defined relative to the corpus.",Can the diversity problem in automated conversational dialogue generation be solved by Diversity-Informed Data Collection?,1.0,1.0,1.0
142,More Diverse Dialogue Datasets via Diversity-Informed Data Collection,"Katherine Stasaski, Grace Hui Yang, and Marti A. Hearst. 2020. More Diverse Dialogue Datasets via Diversity-Informed Data Collection. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4958–4968, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.446.pdf,https://aclanthology.org/2020.acl-main.446/,"Automated generation of conversational dialogue using modern neural architectures has made notable advances. However, these models are known to have a drawback of often producing uninteresting, predictable responses; this is known as the diversity problem. We introduce a new strategy to address this problem, called Diversity-Informed Data Collection. Unlike prior approaches, which modify model architectures to solve the problem, this method uses dynamically computed corpuslevel statistics to determine which conversational participants to collect data from. Diversity-Informed Data Collection produces significantly more diverse data than baseline data collection methods, and better results on two downstream tasks: emotion classification and dialogue generation. This method is generalizable and can be used with other corpuslevel metrics.","It is well-documented that neural dialogue models struggle with generating engaging, relevant responses (Li et al., 2016a) and often produce banal responses such as “Yeah.” While this may be an appropriate response to a chitchat conversation, to keep a human participant engaged, diversity of responses is important. Diverse models vary the language used and the content referenced, and the generated utterances differ from the most typical conversation responses some proportion of the time. A model which only generates “Yeah,” “No,” and “I don’t know” is not diverse and is not be engaging to converse with. Past work has improved model diversity with innovation on model architectures and decoding strategies (Li et al., 2016a; Baheti et al., 2018; Li et al., 2017; Shao et al., 2017; Cao and Clark, 2017; Serban et al., 2017; Zhao et al., 2017). We build upon this work to propose a novel method to collect and determine more diverse data to train these models with. Our method can be used in conjunction with existing generation-specific model innovations. Some prior work on data collection processes has prioritized diversity. For instance, Rashkin et al. (2019) prompts crowdworkers to choose an underused emotion class to generate dialogue. This work encourages coverage of emotion classes, but does not consider the likelihood that some crowdworkers are better at producing certain types of data than others. This paper introduces Diversity-Informed Data Collection (DIDC), a new strategy for creating a dataset of conversational utterances via selecting which participants’ data to include in the collection. The strategy progressively builds up a more diverse sub-corpus from an existing larger collection. The main idea is to grow the sub-corpus by adding conversations sequentially and to assess the contribution of a new participant’s utterances to the diversity of the entire sub-corpus. This strategy is also applicable to on-the-fly collection of new datasets via crowdworking or similar methods. We implement DIDC with three diversity metrics: Outlier, Entropy, and Mean-IDF. Diversity-Informed Data Collection also provides a new method for finding an upper bound on a current corpus’s diversity via a Corpus-Wide Oracle which has access to information about which utterances are most diverse across the corpus. Prior work has not used corpus-level statistics to enhance the diversity of the collected data. Instead, when collecting data with crowdworkers, researchers have sought more diverse responses by altering the task (Kang et al., 2018) or by altering the stimulus (Larson et al., 2019). Prior work that trains neural dialogue models has not made use of subsets of existing datasets that exhibit properties of diversity. Our experiments show this strategy yields significantly more diverse data than baseline collection processes. It also yields better, more diverse model output on two downstream tasks. Additionally, this method can be implemented for other metrics which are defined relative to the corpus.",Can the problem of generating engaging and diverse conversational responses in neural dialogue models be mitigated by the method of Diversity-Informed Data Collection (DIDC) using dynamically computed corpus-level statistics?,2.0,2.0,1.0
143,Improving the Similarity Measure of Determinantal Point Processes for Extractive Multi-Document Summarization,"Sangwoo Cho, Logan Lebanoff, Hassan Foroosh, and Fei Liu. 2019. Improving the Similarity Measure of Determinantal Point Processes for Extractive Multi-Document Summarization. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1027–1038, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1098.pdf,https://aclanthology.org/P19-1098/,"The most important obstacles facing multidocument summarization include excessive redundancy in source descriptions and the looming shortage of training data. These obstacles prevent encoder-decoder models from being used directly, but optimization-based methods such as determinantal point processes (DPPs) are known to handle them well. In this paper we seek to strengthen a DPP-based method for extractive multi-document summarization by presenting a novel similarity measure inspired by capsule networks. The approach measures redundancy between a pair of sentences based on surface form and semantic information. We show that our DPP system with improved similarity measure performs competitively, outperforming strong summarization baselines on benchmark datasets. Our findings are particularly meaningful for summarizing documents created by multiple authors containing redundant yet lexically diverse expressions.","Multi-document summarization is arguably one of the most important tools for information aggregation. It seeks to produce a succinct summary from a collection of textual documents created by multiple authors concerning a single topic (Nenkova and McKeown, 2011). The summarization technique has seen growing interest in a broad spectrum of domains that include summarizing product reviews (Gerani et al., 2014; Yang et al., 2018), student survey responses (Luo and Litman, 2015; Luo et al., 2016), forum discussion threads (Ding and Jiang, 2015; Tarnpradab et al., 2017), and news articles about a particular event (Hong et al., 2014). Despite the empirical success, most of the datasets remain small, and the cost of hiring human annotators to create ground-truth summaries for multi-document inputs can be prohibitive. Impressive progress has been made on neural abstractive summarization using encoder-decoder models (Rush et al., 2015; See et al., 2017; Paulus et al., 2017; Chen and Bansal, 2018). These models, nonetheless, are data-hungry and learn poorly from small datasets, as is often the case with multidocument summarization. To date, studies have primarily focused on single-document summarization (See et al., 2017; Celikyilmaz et al., 2018; Kryscinski et al., 2018) and sentence summarization (Nallapati et al., 2016; Zhou et al., 2017; Cao et al., 2018; Song et al., 2018) in part because parallel training data are abundant and they can be conveniently acquired from the Web. Further, a notable issue with abstractive summarization is the reliability. These models are equipped with the capability of generating new words not present in the source. With greater freedom of lexical choices, the system summaries can contain inaccurate factual details and falsified content that prevent them from staying “true-to-original.” In this paper we instead focus on an extractive method exploiting the determinantal point process (DPP; Kulesza and Taskar, 2012) for multidocument summarization. DPP can be trained on small data, and because extractive summaries are free from manipulation, they largely remain true to the original. DPP selects a set of most representative sentences from the given source documents to form a summary, while maintaining high diversity among summary sentences. It is one of a family of optimization-based summarization methods that performed strongest in previous summarization competitions (Gillick and Favre, 2009; Lin and Bilmes, 2010; Kulesza and Taskar, 2011). Diversity is an integral part of the DPP model. It is modelled by pairwise repulsion between sentences. In this paper we exploit the capsule networks (Hinton et al., 2018) to measure pairwise sentence (dis)similarity, then leverage DPP to obtain a set of diverse summary sentences. Traditionally, the DPP method computes similarity scores based on the bag-of-words representation of sentences (Kulesza and Taskar, 2011) and with kernel methods (Gong et al., 2014). These methods, however, are incapable of capturing lexical and syntactic variations in the sentences (e.g., paraphrases), which are ubiquitous in multi-document summarization data as the source documents are created by multiple authors with distinct writing styles. We hypothesize that the recently proposed capsule networks, which learn high-level representations based on the orientational and spatial relationships of low-level components, can be a suitable supplement to model pairwise sentence similarity. Importantly, we argue that predicting sentence similarity within the context of summarization has its uniqueness. It estimates if two sentences contain redundant information based on both surface word form and their underlying semantics. E.g., the two sentences “Snowstorm slams eastern US on Friday” and “A strong wintry storm was dumping snow in eastern US after creating traffic havoc that claimed at least eight lives” are considered similar because they carry redundant information and cannot both be included in the summary. These sentences are by no means semantically equivalent, nor do they exhibit a clear entailment relationship. The task thus should be distinguished from similar tasks such as predicting natural language inference (Bowman et al., 2015; Williams et al., 2018) or semantic textual similarity (Cer et al., 2017). In this work, we describe a novel method to collect a large amount of sentence pairs that are deemed similar for summarization purpose. We contrast this new dataset with those used for textual entailment for modeling sentence similarity and demonstrate its effectiveness on discriminating sentences and generating diverse summaries. The contributions of this work can be summarized as follows: • we present a novel method inspired by the determinantal point process for multi-document summarization. The method includes a diversity measure assessing the redundancy between sentences, and a quality measure that indicates the importance of sentences. DPP extracts a set of summary sentences that are both representative of the document set and remain diverse; • we present the first study exploiting capsule networks for determining sentence similarity for summarization purpose. It is important to recognize that summarization places particular emphasis on measuring redundancy between sentences; and this notion of similarity is different from that of entailment and semantic textual similarity (STS); • our findings suggest that effectively modeling pairwise sentence similarity is crucial for increasing summary diversity and boosting summarization performance. Our DPP system with improved similarity measure performs competitively, outperforming strong summarization baselines on benchmark datasets.",Can the challenges of multidocument summarization be addressed by an improved DPP-based approach that incorporates a capsule network-inspired similarity measure for enhanced handling of redundancy and diversity?,2.0,1.0,1.0
144,EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing,"Yue Dong, Zichao Li, Mehdi Rezagholizadeh, and Jackie Chi Kit Cheung. 2019. EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3393–3402, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1331.pdf,https://aclanthology.org/P19-1331/,"We present the first sentence simplification model that learns explicit edit operations (ADD, DELETE, and KEEP) via a neural programmer-interpreter approach. Most current neural sentence simplification systems are variants of sequence-to-sequence models adopted from machine translation. These methods learn to simplify sentences as a byproduct of the fact that they are trained on complex-simple sentence pairs. By contrast, our neural programmer-interpreter is directly trained to predict explicit edit operations on targeted parts of the input sentence, resembling the way that humans might perform simplification and revision. Our model outperforms previous state-of-the-art neural sentence simplification models (without external knowledge) by large margins on three benchmark text simplification corpora in terms of SARI (+0.95 WikiLarge, +1.89 WikiSmall, +1.41 Newsela), and is judged by humans to produce overall better and simpler output sentences.","Sentence simplification aims to reduce the reading complexity of a sentence while preserving its meaning. Simplification systems can benefit populations with limited literacy skills (Watanabe et al., 2009), such as children, second language speakers and individuals with language impairments including dyslexia (Rello et al., 2013), aphasia (Carroll et al., 1999) and autism (Evans et al., 2014). Inspired by the success of machine translation, many text simplification (TS) systems treat sentence simplification as a monolingual translation task, in which complex-simple sentence pairs are presented to the models as source-target pairs (Zhang and Lapata, 2017). Two major machine translation (MT) approaches are adapted into TS systems, each with its advantages: statistical machine translation (SMT)-based models (Zhu et al., 2010; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2016) can easily integrate human-curated features into the model, while neural machine translation (NMT)-based models (Nisioi et al., 2017; Zhang and Lapata, 2017; Vu et al., 2018) can operate in an end-to-end fashion by extracting features automatically. Nevertheless, MTbased models must learn the simplifying operations that are embedded in the parallel complexsimple sentences implicitly. These operations are relatively infrequent, as a large part of the original complex sentence usually remains unchanged in the simplification process (Zhang et al., 2017). This leads to MT-based models that often produce outputs that are identical to the inputs (Zhao et al., 2018), which is also confirmed in our experiments. We instead propose a novel end-to-end Neural Programmer-Interpreter (Reed and de Freitas, 2016) that learns to explicitly generate edit operations in a sequential fashion, resembling the way that a human editor might perform simplifications on sentences. Our proposed framework consists of a programmer and an interpreter that operate alternately at each time step: the programmer predicts a simplifying edit operation (program) such as ADD, DELETE, or KEEP; the interpreter executes the edit operation while maintaining a context and an edit pointer to assist the programmer for further decisions. Table 1 shows sample runs of our model. Intuitively, our model learns to skip words that do not need to be modified by predicting KEEP, so it can focus on simplifying the parts that actually require changes. An analogy can be drawn to residual connections popular in deep neural architectures for image recognition, which give models the flexibility to directly copy parameters from previous layers if they are not the focus of the visual signal (He et al., 2016). In addition, the edit operations generated by our model are easier to interpret than the black-box MT-based seq2seq systems: by looking at our model’s generated programs, we can trace the simplification operations used to transform complex sentences to simple ones. Moreover, our model offers control over the ratio of simplification operations. By simply changing the loss weights on edit operations, our model can prioritize different simplification operations for different sentence simplification tasks (e.g., compression or lexical replacement). The idea of learning sentence simplification through edit operations was attempted by AlvaManchego et al. (2017). They were mainly focused on creating better-aligned simplification edit labels (“silver” labels) and showed that a simple sequence labelling model (BiLSTM) fails to predict these silver simplification labels. We speculate that the limited success of their proposed model is due to the facts that the model relies on an external system and assumes the edit operations are independent of each other. We address these two problems by 1) using variants of Levenshtein distances to create edit labels that do not require external tools to execute; 2) using an interpreter to execute the programs and summarize the partial output sequence immediately before making the next edit decision. Our interpreter also acts as a language model to regularize the operations that would lead to ungrammatical outputs, as a programmer alone will output edit labels with little consideration of context and grammar. In addition, our model is completely end-to-end and does not require any extra modules. Our contributions are two-fold: 1) we propose to model the edit operations explicitly for sentence simplification in an end-to-end fashion, rather than relying on MT-based models to learn the simplification mappings implicitly, which often generates outputs by blindly repeating the source sentences; 2) we design an NPI-based model that simulates the editing process by a programmer and an interpreter, which outperforms the state-of-the-art neural MT-based TS models by large margins in terms of SARI and is judged by humans as simpler and overall better.","Can sentence simplification be improved by using a Neural Programmer-Interpreter model that learns explicit edit operations (ADD, DELETE, KEEP)?",1.0,1.0,1.0
145,EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing,"Yue Dong, Zichao Li, Mehdi Rezagholizadeh, and Jackie Chi Kit Cheung. 2019. EditNTS: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3393–3402, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1331.pdf,https://aclanthology.org/P19-1331/,"We present the first sentence simplification model that learns explicit edit operations (ADD, DELETE, and KEEP) via a neural programmer-interpreter approach. Most current neural sentence simplification systems are variants of sequence-to-sequence models adopted from machine translation. These methods learn to simplify sentences as a byproduct of the fact that they are trained on complex-simple sentence pairs. By contrast, our neural programmer-interpreter is directly trained to predict explicit edit operations on targeted parts of the input sentence, resembling the way that humans might perform simplification and revision. Our model outperforms previous state-of-the-art neural sentence simplification models (without external knowledge) by large margins on three benchmark text simplification corpora in terms of SARI (+0.95 WikiLarge, +1.89 WikiSmall, +1.41 Newsela), and is judged by humans to produce overall better and simpler output sentences.","Sentence simplification aims to reduce the reading complexity of a sentence while preserving its meaning. Simplification systems can benefit populations with limited literacy skills (Watanabe et al., 2009), such as children, second language speakers and individuals with language impairments including dyslexia (Rello et al., 2013), aphasia (Carroll et al., 1999) and autism (Evans et al., 2014). Inspired by the success of machine translation, many text simplification (TS) systems treat sentence simplification as a monolingual translation task, in which complex-simple sentence pairs are presented to the models as source-target pairs (Zhang and Lapata, 2017). Two major machine translation (MT) approaches are adapted into TS systems, each with its advantages: statistical machine translation (SMT)-based models (Zhu et al., 2010; Wubben et al., 2012; Narayan and Gardent, 2014; Xu et al., 2016) can easily integrate human-curated features into the model, while neural machine translation (NMT)-based models (Nisioi et al., 2017; Zhang and Lapata, 2017; Vu et al., 2018) can operate in an end-to-end fashion by extracting features automatically. Nevertheless, MTbased models must learn the simplifying operations that are embedded in the parallel complexsimple sentences implicitly. These operations are relatively infrequent, as a large part of the original complex sentence usually remains unchanged in the simplification process (Zhang et al., 2017). This leads to MT-based models that often produce outputs that are identical to the inputs (Zhao et al., 2018), which is also confirmed in our experiments. We instead propose a novel end-to-end Neural Programmer-Interpreter (Reed and de Freitas, 2016) that learns to explicitly generate edit operations in a sequential fashion, resembling the way that a human editor might perform simplifications on sentences. Our proposed framework consists of a programmer and an interpreter that operate alternately at each time step: the programmer predicts a simplifying edit operation (program) such as ADD, DELETE, or KEEP; the interpreter executes the edit operation while maintaining a context and an edit pointer to assist the programmer for further decisions. Table 1 shows sample runs of our model. Intuitively, our model learns to skip words that do not need to be modified by predicting KEEP, so it can focus on simplifying the parts that actually require changes. An analogy can be drawn to residual connections popular in deep neural architectures for image recognition, which give models the flexibility to directly copy parameters from previous layers if they are not the focus of the visual signal (He et al., 2016). In addition, the edit operations generated by our model are easier to interpret than the black-box MT-based seq2seq systems: by looking at our model’s generated programs, we can trace the simplification operations used to transform complex sentences to simple ones. Moreover, our model offers control over the ratio of simplification operations. By simply changing the loss weights on edit operations, our model can prioritize different simplification operations for different sentence simplification tasks (e.g., compression or lexical replacement). The idea of learning sentence simplification through edit operations was attempted by AlvaManchego et al. (2017). They were mainly focused on creating better-aligned simplification edit labels (“silver” labels) and showed that a simple sequence labelling model (BiLSTM) fails to predict these silver simplification labels. We speculate that the limited success of their proposed model is due to the facts that the model relies on an external system and assumes the edit operations are independent of each other. We address these two problems by 1) using variants of Levenshtein distances to create edit labels that do not require external tools to execute; 2) using an interpreter to execute the programs and summarize the partial output sequence immediately before making the next edit decision. Our interpreter also acts as a language model to regularize the operations that would lead to ungrammatical outputs, as a programmer alone will output edit labels with little consideration of context and grammar. In addition, our model is completely end-to-end and does not require any extra modules. Our contributions are two-fold: 1) we propose to model the edit operations explicitly for sentence simplification in an end-to-end fashion, rather than relying on MT-based models to learn the simplification mappings implicitly, which often generates outputs by blindly repeating the source sentences; 2) we design an NPI-based model that simulates the editing process by a programmer and an interpreter, which outperforms the state-of-the-art neural MT-based TS models by large margins in terms of SARI and is judged by humans as simpler and overall better.",Can the problem of ineffective sentence simplification in current neural sequence-to-sequence models be solved by adopting a neural programmer-interpreter model that explicitly predicts edit operations tailored to simplify sentences in a way more akin to human editing processes?,1.0,2.0,1.0
146,Inferring Logical Forms From Denotations,"Panupong Pasupat and Percy Liang. 2016. Inferring Logical Forms From Denotations. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 23–32, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1003.pdf,https://aclanthology.org/P16-1003/,"A core problem in learning semantic parsers from denotations is picking out consistent logical forms—those that yield the correct denotation—from a combinatorially large space. To control the search space, previous work relied on restricted set of rules, which limits expressivity. In this paper, we consider a much more expressive class of logical forms, and show how to use dynamic programming to efficiently represent the complete set of consistent logical forms. Expressivity also introduces many more spurious logical forms which are consistent with the correct denotation but do not represent the meaning of the utterance. To address this, we generate fictitious worlds and use crowdsourced denotations on these worlds to filter out spurious logical forms. On the WIKITABLEQUESTIONS dataset, we increase the coverage of answerable questions from 53.5% to 76%, and the additional crowdsourced supervision lets us rule out 92.1% of spurious logical forms.","Consider the task of learning to answer complex natural language questions (e.g., “Where did the last 1st place finish occur?”) using only question-answer pairs as supervision (Clarke et al., 2010; Liang et al., 2011; Berant et al., 2013; Artzi and Zettlemoyer, 2013). Semantic parsers map the question into a logical form (e.g., R[Venue].argmax(Position.1st, Index)) that can be executed on a knowledge source to obtain the answer (denotation). Logical forms are very expressive since they can be recursively composed, but this very expressivity makes it more difficult to search over the space of logical forms. Previous work sidesteps this obstacle by restricting the set of possible logical form compositions, but this is limiting. For instance, for the system in Pasupat and Liang (2015), in only 53.5% of the examples was the correct logical form even in the set of generated logical forms. The goal of this paper is to solve two main challenges that prevent us from generating more expressive logical forms. The first challenge is computational: the number of logical forms grows exponentially as their size increases. Directly enumerating over all logical forms becomes infeasible, and pruning techniques such as beam search can inadvertently prune out correct logical forms. The second challenge is the large increase in spurious logical forms—those that do not reflect the semantics of the question but coincidentally execute to the correct denotation. For example, while logical forms z1, . . . , z5 in Figure 1 are all consistent (they execute to the correct answer y), the logical forms z4 and z5 are spurious and would give incorrect answers if the table were to change. We address these two challenges by solving two interconnected tasks. The first task, which addresses the computational challenge, is to enumerate the set Z of all consistent logical forms given a question x, a knowledge source w (“world”), and the target denotation y (Section 4). Observing that the space of possible denotations grows much more slowly than the space of logical forms, we perform dynamic programming on denotations (DPD) to make search feasible. Our method is guaranteed to find all consistent logical forms up to some bounded size. Given the set Z of consistent logical forms, the second task is to filter out spurious logical forms from Z (Section 5). Using the property that spurious logical forms ultimately give a wrong answer when the data in the world w changes, we create fictitious worlds to test the denotations of the logical forms in Z. We use crowdsourcing to annotate the correct denotations on a subset of the generated worlds. To reduce the amount of annotation needed, we choose the subset that maximizes the expected information gain. The pruned set of logical forms would provide a stronger supervision signal for training a semantic parser. We test our methods on the WIKITABLEQUESTIONS dataset of complex questions on Wikipedia tables. We define a simple, general set of deduction rules (Section 3), and use DPD to confirm that the rules generate a correct logical form in 76% of the examples, up from the 53.5% in Pasupat and Liang (2015). Moreover, unlike beam search, DPD is guaranteed to find all consistent logical forms up to a bounded size. Finally, by using annotated data on fictitious worlds, we are able to prune out 92.1% of the spurious logical forms.",Can the enumeration of all consistent logical forms and filtering out of spurious logical forms be achieved by using dynamic programming on denotations and crowdsourced annotations on fictitious worlds?,0.0,1.0,1.0
147,Inferring Logical Forms From Denotations,"Panupong Pasupat and Percy Liang. 2016. Inferring Logical Forms From Denotations. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 23–32, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1003.pdf,https://aclanthology.org/P16-1003/,"A core problem in learning semantic parsers from denotations is picking out consistent logical forms—those that yield the correct denotation—from a combinatorially large space. To control the search space, previous work relied on restricted set of rules, which limits expressivity. In this paper, we consider a much more expressive class of logical forms, and show how to use dynamic programming to efficiently represent the complete set of consistent logical forms. Expressivity also introduces many more spurious logical forms which are consistent with the correct denotation but do not represent the meaning of the utterance. To address this, we generate fictitious worlds and use crowdsourced denotations on these worlds to filter out spurious logical forms. On the WIKITABLEQUESTIONS dataset, we increase the coverage of answerable questions from 53.5% to 76%, and the additional crowdsourced supervision lets us rule out 92.1% of spurious logical forms.","Consider the task of learning to answer complex natural language questions (e.g., “Where did the last 1st place finish occur?”) using only question-answer pairs as supervision (Clarke et al., 2010; Liang et al., 2011; Berant et al., 2013; Artzi and Zettlemoyer, 2013). Semantic parsers map the question into a logical form (e.g., R[Venue].argmax(Position.1st, Index)) that can be executed on a knowledge source to obtain the answer (denotation). Logical forms are very expressive since they can be recursively composed, but this very expressivity makes it more difficult to search over the space of logical forms. Previous work sidesteps this obstacle by restricting the set of possible logical form compositions, but this is limiting. For instance, for the system in Pasupat and Liang (2015), in only 53.5% of the examples was the correct logical form even in the set of generated logical forms. The goal of this paper is to solve two main challenges that prevent us from generating more expressive logical forms. The first challenge is computational: the number of logical forms grows exponentially as their size increases. Directly enumerating over all logical forms becomes infeasible, and pruning techniques such as beam search can inadvertently prune out correct logical forms. The second challenge is the large increase in spurious logical forms—those that do not reflect the semantics of the question but coincidentally execute to the correct denotation. For example, while logical forms z1, . . . , z5 in Figure 1 are all consistent (they execute to the correct answer y), the logical forms z4 and z5 are spurious and would give incorrect answers if the table were to change. We address these two challenges by solving two interconnected tasks. The first task, which addresses the computational challenge, is to enumerate the set Z of all consistent logical forms given a question x, a knowledge source w (“world”), and the target denotation y (Section 4). Observing that the space of possible denotations grows much more slowly than the space of logical forms, we perform dynamic programming on denotations (DPD) to make search feasible. Our method is guaranteed to find all consistent logical forms up to some bounded size. Given the set Z of consistent logical forms, the second task is to filter out spurious logical forms from Z (Section 5). Using the property that spurious logical forms ultimately give a wrong answer when the data in the world w changes, we create fictitious worlds to test the denotations of the logical forms in Z. We use crowdsourcing to annotate the correct denotations on a subset of the generated worlds. To reduce the amount of annotation needed, we choose the subset that maximizes the expected information gain. The pruned set of logical forms would provide a stronger supervision signal for training a semantic parser. We test our methods on the WIKITABLEQUESTIONS dataset of complex questions on Wikipedia tables. We define a simple, general set of deduction rules (Section 3), and use DPD to confirm that the rules generate a correct logical form in 76% of the examples, up from the 53.5% in Pasupat and Liang (2015). Moreover, unlike beam search, DPD is guaranteed to find all consistent logical forms up to a bounded size. Finally, by using annotated data on fictitious worlds, we are able to prune out 92.1% of the spurious logical forms.","Can the problem of efficiently identifying and representing consistent logical forms in learning semantic parsers from denotations, and filtering out spurious logical forms, be addressed by using dynamic programming to efficiently represent the complete set of consistent logical forms and generating fictitious worlds with crowdsourced denotations?",1.0,2.0,1.0
148,Context-Aware Neural Model for Temporal Information Extraction,"Yuanliang Meng and Anna Rumshisky. 2018. Context-Aware Neural Model for Temporal Information Extraction. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 527–536, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1049.pdf,https://aclanthology.org/P18-1049/,"We propose a context-aware neural network model for temporal information extraction, with a uniform architecture for event-event, event-timex and timex-timex pairs. A Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM), stores processed temporal relations in the narrative order, and retrieves them for use when the relevant entities are encountered. Relations are then classified in this larger context. The GCL model uses long-term memory and attention mechanisms to resolve long-distance dependencies that regular RNNs cannot recognize. GCL does not use postprocessing to resolve timegraph conflicts, outperforming previous approaches that do so. To our knowledge, GCL is also the first model to use an NTM-like architecture to incorporate the information about global context into discourse-scale processing of natural text.","Extracting information about the order and timing of events from text is crucial to any system that attempts an in-depth natural language understanding, whether related to question answering, temporal inference, or other related tasks. Earlier temporal information extraction (TemporalIE) systems tended to rely on traditional statistical learning with feature-engineered task-specific models, typically used in succession (Yoshikawa et al., 2009; Ling and Weld, 2010; Sun et al., 2013; Chambers et al., 2014; Mirza and Minard, 2015). Recently, there have been some attempts to extract temporal relations with neural network models, particularly with recurrent neural networks (RNN) models (Meng et al., 2017; Cheng and Miyao, 2017; Tourille et al., 2017) and convolutional neural networks (CNN) (Lin et al., 2017). These models predominantly use token embeddings as input, avoiding handcrafted features for each task. Typically, neural network models outperform traditional statistical models. Some studies also try to combine neural network models with rule-based information retrieval methods (Fries, 2016). These systems require different models for different pair types, so several models must be combined to fully process text. A common disadvantage of all these models is that they build relations from isolated pairs of entities (events or temporal expressions). This context-blind, pairwise classification often generates conflicts in the resulting timegraph. Common ways of ameliorating the conflicts is to apply some ad hoc constraints to account for basic properties of relations (e.g. transitivity), often without considering the content of the text per se. For example, Ling and Weld (2010) designed transitivity formulae, used with local features. Sun (2014) proposed a strategy that “prefers the edges that can be inferred by other edges in the graph and remove the ones that are least so”. Another approach is to use the results from separate classifiers to rank results according to their general confidence (Mani et al., 2007; Chambers et al., 2014). High-ranking results overwrite low-ranking ones. Meng et al. (2017) used a greedy pruning algorithm to remove weak edges from the timegraph until it is coherent. When humans read text, we certainly do not follow the procedure of interpreting interpret relations only locally first, and later come up with a compromise solution that involves all the entities. Instead, if local information is insufficient, we consider the relevant information from the wider context, and resolve the ambiguity as soon as possible. The resolved relations are stored in our memory as “context” for further processing. If the later evidence suggests our early interpretation was wrong, we can correct it. This paper proposes a model to simulate such mechanisms. Our model introduces a Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM) architecture (Graves et al., 2014), to store processed relations in narrative order, and retrieve them for use when related entities are encountered. The stored information can also be updated if necessary, allowing for self-correction. This paper’s contributions are as follows. To our knowledge, this is the first attempt to use neural network models with updateable external memory to incorporate global context information for discourse-level processing of natural text in general and for temporal relation extraction in particular. It gives a uniform treatment of all pairs of temporally relevant entities. We obtain stateof-the-art results on TimeBank-Dense, which is a standard benchmark for TemporalIE.","How does the proposed Global Context Layer (GCL) model, inspired by the Neural Turing Machine architecture, enhance the extraction of temporal relations from text by incorporating global context information, compare to traditional statistical models and neural network models that do not utilize an external updateable memory system?",2.0,2.0,1.0
149,Context-Aware Neural Model for Temporal Information Extraction,"Yuanliang Meng and Anna Rumshisky. 2018. Context-Aware Neural Model for Temporal Information Extraction. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 527–536, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1049.pdf,https://aclanthology.org/P18-1049/,"We propose a context-aware neural network model for temporal information extraction, with a uniform architecture for event-event, event-timex and timex-timex pairs. A Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM), stores processed temporal relations in the narrative order, and retrieves them for use when the relevant entities are encountered. Relations are then classified in this larger context. The GCL model uses long-term memory and attention mechanisms to resolve long-distance dependencies that regular RNNs cannot recognize. GCL does not use postprocessing to resolve timegraph conflicts, outperforming previous approaches that do so. To our knowledge, GCL is also the first model to use an NTM-like architecture to incorporate the information about global context into discourse-scale processing of natural text.","Extracting information about the order and timing of events from text is crucial to any system that attempts an in-depth natural language understanding, whether related to question answering, temporal inference, or other related tasks. Earlier temporal information extraction (TemporalIE) systems tended to rely on traditional statistical learning with feature-engineered task-specific models, typically used in succession (Yoshikawa et al., 2009; Ling and Weld, 2010; Sun et al., 2013; Chambers et al., 2014; Mirza and Minard, 2015). Recently, there have been some attempts to extract temporal relations with neural network models, particularly with recurrent neural networks (RNN) models (Meng et al., 2017; Cheng and Miyao, 2017; Tourille et al., 2017) and convolutional neural networks (CNN) (Lin et al., 2017). These models predominantly use token embeddings as input, avoiding handcrafted features for each task. Typically, neural network models outperform traditional statistical models. Some studies also try to combine neural network models with rule-based information retrieval methods (Fries, 2016). These systems require different models for different pair types, so several models must be combined to fully process text. A common disadvantage of all these models is that they build relations from isolated pairs of entities (events or temporal expressions). This context-blind, pairwise classification often generates conflicts in the resulting timegraph. Common ways of ameliorating the conflicts is to apply some ad hoc constraints to account for basic properties of relations (e.g. transitivity), often without considering the content of the text per se. For example, Ling and Weld (2010) designed transitivity formulae, used with local features. Sun (2014) proposed a strategy that “prefers the edges that can be inferred by other edges in the graph and remove the ones that are least so”. Another approach is to use the results from separate classifiers to rank results according to their general confidence (Mani et al., 2007; Chambers et al., 2014). High-ranking results overwrite low-ranking ones. Meng et al. (2017) used a greedy pruning algorithm to remove weak edges from the timegraph until it is coherent. When humans read text, we certainly do not follow the procedure of interpreting interpret relations only locally first, and later come up with a compromise solution that involves all the entities. Instead, if local information is insufficient, we consider the relevant information from the wider context, and resolve the ambiguity as soon as possible. The resolved relations are stored in our memory as “context” for further processing. If the later evidence suggests our early interpretation was wrong, we can correct it. This paper proposes a model to simulate such mechanisms. Our model introduces a Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM) architecture (Graves et al., 2014), to store processed relations in narrative order, and retrieve them for use when related entities are encountered. The stored information can also be updated if necessary, allowing for self-correction. This paper’s contributions are as follows. To our knowledge, this is the first attempt to use neural network models with updateable external memory to incorporate global context information for discourse-level processing of natural text in general and for temporal relation extraction in particular. It gives a uniform treatment of all pairs of temporally relevant entities. We obtain stateof-the-art results on TimeBank-Dense, which is a standard benchmark for TemporalIE.",Can temporal information extraction be improved by using a context-aware neural network model that incorporates a Global Context Layer inspired by the Neural Turing Machine architecture?,1.0,2.0,1.0
150,Context-Aware Neural Model for Temporal Information Extraction,"Yuanliang Meng and Anna Rumshisky. 2018. Context-Aware Neural Model for Temporal Information Extraction. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 527–536, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1049.pdf,https://aclanthology.org/P18-1049/,"We propose a context-aware neural network model for temporal information extraction, with a uniform architecture for event-event, event-timex and timex-timex pairs. A Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM), stores processed temporal relations in the narrative order, and retrieves them for use when the relevant entities are encountered. Relations are then classified in this larger context. The GCL model uses long-term memory and attention mechanisms to resolve long-distance dependencies that regular RNNs cannot recognize. GCL does not use postprocessing to resolve timegraph conflicts, outperforming previous approaches that do so. To our knowledge, GCL is also the first model to use an NTM-like architecture to incorporate the information about global context into discourse-scale processing of natural text.","Extracting information about the order and timing of events from text is crucial to any system that attempts an in-depth natural language understanding, whether related to question answering, temporal inference, or other related tasks. Earlier temporal information extraction (TemporalIE) systems tended to rely on traditional statistical learning with feature-engineered task-specific models, typically used in succession (Yoshikawa et al., 2009; Ling and Weld, 2010; Sun et al., 2013; Chambers et al., 2014; Mirza and Minard, 2015). Recently, there have been some attempts to extract temporal relations with neural network models, particularly with recurrent neural networks (RNN) models (Meng et al., 2017; Cheng and Miyao, 2017; Tourille et al., 2017) and convolutional neural networks (CNN) (Lin et al., 2017). These models predominantly use token embeddings as input, avoiding handcrafted features for each task. Typically, neural network models outperform traditional statistical models. Some studies also try to combine neural network models with rule-based information retrieval methods (Fries, 2016). These systems require different models for different pair types, so several models must be combined to fully process text. A common disadvantage of all these models is that they build relations from isolated pairs of entities (events or temporal expressions). This context-blind, pairwise classification often generates conflicts in the resulting timegraph. Common ways of ameliorating the conflicts is to apply some ad hoc constraints to account for basic properties of relations (e.g. transitivity), often without considering the content of the text per se. For example, Ling and Weld (2010) designed transitivity formulae, used with local features. Sun (2014) proposed a strategy that “prefers the edges that can be inferred by other edges in the graph and remove the ones that are least so”. Another approach is to use the results from separate classifiers to rank results according to their general confidence (Mani et al., 2007; Chambers et al., 2014). High-ranking results overwrite low-ranking ones. Meng et al. (2017) used a greedy pruning algorithm to remove weak edges from the timegraph until it is coherent. When humans read text, we certainly do not follow the procedure of interpreting interpret relations only locally first, and later come up with a compromise solution that involves all the entities. Instead, if local information is insufficient, we consider the relevant information from the wider context, and resolve the ambiguity as soon as possible. The resolved relations are stored in our memory as “context” for further processing. If the later evidence suggests our early interpretation was wrong, we can correct it. This paper proposes a model to simulate such mechanisms. Our model introduces a Global Context Layer (GCL), inspired by the Neural Turing Machine (NTM) architecture (Graves et al., 2014), to store processed relations in narrative order, and retrieve them for use when related entities are encountered. The stored information can also be updated if necessary, allowing for self-correction. This paper’s contributions are as follows. To our knowledge, this is the first attempt to use neural network models with updateable external memory to incorporate global context information for discourse-level processing of natural text in general and for temporal relation extraction in particular. It gives a uniform treatment of all pairs of temporally relevant entities. We obtain stateof-the-art results on TimeBank-Dense, which is a standard benchmark for TemporalIE.","Can the accurate extraction of temporal information from text, overcoming the limitations of traditional statistical models and context-blind neural network models, be achieved through a neural network model with a Neural Turing Machine-like architecture that incorporates global context information and long-term memory?",1.0,2.0,1.0
151,UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System,"Zhiyuan Ma, Jianjun Li, Guohui Li, and Yongjing Cheng. 2022. UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 103–114, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.9.pdf,https://aclanthology.org/2022.acl-long.9/,"As a more natural and intelligent interaction manner, multimodal task-oriented dialog system recently has received great attention and many remarkable progresses have been achieved. Nevertheless, almost all existing studies follow the pipeline to first learn intra-modal features separately and then conduct simple feature concatenation or attention-based feature fusion to generate responses, which hampers them from learning inter-modal interactions and conducting crossmodal feature alignment for generating more intention-aware responses. To address these issues, we propose UniTranSeR, a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning for multimodal dialog systems. Specifically, we first embed the multimodal features into a unified Transformer semantic space to prompt inter-modal interactions, and then devise a feature alignment and intention reasoning (FAIR) layer to perform cross-modal entity alignment and fine-grained key-value reasoning, so as to effectively identify user’s intention for generating more accurate responses. Experimental results verify the effectiveness of UniTranSeR, showing that it significantly outperforms state-of-the-art approaches on the representative MMD dataset.","The multimodal task-oriented dialog systems are designed to help users achieve specific goals such as clothing recommendation or restaurant reservation, which is in growing demand in the current business environment. As a leading study, Saha et al. (2018) released a multimodal dialog dataset (MMD) in the online retail domain. Based on such a benchmark dataset, many multimodal dialog models incorporating domain knowledge have recently been proposed (Chauhan et al., 2019; Zhang et al., 2019, 2021), which basically exploit taxonomybased method (Liao et al., 2018; Cui et al., 2019) or attention-based method (Nie et al., 2019; He et al., 2020) to incorporate knowledge base (KB) information for better performance. Though achieving remarkable progress, existing multimodal task-oriented dialog systems still suffer from the following three limitations. Firstly, prior models only learn the intra-modal features (including textual features, visual features and domain knowledge) separately before fusing them. Since these multimodal cues in general can enhance and complement each other, projecting them into a unified semantic space to learn the inter-modal features, with no doubt, can help improve the abilities of natural language understanding, which in turn will benefit the response generation. Secondly, prior models only conduct simple feature concatenation (Saha et al., 2018; Nie et al., 2019) or attention-based feature fusion (Cui et al., 2019) after acquiring intra-modal representations, but without learning fine-grained alignment between different modalities before fusion, which is not favorable to query knowledge for accurate multimodal response generation. Take the dialog in Figure 1 as an example, when answering the user’s query on similar style of jackets, the model is expected to align the word “jackets” with the corresponding visual features for proper semantic complement and entity enhancement. Thirdly, prior models basically lack the capability of entity-level reasoning, which prevents them from performing reasoning over crucial entities to guide intention-aware response generation. For example, in Figure 1, when the user asks “show some similar jackets in black color”, the chatbot is expected to properly explore the pivot attribute “black” that connects the start query cue “jackets” with the target recommended product images. Specifically, the model needs to perform a 2-hop reasoning over triples (jacket_q, attribute, black_v) and (black_q, image, jacket_v) and obtain the intended 4 images. To address the aforementioned limitations, we propose a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning, UniTranSeR for short. Specifically, to address the first limitation, we stand on the shoulder of Vision-and-Language Pre-training (VLP) methods (Lu et al., 2019; Li et al., 2019; Chen et al., 2020; Li et al., 2021) to propose a unified-modal Transformer encoder, which is used to project all the multimodal features into a unified semantic space to prompt inter-modality interactions, with the objective of learning better representations. Based on the unified encoder, we further address the second limitation by designing a feature alignment module to perform cross-modal feature alignment. Finally, to address the third limitation, we devise a fine-grained intention reasoning module for capturing users’ real intentions, by leveraging a key-value attention based memory mechanism to perform multi-hop knowledge query for generating text or image responses. We conduct experiments on MMD, one of the most influential benchmark datasets for multimodal dialog generation. We follow the mainstream evaluation script of dialog generation and demonstrate that UniTranSeR significantly outperforms the current state-of-the-art baselines. Ablation study also shows the efficacy of each component in improving the performance of dialog generation, and a further case study reveals that our model can effectively perform fine-grained token-level feature alignment for multimodal dialog generation.","How can a multimodal dialog system effectively integrate inter-modal interactions, cross-modal feature alignment, and intention reasoning to generate more accurate and intention-aware responses in task-oriented dialogues?",0.0,1.0,1.0
152,UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System,"Zhiyuan Ma, Jianjun Li, Guohui Li, and Yongjing Cheng. 2022. UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 103–114, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.9.pdf,https://aclanthology.org/2022.acl-long.9/,"As a more natural and intelligent interaction manner, multimodal task-oriented dialog system recently has received great attention and many remarkable progresses have been achieved. Nevertheless, almost all existing studies follow the pipeline to first learn intra-modal features separately and then conduct simple feature concatenation or attention-based feature fusion to generate responses, which hampers them from learning inter-modal interactions and conducting crossmodal feature alignment for generating more intention-aware responses. To address these issues, we propose UniTranSeR, a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning for multimodal dialog systems. Specifically, we first embed the multimodal features into a unified Transformer semantic space to prompt inter-modal interactions, and then devise a feature alignment and intention reasoning (FAIR) layer to perform cross-modal entity alignment and fine-grained key-value reasoning, so as to effectively identify user’s intention for generating more accurate responses. Experimental results verify the effectiveness of UniTranSeR, showing that it significantly outperforms state-of-the-art approaches on the representative MMD dataset.","The multimodal task-oriented dialog systems are designed to help users achieve specific goals such as clothing recommendation or restaurant reservation, which is in growing demand in the current business environment. As a leading study, Saha et al. (2018) released a multimodal dialog dataset (MMD) in the online retail domain. Based on such a benchmark dataset, many multimodal dialog models incorporating domain knowledge have recently been proposed (Chauhan et al., 2019; Zhang et al., 2019, 2021), which basically exploit taxonomybased method (Liao et al., 2018; Cui et al., 2019) or attention-based method (Nie et al., 2019; He et al., 2020) to incorporate knowledge base (KB) information for better performance. Though achieving remarkable progress, existing multimodal task-oriented dialog systems still suffer from the following three limitations. Firstly, prior models only learn the intra-modal features (including textual features, visual features and domain knowledge) separately before fusing them. Since these multimodal cues in general can enhance and complement each other, projecting them into a unified semantic space to learn the inter-modal features, with no doubt, can help improve the abilities of natural language understanding, which in turn will benefit the response generation. Secondly, prior models only conduct simple feature concatenation (Saha et al., 2018; Nie et al., 2019) or attention-based feature fusion (Cui et al., 2019) after acquiring intra-modal representations, but without learning fine-grained alignment between different modalities before fusion, which is not favorable to query knowledge for accurate multimodal response generation. Take the dialog in Figure 1 as an example, when answering the user’s query on similar style of jackets, the model is expected to align the word “jackets” with the corresponding visual features for proper semantic complement and entity enhancement. Thirdly, prior models basically lack the capability of entity-level reasoning, which prevents them from performing reasoning over crucial entities to guide intention-aware response generation. For example, in Figure 1, when the user asks “show some similar jackets in black color”, the chatbot is expected to properly explore the pivot attribute “black” that connects the start query cue “jackets” with the target recommended product images. Specifically, the model needs to perform a 2-hop reasoning over triples (jacket_q, attribute, black_v) and (black_q, image, jacket_v) and obtain the intended 4 images. To address the aforementioned limitations, we propose a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning, UniTranSeR for short. Specifically, to address the first limitation, we stand on the shoulder of Vision-and-Language Pre-training (VLP) methods (Lu et al., 2019; Li et al., 2019; Chen et al., 2020; Li et al., 2021) to propose a unified-modal Transformer encoder, which is used to project all the multimodal features into a unified semantic space to prompt inter-modality interactions, with the objective of learning better representations. Based on the unified encoder, we further address the second limitation by designing a feature alignment module to perform cross-modal feature alignment. Finally, to address the third limitation, we devise a fine-grained intention reasoning module for capturing users’ real intentions, by leveraging a key-value attention based memory mechanism to perform multi-hop knowledge query for generating text or image responses. We conduct experiments on MMD, one of the most influential benchmark datasets for multimodal dialog generation. We follow the mainstream evaluation script of dialog generation and demonstrate that UniTranSeR significantly outperforms the current state-of-the-art baselines. Ablation study also shows the efficacy of each component in improving the performance of dialog generation, and a further case study reveals that our model can effectively perform fine-grained token-level feature alignment for multimodal dialog generation.",Can generating more accurate and intention-aware responses in multimodal task-oriented dialog systems be achieved by employing a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning?,0.0,1.0,1.0
153,UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System,"Zhiyuan Ma, Jianjun Li, Guohui Li, and Yongjing Cheng. 2022. UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 103–114, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.9.pdf,https://aclanthology.org/2022.acl-long.9/,"As a more natural and intelligent interaction manner, multimodal task-oriented dialog system recently has received great attention and many remarkable progresses have been achieved. Nevertheless, almost all existing studies follow the pipeline to first learn intra-modal features separately and then conduct simple feature concatenation or attention-based feature fusion to generate responses, which hampers them from learning inter-modal interactions and conducting crossmodal feature alignment for generating more intention-aware responses. To address these issues, we propose UniTranSeR, a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning for multimodal dialog systems. Specifically, we first embed the multimodal features into a unified Transformer semantic space to prompt inter-modal interactions, and then devise a feature alignment and intention reasoning (FAIR) layer to perform cross-modal entity alignment and fine-grained key-value reasoning, so as to effectively identify user’s intention for generating more accurate responses. Experimental results verify the effectiveness of UniTranSeR, showing that it significantly outperforms state-of-the-art approaches on the representative MMD dataset.","The multimodal task-oriented dialog systems are designed to help users achieve specific goals such as clothing recommendation or restaurant reservation, which is in growing demand in the current business environment. As a leading study, Saha et al. (2018) released a multimodal dialog dataset (MMD) in the online retail domain. Based on such a benchmark dataset, many multimodal dialog models incorporating domain knowledge have recently been proposed (Chauhan et al., 2019; Zhang et al., 2019, 2021), which basically exploit taxonomybased method (Liao et al., 2018; Cui et al., 2019) or attention-based method (Nie et al., 2019; He et al., 2020) to incorporate knowledge base (KB) information for better performance. Though achieving remarkable progress, existing multimodal task-oriented dialog systems still suffer from the following three limitations. Firstly, prior models only learn the intra-modal features (including textual features, visual features and domain knowledge) separately before fusing them. Since these multimodal cues in general can enhance and complement each other, projecting them into a unified semantic space to learn the inter-modal features, with no doubt, can help improve the abilities of natural language understanding, which in turn will benefit the response generation. Secondly, prior models only conduct simple feature concatenation (Saha et al., 2018; Nie et al., 2019) or attention-based feature fusion (Cui et al., 2019) after acquiring intra-modal representations, but without learning fine-grained alignment between different modalities before fusion, which is not favorable to query knowledge for accurate multimodal response generation. Take the dialog in Figure 1 as an example, when answering the user’s query on similar style of jackets, the model is expected to align the word “jackets” with the corresponding visual features for proper semantic complement and entity enhancement. Thirdly, prior models basically lack the capability of entity-level reasoning, which prevents them from performing reasoning over crucial entities to guide intention-aware response generation. For example, in Figure 1, when the user asks “show some similar jackets in black color”, the chatbot is expected to properly explore the pivot attribute “black” that connects the start query cue “jackets” with the target recommended product images. Specifically, the model needs to perform a 2-hop reasoning over triples (jacket_q, attribute, black_v) and (black_q, image, jacket_v) and obtain the intended 4 images. To address the aforementioned limitations, we propose a Unified Transformer Semantic Representation framework with feature alignment and intention reasoning, UniTranSeR for short. Specifically, to address the first limitation, we stand on the shoulder of Vision-and-Language Pre-training (VLP) methods (Lu et al., 2019; Li et al., 2019; Chen et al., 2020; Li et al., 2021) to propose a unified-modal Transformer encoder, which is used to project all the multimodal features into a unified semantic space to prompt inter-modality interactions, with the objective of learning better representations. Based on the unified encoder, we further address the second limitation by designing a feature alignment module to perform cross-modal feature alignment. Finally, to address the third limitation, we devise a fine-grained intention reasoning module for capturing users’ real intentions, by leveraging a key-value attention based memory mechanism to perform multi-hop knowledge query for generating text or image responses. We conduct experiments on MMD, one of the most influential benchmark datasets for multimodal dialog generation. We follow the mainstream evaluation script of dialog generation and demonstrate that UniTranSeR significantly outperforms the current state-of-the-art baselines. Ablation study also shows the efficacy of each component in improving the performance of dialog generation, and a further case study reveals that our model can effectively perform fine-grained token-level feature alignment for multimodal dialog generation.","Can the limitations of existing multimodal task-oriented dialog systems in learning inter-modal interactions, conducting cross-modal feature alignment, and performing fine-grained intention reasoning be addressed by the UniTranSeR framework, which embeds multimodal features into a unified Transformer semantic space and devises a feature alignment and intention reasoning (FAIR) layer?",2.0,2.0,1.0
154,Semantic Scaffolds for Pseudocode-to-Code Generation,"Ruiqi Zhong, Mitchell Stern, and Dan Klein. 2020. Semantic Scaffolds for Pseudocode-to-Code Generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2283–2295, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.208.pdf,https://aclanthology.org/2020.acl-main.208/,"We propose a method for program generation based on semantic scaffolds, lightweight structures representing the high-level semantic and syntactic composition of a program. By first searching over plausible scaffolds then using these as constraints for a beam search over programs, we achieve better coverage of the search space when compared with existing techniques. We apply our hierarchical search method to the SPoC dataset for pseudocodeto-code generation, in which we are given line-level natural language pseudocode annotations and aim to produce a program satisfying execution-based test cases. By using semantic scaffolds during inference, we achieve a 10% absolute improvement in top-100 accuracy over the previous state-of-the-art. Additionally, we require only 11 candidates to reach the top-3000 performance of the previous best approach when tested against unseen problems, demonstrating a substantial improvement in efficiency.","Systems that can map from natural language descriptions of tasks or programs to executable code have the potential for great societal impact, helping to bridge the gap between non-expert users and basic automation or full-fledged software development. Accordingly, this area of research has garnered significant interest in recent years, with systems being devised for the translation of natural language specifications into database queries (Wang et al., 2018), if-then programs (Chen et al., 2016), game elements (Ling et al., 2016), and more. While much of the prior work in executable semantic parsing involves short descriptions being mapped into single-line programs, some tasks have recently been proposed that involve multiple natural language utterances on the input side and full programs on the output side, often reaching tens of lines in length and including non-trivial state manipulation. Examples include the Magic the Gathering and Hearthstone datasets (Ling et al., 2016) derived from trading cards and Java or Python classes implementing their behavior in a game engine, the CONCODE dataset (Iyer et al., 2018) consisting of Java documentation strings and method bodies, and the NAPS and SPoC datasets (Zavershynskyi et al., 2018; Kulal et al., 2019) consisting of pseudocode annotations and source code for programming competition problems. Past approaches to these large-scale languageto-code tasks have typically employed sequencebased models (Ling et al., 2016) that do not account for structure on the output side, or tree-based models (Allamanis et al., 2015; Rabinovich et al., 2017a; Yin and Neubig, 2017; Hayati et al., 2018; Iyer et al., 2019) that incorporate the syntax but not the semantics of the output domain. However, if we want to generate programs that can be executed successfully, the inclusion of both syntactic and semantic constraints is crucial. As shown in Figure 1, while multiple program fragments may be syntactically correct and represent plausible translations of the corresponding pseudocode, not all of them will lead to executable programs. To address this, we propose a search procedure based on semantic scaffolds, lightweight summaries of higher-level program structure that include both syntactic information as well as semantic features such as variable declarations and scope constraints. See Section 3 for a more formal definition. While these do not encode the full spectrum of constraints used in some formal program synthesis tools (Solar-Lezama, 2009; Gulwani et al., 2017), they strike a balance between utility, speed, and ease of use, offering substantial improvements in system performance without a significant increase in complexity. In this work we focus on the Search-based Pseudocode to Code (SPoC) dataset (Kulal et al., 2019) due to its challenging multiline programs and availability of input-output test suites to evaluate denotation accuracy. The dataset contains line-level pseudocode annotations for 18,356 C++ programs provided by crowdsource workers from Amazon Mechanical Turk. As in the approach of Kulal et al. (2019), we first obtain candidate code fragments for each line using an off-the-shelf neural machine translation system. We then aim to find the highestscoring combination of fragments that results in a valid program. Although finding the optimal program under this setting is NP-hard when variable usage constraints are introduced (see Section A.3), we can approximate it with a hierarchical beam search. Our algorithm first searches for semantic scaffolds for the program, then assembles fragments together conditioned on these scaffolds. This hierarchical approach speeds up search, produces higher quality variations, and leads to substantial improvements in our system’s final accuracy. We achieve a new state-of-the-art by solving 55.1% of the test cases within 100 attempts. This represents a 10.4% absolute improvement over the previous best (Kulal et al., 2019), and reaches 81% of our model’s oracle performance. When tested against unseen problems (or crowd-workers), our top 11 (or top 52, respectively) candidates have the same performance as their top 3000 candidates, demonstrating marked gains in efficiency. We complement our results with a discussion of specific cases in which our semantic scaffolds use global program context to resolve ambiguities in the pseudocode. We also conduct a manual error analysis of 200 failures to better characterize the limitations of our method and suggest possible extensions for future work. Our contributions are summarized as follows: • We propose the use of semantic scaffolds to add semantic constraints to models for longform language-to-code generation tasks. • We introduce a hierarchical beam search algorithm that incorporates these constraints, resulting in heightened efficiency, better coverage of the search space, and stronger performance when compared with the standard approach. • We achieve a new state-of-the-art accuracy of 55.1% on the SPoC pseudocode-to-code dataset.",Can the problem of generating executable programs from line-level natural language pseudocode annotations be solved by employing a hierarchical search method that leverages semantic scaffolds for better search space coverage and performance improvement?,0.0,1.0,1.0
155,A Synthetic Data Generation Framework for Grounded Dialogues,"Jianzhu Bao, Rui Wang, Yasheng Wang, Aixin Sun, Yitong Li, Fei Mi, and Ruifeng Xu. 2023. A Synthetic Data Generation Framework for Grounded Dialogues. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10866–10882, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.608.pdf,https://aclanthology.org/2023.acl-long.608/,"Training grounded response generation models often requires a large collection of grounded dialogues. However, it is costly to build such dialogues. In this paper, we present a synthetic data generation framework (SynDG) for grounded dialogues. The generation process utilizes large pre-trained language models and freely available knowledge data (e.g., Wikipedia pages, persona profiles, etc.). The key idea of designing SynDG is to consider dialogue flow and coherence in the generation process. Specifically, given knowledge data, we first heuristically determine a dialogue flow, which is a series of knowledge pieces. Then, we employ T5 to incrementally turn the dialogue flow into a dialogue. To ensure coherence of both the dialogue flow and the synthetic dialogue, we design a two-level filtering strategy, at the flow-level and the utterance-level respectively. Experiments on two public benchmarks show that the synthetic grounded dialogue data produced by our framework is able to significantly boost model performance in both full training data and low-resource scenarios.","Grounded dialogue systems are designed to engage in conversation with humans by incorporating external knowledge to provide relevant and informative responses (Ghazvininejad et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Zhou et al., 2018b). In recent years, various advanced techniques have been developed to train grounded dialogue models (Zheng et al., 2020; Cui et al., 2021; Xu et al., 2022; Li et al., 2022a). Despite the notable progress, training these models often requires large amounts of data. However, it is expensive and time-consuming to build a collection of dialogue data that is naturally grounded on documents or knowledge (Li et al., 2020, 2022b). One solution is to generate grounded dialogue data from unstructured knowledge, by using large pre-trained language models (LMs). Previous work on this topic has explored synthetic dialogue data generation with reinforcement learning (Lin et al., 2022) or user simulation (Wu et al., 2022). However, a key missing component in all these methods is the modeling of dialogue flow. Dialogue flow can be viewed as the outline of a dialogue. The flow reflects the dialogue’s content and trajectory, i.e., the topics discussed in each session and the topic shifts between sessions. We consider the dialogue flow of a grounded dialogue as the sequence of the grounded knowledge pieces. Figure 1 shows an example dialogue along with its associated dialogue flow. In this example, the grounded knowledge is primarily from a Wikipedia page about “husky” dogs. This dialogue follows a smooth knowledge flow, transitioning from “husky” to “sled dogs” and then to “huskies as pets”. However, if we replace the second knowledge piece with “‘Esquimaux’ or ‘Eskimo’ was a common term for pre-Columbian Arctic inhabitants of North America.”, which is also from the same Wikipedia page, then the flow becomes less consistent. As the backbone guiding the dialogue generation process, a carefully planned dialogue flow is crucial for the coherence and smoothness of the resulting dialogue. To this end, we propose a novel framework named SynDG, to synthetically generate coherent grounded dialogues. The generated dialogues are meant to be used as auxiliary training data. In SynDG, we first determine the dialogue flow by task-specific heuristics, from the unstructured knowledge data (e.g., Wikipedia pages, persona profiles, etc.). Then, we employ T5 (Raffel et al., 2020), a large pre-trained LM, to transform the dialogue flow into a synthetic dialogue, with sequential utterance generation, one at a time. To ensure the quality of the synthetic dialogue, we propose a two-level filtering strategy based on T5: flow-level filtering and utterance-level filtering. The flowlevel filtering is designed to select dialogue flows with higher consistency, whereas the utterancelevel filtering aims to eliminate the synthetic dialogues with poor coherence. We conduct experiments on two grounded dialogue benchmarks, in both full training data and low-resource scenarios. We use the synthetic grounded dialogue data produced by our framework as additional training data for commonly used grounded dialogue models. Both the automatic and human evaluation results show that our synthetic data leads to significant improvement on model performance. Further analysis also reveals that model performance increases along the increase in the number of synthetic dialogues.","How does the SynDG framework utilize large pre-trained language models and freely available knowledge data to generate synthetic grounded dialogues, and how does this process, including a two-level filtering strategy, enhance model performance in both full training data and low-resource scenarios?",1.0,1.0,1.0
156,A Synthetic Data Generation Framework for Grounded Dialogues,"Jianzhu Bao, Rui Wang, Yasheng Wang, Aixin Sun, Yitong Li, Fei Mi, and Ruifeng Xu. 2023. A Synthetic Data Generation Framework for Grounded Dialogues. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10866–10882, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.608.pdf,https://aclanthology.org/2023.acl-long.608/,"Training grounded response generation models often requires a large collection of grounded dialogues. However, it is costly to build such dialogues. In this paper, we present a synthetic data generation framework (SynDG) for grounded dialogues. The generation process utilizes large pre-trained language models and freely available knowledge data (e.g., Wikipedia pages, persona profiles, etc.). The key idea of designing SynDG is to consider dialogue flow and coherence in the generation process. Specifically, given knowledge data, we first heuristically determine a dialogue flow, which is a series of knowledge pieces. Then, we employ T5 to incrementally turn the dialogue flow into a dialogue. To ensure coherence of both the dialogue flow and the synthetic dialogue, we design a two-level filtering strategy, at the flow-level and the utterance-level respectively. Experiments on two public benchmarks show that the synthetic grounded dialogue data produced by our framework is able to significantly boost model performance in both full training data and low-resource scenarios.","Grounded dialogue systems are designed to engage in conversation with humans by incorporating external knowledge to provide relevant and informative responses (Ghazvininejad et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Zhou et al., 2018b). In recent years, various advanced techniques have been developed to train grounded dialogue models (Zheng et al., 2020; Cui et al., 2021; Xu et al., 2022; Li et al., 2022a). Despite the notable progress, training these models often requires large amounts of data. However, it is expensive and time-consuming to build a collection of dialogue data that is naturally grounded on documents or knowledge (Li et al., 2020, 2022b). One solution is to generate grounded dialogue data from unstructured knowledge, by using large pre-trained language models (LMs). Previous work on this topic has explored synthetic dialogue data generation with reinforcement learning (Lin et al., 2022) or user simulation (Wu et al., 2022). However, a key missing component in all these methods is the modeling of dialogue flow. Dialogue flow can be viewed as the outline of a dialogue. The flow reflects the dialogue’s content and trajectory, i.e., the topics discussed in each session and the topic shifts between sessions. We consider the dialogue flow of a grounded dialogue as the sequence of the grounded knowledge pieces. Figure 1 shows an example dialogue along with its associated dialogue flow. In this example, the grounded knowledge is primarily from a Wikipedia page about “husky” dogs. This dialogue follows a smooth knowledge flow, transitioning from “husky” to “sled dogs” and then to “huskies as pets”. However, if we replace the second knowledge piece with “‘Esquimaux’ or ‘Eskimo’ was a common term for pre-Columbian Arctic inhabitants of North America.”, which is also from the same Wikipedia page, then the flow becomes less consistent. As the backbone guiding the dialogue generation process, a carefully planned dialogue flow is crucial for the coherence and smoothness of the resulting dialogue. To this end, we propose a novel framework named SynDG, to synthetically generate coherent grounded dialogues. The generated dialogues are meant to be used as auxiliary training data. In SynDG, we first determine the dialogue flow by task-specific heuristics, from the unstructured knowledge data (e.g., Wikipedia pages, persona profiles, etc.). Then, we employ T5 (Raffel et al., 2020), a large pre-trained LM, to transform the dialogue flow into a synthetic dialogue, with sequential utterance generation, one at a time. To ensure the quality of the synthetic dialogue, we propose a two-level filtering strategy based on T5: flow-level filtering and utterance-level filtering. The flowlevel filtering is designed to select dialogue flows with higher consistency, whereas the utterancelevel filtering aims to eliminate the synthetic dialogues with poor coherence. We conduct experiments on two grounded dialogue benchmarks, in both full training data and low-resource scenarios. We use the synthetic grounded dialogue data produced by our framework as additional training data for commonly used grounded dialogue models. Both the automatic and human evaluation results show that our synthetic data leads to significant improvement on model performance. Further analysis also reveals that model performance increases along the increase in the number of synthetic dialogues.",Can the quality and coherence of synthetic grounded dialogues be improved by using a synthetic data generation framework (SynDG) that employs large pre-trained language models and a two-level filtering strategy?,1.0,1.0,1.0
157,A Synthetic Data Generation Framework for Grounded Dialogues,"Jianzhu Bao, Rui Wang, Yasheng Wang, Aixin Sun, Yitong Li, Fei Mi, and Ruifeng Xu. 2023. A Synthetic Data Generation Framework for Grounded Dialogues. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10866–10882, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.608.pdf,https://aclanthology.org/2023.acl-long.608/,"Training grounded response generation models often requires a large collection of grounded dialogues. However, it is costly to build such dialogues. In this paper, we present a synthetic data generation framework (SynDG) for grounded dialogues. The generation process utilizes large pre-trained language models and freely available knowledge data (e.g., Wikipedia pages, persona profiles, etc.). The key idea of designing SynDG is to consider dialogue flow and coherence in the generation process. Specifically, given knowledge data, we first heuristically determine a dialogue flow, which is a series of knowledge pieces. Then, we employ T5 to incrementally turn the dialogue flow into a dialogue. To ensure coherence of both the dialogue flow and the synthetic dialogue, we design a two-level filtering strategy, at the flow-level and the utterance-level respectively. Experiments on two public benchmarks show that the synthetic grounded dialogue data produced by our framework is able to significantly boost model performance in both full training data and low-resource scenarios.","Grounded dialogue systems are designed to engage in conversation with humans by incorporating external knowledge to provide relevant and informative responses (Ghazvininejad et al., 2018; Dinan et al., 2019; Gopalakrishnan et al., 2019; Zhou et al., 2018b). In recent years, various advanced techniques have been developed to train grounded dialogue models (Zheng et al., 2020; Cui et al., 2021; Xu et al., 2022; Li et al., 2022a). Despite the notable progress, training these models often requires large amounts of data. However, it is expensive and time-consuming to build a collection of dialogue data that is naturally grounded on documents or knowledge (Li et al., 2020, 2022b). One solution is to generate grounded dialogue data from unstructured knowledge, by using large pre-trained language models (LMs). Previous work on this topic has explored synthetic dialogue data generation with reinforcement learning (Lin et al., 2022) or user simulation (Wu et al., 2022). However, a key missing component in all these methods is the modeling of dialogue flow. Dialogue flow can be viewed as the outline of a dialogue. The flow reflects the dialogue’s content and trajectory, i.e., the topics discussed in each session and the topic shifts between sessions. We consider the dialogue flow of a grounded dialogue as the sequence of the grounded knowledge pieces. Figure 1 shows an example dialogue along with its associated dialogue flow. In this example, the grounded knowledge is primarily from a Wikipedia page about “husky” dogs. This dialogue follows a smooth knowledge flow, transitioning from “husky” to “sled dogs” and then to “huskies as pets”. However, if we replace the second knowledge piece with “‘Esquimaux’ or ‘Eskimo’ was a common term for pre-Columbian Arctic inhabitants of North America.”, which is also from the same Wikipedia page, then the flow becomes less consistent. As the backbone guiding the dialogue generation process, a carefully planned dialogue flow is crucial for the coherence and smoothness of the resulting dialogue. To this end, we propose a novel framework named SynDG, to synthetically generate coherent grounded dialogues. The generated dialogues are meant to be used as auxiliary training data. In SynDG, we first determine the dialogue flow by task-specific heuristics, from the unstructured knowledge data (e.g., Wikipedia pages, persona profiles, etc.). Then, we employ T5 (Raffel et al., 2020), a large pre-trained LM, to transform the dialogue flow into a synthetic dialogue, with sequential utterance generation, one at a time. To ensure the quality of the synthetic dialogue, we propose a two-level filtering strategy based on T5: flow-level filtering and utterance-level filtering. The flowlevel filtering is designed to select dialogue flows with higher consistency, whereas the utterancelevel filtering aims to eliminate the synthetic dialogues with poor coherence. We conduct experiments on two grounded dialogue benchmarks, in both full training data and low-resource scenarios. We use the synthetic grounded dialogue data produced by our framework as additional training data for commonly used grounded dialogue models. Both the automatic and human evaluation results show that our synthetic data leads to significant improvement on model performance. Further analysis also reveals that model performance increases along the increase in the number of synthetic dialogues.","Can the problem of the difficulty in training grounded response generation models due to the costly and time-consuming collection of large datasets of naturally grounded dialogues be addressed by a novel synthetic data generation framework named SynDG, which generates coherent grounded dialogues by utilizing dialogue flow and coherence in the generation process and employs a two-level filtering strategy?",2.0,2.0,1.0
158,Neural Machine Translation with Reordering Embeddings,"Kehai Chen, Rui Wang, Masao Utiyama, and Eiichiro Sumita. 2019. Neural Machine Translation with Reordering Embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1787–1799, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1174.pdf,https://aclanthology.org/P19-1174/,"The reordering model plays an important role in phrase-based statistical machine translation. However, there are few works that exploit the reordering information in neural machine translation. In this paper, we propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information. These reordering embeddings are stacked together with self-attention networks to learn sentence representation for machine translation. The reordering mechanism can be easily integrated into both the encoder and the decoder in the Transformer translation system. Experimental results on WMT’14 English-toGerman, NIST Chinese-to-English, and WAT ASPEC Japanese-to-English translation tasks demonstrate that the proposed methods can significantly improve the performance of the Transformer translation system.","The reordering model plays an important role in phrase-based statistical machine translation (PBSMT), especially for translation between distant language pairs with large differences in word order, such as Chinese-to-English and Japaneseto-English translations (Galley and Manning, 2008; Goto et al., 2013). Typically, the traditional PBSMT learns large-scale reordering rules from parallel bilingual sentence pairs in advance to form a reordering model. This reordering model is then integrated into the translation decoding process to ensure a reasonable order of translations of the source words (Chiang, 2005; Xiong et al., 2006; Galley and Manning, 2008). In contrast to the explicit reordering model for PBSMT, the RNN-based NMT (Sutskever et al., 2014; Bahdanau et al., 2015) depends on neural networks to implicitly encode order dependencies between words in a sentence to generate a fluent translation. Inspired by a distortion method originating in SMT (Brown et al., 1993; Koehn et al., 2003; Al-Onaizan and Papineni, 2006), there is a quite recent preliminary exploration work for NMT (Zhang et al., 2017). They distorted the existing content-based attention by an additional position-based attention inside the fixed-size window, and reported a considerable improvement on the classical RNN-based NMT. This means that the word reordering information is also beneficial to the NMT. The Transformer (Vaswani et al., 2017) translation system relies on self-attention networks (SANs), and has attracted growing interesting in the machine translation community. The Transformer generates an ordered sequence of positional embeddings by a positional encoding mechanism (Gehring et al., 2017a) to explicitly encode the order of dependencies between words in a sentence. The Transformer is adept at parallelizing of performing (multi-head) and stacking (multi-layer) SANs to learn the sentence representation to predict translation, and has delivered state-of-the-art performance on various translation tasks (Bojar et al., 2018; Marie et al., 2018). However, these positional embeddings focus on sequentially encoding order relations between words, and does not explicitly consider reordering information in a sentence, which may degrade the performance of Transformer translation systems. Thus, the reordering problem in NMT has not been studied extensively, especially in Transformer. In this paper, we propose a reordering mechanism for the Transformer translation system. We dynamically penalize the given positional embedding of a word depending on its contextual information, thus generating a reordering embedding for each word. The reordering mechanism is then stacked together with the existing SANs to learn the final sentence representation with word reordering information. The proposed method can be easily integrated into both the encoder and the decoder in the Transformer. Experimental results on the WMT14 Englishto-German, NIST Chinese-to-English, and WAT ASPEC Japanese-to-English translation tasks verify the effectiveness and universality of the proposed approach. This paper primarily makes the following contributions: • We propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information, and thus these learned reordering embeddings are added to the sentence representation for archiving reordering of words. To the best of our knowledge, this is the first work to introduce the reordering information to the Transformer translation system. • The proposed reordering mechanism can be easily integrated into the Transformer to learn reordering-aware sentence representation for machine translation. The proposed translation models outperform the state-of-the-art NMT baselines systems with a similar number of parameters and achieve comparable results compared to NMT systems with much more parameters.","How does integrating a reordering mechanism based on the contextual information of words into the Transformer translation system affect the system's ability to handle translations between language pairs with significant differences in word order, compared to state-of-the-art neural machine translation baselines?",0.0,1.0,1.0
159,Neural Machine Translation with Reordering Embeddings,"Kehai Chen, Rui Wang, Masao Utiyama, and Eiichiro Sumita. 2019. Neural Machine Translation with Reordering Embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1787–1799, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1174.pdf,https://aclanthology.org/P19-1174/,"The reordering model plays an important role in phrase-based statistical machine translation. However, there are few works that exploit the reordering information in neural machine translation. In this paper, we propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information. These reordering embeddings are stacked together with self-attention networks to learn sentence representation for machine translation. The reordering mechanism can be easily integrated into both the encoder and the decoder in the Transformer translation system. Experimental results on WMT’14 English-toGerman, NIST Chinese-to-English, and WAT ASPEC Japanese-to-English translation tasks demonstrate that the proposed methods can significantly improve the performance of the Transformer translation system.","The reordering model plays an important role in phrase-based statistical machine translation (PBSMT), especially for translation between distant language pairs with large differences in word order, such as Chinese-to-English and Japaneseto-English translations (Galley and Manning, 2008; Goto et al., 2013). Typically, the traditional PBSMT learns large-scale reordering rules from parallel bilingual sentence pairs in advance to form a reordering model. This reordering model is then integrated into the translation decoding process to ensure a reasonable order of translations of the source words (Chiang, 2005; Xiong et al., 2006; Galley and Manning, 2008). In contrast to the explicit reordering model for PBSMT, the RNN-based NMT (Sutskever et al., 2014; Bahdanau et al., 2015) depends on neural networks to implicitly encode order dependencies between words in a sentence to generate a fluent translation. Inspired by a distortion method originating in SMT (Brown et al., 1993; Koehn et al., 2003; Al-Onaizan and Papineni, 2006), there is a quite recent preliminary exploration work for NMT (Zhang et al., 2017). They distorted the existing content-based attention by an additional position-based attention inside the fixed-size window, and reported a considerable improvement on the classical RNN-based NMT. This means that the word reordering information is also beneficial to the NMT. The Transformer (Vaswani et al., 2017) translation system relies on self-attention networks (SANs), and has attracted growing interesting in the machine translation community. The Transformer generates an ordered sequence of positional embeddings by a positional encoding mechanism (Gehring et al., 2017a) to explicitly encode the order of dependencies between words in a sentence. The Transformer is adept at parallelizing of performing (multi-head) and stacking (multi-layer) SANs to learn the sentence representation to predict translation, and has delivered state-of-the-art performance on various translation tasks (Bojar et al., 2018; Marie et al., 2018). However, these positional embeddings focus on sequentially encoding order relations between words, and does not explicitly consider reordering information in a sentence, which may degrade the performance of Transformer translation systems. Thus, the reordering problem in NMT has not been studied extensively, especially in Transformer. In this paper, we propose a reordering mechanism for the Transformer translation system. We dynamically penalize the given positional embedding of a word depending on its contextual information, thus generating a reordering embedding for each word. The reordering mechanism is then stacked together with the existing SANs to learn the final sentence representation with word reordering information. The proposed method can be easily integrated into both the encoder and the decoder in the Transformer. Experimental results on the WMT14 Englishto-German, NIST Chinese-to-English, and WAT ASPEC Japanese-to-English translation tasks verify the effectiveness and universality of the proposed approach. This paper primarily makes the following contributions: • We propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information, and thus these learned reordering embeddings are added to the sentence representation for archiving reordering of words. To the best of our knowledge, this is the first work to introduce the reordering information to the Transformer translation system. • The proposed reordering mechanism can be easily integrated into the Transformer to learn reordering-aware sentence representation for machine translation. The proposed translation models outperform the state-of-the-art NMT baselines systems with a similar number of parameters and achieve comparable results compared to NMT systems with much more parameters.","Can the lack of explicit consideration for reordering information in current Transformer-based NMT systems, which potentially degrades translation quality, be addressed by a reordering mechanism that learns reordering embeddings of words based on their contextual information and integrates these embeddings with self-attention networks to enhance sentence representation for translation?",2.0,2.0,1.0
160,A Neural Local Coherence Model,"Dat Tien Nguyen and Shafiq Joty. 2017. A Neural Local Coherence Model. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1320–1330, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1121.pdf,https://aclanthology.org/P17-1121/,"We propose a local coherence model based on a convolutional neural network that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing generalization, thanks to the power of distributed representation. We present a pairwise ranking method to train the model in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our model achieves state of the art results outperforming existing models by a good margin.","What distinguishes a coherent text from a random sequence of sentences is that it binds the sentences together to express a meaning as a whole — the interpretation of a sentence usually depends on the meaning of its neighbors. Coherence models that can distinguish a coherent from incoherent texts have a wide range of applications in text generation, summarization, and coherence scoring. Several formal theories of coherence have been proposed (Mann and Thompson, 1988a; Grosz et al., 1995; Asher and Lascarides, 2003), and their principles have inspired development of many existing coherence models (Barzilay and Lapata, 2008; Lin et al., 2011; Li and Hovy, 2014). Among these models, the entity grid (Barzilay and Lapata, 2008), which is based on Centering Theory (Grosz et al., 1995), is arguably the most popular, and has seen a number of improvements over the years. As shown in Figure 1, the entity grid model represents a text by a grid that captures how grammatical roles of different entities change from sentence to sentence. The grid is then converted into a feature vector containing probabilities of local entity transitions, which enables machine learning models to learn the degree of text coherence. Extensions of this basic grid model incorporate entity-specific features (Elsner and Charniak, 2011), multiple ranks (Feng and Hirst, 2012), and coherence relations (Feng et al., 2014). While the entity grid and its extensions have been successful in many applications, they are limited in several ways. First, they use discrete representation for grammatical roles and features, which prevents the model from considering sufficiently long transitions (Bengio et al., 2003). Second, feature vector computation in existing models is decoupled from the target task, which limits the model’s capacity to learn task-specific features. In this paper, we propose a neural architecture for coherence assessment that can capture long range entity transitions along with arbitrary entityspecific features. Our model obtains generalization through distributed representations of entity transitions and entity features. We also present an end-to-end training method to learn task-specific high level features automatically in our model. We evaluate our approach on three different evaluation tasks: discrimination, insertion, and summary coherence rating, proposed previously for evaluating coherence models (Barzilay and Lapata, 2008; Elsner and Charniak, 2011). Discrimination and insertion involve identifying the right order of the sentences in a text with different levels of difficulty. In the summary coherence rating task, we compare the rankings, given by the model, against human judgments of coherence. The experimental results show that our neural models consistently improve over the nonneural counterparts (i.e., existing entity grid models) yielding absolute gains of about 4% on discrimination, up to 2.5% on insertion, and more than 4% on summary coherence rating. Furthermore, our model achieves state of the art results in all these tasks. We have released our source code for research purposes.1 The remainder of this paper is organized as follows. We describe entity grid, its extensions, and its limitations in Section 2. In Section 3, we present our neural model. We describe evaluation tasks and results in Sections 4 and 5. We give a brief account of related work in Section 6. Finally, we conclude with future directions in Section 7.",Can text coherence be assessed by a local coherence model based on a convolutional neural network operating over the entity grid representation?,0.0,1.0,0.0
161,A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data,"Qiaolin Xia, Lei Sha, Baobao Chang, and Zhifang Sui. 2017. A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2069–2077, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1189.pdf,https://aclanthology.org/P17-1189/,"Previous studies on Chinese semantic role labeling (SRL) have concentrated on a single semantically annotated corpus. But the training data of single corpus is often limited. Whereas the other existing semantically annotated corpora for Chinese SRL are scattered across different annotation frameworks. But still, Data sparsity remains a bottleneck. This situation calls for larger training datasets, or effective approaches which can take advantage of highly heterogeneous data. In this paper, we focus mainly on the latter, that is, to improve Chinese SRL by using heterogeneous corpora together. We propose a novel progressive learning model which augments the Progressive Neural Network with Gated Recurrent Adapters. The model can accommodate heterogeneous inputs and effectively transfer knowledge between them. We also release a new corpus, Chinese SemBank, for Chinese SRL1 . Experiments on CPB 1.0 show that our model outperforms state-of-the-art methods.","Semantic role labeling (SRL) is one of the fundamental tasks in natural language processing because of its important role in information extraction (Bastianelli et al., 2013), statistical machine translation (Aziz et al., 2016; Xiong et al., 2012), and so on. However, state-of-the-art performance of Chinese SRL is still far from satisfactory. And data sparsity has been a bottleneck which can not be ignored. For English, the most commonly used benchmark dataset PropBank (Xue and Palmer, 2003) has about 54,900 sentences. But for Chinese, there are only 10,364 sentences in Chinese PropBank 1.0 (CPB) (with about 35,700 propositions) (Xue, 2008). To mitigate the data sparsity, models incorporating heterogeneous resources have been introduced to improve Chinese SRL performance (Wang et al., 2015; Guo et al., 2016; Li et al., 2016). The heterogeneous resources introduced by these models include other semantically annotated corpora with annotation schema different to that used in PropBank, and even of a different language. The challenge here lies in the fact that those newly introduced resources are heterogeneous in nature, without sharing the same tagging schema, semantic role set, syntactic tag set and domain. For example, Wang et al. (2015) introduced a heterogeneous dataset, Chinese NetBank, by pretraining word embeddings. Specifically, they learn an LSTM RNN model based on NetBank first, then initialize a new model with the pretrained embeddings obtained from NetBank, and then train it on CPB. Chinese NetBank (Yulin, 2007) is also a corpus annotated with semantic roles, but using a very different role set and annotation schema. Wang’s method can inherit knowledge acquired from other resources conveniently, but only at word representation level, missing more generalized semantic meanings in higher hidden layers. Li (2016) proposed a twopass training approach to use corpora of two languages, but a few non-common roles are ignored in the first pass. Guo et al. (2016) proposed a unified neural network model for SRL and relation classification (RC). It can learn two tasks at the same time, but cannot filter out harmful features learned in incompatible tasks. Recently, Progressive Neural Networks (PNN) model was proposed by Rusu et al. (2016) to transfer learned reinforcement learning policies from one game to another, or from simulation to the real robot. PNN “freezes” learned parameters once starting to learn a new task, and it uses lateral connections, namely adapter, to access previously learned features. Inspired by the PNN model, we propose a progressive learning model to Chinese semantic role labeling in this paper. Especially, we extend the model with Gated Recurrent Adapters (GRA). Since the standard PNN takes pixels as input, policies as output, it is not suitable for SRL task we focus in this context. Moreover, to handle long sentences in the corpus, we enhance adapters with internal memories, and gates to keep the gradient stable. The contributions of this paper are threefold: 1. We reconstruct PNN columns with bidirectional LSTMs to introduce heterogeneous corpora to improve Chinese SRL. The architecture can also be applied to a wider range of NLP tasks, like event extraction and relation classification, etc. 2. We further extend the model with GRA to remember and take advantage of what has been transferred, thus improve the performance on long sentences. 3. We also release a new corpus, Chinese SemBank, which was annotated with the schema different to that used in CPB. We hope that it will be helpful for future work on SRL tasks. We use our new corpus as a heterogeneous resource, and evaluate the proposed model on the benchmark dataset CPB 1.0. The experiment shows that our approach achieves 79.67% F1 score, significantly outperforms existing state-ofthe-art systems by a large margin (Section 5).",How can a progressive learning model that incorporates Gated Recurrent Adapters improve the performance of Chinese Semantic Role Labeling by effectively utilizing heterogeneous corpora?,2.0,2.0,1.0
162,A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data,"Qiaolin Xia, Lei Sha, Baobao Chang, and Zhifang Sui. 2017. A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2069–2077, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1189.pdf,https://aclanthology.org/P17-1189/,"Previous studies on Chinese semantic role labeling (SRL) have concentrated on a single semantically annotated corpus. But the training data of single corpus is often limited. Whereas the other existing semantically annotated corpora for Chinese SRL are scattered across different annotation frameworks. But still, Data sparsity remains a bottleneck. This situation calls for larger training datasets, or effective approaches which can take advantage of highly heterogeneous data. In this paper, we focus mainly on the latter, that is, to improve Chinese SRL by using heterogeneous corpora together. We propose a novel progressive learning model which augments the Progressive Neural Network with Gated Recurrent Adapters. The model can accommodate heterogeneous inputs and effectively transfer knowledge between them. We also release a new corpus, Chinese SemBank, for Chinese SRL1 . Experiments on CPB 1.0 show that our model outperforms state-of-the-art methods.","Semantic role labeling (SRL) is one of the fundamental tasks in natural language processing because of its important role in information extraction (Bastianelli et al., 2013), statistical machine translation (Aziz et al., 2016; Xiong et al., 2012), and so on. However, state-of-the-art performance of Chinese SRL is still far from satisfactory. And data sparsity has been a bottleneck which can not be ignored. For English, the most commonly used benchmark dataset PropBank (Xue and Palmer, 2003) has about 54,900 sentences. But for Chinese, there are only 10,364 sentences in Chinese PropBank 1.0 (CPB) (with about 35,700 propositions) (Xue, 2008). To mitigate the data sparsity, models incorporating heterogeneous resources have been introduced to improve Chinese SRL performance (Wang et al., 2015; Guo et al., 2016; Li et al., 2016). The heterogeneous resources introduced by these models include other semantically annotated corpora with annotation schema different to that used in PropBank, and even of a different language. The challenge here lies in the fact that those newly introduced resources are heterogeneous in nature, without sharing the same tagging schema, semantic role set, syntactic tag set and domain. For example, Wang et al. (2015) introduced a heterogeneous dataset, Chinese NetBank, by pretraining word embeddings. Specifically, they learn an LSTM RNN model based on NetBank first, then initialize a new model with the pretrained embeddings obtained from NetBank, and then train it on CPB. Chinese NetBank (Yulin, 2007) is also a corpus annotated with semantic roles, but using a very different role set and annotation schema. Wang’s method can inherit knowledge acquired from other resources conveniently, but only at word representation level, missing more generalized semantic meanings in higher hidden layers. Li (2016) proposed a twopass training approach to use corpora of two languages, but a few non-common roles are ignored in the first pass. Guo et al. (2016) proposed a unified neural network model for SRL and relation classification (RC). It can learn two tasks at the same time, but cannot filter out harmful features learned in incompatible tasks. Recently, Progressive Neural Networks (PNN) model was proposed by Rusu et al. (2016) to transfer learned reinforcement learning policies from one game to another, or from simulation to the real robot. PNN “freezes” learned parameters once starting to learn a new task, and it uses lateral connections, namely adapter, to access previously learned features. Inspired by the PNN model, we propose a progressive learning model to Chinese semantic role labeling in this paper. Especially, we extend the model with Gated Recurrent Adapters (GRA). Since the standard PNN takes pixels as input, policies as output, it is not suitable for SRL task we focus in this context. Moreover, to handle long sentences in the corpus, we enhance adapters with internal memories, and gates to keep the gradient stable. The contributions of this paper are threefold: 1. We reconstruct PNN columns with bidirectional LSTMs to introduce heterogeneous corpora to improve Chinese SRL. The architecture can also be applied to a wider range of NLP tasks, like event extraction and relation classification, etc. 2. We further extend the model with GRA to remember and take advantage of what has been transferred, thus improve the performance on long sentences. 3. We also release a new corpus, Chinese SemBank, which was annotated with the schema different to that used in CPB. We hope that it will be helpful for future work on SRL tasks. We use our new corpus as a heterogeneous resource, and evaluate the proposed model on the benchmark dataset CPB 1.0. The experiment shows that our approach achieves 79.67% F1 score, significantly outperforms existing state-ofthe-art systems by a large margin (Section 5).",Can Chinese semantic role labeling be improved by using a novel progressive learning model which augments the Progressive Neural Network with Gated Recurrent Adapters on heterogeneous corpora?,2.0,2.0,1.0
163,A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data,"Qiaolin Xia, Lei Sha, Baobao Chang, and Zhifang Sui. 2017. A Progressive Learning Approach to Chinese SRL Using Heterogeneous Data. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2069–2077, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1189.pdf,https://aclanthology.org/P17-1189/,"Previous studies on Chinese semantic role labeling (SRL) have concentrated on a single semantically annotated corpus. But the training data of single corpus is often limited. Whereas the other existing semantically annotated corpora for Chinese SRL are scattered across different annotation frameworks. But still, Data sparsity remains a bottleneck. This situation calls for larger training datasets, or effective approaches which can take advantage of highly heterogeneous data. In this paper, we focus mainly on the latter, that is, to improve Chinese SRL by using heterogeneous corpora together. We propose a novel progressive learning model which augments the Progressive Neural Network with Gated Recurrent Adapters. The model can accommodate heterogeneous inputs and effectively transfer knowledge between them. We also release a new corpus, Chinese SemBank, for Chinese SRL1 . Experiments on CPB 1.0 show that our model outperforms state-of-the-art methods.","Semantic role labeling (SRL) is one of the fundamental tasks in natural language processing because of its important role in information extraction (Bastianelli et al., 2013), statistical machine translation (Aziz et al., 2016; Xiong et al., 2012), and so on. However, state-of-the-art performance of Chinese SRL is still far from satisfactory. And data sparsity has been a bottleneck which can not be ignored. For English, the most commonly used benchmark dataset PropBank (Xue and Palmer, 2003) has about 54,900 sentences. But for Chinese, there are only 10,364 sentences in Chinese PropBank 1.0 (CPB) (with about 35,700 propositions) (Xue, 2008). To mitigate the data sparsity, models incorporating heterogeneous resources have been introduced to improve Chinese SRL performance (Wang et al., 2015; Guo et al., 2016; Li et al., 2016). The heterogeneous resources introduced by these models include other semantically annotated corpora with annotation schema different to that used in PropBank, and even of a different language. The challenge here lies in the fact that those newly introduced resources are heterogeneous in nature, without sharing the same tagging schema, semantic role set, syntactic tag set and domain. For example, Wang et al. (2015) introduced a heterogeneous dataset, Chinese NetBank, by pretraining word embeddings. Specifically, they learn an LSTM RNN model based on NetBank first, then initialize a new model with the pretrained embeddings obtained from NetBank, and then train it on CPB. Chinese NetBank (Yulin, 2007) is also a corpus annotated with semantic roles, but using a very different role set and annotation schema. Wang’s method can inherit knowledge acquired from other resources conveniently, but only at word representation level, missing more generalized semantic meanings in higher hidden layers. Li (2016) proposed a twopass training approach to use corpora of two languages, but a few non-common roles are ignored in the first pass. Guo et al. (2016) proposed a unified neural network model for SRL and relation classification (RC). It can learn two tasks at the same time, but cannot filter out harmful features learned in incompatible tasks. Recently, Progressive Neural Networks (PNN) model was proposed by Rusu et al. (2016) to transfer learned reinforcement learning policies from one game to another, or from simulation to the real robot. PNN “freezes” learned parameters once starting to learn a new task, and it uses lateral connections, namely adapter, to access previously learned features. Inspired by the PNN model, we propose a progressive learning model to Chinese semantic role labeling in this paper. Especially, we extend the model with Gated Recurrent Adapters (GRA). Since the standard PNN takes pixels as input, policies as output, it is not suitable for SRL task we focus in this context. Moreover, to handle long sentences in the corpus, we enhance adapters with internal memories, and gates to keep the gradient stable. The contributions of this paper are threefold: 1. We reconstruct PNN columns with bidirectional LSTMs to introduce heterogeneous corpora to improve Chinese SRL. The architecture can also be applied to a wider range of NLP tasks, like event extraction and relation classification, etc. 2. We further extend the model with GRA to remember and take advantage of what has been transferred, thus improve the performance on long sentences. 3. We also release a new corpus, Chinese SemBank, which was annotated with the schema different to that used in CPB. We hope that it will be helpful for future work on SRL tasks. We use our new corpus as a heterogeneous resource, and evaluate the proposed model on the benchmark dataset CPB 1.0. The experiment shows that our approach achieves 79.67% F1 score, significantly outperforms existing state-ofthe-art systems by a large margin (Section 5).",Can the problem of data sparsity in Chinese semantic role labeling (SRL) be effectively addressed by utilizing a novel progressive learning model that incorporates heterogeneous corpora through the augmentation of the Progressive Neural Network with Gated Recurrent Adapters?,2.0,2.0,1.0
164,Chinese Zero Pronoun Resolution with Deep Neural Networks,"Chen Chen and Vincent Ng. 2016. Chinese Zero Pronoun Resolution with Deep Neural Networks. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 778–788, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1074.pdf,https://aclanthology.org/P16-1074/,"While unsupervised anaphoric zero pronoun (AZP) resolvers have recently been shown to rival their supervised counterparts in performance, it is relatively difficult to scale them up to reach the next level of performance due to the large amount of feature engineering efforts involved and their ineffectiveness in exploiting lexical features. To address these weaknesses, we propose a supervised approach to AZP resolution based on deep neural networks, taking advantage of their ability to learn useful task-specific representations and effectively exploit lexical features via word embeddings. Our approach achieves stateof-the-art performance when resolving the Chinese AZPs in the OntoNotes corpus.","A zero pronoun (ZP) is a gap in a sentence that is found when a phonetically null form is used to refer to a real-world entity. An anaphoric zero pronoun (AZP) is a ZP that corefers with one or more preceding mentions in the associated text. Below is an example taken from the Chinese Treebank (CTB), where the ZP (denoted as *pro*) refers to 俄罗斯 (Russia). [俄罗斯] 作为米洛舍夫维奇一贯的支持者， *pro* 曾经提出调停这场政治危机。 ([Russia] is a consistent supporter of Milošević, *pro* has proposed to mediate the political crisis.) As we can see, ZPs lack grammatical attributes that are useful for overt pronoun resolution such as number and gender. This makes ZP resolution more challenging than overt pronoun resolution. Automatic ZP resolution is typically composed of two steps. The first step, AZP identification, involves extracting ZPs that are anaphoric. The second step, AZP resolution, aims to identify an antecedent of an AZP. State-of-the-art ZP resolvers have tackled both of these steps in a supervised manner, training one classifier for AZP identification and another for AZP resolution (e.g., Zhao and Ng (2007), Kong and Zhou (2010)). More recently, Chen and Ng (2014b; 2015) have proposed unsupervised probabilistic AZP resolution models (henceforth the CN14 model and the CN15 model, respectively) that rival their supervised counterparts in performance. An appealing aspect of these unsupervised models is that their language-independent generative process enables them to be applied to languages where data annotated with ZP links are not readily available. Though achieving state-of-the-art performance, these models have several weaknesses. First, a lot of manual efforts need to be spent on engineering the features for generative probabilistic models, as these models are sensitive to the choice of features. For instance, having features that are (partially) dependent on each other could harm model performance. Second, in the absence of labeled data, it is difficult, though not impossible, for these models to profitably employ lexical features (e.g., word pairs, syntactic patterns involving words), as determining which lexical features are useful and how to combine the potentially large number of lexical features in an unsupervised manner is a very challenging task. In fact, the unsupervised models proposed by Chen and Ng (2014b; 2015) are unlexicalized, presumably owing to the aforementioned reasons. Unfortunately, as shown in previous work (e.g, Zhao and Ng (2007), Chen and Ng (2013)), the use of lexical features contributed significantly to the performance of state-of-the-art supervised AZP resolvers. Finally, owing to the lack of labeled data, the model parameters are learned to maximize data likelihood, which may not correlate well with the desired evaluation measure (i.e., F-score). Hence, while unsupervised resolvers have achieved stateof-the-art performance, these weaknesses together suggest that it is very challenging to scale these models up so that they can achieve the next level of performance. Our goal in this paper is to improve the state of the art in AZP resolution. Motivated by the aforementioned weaknesses, we propose a novel approach to AZP resolution using deep neural networks, which we believe has three key advantages over competing unsupervised counterparts. First, deep neural networks are particularly good at discovering hidden structures from the input data and learning task-specific representations via successive transformations of the input vectors, where different layers of a network correspond to different levels of abstractions that are useful for the target task. For the task of AZP resolution, this is desirable. Traditionally, it is difficult to correctly resolve an AZP if its context is lexically different from its antecedent's context. This is especially the case for unsupervised resolvers. In contrast, a deep network can handle difficult cases like this via learning representations that make lexically different contexts look similar. Second, we train our deep network in a supervised manner.1 In particular, motivated by recent successes of applying the mention-ranking model (Denis and Baldridge, 2008) to entity coreference resolution (e.g., Chang et al. (2013), Durrett and Klein (2013), Clark and Manning (2015), Martschat and Strube (2015), Wiseman et al. (2015)), we propose to employ a ranking-based deep network, which is trained to assign the highest probability to the correct antecedent of an AZP given a set of candidate antecedents. This contrasts with existing supervised AZP resolvers, all of which are classification-based. Optimizing this objective function is better than maximizing data likelihood, as the former is more tightly coupled with the desired evaluation metric (F-score) than the latter. Finally, given that our network is trained in a supervised manner, we can extensively employ lexical features and use them in combination with other types of features that have been shown to be useful for AZP resolution. However, rather than employing words directly as features, we employ word embeddings trained in an unsupervised manner. The goal of the deep network will then be to take these task-independent word embeddings as input and convert them into embeddings that would work best for AZP resolution via supervised learning. We call our approach an embedding matching approach because the underlying deep network attempts to compare the embedding learned for an AZP with the embedding learned for each of its antecedents. To our knowledge, this is the first approach to AZP resolution based on deep networks. When evaluated on the Chinese portion of the OntoNotes 5.0 corpus, our embedding matching approach to AZP resolution outperforms the CN15 model, achieving state-of-the-art results. The rest of the paper is organized as follows. Section 2 overviews related work on zero pronoun resolution for Chinese and other languages. Section 3 describes our embedding matching approach, specifically the network architecture and the way we train and apply the network. We present our evaluation results in Section 4 and our conclusions in Section 5.","How can a supervised deep neural network approach, utilizing word embeddings, effectively improve the resolution of anaphoric zero pronouns in Chinese texts over existing unsupervised models?",0.0,1.0,1.0
165,Chinese Zero Pronoun Resolution with Deep Neural Networks,"Chen Chen and Vincent Ng. 2016. Chinese Zero Pronoun Resolution with Deep Neural Networks. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 778–788, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1074.pdf,https://aclanthology.org/P16-1074/,"While unsupervised anaphoric zero pronoun (AZP) resolvers have recently been shown to rival their supervised counterparts in performance, it is relatively difficult to scale them up to reach the next level of performance due to the large amount of feature engineering efforts involved and their ineffectiveness in exploiting lexical features. To address these weaknesses, we propose a supervised approach to AZP resolution based on deep neural networks, taking advantage of their ability to learn useful task-specific representations and effectively exploit lexical features via word embeddings. Our approach achieves stateof-the-art performance when resolving the Chinese AZPs in the OntoNotes corpus.","A zero pronoun (ZP) is a gap in a sentence that is found when a phonetically null form is used to refer to a real-world entity. An anaphoric zero pronoun (AZP) is a ZP that corefers with one or more preceding mentions in the associated text. Below is an example taken from the Chinese Treebank (CTB), where the ZP (denoted as *pro*) refers to 俄罗斯 (Russia). [俄罗斯] 作为米洛舍夫维奇一贯的支持者， *pro* 曾经提出调停这场政治危机。 ([Russia] is a consistent supporter of Milošević, *pro* has proposed to mediate the political crisis.) As we can see, ZPs lack grammatical attributes that are useful for overt pronoun resolution such as number and gender. This makes ZP resolution more challenging than overt pronoun resolution. Automatic ZP resolution is typically composed of two steps. The first step, AZP identification, involves extracting ZPs that are anaphoric. The second step, AZP resolution, aims to identify an antecedent of an AZP. State-of-the-art ZP resolvers have tackled both of these steps in a supervised manner, training one classifier for AZP identification and another for AZP resolution (e.g., Zhao and Ng (2007), Kong and Zhou (2010)). More recently, Chen and Ng (2014b; 2015) have proposed unsupervised probabilistic AZP resolution models (henceforth the CN14 model and the CN15 model, respectively) that rival their supervised counterparts in performance. An appealing aspect of these unsupervised models is that their language-independent generative process enables them to be applied to languages where data annotated with ZP links are not readily available. Though achieving state-of-the-art performance, these models have several weaknesses. First, a lot of manual efforts need to be spent on engineering the features for generative probabilistic models, as these models are sensitive to the choice of features. For instance, having features that are (partially) dependent on each other could harm model performance. Second, in the absence of labeled data, it is difficult, though not impossible, for these models to profitably employ lexical features (e.g., word pairs, syntactic patterns involving words), as determining which lexical features are useful and how to combine the potentially large number of lexical features in an unsupervised manner is a very challenging task. In fact, the unsupervised models proposed by Chen and Ng (2014b; 2015) are unlexicalized, presumably owing to the aforementioned reasons. Unfortunately, as shown in previous work (e.g, Zhao and Ng (2007), Chen and Ng (2013)), the use of lexical features contributed significantly to the performance of state-of-the-art supervised AZP resolvers. Finally, owing to the lack of labeled data, the model parameters are learned to maximize data likelihood, which may not correlate well with the desired evaluation measure (i.e., F-score). Hence, while unsupervised resolvers have achieved stateof-the-art performance, these weaknesses together suggest that it is very challenging to scale these models up so that they can achieve the next level of performance. Our goal in this paper is to improve the state of the art in AZP resolution. Motivated by the aforementioned weaknesses, we propose a novel approach to AZP resolution using deep neural networks, which we believe has three key advantages over competing unsupervised counterparts. First, deep neural networks are particularly good at discovering hidden structures from the input data and learning task-specific representations via successive transformations of the input vectors, where different layers of a network correspond to different levels of abstractions that are useful for the target task. For the task of AZP resolution, this is desirable. Traditionally, it is difficult to correctly resolve an AZP if its context is lexically different from its antecedent's context. This is especially the case for unsupervised resolvers. In contrast, a deep network can handle difficult cases like this via learning representations that make lexically different contexts look similar. Second, we train our deep network in a supervised manner.1 In particular, motivated by recent successes of applying the mention-ranking model (Denis and Baldridge, 2008) to entity coreference resolution (e.g., Chang et al. (2013), Durrett and Klein (2013), Clark and Manning (2015), Martschat and Strube (2015), Wiseman et al. (2015)), we propose to employ a ranking-based deep network, which is trained to assign the highest probability to the correct antecedent of an AZP given a set of candidate antecedents. This contrasts with existing supervised AZP resolvers, all of which are classification-based. Optimizing this objective function is better than maximizing data likelihood, as the former is more tightly coupled with the desired evaluation metric (F-score) than the latter. Finally, given that our network is trained in a supervised manner, we can extensively employ lexical features and use them in combination with other types of features that have been shown to be useful for AZP resolution. However, rather than employing words directly as features, we employ word embeddings trained in an unsupervised manner. The goal of the deep network will then be to take these task-independent word embeddings as input and convert them into embeddings that would work best for AZP resolution via supervised learning. We call our approach an embedding matching approach because the underlying deep network attempts to compare the embedding learned for an AZP with the embedding learned for each of its antecedents. To our knowledge, this is the first approach to AZP resolution based on deep networks. When evaluated on the Chinese portion of the OntoNotes 5.0 corpus, our embedding matching approach to AZP resolution outperforms the CN15 model, achieving state-of-the-art results. The rest of the paper is organized as follows. Section 2 overviews related work on zero pronoun resolution for Chinese and other languages. Section 3 describes our embedding matching approach, specifically the network architecture and the way we train and apply the network. We present our evaluation results in Section 4 and our conclusions in Section 5.",Can the challenges associated with resolving anaphoric zero pronouns (AZPs) in the Chinese language be effectively addressed by a supervised deep learning approach that utilizes deep neural networks for task-specific representation learning and leverages word embeddings to efficiently use lexical features?,1.0,2.0,1.0
166,Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References,"Lisong Qiu, Juntao Li, Wei Bi, Dongyan Zhao, and Rui Yan. 2019. Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3826–3835, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1372.pdf,https://aclanthology.org/P19-1372/,"Due to its potential applications, open-domain dialogue generation has become popular and achieved remarkable progress in recent years, but sometimes suffers from generic responses. Previous models are generally trained based on 1-to-1 mapping from an input query to its response, which actually ignores the nature of 1-to-n mapping in dialogue that there may exist multiple valid responses corresponding to the same query. In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture. The first generation phase extracts the common features of different responses which, combined with distinctive features obtained in the second phase, can generate multiple diverse and appropriate responses. Experimental results show that our proposed model can effectively improve the quality of response and outperform existing neural dialogue models on both automatic and human evaluations.","In recent years, open-domain dialogue generation has become a research hotspot in Natural Language Processing due to its broad application prospect, including chatbots, virtual personal assistants, etc. Though plenty of systems have been proposed to improve the quality of generated responses from various aspects such as topic (Xing et al., 2017), persona modeling (Zhang et al., 2018b) and emotion controlling (Zhou et al., 2018b), most of these recent approaches are primarily built upon the sequence-to-sequence architecture (Cho et al., 2014; Shang et al., 2015) which suffers from the “safe” response problem (Li et al., 2016a; Sato et al., 2017). This can be ascribed to modeling the response generation process as 1- to-1 mapping, which ignores the nature of 1-to-n mapping of dialogue that multiple possible responses can correspond to the same query. To deal with the generic response problem, various methods have been proposed, including diversity-promoting objective function (Li et al., 2016a), enhanced beam search (Shao et al., 2016), latent dialogue mechanism (Zhou et al., 2017, 2018a), Variational Autoencoders (VAEs) based models (Zhao et al., 2017; Serban et al., 2017), etc. However, these methods still view multiple responses as independent ones and fail to model multiple responses jointly. Recently, Zhang et al. (2018a) introduce a maximum likelihood strategy that given an input query, the most likely response is approximated rather than all possible responses, which is further implemented by Rajendran et al. (2018) with reinforcement learning for task-oriented dialogue. Although capable of generating the most likely response, these methods fail to model other possible responses and ignore the correlation of different responses. In this paper, we propose a novel response generation model for open-domain conversation, which learns to generate multiple diverse responses with multiple references by considering the correlation of different responses. Our motivation lies in two aspects: 1) multiple responses for a query are likely correlated, which can facilitate building the dialogue system. 2) it is easier to model each response based on other responses than from scratch every time. As shown in Figure 1, given an input query, different responses may share some common features e.g. positive attitudes or something else, but vary in discourses or expressions which we refer to as distinct features. Accordingly, the system can benefit from modeling these features respectively rather than learning each query-response mapping from scratch. Inspired by this idea, we propose a two-step dialogue generation architecture as follows. We jointly view the multiple possible responses to the same query as a response bag. In the first generation phase, the common feature of different valid responses is extracted, serving as a base from which each specific response in the bag is further approximated. The system then, in the second generation phase, learns to model the distinctive feature of each individual response which, combined with the common feature, can generate multiple diverse responses simultaneously. Experimental results show that our method can outperform existing competitive neural models under both automatic and human evaluation metrics, which demonstrates the effectiveness of the overall approach. We also provide ablation analyses to validate each component of our model. To summarize, our contributions are threefold: • We propose to model multiple responses to a query jointly by considering the correlations of responses with multi-reference learning. • We consider the common and distinctive features of the response bag and propose a novel two-step dialogue generation architecture. • Experiments show that the proposed method can generate multiple diverse responses and outperform existing competitive models on both automatic and human evaluations.",Can the generic response problem in open-domain dialogue generation be solved by utilizing a novel two-step generation architecture that models multiple responses jointly by considering their correlations?,2.0,2.0,1.0
167,Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References,"Lisong Qiu, Juntao Li, Wei Bi, Dongyan Zhao, and Rui Yan. 2019. Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3826–3835, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1372.pdf,https://aclanthology.org/P19-1372/,"Due to its potential applications, open-domain dialogue generation has become popular and achieved remarkable progress in recent years, but sometimes suffers from generic responses. Previous models are generally trained based on 1-to-1 mapping from an input query to its response, which actually ignores the nature of 1-to-n mapping in dialogue that there may exist multiple valid responses corresponding to the same query. In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture. The first generation phase extracts the common features of different responses which, combined with distinctive features obtained in the second phase, can generate multiple diverse and appropriate responses. Experimental results show that our proposed model can effectively improve the quality of response and outperform existing neural dialogue models on both automatic and human evaluations.","In recent years, open-domain dialogue generation has become a research hotspot in Natural Language Processing due to its broad application prospect, including chatbots, virtual personal assistants, etc. Though plenty of systems have been proposed to improve the quality of generated responses from various aspects such as topic (Xing et al., 2017), persona modeling (Zhang et al., 2018b) and emotion controlling (Zhou et al., 2018b), most of these recent approaches are primarily built upon the sequence-to-sequence architecture (Cho et al., 2014; Shang et al., 2015) which suffers from the “safe” response problem (Li et al., 2016a; Sato et al., 2017). This can be ascribed to modeling the response generation process as 1- to-1 mapping, which ignores the nature of 1-to-n mapping of dialogue that multiple possible responses can correspond to the same query. To deal with the generic response problem, various methods have been proposed, including diversity-promoting objective function (Li et al., 2016a), enhanced beam search (Shao et al., 2016), latent dialogue mechanism (Zhou et al., 2017, 2018a), Variational Autoencoders (VAEs) based models (Zhao et al., 2017; Serban et al., 2017), etc. However, these methods still view multiple responses as independent ones and fail to model multiple responses jointly. Recently, Zhang et al. (2018a) introduce a maximum likelihood strategy that given an input query, the most likely response is approximated rather than all possible responses, which is further implemented by Rajendran et al. (2018) with reinforcement learning for task-oriented dialogue. Although capable of generating the most likely response, these methods fail to model other possible responses and ignore the correlation of different responses. In this paper, we propose a novel response generation model for open-domain conversation, which learns to generate multiple diverse responses with multiple references by considering the correlation of different responses. Our motivation lies in two aspects: 1) multiple responses for a query are likely correlated, which can facilitate building the dialogue system. 2) it is easier to model each response based on other responses than from scratch every time. As shown in Figure 1, given an input query, different responses may share some common features e.g. positive attitudes or something else, but vary in discourses or expressions which we refer to as distinct features. Accordingly, the system can benefit from modeling these features respectively rather than learning each query-response mapping from scratch. Inspired by this idea, we propose a two-step dialogue generation architecture as follows. We jointly view the multiple possible responses to the same query as a response bag. In the first generation phase, the common feature of different valid responses is extracted, serving as a base from which each specific response in the bag is further approximated. The system then, in the second generation phase, learns to model the distinctive feature of each individual response which, combined with the common feature, can generate multiple diverse responses simultaneously. Experimental results show that our method can outperform existing competitive neural models under both automatic and human evaluation metrics, which demonstrates the effectiveness of the overall approach. We also provide ablation analyses to validate each component of our model. To summarize, our contributions are threefold: • We propose to model multiple responses to a query jointly by considering the correlations of responses with multi-reference learning. • We consider the common and distinctive features of the response bag and propose a novel two-step dialogue generation architecture. • Experiments show that the proposed method can generate multiple diverse responses and outperform existing competitive models on both automatic and human evaluations.",Can the problem of generic responses in open-domain dialogue generation systems be addressed by a two-step generation architecture that utilizes the correlation of different valid responses and a combination of their common and distinctive features?,2.0,2.0,1.0
168,Gloss-Free End-to-End Sign Language Translation,"Kezhou Lin, Xiaohan Wang, Linchao Zhu, Ke Sun, Bang Zhang, and Yi Yang. 2023. Gloss-Free End-to-End Sign Language Translation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12904–12916, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.722.pdf,https://aclanthology.org/2023.acl-long.722/,"In this paper, we tackle the problem of sign language translation (SLT) without gloss annotations. Although intermediate representation like gloss has been proven effective, gloss annotations are hard to acquire, especially in large quantities. This limits the domain coverage of translation datasets, thus handicapping real-world applications. To mitigate this problem, we design the Gloss-Free End-to-end sign language translation framework (GloFE). Our method improves the performance of SLT in the gloss-free setting by exploiting the shared underlying semantics of signs and the corresponding spoken translation. Common concepts are extracted from the text and used as a weak form of intermediate representation. The global embedding of these concepts is used as a query for cross-attention to find the corresponding information within the learned visual features. In a contrastive manner, we encourage the similarity of query results between samples containing such concepts and decrease those that do not. We obtained state-of-the-art results on large-scale datasets, including OpenASL and How2Sign.","Sign language is a type of visual language mainly used by the community of deaf and hard of hearing. It uses a combination of hand gestures, facial expressions, and body movements to convey the message of the signer. Sign languages are not simple transcripts of the corresponding spoken languages. They possess unique grammar structures and have their own linguistic properties. According to the World Federation of the Deaf, there are over 70 million deaf people around the world. The study of automated sign language processing can facilitate their day-to-day life. In this paper, we study the task of sign language translation (SLT), which translates the sign videos into the corresponding spoken language. Glosses are the transliteration system for sign language. They serve as an intermediate representation of the signs. However, the vocabulary of gloss does not align with the spoken language nor does the order of the glosses. Unlike translation between two spoken languages, the number of frames in a sign video is much larger than the number of words in the spoken translation. This imposes a unique challenge for SLT. Models need to learn a clustering of the frames into gloss-level representation before they can translate the tokens. Previous methods solve this problem in two major ways, i.e., pre-train the visual backbone with gloss (Camgoz et al., 2020) or jointly train on both translation and continuous recognition task (Camgoz et al., 2020; Chen et al., 2022) with an additional CTC loss (Graves et al., 2006). These methods have been proven effective, but the reliance on gloss annotations makes them hard to apply to more realistic scenarios. As gloss annotations require expert knowledge to make and often are limited in quantity or coverage of domains. Like the most frequently used PHOENIX14T dataset (Camgoz et al., 2018) that focuses on weather reports or the KETI dataset (Ko et al., 2019) that dedicates to emergencies. Datasets like OpenASL (Shi et al., 2022) and How2Sign (Duarte et al., 2021) provide more samples but there are no gloss annotations for training. Motivated by these observations and the availability of large-scale SLT datasets, we designed a new framework that is gloss-free throughout the entire process and train the visual backbone jointly in an end-to-end manner. The core idea of our method is illustrated in Figure 1, we extract conceptual words from the ground truth spoken translation to be used as a weak form of intermediate representations. This exploits the shared semantics between signs and text. Though the extracted words might be different from the glosses, the concept expressed by these words should exist in both sign and text. We treat these words as conceptual anchors (CA) between the two modalities. Specifically, we use pre-trained GloVe embeddings (Pennington et al., 2014) as the initialization of these anchors. Then they are treated as the query of cross attention against the encoded visual features. As illustrated in Figure 1, the query attend to each visual feature across the temporal dimension to calculate the similarity between the query and the visual features. With these similarities as weights of pooling, we get the attended visual features. The order of the most relevant features from the signing video does not match the order of the queries in the translation, so CTC is not viable in this situation. Instead, we impose the conceptual constraints in a contrastive manner. For each anchor word, we treated samples containing such words as positive and vice versus. For example, for the word identities in Figure 1 sample B is positive and sample A is negative. Query results for these positive and negative pairs along with the anchor word form a triplet, among which we conduct a hinge-based triplet loss. This process forces the visual2text encoder to learn the relation between different frames that is part of one sign. In all, our contribution can be summarized as: • An end-to-end sign language translation framework that takes the visual backbone in its training process. And we prove that proper design to accompany the text generation objective, will improve the performance of the framework rather than deteriorate it. • A replacement for gloss as a weak form of intermediate representation that facilitates the training of the visual backbone and encoder. It exploits the shared semantics between sign and text, bridging the gap between these two modalities. This also allows us to train the model on larger datasets without gloss annotations. • We obtained state-of-the-art performance on the currently largest SLT dataset publicly available, improving the more modern BLEURT metric by a margin of 5.26, which is 16.9% higher than the previous state-of-the-art.",Can sign language translation without gloss annotations be solved by leveraging shared underlying semantics of signs and spoken translations and employing a gloss-free end-to-end framework (GloFE)?,1.0,1.0,1.0
169,Gloss-Free End-to-End Sign Language Translation,"Kezhou Lin, Xiaohan Wang, Linchao Zhu, Ke Sun, Bang Zhang, and Yi Yang. 2023. Gloss-Free End-to-End Sign Language Translation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12904–12916, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.722.pdf,https://aclanthology.org/2023.acl-long.722/,"In this paper, we tackle the problem of sign language translation (SLT) without gloss annotations. Although intermediate representation like gloss has been proven effective, gloss annotations are hard to acquire, especially in large quantities. This limits the domain coverage of translation datasets, thus handicapping real-world applications. To mitigate this problem, we design the Gloss-Free End-to-end sign language translation framework (GloFE). Our method improves the performance of SLT in the gloss-free setting by exploiting the shared underlying semantics of signs and the corresponding spoken translation. Common concepts are extracted from the text and used as a weak form of intermediate representation. The global embedding of these concepts is used as a query for cross-attention to find the corresponding information within the learned visual features. In a contrastive manner, we encourage the similarity of query results between samples containing such concepts and decrease those that do not. We obtained state-of-the-art results on large-scale datasets, including OpenASL and How2Sign.","Sign language is a type of visual language mainly used by the community of deaf and hard of hearing. It uses a combination of hand gestures, facial expressions, and body movements to convey the message of the signer. Sign languages are not simple transcripts of the corresponding spoken languages. They possess unique grammar structures and have their own linguistic properties. According to the World Federation of the Deaf, there are over 70 million deaf people around the world. The study of automated sign language processing can facilitate their day-to-day life. In this paper, we study the task of sign language translation (SLT), which translates the sign videos into the corresponding spoken language. Glosses are the transliteration system for sign language. They serve as an intermediate representation of the signs. However, the vocabulary of gloss does not align with the spoken language nor does the order of the glosses. Unlike translation between two spoken languages, the number of frames in a sign video is much larger than the number of words in the spoken translation. This imposes a unique challenge for SLT. Models need to learn a clustering of the frames into gloss-level representation before they can translate the tokens. Previous methods solve this problem in two major ways, i.e., pre-train the visual backbone with gloss (Camgoz et al., 2020) or jointly train on both translation and continuous recognition task (Camgoz et al., 2020; Chen et al., 2022) with an additional CTC loss (Graves et al., 2006). These methods have been proven effective, but the reliance on gloss annotations makes them hard to apply to more realistic scenarios. As gloss annotations require expert knowledge to make and often are limited in quantity or coverage of domains. Like the most frequently used PHOENIX14T dataset (Camgoz et al., 2018) that focuses on weather reports or the KETI dataset (Ko et al., 2019) that dedicates to emergencies. Datasets like OpenASL (Shi et al., 2022) and How2Sign (Duarte et al., 2021) provide more samples but there are no gloss annotations for training. Motivated by these observations and the availability of large-scale SLT datasets, we designed a new framework that is gloss-free throughout the entire process and train the visual backbone jointly in an end-to-end manner. The core idea of our method is illustrated in Figure 1, we extract conceptual words from the ground truth spoken translation to be used as a weak form of intermediate representations. This exploits the shared semantics between signs and text. Though the extracted words might be different from the glosses, the concept expressed by these words should exist in both sign and text. We treat these words as conceptual anchors (CA) between the two modalities. Specifically, we use pre-trained GloVe embeddings (Pennington et al., 2014) as the initialization of these anchors. Then they are treated as the query of cross attention against the encoded visual features. As illustrated in Figure 1, the query attend to each visual feature across the temporal dimension to calculate the similarity between the query and the visual features. With these similarities as weights of pooling, we get the attended visual features. The order of the most relevant features from the signing video does not match the order of the queries in the translation, so CTC is not viable in this situation. Instead, we impose the conceptual constraints in a contrastive manner. For each anchor word, we treated samples containing such words as positive and vice versus. For example, for the word identities in Figure 1 sample B is positive and sample A is negative. Query results for these positive and negative pairs along with the anchor word form a triplet, among which we conduct a hinge-based triplet loss. This process forces the visual2text encoder to learn the relation between different frames that is part of one sign. In all, our contribution can be summarized as: • An end-to-end sign language translation framework that takes the visual backbone in its training process. And we prove that proper design to accompany the text generation objective, will improve the performance of the framework rather than deteriorate it. • A replacement for gloss as a weak form of intermediate representation that facilitates the training of the visual backbone and encoder. It exploits the shared semantics between sign and text, bridging the gap between these two modalities. This also allows us to train the model on larger datasets without gloss annotations. • We obtained state-of-the-art performance on the currently largest SLT dataset publicly available, improving the more modern BLEURT metric by a margin of 5.26, which is 16.9% higher than the previous state-of-the-art.","Can the problem of requiring gloss annotations for sign language translation, which limits domain coverage and hinders real-world applications, be addressed by introducing a Gloss-Free End-to-end sign language translation framework (GloFE) that improves SLT in a gloss-free setting by exploiting shared semantics and extracting common concepts as a weak intermediate representation?",2.0,1.0,1.0
170,Document-level Event Extraction via Parallel Prediction Networks,"Hang Yang, Dianbo Sui, Yubo Chen, Kang Liu, Jun Zhao, and Taifeng Wang. 2021. Document-level Event Extraction via Parallel Prediction Networks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6298–6308, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.492.pdf,https://aclanthology.org/2021.acl-long.492/,"Document-level event extraction (DEE) is indispensable when events are described throughout a document. We argue that sentence-level extractors are ill-suited to the DEE task where event arguments always scatter across sentences and multiple events may co-exist in a document. It is a challenging task because it requires a holistic understanding of the document and an aggregated ability to assemble arguments across multiple sentences. In this paper, we propose an end-to-end model, which can extract structured events from a document in a parallel manner. Specifically, we first introduce a document-level encoder to obtain the document-aware representations. Then, a multi-granularity non-autoregressive decoder is used to generate events in parallel. Finally, to train the entire model, a matching loss function is proposed, which can bootstrap a global optimization. The empirical results on the widely used DEE dataset show that our approach significantly outperforms current stateof-the-art methods in the challenging DEE task. Code will be available at https:// github.com/HangYang-NLP/DE-PPN.","The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE: arguments-scattering and multievents. Specifically, arguments-scattering indicates that arguments of an event may scatter across multiple sentences. For example, As shown in Figure 1, the arguments of Event-1 are distributed in different sentences ([S3] and [S7]) and extraction within an individual sentence will lead to incomplete results. So this challenge requires the DEE model to have a holistic understanding of the entire document and an ability to assemble all relevant arguments across sentences. Furthermore, it will be more difficult when coupled with the second challenge: multi-events, where multiple events are contained in a document.2 As shown in Figure 1, there are two events Event-1 and Event-2 in a document with the same event type and there is no obvious textual boundary between the two events. The multi-events problem requires the DEE method to recognize how many events are contained in a document and achieve accurate arguments assembling (i.e., assign arguments to the corresponding event). As a result of these two complications, SEE methods are ill-suited for the DEE task, which calls for a model that can integrate document-level information, assemble relevant arguments across multiple sentences and capture multiple events simultaneously. To handle these challenges in DEE, previous works (Yang et al., 2018; Zheng et al., 2019) formulate DEE as an event table filling task, i.e., filling candidate arguments into a predefined event table. Specifically, they model the DEE as a serial prediction paradigm, in which arguments are predicted in a predefined role order and multiple events are also extracted in predefined event order. Such a manner is restricted to the extraction of individual arguments, and the former extraction will not consider the latter extraction results. As a result, errors will be propagated and the extraction performance is under satisfaction. In this paper, to avoid the shortage of serial prediction and tackle the aforementioned challenges in DEE, we propose an end-to-end model, named Document-to-Events via Parallel Prediction Networks (DE-PPN). DE-PPN is based on an encoder-decoder framework that can extract structured events from a whole document in a parallel manner. In detail, we first introduce a documentlevel encoder to obtain the document-aware representations. In such a way, a holistic understanding of the entire document is obtained. Then, we leverage a multi-granularity decoder to generate events, which consists of two key parts: a role decoder and an event decoder. The role decoder is designed for handling the argument-scattering challenge, which can assemble arguments for an event based on document-aware representations. For addressing the challenge of multi-events effectively, an event decoder is designed to support generating multiple events. Both of them are based on the non-autoregressive mechanism (Gu et al., 2018), which supports the extraction of multiple events in parallel. Finally, for comparing extracted events to ground truths, we propose a matching loss function inspired by the Hungarian algorithm (Kuhn, 1955; Munkres, 1957). The proposed loss function can perform a global optimization by computing a bipartite matching between predicted and groundtruth events. In summary, our contributions are as follows: • We propose an encoder-decoder model, DEPPN, that is based on a document-level encoder and a multi-granularity decoder to extract events in parallel with document-aware representations. • We introduce a novel matching loss function to train the end-to-end model, which can bootstrap a global optimization. • We conduct extensive experiments on the widely used DEE dataset and experimental results demonstrate that DE-PPN can significantly outperform state-of-the-art methods when facing the specific challenges in DEE.",How can a novel end-to-end model employing a document-level encoder and a multi-granularity decoder effectively address the challenges of argument-scattering and multi-events in document-level event extraction?,1.0,1.0,1.0
171,Document-level Event Extraction via Parallel Prediction Networks,"Hang Yang, Dianbo Sui, Yubo Chen, Kang Liu, Jun Zhao, and Taifeng Wang. 2021. Document-level Event Extraction via Parallel Prediction Networks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6298–6308, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.492.pdf,https://aclanthology.org/2021.acl-long.492/,"Document-level event extraction (DEE) is indispensable when events are described throughout a document. We argue that sentence-level extractors are ill-suited to the DEE task where event arguments always scatter across sentences and multiple events may co-exist in a document. It is a challenging task because it requires a holistic understanding of the document and an aggregated ability to assemble arguments across multiple sentences. In this paper, we propose an end-to-end model, which can extract structured events from a document in a parallel manner. Specifically, we first introduce a document-level encoder to obtain the document-aware representations. Then, a multi-granularity non-autoregressive decoder is used to generate events in parallel. Finally, to train the entire model, a matching loss function is proposed, which can bootstrap a global optimization. The empirical results on the widely used DEE dataset show that our approach significantly outperforms current stateof-the-art methods in the challenging DEE task. Code will be available at https:// github.com/HangYang-NLP/DE-PPN.","The goal of event extraction (EE) is to identify events of a pre-specified type along with corresponding arguments from plain texts. A great number of previous studies (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Chen et al., 2017; Huang et al., 2018; Yang et al., 2019; Liu et al., 2020) focus on the sentence-level EE (SEE), while most of these works are based on the ACE evaluation (Doddington et al., 2004). 1 However, these SEE-based methods make predictions within a sentence and fail to extract events across sentences. To this end, document-level EE (DEE) is needed when the event information scatters across the whole document. In contrast to SEE, there are two specific challenges in DEE: arguments-scattering and multievents. Specifically, arguments-scattering indicates that arguments of an event may scatter across multiple sentences. For example, As shown in Figure 1, the arguments of Event-1 are distributed in different sentences ([S3] and [S7]) and extraction within an individual sentence will lead to incomplete results. So this challenge requires the DEE model to have a holistic understanding of the entire document and an ability to assemble all relevant arguments across sentences. Furthermore, it will be more difficult when coupled with the second challenge: multi-events, where multiple events are contained in a document.2 As shown in Figure 1, there are two events Event-1 and Event-2 in a document with the same event type and there is no obvious textual boundary between the two events. The multi-events problem requires the DEE method to recognize how many events are contained in a document and achieve accurate arguments assembling (i.e., assign arguments to the corresponding event). As a result of these two complications, SEE methods are ill-suited for the DEE task, which calls for a model that can integrate document-level information, assemble relevant arguments across multiple sentences and capture multiple events simultaneously. To handle these challenges in DEE, previous works (Yang et al., 2018; Zheng et al., 2019) formulate DEE as an event table filling task, i.e., filling candidate arguments into a predefined event table. Specifically, they model the DEE as a serial prediction paradigm, in which arguments are predicted in a predefined role order and multiple events are also extracted in predefined event order. Such a manner is restricted to the extraction of individual arguments, and the former extraction will not consider the latter extraction results. As a result, errors will be propagated and the extraction performance is under satisfaction. In this paper, to avoid the shortage of serial prediction and tackle the aforementioned challenges in DEE, we propose an end-to-end model, named Document-to-Events via Parallel Prediction Networks (DE-PPN). DE-PPN is based on an encoder-decoder framework that can extract structured events from a whole document in a parallel manner. In detail, we first introduce a documentlevel encoder to obtain the document-aware representations. In such a way, a holistic understanding of the entire document is obtained. Then, we leverage a multi-granularity decoder to generate events, which consists of two key parts: a role decoder and an event decoder. The role decoder is designed for handling the argument-scattering challenge, which can assemble arguments for an event based on document-aware representations. For addressing the challenge of multi-events effectively, an event decoder is designed to support generating multiple events. Both of them are based on the non-autoregressive mechanism (Gu et al., 2018), which supports the extraction of multiple events in parallel. Finally, for comparing extracted events to ground truths, we propose a matching loss function inspired by the Hungarian algorithm (Kuhn, 1955; Munkres, 1957). The proposed loss function can perform a global optimization by computing a bipartite matching between predicted and groundtruth events. In summary, our contributions are as follows: • We propose an encoder-decoder model, DEPPN, that is based on a document-level encoder and a multi-granularity decoder to extract events in parallel with document-aware representations. • We introduce a novel matching loss function to train the end-to-end model, which can bootstrap a global optimization. • We conduct extensive experiments on the widely used DEE dataset and experimental results demonstrate that DE-PPN can significantly outperform state-of-the-art methods when facing the specific challenges in DEE.","Can the challenges of argument-scattering across multiple sentences and the simultaneous presence of multiple events in a document be effectively addressed by the proposed end-to-end model DE-PPN, which uses a parallel prediction mechanism to extract structured events from documents?",1.0,2.0,1.0
172,Learning Functional Distributional Semantics with Visual Data,"Yinhong Liu and Guy Emerson. 2022. Learning Functional Distributional Semantics with Visual Data. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3976–3988, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.275.pdf,https://aclanthology.org/2022.acl-long.275/,"Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.","The target of distributional semantics models is to understand and represent the meanings of words from their distributions in large corpus. Many approaches learn a numerical vector for each word, which encodes its distributional information. They can be roughly divided into two categories: frequency-based methods such as cooccurrence matrix (Sahlgren, 2006), and predictionbased methods such as Word2vec (Mikolov et al., 2013). More recently, progress has been made in learning word representations in a specific context, which are also called contextualized embeddings. Examples include ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019). Functional Distributional Semantics is a framework that not only provides contextualized semantic representations, but also provides more interpretability. It was first proposed by Emerson and Copestake (2016), and it explicitly separates the modeling of words and the modeling of objects and events. This is a fundamental distinction in predicate logic. While logic is not necessary for all NLP tasks, it is an essential tool for modeling many semantic phenomena (for example, see: Cann, 1993; Allan, 2001; Kamp and Reyle, 2013). For semantic research questions, having a logical interpretation is a clear advantage over vector-based models. We will explain the framework in Section 2.2. Another issue with distributional semantic models, as discussed by Emerson (2020c), is the symbol grounding problem – if meanings of words are defined in terms of other words, the definitions are circular. During human language acquisition, words are learned while interacting with the physical world, rather than from text or speech alone. An important goal for a semantic theory is to explain how language relates to the world, and how this relationship is learned. We focus on the Visual Genome dataset, not only because it provides relatively fine-grained annotations, but also it is similar to realistic circumstance encountered during language acquisition, as we will explain in Section 2.3. Our main theoretical contribution is to adapt the Functional Distributional Semantics framework to better suit visual data. This is a step approaching the completion of long-term goal: leveraging previous work (Emerson, 2020a), we could joint train the Functional Distributional Semantics model with both textual and visual data. In order to make it compatible with modern techniques for machine vision, while retaining its logical interpretability, we replace the RBM of previous work with a Gaussian MRF, as explained in Section 3. Our main empirical contribution is to demonstrate the effectiveness of the resulting model. In Section 4.1, we intrinsically evaluate the major components of our model, to see how well they fit the training data. In Section 4.2, we evaluate our model on four external evaluation datasets, comparing against previous approaches to learning from Visual Genome, as well as strong text-based baselines. Not only do we confirm Herbelot (2020)’s finding that learning from grounded data is more data-efficient than learning from text alone, but our model outperforms the previous approaches, demonstrating the value of our functional approach.",Can functional distributional semantics be effectively trained with grounded visual data to improve the interpretability and performance of semantic models?,0.0,1.0,1.0
173,Learning Functional Distributional Semantics with Visual Data,"Yinhong Liu and Guy Emerson. 2022. Learning Functional Distributional Semantics with Visual Data. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3976–3988, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.275.pdf,https://aclanthology.org/2022.acl-long.275/,"Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.","The target of distributional semantics models is to understand and represent the meanings of words from their distributions in large corpus. Many approaches learn a numerical vector for each word, which encodes its distributional information. They can be roughly divided into two categories: frequency-based methods such as cooccurrence matrix (Sahlgren, 2006), and predictionbased methods such as Word2vec (Mikolov et al., 2013). More recently, progress has been made in learning word representations in a specific context, which are also called contextualized embeddings. Examples include ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019). Functional Distributional Semantics is a framework that not only provides contextualized semantic representations, but also provides more interpretability. It was first proposed by Emerson and Copestake (2016), and it explicitly separates the modeling of words and the modeling of objects and events. This is a fundamental distinction in predicate logic. While logic is not necessary for all NLP tasks, it is an essential tool for modeling many semantic phenomena (for example, see: Cann, 1993; Allan, 2001; Kamp and Reyle, 2013). For semantic research questions, having a logical interpretation is a clear advantage over vector-based models. We will explain the framework in Section 2.2. Another issue with distributional semantic models, as discussed by Emerson (2020c), is the symbol grounding problem – if meanings of words are defined in terms of other words, the definitions are circular. During human language acquisition, words are learned while interacting with the physical world, rather than from text or speech alone. An important goal for a semantic theory is to explain how language relates to the world, and how this relationship is learned. We focus on the Visual Genome dataset, not only because it provides relatively fine-grained annotations, but also it is similar to realistic circumstance encountered during language acquisition, as we will explain in Section 2.3. Our main theoretical contribution is to adapt the Functional Distributional Semantics framework to better suit visual data. This is a step approaching the completion of long-term goal: leveraging previous work (Emerson, 2020a), we could joint train the Functional Distributional Semantics model with both textual and visual data. In order to make it compatible with modern techniques for machine vision, while retaining its logical interpretability, we replace the RBM of previous work with a Gaussian MRF, as explained in Section 3. Our main empirical contribution is to demonstrate the effectiveness of the resulting model. In Section 4.1, we intrinsically evaluate the major components of our model, to see how well they fit the training data. In Section 4.2, we evaluate our model on four external evaluation datasets, comparing against previous approaches to learning from Visual Genome, as well as strong text-based baselines. Not only do we confirm Herbelot (2020)’s finding that learning from grounded data is more data-efficient than learning from text alone, but our model outperforms the previous approaches, demonstrating the value of our functional approach.",Can the limitations of current semantic models in accurately grounding language semantics in the physical world and in providing interpretable representations be addressed by training a Functional Distributional Semantics model with grounded visual data from the Visual Genome dataset?,1.0,1.0,1.0
174,Multitask Pretraining with Structured Knowledge for Text-to-SQL Generation,"Robert Giaquinto, Dejiao Zhang, Benjamin Kleiner, Yang Li, Ming Tan, Parminder Bhatia, Ramesh Nallapati, and Xiaofei Ma. 2023. Multitask Pretraining with Structured Knowledge for Text-to-SQL Generation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 11067–11083, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.620.pdf,https://aclanthology.org/2023.acl-long.620/,"Many machine learning-based low-code or nocode applications involve generating code that interacts with structured knowledge. For example, one of the most studied tasks in this area is generating SQL code from a natural language statement. Prior work shows that incorporating context information from the database schema, such as table and column names, is beneficial to model performance on this task. In this work we present a large pretraining dataset and strategy for learning representations of text, tables, and SQL code that leverages the entire context of the problem. Specifically, we build on existing encoder-decoder architecture by introducing a multitask pretraining framework that complements the unique attributes of our diverse pretraining data. Our work represents the first study on large-scale pretraining of encoderdecoder models for interacting with structured knowledge, and offers a new state-of-the-art foundation model in text-to-SQL generation. We validate our approach with experiments on two SQL tasks, showing improvement over existing methods, including a 1.7 and 2.2 percentage point improvement over prior state-of-thearts on Spider and CoSQL.","Tables, relational databases, and other forms of structured knowledge (SK) encompass a massive amount of data across a wide range of applications. Extracting insights held in such data often requires proficiency in query languages like SQL, making it only accessible to the minority of people with the technical skills. A natural language interface, however, would expand access to these information exponentially. Likewise, querying via natural language allows users quickly hone in on an answer to their particular question, rather than visually scanning dense tables where the majority of the information is irrelevant to the user. To that end, we explore pretraining techniques for large language models that focus on the challenging interplay between structured and unstructured knowledge, and target a variety of downstream text-to-SQL tasks. Recently there have been significant advancements in learning representations for tables (Yin et al., 2020; Herzig et al., 2020; Eisenschlos et al., 2020; Liu et al., 2022; Wang et al., 2021c; Yu et al., 2021; Cheng et al., 2022; Dong et al., 2022), which advanced the state-of-the-art in a range of table-totext tasks, like table question-answering (Nan et al., 2022; Chen et al., 2021), fact verification (Chen et al., 2020; Aly et al., 2021), data-to-text (Parikh et al., 2020; Nan et al., 2021), and semantic parsing (Yu et al., 2019b; Zhong et al., 2017). While better table understanding benefits a range of tasks, pretraining focused on text-to-SQL has thus far received less attention. Pretrained encoders, such as TaBERT and TAPAS (Yu et al., 2021; Yin et al., 2020; Herzig et al., 2020), show that pretraining BERT-style encoders (Devlin et al., 2019) on tables with mask language modeling (MLM) loss produces a strong foundation model that can be extended for text-to-SQL. GRAPPA includes small amount of synthetic SQL code in the pretraining data to more specifically target the text-to-SQL task (Yu et al., 2021). These encoder-only approaches are, however, restricted in their generative capabilities as they must be combined with an additional module that is carefully designed to generate valid SQL code (Zhong et al., 2017; Wang et al., 2021a). Encoder-decoder architectures like T5 (Raffel et al., 2020), on the other hand, exhibit better performance on text-to-SQL to-date when constraining the decoder with rules that check for syntactic correctness (Scholak et al., 2021). However, the T5- based models with exceptional text-to-SQL performance (Xie et al., 2022; Scholak et al., 2021) have still only been pretrained on natural language (NL) — begging the question, can text-to-SQL encoderdecoders benefit from pretraining on structured in formation or code? Most recently, Andrejczuk et al. (2022) proposed a multi-task tabular pretraining strategy for T5 model, but their work introduced the tabular knowledge to the model with a single data source, i.e. Wikipedia tables. In this work we introduce our SQL and Table Aligned Multi-task Pretraining (STAMP) framework, which explores pretraining encoder-decoder models for text-to-SQL. Starting from text-only T5 (Raffel et al., 2020) checkpoints, our multi-stage pretraining framework refines previous text-only models by continuing training on a collection of large multi-modal datasets that combine structured knowledge with natural language and SQL. Additionally, inspired by the impressive generalization of large language models incorporating code in pretraining data (Athiwaratkun et al., 2022; Brown et al., 2020; Chowdhery et al., 2022; Du et al., 2022; Thoppilan et al., 2022), we apply our pretraining framework to CodeT5 (Wang et al., 2021b) checkpoints that are trained on code. Building on recent work in multi-task pretraining (Tay et al., 2022; Aghajanyan et al., 2021; Sanh et al., 2022; Aribandi et al., 2021), we combine masked language modeling (MLM) with taskaware context-to-output objectives that vary across tasks and datasets. For pretraining datasets with multiple modalities (i.e. combinations of NL, SQL, and structured knowledge) or intrinsic splits (e.g. question and answer), we explore the benefit of the dual learning objectives (Wang et al., 2021b). We assess our pretraining strategy on a variety of SQL benchmarks following the UnifiedSKG framework (Xie et al., 2022). Our approach outperforms previous text- and code-only pretraining, and gives a new state-of-the-art on a range of benchmarks. To better understand our strategy, we present ablation studies on the optimal objective mix, the impact of linearizing structured knowledge into row- versus column-centric tables, and the effect of building on previously pretrained text- versus code-only checkpoints. Our work shows that continued pretraining with multi-task learning is a promising direction for advancing the capacity of language models.","Can multi-stage pretraining, incorporating a combination of natural language, SQL, and structured knowledge, enhance the performance of encoder-decoder models on text-to-SQL generation tasks?",1.0,1.0,1.0
175,Multitask Pretraining with Structured Knowledge for Text-to-SQL Generation,"Robert Giaquinto, Dejiao Zhang, Benjamin Kleiner, Yang Li, Ming Tan, Parminder Bhatia, Ramesh Nallapati, and Xiaofei Ma. 2023. Multitask Pretraining with Structured Knowledge for Text-to-SQL Generation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 11067–11083, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.620.pdf,https://aclanthology.org/2023.acl-long.620/,"Many machine learning-based low-code or nocode applications involve generating code that interacts with structured knowledge. For example, one of the most studied tasks in this area is generating SQL code from a natural language statement. Prior work shows that incorporating context information from the database schema, such as table and column names, is beneficial to model performance on this task. In this work we present a large pretraining dataset and strategy for learning representations of text, tables, and SQL code that leverages the entire context of the problem. Specifically, we build on existing encoder-decoder architecture by introducing a multitask pretraining framework that complements the unique attributes of our diverse pretraining data. Our work represents the first study on large-scale pretraining of encoderdecoder models for interacting with structured knowledge, and offers a new state-of-the-art foundation model in text-to-SQL generation. We validate our approach with experiments on two SQL tasks, showing improvement over existing methods, including a 1.7 and 2.2 percentage point improvement over prior state-of-thearts on Spider and CoSQL.","Tables, relational databases, and other forms of structured knowledge (SK) encompass a massive amount of data across a wide range of applications. Extracting insights held in such data often requires proficiency in query languages like SQL, making it only accessible to the minority of people with the technical skills. A natural language interface, however, would expand access to these information exponentially. Likewise, querying via natural language allows users quickly hone in on an answer to their particular question, rather than visually scanning dense tables where the majority of the information is irrelevant to the user. To that end, we explore pretraining techniques for large language models that focus on the challenging interplay between structured and unstructured knowledge, and target a variety of downstream text-to-SQL tasks. Recently there have been significant advancements in learning representations for tables (Yin et al., 2020; Herzig et al., 2020; Eisenschlos et al., 2020; Liu et al., 2022; Wang et al., 2021c; Yu et al., 2021; Cheng et al., 2022; Dong et al., 2022), which advanced the state-of-the-art in a range of table-totext tasks, like table question-answering (Nan et al., 2022; Chen et al., 2021), fact verification (Chen et al., 2020; Aly et al., 2021), data-to-text (Parikh et al., 2020; Nan et al., 2021), and semantic parsing (Yu et al., 2019b; Zhong et al., 2017). While better table understanding benefits a range of tasks, pretraining focused on text-to-SQL has thus far received less attention. Pretrained encoders, such as TaBERT and TAPAS (Yu et al., 2021; Yin et al., 2020; Herzig et al., 2020), show that pretraining BERT-style encoders (Devlin et al., 2019) on tables with mask language modeling (MLM) loss produces a strong foundation model that can be extended for text-to-SQL. GRAPPA includes small amount of synthetic SQL code in the pretraining data to more specifically target the text-to-SQL task (Yu et al., 2021). These encoder-only approaches are, however, restricted in their generative capabilities as they must be combined with an additional module that is carefully designed to generate valid SQL code (Zhong et al., 2017; Wang et al., 2021a). Encoder-decoder architectures like T5 (Raffel et al., 2020), on the other hand, exhibit better performance on text-to-SQL to-date when constraining the decoder with rules that check for syntactic correctness (Scholak et al., 2021). However, the T5- based models with exceptional text-to-SQL performance (Xie et al., 2022; Scholak et al., 2021) have still only been pretrained on natural language (NL) — begging the question, can text-to-SQL encoderdecoders benefit from pretraining on structured in formation or code? Most recently, Andrejczuk et al. (2022) proposed a multi-task tabular pretraining strategy for T5 model, but their work introduced the tabular knowledge to the model with a single data source, i.e. Wikipedia tables. In this work we introduce our SQL and Table Aligned Multi-task Pretraining (STAMP) framework, which explores pretraining encoder-decoder models for text-to-SQL. Starting from text-only T5 (Raffel et al., 2020) checkpoints, our multi-stage pretraining framework refines previous text-only models by continuing training on a collection of large multi-modal datasets that combine structured knowledge with natural language and SQL. Additionally, inspired by the impressive generalization of large language models incorporating code in pretraining data (Athiwaratkun et al., 2022; Brown et al., 2020; Chowdhery et al., 2022; Du et al., 2022; Thoppilan et al., 2022), we apply our pretraining framework to CodeT5 (Wang et al., 2021b) checkpoints that are trained on code. Building on recent work in multi-task pretraining (Tay et al., 2022; Aghajanyan et al., 2021; Sanh et al., 2022; Aribandi et al., 2021), we combine masked language modeling (MLM) with taskaware context-to-output objectives that vary across tasks and datasets. For pretraining datasets with multiple modalities (i.e. combinations of NL, SQL, and structured knowledge) or intrinsic splits (e.g. question and answer), we explore the benefit of the dual learning objectives (Wang et al., 2021b). We assess our pretraining strategy on a variety of SQL benchmarks following the UnifiedSKG framework (Xie et al., 2022). Our approach outperforms previous text- and code-only pretraining, and gives a new state-of-the-art on a range of benchmarks. To better understand our strategy, we present ablation studies on the optimal objective mix, the impact of linearizing structured knowledge into row- versus column-centric tables, and the effect of building on previously pretrained text- versus code-only checkpoints. Our work shows that continued pretraining with multi-task learning is a promising direction for advancing the capacity of language models.","Can text-to-SQL performance be improved by introducing a multitask pretraining framework that leverages the entire context of natural language, SQL, and structured knowledge?",1.0,1.0,1.0
176,Multitask Pretraining with Structured Knowledge for Text-to-SQL Generation,"Robert Giaquinto, Dejiao Zhang, Benjamin Kleiner, Yang Li, Ming Tan, Parminder Bhatia, Ramesh Nallapati, and Xiaofei Ma. 2023. Multitask Pretraining with Structured Knowledge for Text-to-SQL Generation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 11067–11083, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.620.pdf,https://aclanthology.org/2023.acl-long.620/,"Many machine learning-based low-code or nocode applications involve generating code that interacts with structured knowledge. For example, one of the most studied tasks in this area is generating SQL code from a natural language statement. Prior work shows that incorporating context information from the database schema, such as table and column names, is beneficial to model performance on this task. In this work we present a large pretraining dataset and strategy for learning representations of text, tables, and SQL code that leverages the entire context of the problem. Specifically, we build on existing encoder-decoder architecture by introducing a multitask pretraining framework that complements the unique attributes of our diverse pretraining data. Our work represents the first study on large-scale pretraining of encoderdecoder models for interacting with structured knowledge, and offers a new state-of-the-art foundation model in text-to-SQL generation. We validate our approach with experiments on two SQL tasks, showing improvement over existing methods, including a 1.7 and 2.2 percentage point improvement over prior state-of-thearts on Spider and CoSQL.","Tables, relational databases, and other forms of structured knowledge (SK) encompass a massive amount of data across a wide range of applications. Extracting insights held in such data often requires proficiency in query languages like SQL, making it only accessible to the minority of people with the technical skills. A natural language interface, however, would expand access to these information exponentially. Likewise, querying via natural language allows users quickly hone in on an answer to their particular question, rather than visually scanning dense tables where the majority of the information is irrelevant to the user. To that end, we explore pretraining techniques for large language models that focus on the challenging interplay between structured and unstructured knowledge, and target a variety of downstream text-to-SQL tasks. Recently there have been significant advancements in learning representations for tables (Yin et al., 2020; Herzig et al., 2020; Eisenschlos et al., 2020; Liu et al., 2022; Wang et al., 2021c; Yu et al., 2021; Cheng et al., 2022; Dong et al., 2022), which advanced the state-of-the-art in a range of table-totext tasks, like table question-answering (Nan et al., 2022; Chen et al., 2021), fact verification (Chen et al., 2020; Aly et al., 2021), data-to-text (Parikh et al., 2020; Nan et al., 2021), and semantic parsing (Yu et al., 2019b; Zhong et al., 2017). While better table understanding benefits a range of tasks, pretraining focused on text-to-SQL has thus far received less attention. Pretrained encoders, such as TaBERT and TAPAS (Yu et al., 2021; Yin et al., 2020; Herzig et al., 2020), show that pretraining BERT-style encoders (Devlin et al., 2019) on tables with mask language modeling (MLM) loss produces a strong foundation model that can be extended for text-to-SQL. GRAPPA includes small amount of synthetic SQL code in the pretraining data to more specifically target the text-to-SQL task (Yu et al., 2021). These encoder-only approaches are, however, restricted in their generative capabilities as they must be combined with an additional module that is carefully designed to generate valid SQL code (Zhong et al., 2017; Wang et al., 2021a). Encoder-decoder architectures like T5 (Raffel et al., 2020), on the other hand, exhibit better performance on text-to-SQL to-date when constraining the decoder with rules that check for syntactic correctness (Scholak et al., 2021). However, the T5- based models with exceptional text-to-SQL performance (Xie et al., 2022; Scholak et al., 2021) have still only been pretrained on natural language (NL) — begging the question, can text-to-SQL encoderdecoders benefit from pretraining on structured in formation or code? Most recently, Andrejczuk et al. (2022) proposed a multi-task tabular pretraining strategy for T5 model, but their work introduced the tabular knowledge to the model with a single data source, i.e. Wikipedia tables. In this work we introduce our SQL and Table Aligned Multi-task Pretraining (STAMP) framework, which explores pretraining encoder-decoder models for text-to-SQL. Starting from text-only T5 (Raffel et al., 2020) checkpoints, our multi-stage pretraining framework refines previous text-only models by continuing training on a collection of large multi-modal datasets that combine structured knowledge with natural language and SQL. Additionally, inspired by the impressive generalization of large language models incorporating code in pretraining data (Athiwaratkun et al., 2022; Brown et al., 2020; Chowdhery et al., 2022; Du et al., 2022; Thoppilan et al., 2022), we apply our pretraining framework to CodeT5 (Wang et al., 2021b) checkpoints that are trained on code. Building on recent work in multi-task pretraining (Tay et al., 2022; Aghajanyan et al., 2021; Sanh et al., 2022; Aribandi et al., 2021), we combine masked language modeling (MLM) with taskaware context-to-output objectives that vary across tasks and datasets. For pretraining datasets with multiple modalities (i.e. combinations of NL, SQL, and structured knowledge) or intrinsic splits (e.g. question and answer), we explore the benefit of the dual learning objectives (Wang et al., 2021b). We assess our pretraining strategy on a variety of SQL benchmarks following the UnifiedSKG framework (Xie et al., 2022). Our approach outperforms previous text- and code-only pretraining, and gives a new state-of-the-art on a range of benchmarks. To better understand our strategy, we present ablation studies on the optimal objective mix, the impact of linearizing structured knowledge into row- versus column-centric tables, and the effect of building on previously pretrained text- versus code-only checkpoints. Our work shows that continued pretraining with multi-task learning is a promising direction for advancing the capacity of language models.","Can the insufficiency of current pretraining methods for text-to-SQL tasks, which focus primarily on natural language or structured knowledge in isolation, be addressed by a multitask pretraining framework that combines natural language, SQL, and structured knowledge into the pretraining phase?",1.0,2.0,1.0
177,Tailored Sequence to Sequence Models to Different Conversation Scenarios,"Hainan Zhang, Yanyan Lan, Jiafeng Guo, Jun Xu, and Xueqi Cheng. 2018. Tailored Sequence to Sequence Models to Different Conversation Scenarios. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1479–1488, Melbourne, Australia. Association for Computational Linguistics.",https://aclanthology.org/P18-1137.pdf,https://aclanthology.org/P18-1137/,"Sequence to sequence (Seq2Seq) models have been widely used for response generation in the area of conversation. However, the requirements for different conversation scenarios are distinct. For example, customer service requires the generated responses to be specific and accurate, while chatbot prefers diverse responses so as to attract different users. The current Seq2Seq model fails to meet these diverse requirements, by using a general average likelihood as the optimization criteria. As a result, it usually generates safe and commonplace responses, such as ‘I don’t know’. In this paper, we propose two tailored optimization criteria for Seq2Seq to different conversation scenarios, i.e., the maximum generated likelihood for specific-requirement scenario, and the conditional value-at-risk for diverse-requirement scenario. Experimental results on the Ubuntu dialogue corpus (Ubuntu service scenario) and Chinese Weibo dataset (social chatbot scenario) show that our proposed models not only satisfies diverse requirements for different scenarios, but also yields better performances against traditional Seq2Seq models in terms of both metric-based and human evaluations.","This paper focuses on the problem of the singleturn dialogue generation, which is critical in many natural language processing applications such as customer services, intelligent assistant and chatbot. Recently, sequence to sequence (Seq2Seq) models (Sutskever et al., 2014) have been widely used in this area. In these Seq2Seq models, a recurrent neural network (RNN) based encoder is first utilized to encode the input post to a vector, and another RNN decoder is then used to automatically generate the response word by word. The parameters of the encoder and decoder are learned by maximizing the averaged likelihood of the training data. It is clear that the requirements for generated responses are distinct in different dialogue scenarios. For instance, in the scenario of customer service or mobile assistant, users mainly expect the system to help them solve a problem. Therefore, the responses should be specific and accurate to provide useful assistance. For example, if the user asks a question ‘How can I get the AMD driver running on Ubuntu 12.10?’, the system is expected to reply ‘The fglrx driver is in the repo. But it may depend on your exact chipset.’, rather than ‘I do not know about the package.’, even though the latter can also be viewed as relevant for the proposed question. We called this kind of scenario as specific-requirement scenario. While in other scenarios such as chatbot, users are interacting with the dialogue system for fun. Therefore, the generated responses should be diverse to attract different users. Take the post ‘Can you recommend me a tourist city?’ as an example. If the user prefers the magnificent mountains and rivers, it is better to reply ‘You may like the Bernina Express to the Alps’. While if the user loves literature, it is better to reply ‘Paris is a beautiful city with full of the literary atmosphere’. This kind of scenario is called diverse-requirement scenario. However, the current generation model Seq2Seq (Sutskever et al., 2014) usually tend to generate common responses, such as ‘I don’t know’ and ‘What does this mean?’ (Li et al., 2016a,b; Zhou et al., 2017), which fails to meet diverse requirements for different conversation scenarios. Intrinsically, conversation is a typical one-to-many application, i.e., multiple responses with different semantic meanings are correspondent to a same post. That means there are various post-response matching patterns in the training data. Seq2Seq optimizes an averaged likelihood, so it can only capture the common matching patterns, leading to common responses. The purpose of this paper is to propose two tailored optimization criteria for Seq2Seq models to accommodate different conversation scenarios, i.e. specific-requirement scenario and diverserequirement scenario. The key idea is to how capture the required post-response matching patterns. For the specific-requirement scenario, we define the maximum generated likelihood as the objective function. With this kind of criterion, we just require one ground-truth response to be close to the given post, instead of requiring the average of multiple ground-truth responses to be close to the post. Therefore, the most significant post-response matching pattern will be learned from the data, to facilitate generating a specific response. While for the diverse-requirement scenario, the conditional value-at-risk (CVaR) is used as the objective function. CVaR is a risk-sensitive function widely used in finances (Rockafellar and Uryasev, 2002; Alexander et al., 2006; Chen et al., 2015), defined to assessing the likelihood (at a specific confidence level) that a specific loss will exceed the value at risk. With CVaR as the objective function, the worst 1-α responses are required to be close to the post, therefore various post-response patterns can be captured, and the learned model has the ability to generate diverse responses. We use public data to evaluate our proposed models. For the specific-requirement scenario, the experiments on public Ubuntu dialogue corpus(Ubuntu service) show that optimizing the maximum generated likelihood produces more specific and accurate responses than traditional Seq2Seq models. While for the diverserequirement scenario, the experiments on the public Chinese Weibo dataset (social chatbot) show that optimizing CVaR produces diverse responses, as compared with Seq2Seq and the variants.","Can the problem of generating overly generic responses in Seq2Seq models for different conversation scenarios be addressed by employing tailored optimization criteria, specifically maximum generated likelihood for specific-requirement scenarios and CVaR for diverse-requirement scenarios?",2.0,2.0,1.0
178,Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training,"Yan Zeng, Wangchunshu Zhou, Ao Luo, Ziming Cheng, and Xinsong Zhang. 2023. Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5731–5746, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.315.pdf,https://aclanthology.org/2023.acl-long.315/,"In this paper, we introduce Cross-View Language Modeling, a simple and effective pretraining framework that unifies cross-lingual and cross-modal pre-training with shared architectures and objectives. Our approach is motivated by a key observation that cross-lingual and cross-modal pre-training share the same goal of aligning two different views of the same object into a common semantic space. To this end, the cross-view language modeling framework considers both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as two different views of the same object, and trains the model to align the two views by maximizing the mutual information between them with conditional masked language modeling and contrastive learning. We pre-train CCLM, a Crosslingual Cross-modal Language Model, with the cross-view language modeling framework. Empirical results on IGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual image-text retrieval datasets show that while conceptually simpler, CCLM significantly outperforms the prior state-of-the-art with an average absolute improvement of over 10%. Moreover, CCLM is the first multi-lingual multimodal pre-trained model that surpasses the translate-test performance of representative English vision-language models by zero-shot cross-lingual transfer.","Recently, the tremendous success of selfsupervised language model pre-training (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Liu et al., 2019; Radford et al., 2019; Dong et al., 2019; Raffel et al., 2019; Lewis et al., 2020; Brown et al., 2020) has been expanded to the multi-lingual (Conneau and Lample, 2019; Conneau et al., 2020; Pfeiffer et al., 2020; Chi et al., 2021) and multi-modal (Lu et al., 2019; Tan and Bansal, 2019; Su et al., 2020; Chen et al., 2020; Li et al., 2020) domain. Advances on multi-lingual pre-training enables cutting-edge language technology to benefit a much boarder group of users including non-English speakers. Similarly, multimodal pre-training makes pre-trained models applicable to a much larger set of tasks and user groups. Both of these directions make people’s lives in a multi-lingual multi-modal world easier. Therefore, a natural next step is to explore multi-lingual multi-modal pre-training which enables pre-trained models to solve multi-modal tasks expressed in non-English languages without the need of collecting training data in these languages, which can be very costly for certain low-resource languages. While appealing, multi-lingual multi-modal pretraining has its own challenges. Unlike multilingual pre-training and multi-modal pre-training where relatively large amount of parallel data is available, there exists only a few multi-lingual multi-modal corpora and their language coverage is also limited. Two pioneering works, M3P (Ni et al., 2021) and UC2 (Zhou et al., 2021), propose to pivot either on English texts or images to align multi-lingual multi-modal representations. Both of them introduce a number of new objectives to make use of the anchor for alignment. However, a recent benchmark on multi-lingual multi-modal pre-training (Bugliarello et al., 2022) reveals that these multi-lingual multi-modal pre-trained models are still falling short: while achieving seemingly promising zero-shot cross-lingual transfer performance on some vision-and-language tasks, they still significantly under-perform “translatetest”, a simple baseline which translates the test examples into English and uses an English-only vision-language model for inference. This prevents existing multi-lingual multi-modal models to be applicable in real-world applications. In contrast, multi-lingual pre-trained models such as XLMR (Conneau et al., 2020) significantly outperforms the translate-test baseline in most languages and is widely used in practical applications. This paper aims to fully exploit the potential of multi-lingual multi-modal pre-training. We point out two major limitation of current state-of-thearts. First, existing methods do not exploit parallel text corpora, which can be easily collected and are abundant for many language pairs. Instead, M3P performs masked language modeling with monolingual texts in different languages for multi-lingual alignment. However, parallel texts are shown to be more helpful according to multi-lingual pretraining literature (Conneau et al., 2020; Chi et al., 2021). Second, a number of new pre-training objectives involving specific architecture changes and different input-output formats are introduced for English or image pivoting, making it non-trivial to combine them together for better performance and scale to larger data. In this work, we argue that multi-lingual and multi-modal pre-training are essentially achieving the same goal of aligning two different views of a same object into a common semantic space. Therefore, we believe these two seemingly different strategies can be combined into a unified framework. To this end, we introduce cross-view language modeling, a simple and effective framework that unifies cross-lingual and cross-modal pretraining with shared architecture and objectives. Specifically, we consider both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as pairs of two different views of the same object. With either multimodal or multi-lingual data as input, we encode the two views with Transformer models and then fuse their representations with a cross-attention Transformer model shared for both cross-modal and cross-lingual fusion. We train the model to align the two views into a common semantic space by maximizing the mutual information between them with a conditional masked language modeling objective, a contrastive learning objective, and a matching objective. In this way, the cross-view language modeling framework unifies English pivoting and image pivoting schemes seamlessly and makes the best of both worlds. To evaluate the effectiveness of our approach, we pre-train CCLM, a Cross-lingual Cross-modal Language Model, with the proposed cross-view language modeling framework. Experimental results show that CCLM significantly outperforms prior state-of-the-art with an averaged absolute improvement of over 10% and 30% on multi-lingual visionlanguage understanding and retrieval tasks in terms of accuracy and R@1 on IGLUE (Bugliarello et al., 2022), a recently released multi-lingual multimodal benchmark. Notably, CCLM is the first multi-lingual vision-language model that surpasses the “translate-test” performance of mono-lingual vision-language models via zero-shot cross-lingual transfer, which we believe is a crucial step towards practical multi-lingual multi-modal pre-training. Since previous work used different pre-training datasets, making direct comparison difficult, we also conduct an in-depth ablation study to investigate the contribution of different parts in our framework. The results show that use of parallel sentence pairs helps to fully exploit the potential of language pivoting for multi-lingual multi-modal pre-training and also confirm the importance of unified architectures and objectives in CCLM. Contributions. (1) We propose a cross-view language modeling framework that unifies multilingual and multi-modal pre-training with shared architectures and objectives. (2) CCLM advances the state-of-the-art of multi-lingual vision-language pre-training by a large margin. It also surpasses the translate-test baseline for the first time, demonstrating the potential of multi-lingual multi-modal pre-training. (3) We further scale up CCLM with massive pre-training data and larger model size. We will release our large-scale pre-trained multilingual multi-modal models to benefit a larger set of tasks and user groups and setup a strong and easily reproducible baseline for multi-lingual multimodal research.","How can the integration of cross-lingual and cross-modal pre-training into a unified framework improve the performance of language models on multi-lingual and multi-modal tasks, including those involving low-resource languages?",0.0,1.0,1.0
179,Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training,"Yan Zeng, Wangchunshu Zhou, Ao Luo, Ziming Cheng, and Xinsong Zhang. 2023. Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5731–5746, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.315.pdf,https://aclanthology.org/2023.acl-long.315/,"In this paper, we introduce Cross-View Language Modeling, a simple and effective pretraining framework that unifies cross-lingual and cross-modal pre-training with shared architectures and objectives. Our approach is motivated by a key observation that cross-lingual and cross-modal pre-training share the same goal of aligning two different views of the same object into a common semantic space. To this end, the cross-view language modeling framework considers both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as two different views of the same object, and trains the model to align the two views by maximizing the mutual information between them with conditional masked language modeling and contrastive learning. We pre-train CCLM, a Crosslingual Cross-modal Language Model, with the cross-view language modeling framework. Empirical results on IGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual image-text retrieval datasets show that while conceptually simpler, CCLM significantly outperforms the prior state-of-the-art with an average absolute improvement of over 10%. Moreover, CCLM is the first multi-lingual multimodal pre-trained model that surpasses the translate-test performance of representative English vision-language models by zero-shot cross-lingual transfer.","Recently, the tremendous success of selfsupervised language model pre-training (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Liu et al., 2019; Radford et al., 2019; Dong et al., 2019; Raffel et al., 2019; Lewis et al., 2020; Brown et al., 2020) has been expanded to the multi-lingual (Conneau and Lample, 2019; Conneau et al., 2020; Pfeiffer et al., 2020; Chi et al., 2021) and multi-modal (Lu et al., 2019; Tan and Bansal, 2019; Su et al., 2020; Chen et al., 2020; Li et al., 2020) domain. Advances on multi-lingual pre-training enables cutting-edge language technology to benefit a much boarder group of users including non-English speakers. Similarly, multimodal pre-training makes pre-trained models applicable to a much larger set of tasks and user groups. Both of these directions make people’s lives in a multi-lingual multi-modal world easier. Therefore, a natural next step is to explore multi-lingual multi-modal pre-training which enables pre-trained models to solve multi-modal tasks expressed in non-English languages without the need of collecting training data in these languages, which can be very costly for certain low-resource languages. While appealing, multi-lingual multi-modal pretraining has its own challenges. Unlike multilingual pre-training and multi-modal pre-training where relatively large amount of parallel data is available, there exists only a few multi-lingual multi-modal corpora and their language coverage is also limited. Two pioneering works, M3P (Ni et al., 2021) and UC2 (Zhou et al., 2021), propose to pivot either on English texts or images to align multi-lingual multi-modal representations. Both of them introduce a number of new objectives to make use of the anchor for alignment. However, a recent benchmark on multi-lingual multi-modal pre-training (Bugliarello et al., 2022) reveals that these multi-lingual multi-modal pre-trained models are still falling short: while achieving seemingly promising zero-shot cross-lingual transfer performance on some vision-and-language tasks, they still significantly under-perform “translatetest”, a simple baseline which translates the test examples into English and uses an English-only vision-language model for inference. This prevents existing multi-lingual multi-modal models to be applicable in real-world applications. In contrast, multi-lingual pre-trained models such as XLMR (Conneau et al., 2020) significantly outperforms the translate-test baseline in most languages and is widely used in practical applications. This paper aims to fully exploit the potential of multi-lingual multi-modal pre-training. We point out two major limitation of current state-of-thearts. First, existing methods do not exploit parallel text corpora, which can be easily collected and are abundant for many language pairs. Instead, M3P performs masked language modeling with monolingual texts in different languages for multi-lingual alignment. However, parallel texts are shown to be more helpful according to multi-lingual pretraining literature (Conneau et al., 2020; Chi et al., 2021). Second, a number of new pre-training objectives involving specific architecture changes and different input-output formats are introduced for English or image pivoting, making it non-trivial to combine them together for better performance and scale to larger data. In this work, we argue that multi-lingual and multi-modal pre-training are essentially achieving the same goal of aligning two different views of a same object into a common semantic space. Therefore, we believe these two seemingly different strategies can be combined into a unified framework. To this end, we introduce cross-view language modeling, a simple and effective framework that unifies cross-lingual and cross-modal pretraining with shared architecture and objectives. Specifically, we consider both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as pairs of two different views of the same object. With either multimodal or multi-lingual data as input, we encode the two views with Transformer models and then fuse their representations with a cross-attention Transformer model shared for both cross-modal and cross-lingual fusion. We train the model to align the two views into a common semantic space by maximizing the mutual information between them with a conditional masked language modeling objective, a contrastive learning objective, and a matching objective. In this way, the cross-view language modeling framework unifies English pivoting and image pivoting schemes seamlessly and makes the best of both worlds. To evaluate the effectiveness of our approach, we pre-train CCLM, a Cross-lingual Cross-modal Language Model, with the proposed cross-view language modeling framework. Experimental results show that CCLM significantly outperforms prior state-of-the-art with an averaged absolute improvement of over 10% and 30% on multi-lingual visionlanguage understanding and retrieval tasks in terms of accuracy and R@1 on IGLUE (Bugliarello et al., 2022), a recently released multi-lingual multimodal benchmark. Notably, CCLM is the first multi-lingual vision-language model that surpasses the “translate-test” performance of mono-lingual vision-language models via zero-shot cross-lingual transfer, which we believe is a crucial step towards practical multi-lingual multi-modal pre-training. Since previous work used different pre-training datasets, making direct comparison difficult, we also conduct an in-depth ablation study to investigate the contribution of different parts in our framework. The results show that use of parallel sentence pairs helps to fully exploit the potential of language pivoting for multi-lingual multi-modal pre-training and also confirm the importance of unified architectures and objectives in CCLM. Contributions. (1) We propose a cross-view language modeling framework that unifies multilingual and multi-modal pre-training with shared architectures and objectives. (2) CCLM advances the state-of-the-art of multi-lingual vision-language pre-training by a large margin. It also surpasses the translate-test baseline for the first time, demonstrating the potential of multi-lingual multi-modal pre-training. (3) We further scale up CCLM with massive pre-training data and larger model size. We will release our large-scale pre-trained multilingual multi-modal models to benefit a larger set of tasks and user groups and setup a strong and easily reproducible baseline for multi-lingual multimodal research.",Can multi-lingual multi-modal pre-training be effectively unified into a common semantic space using the cross-view language modeling framework?,0.0,1.0,1.0
180,Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training,"Yan Zeng, Wangchunshu Zhou, Ao Luo, Ziming Cheng, and Xinsong Zhang. 2023. Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5731–5746, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.315.pdf,https://aclanthology.org/2023.acl-long.315/,"In this paper, we introduce Cross-View Language Modeling, a simple and effective pretraining framework that unifies cross-lingual and cross-modal pre-training with shared architectures and objectives. Our approach is motivated by a key observation that cross-lingual and cross-modal pre-training share the same goal of aligning two different views of the same object into a common semantic space. To this end, the cross-view language modeling framework considers both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as two different views of the same object, and trains the model to align the two views by maximizing the mutual information between them with conditional masked language modeling and contrastive learning. We pre-train CCLM, a Crosslingual Cross-modal Language Model, with the cross-view language modeling framework. Empirical results on IGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual image-text retrieval datasets show that while conceptually simpler, CCLM significantly outperforms the prior state-of-the-art with an average absolute improvement of over 10%. Moreover, CCLM is the first multi-lingual multimodal pre-trained model that surpasses the translate-test performance of representative English vision-language models by zero-shot cross-lingual transfer.","Recently, the tremendous success of selfsupervised language model pre-training (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019; Liu et al., 2019; Radford et al., 2019; Dong et al., 2019; Raffel et al., 2019; Lewis et al., 2020; Brown et al., 2020) has been expanded to the multi-lingual (Conneau and Lample, 2019; Conneau et al., 2020; Pfeiffer et al., 2020; Chi et al., 2021) and multi-modal (Lu et al., 2019; Tan and Bansal, 2019; Su et al., 2020; Chen et al., 2020; Li et al., 2020) domain. Advances on multi-lingual pre-training enables cutting-edge language technology to benefit a much boarder group of users including non-English speakers. Similarly, multimodal pre-training makes pre-trained models applicable to a much larger set of tasks and user groups. Both of these directions make people’s lives in a multi-lingual multi-modal world easier. Therefore, a natural next step is to explore multi-lingual multi-modal pre-training which enables pre-trained models to solve multi-modal tasks expressed in non-English languages without the need of collecting training data in these languages, which can be very costly for certain low-resource languages. While appealing, multi-lingual multi-modal pretraining has its own challenges. Unlike multilingual pre-training and multi-modal pre-training where relatively large amount of parallel data is available, there exists only a few multi-lingual multi-modal corpora and their language coverage is also limited. Two pioneering works, M3P (Ni et al., 2021) and UC2 (Zhou et al., 2021), propose to pivot either on English texts or images to align multi-lingual multi-modal representations. Both of them introduce a number of new objectives to make use of the anchor for alignment. However, a recent benchmark on multi-lingual multi-modal pre-training (Bugliarello et al., 2022) reveals that these multi-lingual multi-modal pre-trained models are still falling short: while achieving seemingly promising zero-shot cross-lingual transfer performance on some vision-and-language tasks, they still significantly under-perform “translatetest”, a simple baseline which translates the test examples into English and uses an English-only vision-language model for inference. This prevents existing multi-lingual multi-modal models to be applicable in real-world applications. In contrast, multi-lingual pre-trained models such as XLMR (Conneau et al., 2020) significantly outperforms the translate-test baseline in most languages and is widely used in practical applications. This paper aims to fully exploit the potential of multi-lingual multi-modal pre-training. We point out two major limitation of current state-of-thearts. First, existing methods do not exploit parallel text corpora, which can be easily collected and are abundant for many language pairs. Instead, M3P performs masked language modeling with monolingual texts in different languages for multi-lingual alignment. However, parallel texts are shown to be more helpful according to multi-lingual pretraining literature (Conneau et al., 2020; Chi et al., 2021). Second, a number of new pre-training objectives involving specific architecture changes and different input-output formats are introduced for English or image pivoting, making it non-trivial to combine them together for better performance and scale to larger data. In this work, we argue that multi-lingual and multi-modal pre-training are essentially achieving the same goal of aligning two different views of a same object into a common semantic space. Therefore, we believe these two seemingly different strategies can be combined into a unified framework. To this end, we introduce cross-view language modeling, a simple and effective framework that unifies cross-lingual and cross-modal pretraining with shared architecture and objectives. Specifically, we consider both multi-modal data (i.e., image-caption pairs) and multi-lingual data (i.e., parallel sentence pairs) as pairs of two different views of the same object. With either multimodal or multi-lingual data as input, we encode the two views with Transformer models and then fuse their representations with a cross-attention Transformer model shared for both cross-modal and cross-lingual fusion. We train the model to align the two views into a common semantic space by maximizing the mutual information between them with a conditional masked language modeling objective, a contrastive learning objective, and a matching objective. In this way, the cross-view language modeling framework unifies English pivoting and image pivoting schemes seamlessly and makes the best of both worlds. To evaluate the effectiveness of our approach, we pre-train CCLM, a Cross-lingual Cross-modal Language Model, with the proposed cross-view language modeling framework. Experimental results show that CCLM significantly outperforms prior state-of-the-art with an averaged absolute improvement of over 10% and 30% on multi-lingual visionlanguage understanding and retrieval tasks in terms of accuracy and R@1 on IGLUE (Bugliarello et al., 2022), a recently released multi-lingual multimodal benchmark. Notably, CCLM is the first multi-lingual vision-language model that surpasses the “translate-test” performance of mono-lingual vision-language models via zero-shot cross-lingual transfer, which we believe is a crucial step towards practical multi-lingual multi-modal pre-training. Since previous work used different pre-training datasets, making direct comparison difficult, we also conduct an in-depth ablation study to investigate the contribution of different parts in our framework. The results show that use of parallel sentence pairs helps to fully exploit the potential of language pivoting for multi-lingual multi-modal pre-training and also confirm the importance of unified architectures and objectives in CCLM. Contributions. (1) We propose a cross-view language modeling framework that unifies multilingual and multi-modal pre-training with shared architectures and objectives. (2) CCLM advances the state-of-the-art of multi-lingual vision-language pre-training by a large margin. It also surpasses the translate-test baseline for the first time, demonstrating the potential of multi-lingual multi-modal pre-training. (3) We further scale up CCLM with massive pre-training data and larger model size. We will release our large-scale pre-trained multilingual multi-modal models to benefit a larger set of tasks and user groups and setup a strong and easily reproducible baseline for multi-lingual multimodal research.","Can the suboptimal performance of current multi-lingual multi-modal pre-training methods in real-world applications and their limitations in fully exploiting available parallel text corpora be overcome by introducing a unified pre-training framework called Cross-View Language Modeling, which aligns multi-lingual and cross-modal data into a common semantic space using shared architecture and objectives, along with the development of a Cross-lingual Cross-modal Language Model (CCLM)?",2.0,2.0,1.0
181,MGR: Multi-generator Based Rationalization,"Wei Liu, Haozhao Wang, Jun Wang, Ruixuan Li, Xinyang Li, YuanKai Zhang, and Yang Qiu. 2023. MGR: Multi-generator Based Rationalization. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12771–12787, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.715.pdf,https://aclanthology.org/2023.acl-long.715/,"Rationalization is to employ a generator and a predictor to construct a self-explaining NLP model in which the generator selects a subset of human-intelligible pieces of the input text to the following predictor. However, rationalization suffers from two key challenges, i.e., spurious correlation and degeneration, where the predictor overfits the spurious or meaningless pieces solely selected by the not-yet well-trained generator and in turn deteriorates the generator. Although many studies have been proposed to address the two challenges, they are usually designed separately and do not take both of them into account. In this paper, we propose a simple yet effective method named MGR to simultaneously solve the two problems. The key idea of MGR is to employ multiple generators such that the occurrence stability of real pieces is improved and more meaningful pieces are delivered to the predictor. Empirically1 , we show that MGR improves the F1 score by up to 20.9% as compared to state-of-the-art methods.","The widespread use of deep learning in NLP models has led to increased concerns about interpretability. To solve this problem, Lei et al. (2016) proposed rationalization framework RNP in which a generator selects human-intelligible subsets (i.e., rationales) from the input text and feeds them to the subsequent predictor that maximizes the text classification accuracy, as shown in Figure 1. Unlike post-hoc approaches for explaining black-box models, the RNP framework has the built-in selfexplaining ability through a cooperative game between the generator and the predictor. RNP and its variants have become one of the mainstreams to facilitate the interpretability of NLP models (Yu et al., 2021; Liu et al., 2022, 2023). Notably, given the versatility of the self-explaining rationalization framework, such methods have significant potential for application in diverse fields such as multiaspect recommender systems (Deng et al., 2023) and computer vision (Yuan et al., 2022). Despite its strength, rationalization schemes are notoriously hard to train. Two main training obstacles are the spurious correlations (Chang et al., 2020) and the degeneration (Yu et al., 2019). As shown in the example of Table 1(a), the problem of spurious correlations is that the predictor mistakenly makes a correlation between the label on some specific aspect and the spurious pieces on another similar aspect, which commonly exists in multiaspect classification (Chang et al., 2020; Plyler et al., 2021; Yue et al., 2023). Degeneration means that the predictor may overfit to meaningless rationales generated by the not yet well-trained generator (Yu et al., 2019), causing the converged generator tends to select these uninformative rationales, which is illustrated in the example of Table 1(b). Many prior efforts have separately considered the problem of spurious correlations or degeneration in rationalization. For instance, to solve the problem of spurious correlations, some recent methods leverage the idea of causal inference to build the causal relationship between the rationale and label (Chang et al., 2020; Yue et al., 2023). The common idea to address the degeneration problem is to introduce some auxiliary modules such that the predictor has access to the full texts, and thus it cannot overfit the meaningless rationales solely provided by the generator (Yu et al., 2019; Huang et al., 2021; Yu et al., 2021). Although these approaches may be effective at either solving the problem of spurious correlations or degeneration isolation, they are usually designed separately and do not take both of them into account. In this paper, we seek to simultaneously solve the two problems. Specifically, we identify that both two problems arise from that the predictor has only access to the limited view of pieces provided by the single generator, and thus may learn corruptly when this generator selects spurious or meaningless rationales. Besides, recent studies find that the initialization of the model has a significant impact over the training performance, which implicitly indicates that the rationalization model is hardly to train once the single generator is not well initialized (Jain et al., 2020; Yu et al., 2021). Considering these limitations of the rationalization with one single generator, as shown in Figure 2, we design a novel architecture where there is a predictor but with multiple generators. These generators are initialized with different parameters. In this way, the view of the predictor is not limited to one single generator and it can have access to more meaningful rationales. We theoretically show that the occurrence stability of real rationales increases such that the predictor has lower risks at learning spurious correlations, and that the diversity of the rationales is improved such that the predictor can hardly deviate to some specific meaningless rationale. Extensive experiments conducted on three widely used rationalization benchmarks, i.e., the correlated BeerAdvocate dataset (McAuley et al., 2012), the decorrelated BeerAdvocate dataset (Lei et al., 2016), and the Hotel Reviews dataset (Wang et al., 2010), show that MGR achieves significant improvements over several state-of-the-art methods in terms of the rationale quality. Our contributions can be summarized as: ● To the best of our knowledge, this paper is the first to simultaneously solve the spurious correlations and degeneration problem in rationalization. We propose a simple but effective method, namely, MGR, that facilitates the predictor to have a broader view of the rationales by using multiple generators. ● We theoretically prove that using multiple generators can provide real rationales more stably such that the risk of the predictor learning spurious correlations is reduced. Besides, we prove that multiple generators can produce more diverse rationales and thus the predictor will not overfit to some specific meaningless rationale. ● We conduct extensive experiments over various datasets and show that MGR achieves an improvement by up to 20.9% as compared to state-of-theart rationalization methods in terms of F1 score.",How can a rationalization model employing multiple generators simultaneously address the problem of spurious correlations and degeneration to improve the training stability and effectiveness of NLP models?,1.0,1.0,1.0
182,MGR: Multi-generator Based Rationalization,"Wei Liu, Haozhao Wang, Jun Wang, Ruixuan Li, Xinyang Li, YuanKai Zhang, and Yang Qiu. 2023. MGR: Multi-generator Based Rationalization. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12771–12787, Toronto, Canada. Association for Computational Linguistics.",https://aclanthology.org/2023.acl-long.715.pdf,https://aclanthology.org/2023.acl-long.715/,"Rationalization is to employ a generator and a predictor to construct a self-explaining NLP model in which the generator selects a subset of human-intelligible pieces of the input text to the following predictor. However, rationalization suffers from two key challenges, i.e., spurious correlation and degeneration, where the predictor overfits the spurious or meaningless pieces solely selected by the not-yet well-trained generator and in turn deteriorates the generator. Although many studies have been proposed to address the two challenges, they are usually designed separately and do not take both of them into account. In this paper, we propose a simple yet effective method named MGR to simultaneously solve the two problems. The key idea of MGR is to employ multiple generators such that the occurrence stability of real pieces is improved and more meaningful pieces are delivered to the predictor. Empirically1 , we show that MGR improves the F1 score by up to 20.9% as compared to state-of-the-art methods.","The widespread use of deep learning in NLP models has led to increased concerns about interpretability. To solve this problem, Lei et al. (2016) proposed rationalization framework RNP in which a generator selects human-intelligible subsets (i.e., rationales) from the input text and feeds them to the subsequent predictor that maximizes the text classification accuracy, as shown in Figure 1. Unlike post-hoc approaches for explaining black-box models, the RNP framework has the built-in selfexplaining ability through a cooperative game between the generator and the predictor. RNP and its variants have become one of the mainstreams to facilitate the interpretability of NLP models (Yu et al., 2021; Liu et al., 2022, 2023). Notably, given the versatility of the self-explaining rationalization framework, such methods have significant potential for application in diverse fields such as multiaspect recommender systems (Deng et al., 2023) and computer vision (Yuan et al., 2022). Despite its strength, rationalization schemes are notoriously hard to train. Two main training obstacles are the spurious correlations (Chang et al., 2020) and the degeneration (Yu et al., 2019). As shown in the example of Table 1(a), the problem of spurious correlations is that the predictor mistakenly makes a correlation between the label on some specific aspect and the spurious pieces on another similar aspect, which commonly exists in multiaspect classification (Chang et al., 2020; Plyler et al., 2021; Yue et al., 2023). Degeneration means that the predictor may overfit to meaningless rationales generated by the not yet well-trained generator (Yu et al., 2019), causing the converged generator tends to select these uninformative rationales, which is illustrated in the example of Table 1(b). Many prior efforts have separately considered the problem of spurious correlations or degeneration in rationalization. For instance, to solve the problem of spurious correlations, some recent methods leverage the idea of causal inference to build the causal relationship between the rationale and label (Chang et al., 2020; Yue et al., 2023). The common idea to address the degeneration problem is to introduce some auxiliary modules such that the predictor has access to the full texts, and thus it cannot overfit the meaningless rationales solely provided by the generator (Yu et al., 2019; Huang et al., 2021; Yu et al., 2021). Although these approaches may be effective at either solving the problem of spurious correlations or degeneration isolation, they are usually designed separately and do not take both of them into account. In this paper, we seek to simultaneously solve the two problems. Specifically, we identify that both two problems arise from that the predictor has only access to the limited view of pieces provided by the single generator, and thus may learn corruptly when this generator selects spurious or meaningless rationales. Besides, recent studies find that the initialization of the model has a significant impact over the training performance, which implicitly indicates that the rationalization model is hardly to train once the single generator is not well initialized (Jain et al., 2020; Yu et al., 2021). Considering these limitations of the rationalization with one single generator, as shown in Figure 2, we design a novel architecture where there is a predictor but with multiple generators. These generators are initialized with different parameters. In this way, the view of the predictor is not limited to one single generator and it can have access to more meaningful rationales. We theoretically show that the occurrence stability of real rationales increases such that the predictor has lower risks at learning spurious correlations, and that the diversity of the rationales is improved such that the predictor can hardly deviate to some specific meaningless rationale. Extensive experiments conducted on three widely used rationalization benchmarks, i.e., the correlated BeerAdvocate dataset (McAuley et al., 2012), the decorrelated BeerAdvocate dataset (Lei et al., 2016), and the Hotel Reviews dataset (Wang et al., 2010), show that MGR achieves significant improvements over several state-of-the-art methods in terms of the rationale quality. Our contributions can be summarized as: ● To the best of our knowledge, this paper is the first to simultaneously solve the spurious correlations and degeneration problem in rationalization. We propose a simple but effective method, namely, MGR, that facilitates the predictor to have a broader view of the rationales by using multiple generators. ● We theoretically prove that using multiple generators can provide real rationales more stably such that the risk of the predictor learning spurious correlations is reduced. Besides, we prove that multiple generators can produce more diverse rationales and thus the predictor will not overfit to some specific meaningless rationale. ● We conduct extensive experiments over various datasets and show that MGR achieves an improvement by up to 20.9% as compared to state-of-theart rationalization methods in terms of F1 score.","Can employing multiple generators in the rationalization process improve the occurrence stability of real pieces and deliver more meaningful pieces to the predictor, thus addressing the issues of spurious correlation and degeneration in creating effective self-explaining NLP models?",1.0,1.0,1.0
183,Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction,"Lanbo She and Joyce Chai. 2016. Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 108–117, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1011.pdf,https://aclanthology.org/P16-1011/,"As a new generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands and to learn new actions from human language instructions. To address this issue, this paper presents an approach that explicitly represents verb semantics through hypothesis spaces of fluents and automatically acquires these hypothesis spaces by interacting with humans. The learned hypothesis spaces can be used to automatically plan for lower-level primitive actions towards physical world interaction. Our empirical results have shown that the representation of a hypothesis space of fluents, combined with the learned hypothesis selection algorithm, outperforms a previous baseline. In addition, our approach applies incremental learning, which can contribute to life-long learning from humans in the future.","As a new generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands (Tellex et al., 2014; Thomason et al., 2015) and to learn new actions from human language instructions (Cantrell et al., 2012; Mohan et al., 2013). To achieve such a capability, one of the fundamental challenges is to link higher-level concepts expressed by human language to lower-level primitive actions the robot is familiar with. While grounding language to perception (Gorniak and Roy, 2007; Chen and Mooney, 2011; Kim and Mooney, 2012; Artzi and Zettlemoyer, 2013; Tellex et al., 2014; Liu et al., 2014; Liu and Chai, 2015) has received much attention in recent years, less work has addressed grounding language to robotic action. Actions are often expressed by verbs or verb phrases. Most semantic representations for verbs are based on argument frames (e.g., thematic roles which capture participants of an action). For example, suppose a human directs a robot to “fill the cup with milk”. The robot will need to first create a semantic representation for the verb “fill” where “the cup” and “milk” are grounded to the respective objects in the environment (Yang et al., 2016). Suppose the robot is successful in this first step, it still may not be able to execute the action “fill” as it does not know how this higher-level action corresponds to its lower-level primitive actions. In robotic systems, operations usually consist of multiple segments of lower-level primitive actions (e.g., move to, open gripper, and close gripper) which are executed both sequentially and concurrently. Task scheduling provides the order or schedule for executions of different segments of actions and action planning provides the plan for executing each individual segment. Primitive actions are often predefined in terms of how they change the state of the physical world. Given a goal, task scheduling and action planning will derive a sequence of primitive actions that can change the initial environment to the goal state. The goal state of the physical world becomes a driving force for robot actions. Thus, beyond semantic frames, modeling verb semantics through their effects on the state of the world may provide a link to connect higher-level language and lowerlevel primitive actions. Motivated by this perspective, we have developed an approach where each verb is explicitly represented by a hypothesis space of fluents (i.e., desired goal states) of the physical world, which is incrementally acquired and updated through interacting with humans. More specifically, given a human command, if there is no knowledge about the corresponding verb (i.e., no existing hypothesis space for that verb), the robot will initiate a learning process by asking human partners to demonstrate the sequence of actions that is necessary to accomplish this command. Based on this demonstration, a hypothesis space of fluents for that verb frame will be automatically acquired. If there is an existing hypothesis space for the verb, the robot will select the best hypothesis that is most relevant to the current situation and plan for the sequence of lower-level actions. Based on the outcome of the actions (e.g., whether it has successfully executed the command), the corresponding hypothesis space will be updated. Through this fashion, a hypothesis space for each encountered verb frame is incrementally acquired and updated through continuous interactions with human partners. In this paper, to focus our effort on representations and learning algorithms, we adopted an existing benchmark dataset (Misra et al., 2015) to simulate the incremental learning process and interaction with humans. Compared to previous works (She et al., 2014b; Misra et al., 2015), our approach has three unique characteristics. First, rather than a single goal state associated with a verb, our approach captures a space of hypotheses which can potentially account for a wider range of novel situations when the verb is applied. Second, given a new situation, our approach can automatically identify the best hypothesis that fits the current situation and plan for lower-level actions accordingly. Third, through incremental learning and acquisition, our approach has a potential to contribute to life-long learning from humans. This paper provides details on the hypothesis space representation, the induction and inference algorithms, as well as experiments and evaluation results.",Can the understanding and execution of human language commands by robots be improved through the representation of verb semantics as hypothesis spaces of fluents and their incremental acquisition from human interaction?,1.0,2.0,1.0
184,Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction,"Lanbo She and Joyce Chai. 2016. Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 108–117, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1011.pdf,https://aclanthology.org/P16-1011/,"As a new generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands and to learn new actions from human language instructions. To address this issue, this paper presents an approach that explicitly represents verb semantics through hypothesis spaces of fluents and automatically acquires these hypothesis spaces by interacting with humans. The learned hypothesis spaces can be used to automatically plan for lower-level primitive actions towards physical world interaction. Our empirical results have shown that the representation of a hypothesis space of fluents, combined with the learned hypothesis selection algorithm, outperforms a previous baseline. In addition, our approach applies incremental learning, which can contribute to life-long learning from humans in the future.","As a new generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands (Tellex et al., 2014; Thomason et al., 2015) and to learn new actions from human language instructions (Cantrell et al., 2012; Mohan et al., 2013). To achieve such a capability, one of the fundamental challenges is to link higher-level concepts expressed by human language to lower-level primitive actions the robot is familiar with. While grounding language to perception (Gorniak and Roy, 2007; Chen and Mooney, 2011; Kim and Mooney, 2012; Artzi and Zettlemoyer, 2013; Tellex et al., 2014; Liu et al., 2014; Liu and Chai, 2015) has received much attention in recent years, less work has addressed grounding language to robotic action. Actions are often expressed by verbs or verb phrases. Most semantic representations for verbs are based on argument frames (e.g., thematic roles which capture participants of an action). For example, suppose a human directs a robot to “fill the cup with milk”. The robot will need to first create a semantic representation for the verb “fill” where “the cup” and “milk” are grounded to the respective objects in the environment (Yang et al., 2016). Suppose the robot is successful in this first step, it still may not be able to execute the action “fill” as it does not know how this higher-level action corresponds to its lower-level primitive actions. In robotic systems, operations usually consist of multiple segments of lower-level primitive actions (e.g., move to, open gripper, and close gripper) which are executed both sequentially and concurrently. Task scheduling provides the order or schedule for executions of different segments of actions and action planning provides the plan for executing each individual segment. Primitive actions are often predefined in terms of how they change the state of the physical world. Given a goal, task scheduling and action planning will derive a sequence of primitive actions that can change the initial environment to the goal state. The goal state of the physical world becomes a driving force for robot actions. Thus, beyond semantic frames, modeling verb semantics through their effects on the state of the world may provide a link to connect higher-level language and lowerlevel primitive actions. Motivated by this perspective, we have developed an approach where each verb is explicitly represented by a hypothesis space of fluents (i.e., desired goal states) of the physical world, which is incrementally acquired and updated through interacting with humans. More specifically, given a human command, if there is no knowledge about the corresponding verb (i.e., no existing hypothesis space for that verb), the robot will initiate a learning process by asking human partners to demonstrate the sequence of actions that is necessary to accomplish this command. Based on this demonstration, a hypothesis space of fluents for that verb frame will be automatically acquired. If there is an existing hypothesis space for the verb, the robot will select the best hypothesis that is most relevant to the current situation and plan for the sequence of lower-level actions. Based on the outcome of the actions (e.g., whether it has successfully executed the command), the corresponding hypothesis space will be updated. Through this fashion, a hypothesis space for each encountered verb frame is incrementally acquired and updated through continuous interactions with human partners. In this paper, to focus our effort on representations and learning algorithms, we adopted an existing benchmark dataset (Misra et al., 2015) to simulate the incremental learning process and interaction with humans. Compared to previous works (She et al., 2014b; Misra et al., 2015), our approach has three unique characteristics. First, rather than a single goal state associated with a verb, our approach captures a space of hypotheses which can potentially account for a wider range of novel situations when the verb is applied. Second, given a new situation, our approach can automatically identify the best hypothesis that fits the current situation and plan for lower-level actions accordingly. Third, through incremental learning and acquisition, our approach has a potential to contribute to life-long learning from humans. This paper provides details on the hypothesis space representation, the induction and inference algorithms, as well as experiments and evaluation results.","Can the problem of enabling robots to understand and execute human commands given in natural language be solved by representing verb semantics as hypothesis spaces of fluents, acquired and updated through interactions with humans, and using these spaces to plan and execute lower-level actions?",1.0,2.0,1.0
185,Neural Discourse Structure for Text Categorization,"Yangfeng Ji and Noah A. Smith. 2017. Neural Discourse Structure for Text Categorization. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 996–1005, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1092.pdf,https://aclanthology.org/P17-1092/,"We show that discourse structure, as defined by Rhetorical Structure Theory and provided by an existing discourse parser, benefits text categorization. Our approach uses a recursive neural network and a newly proposed attention mechanism to compute a representation of the text that focuses on salient content, from the perspective of both RST and the task. Experiments consider variants of the approach and illustrate its strengths and weaknesses.","Advances in text categorization have the potential to improve systems for analyzing sentiment, inferring authorship or author attributes, making predictions, and many more. Several past researchers have noticed that methods that reason about the relative salience or importance of passages within a text can lead to improvements (Ko et al., 2004). Latent variables (Yessenalina et al., 2010), structured-sparse regularizers (Yogatama and Smith, 2014), and neural attention models (Yang et al., 2016) have all been explored. Discourse structure, which represents the organization of a text as a tree (for an example, see Figure 1), might provide cues for the importance of different parts of a text. Some promising results on sentiment classification tasks support this idea: Bhatia et al. (2015) and Hogenboom et al. (2015) applied hand-crafted weighting schemes to the sentences in a document, based on its discourse structure, and showed benefit to sentiment polarity classification. In this paper, we investigate the value of discourse structure for text categorization more broadly, considering five tasks, through the use of a recursive neural network built on an automatically-derived document parse from a topperforming, open-source discourse parser, DPLP (Ji and Eisenstein, 2014). Our models learn to weight the importance of a document’s sentences, based on their positions and relations in the discourse tree. We introduce a new, unnormalized attention mechanism to this end. Experimental results show that variants of our model outperform prior work on four out of five tasks considered. Our method unsurprisingly underperforms on the fifth task, making predictions about legislative bills—a genre in which discourse conventions are quite different from those in the discourse parser’s training data. Further experiments show the effect of discourse parse quality on text categorization performance, suggesting that future improvements to discourse parsing will pay off for text categorization, and validate our new attention mechanism. Our implementation is available at https:// github.com/jiyfeng/disco4textcat.","How does incorporating discourse structure, as defined by Rhetorical Structure Theory and processed with a new attention mechanism in a recursive neural network, enhance text categorization across various tasks, and how does the quality of discourse parsing affect this categorization performance?",2.0,2.0,1.0
186,Neural Discourse Structure for Text Categorization,"Yangfeng Ji and Noah A. Smith. 2017. Neural Discourse Structure for Text Categorization. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 996–1005, Vancouver, Canada. Association for Computational Linguistics.",https://aclanthology.org/P17-1092.pdf,https://aclanthology.org/P17-1092/,"We show that discourse structure, as defined by Rhetorical Structure Theory and provided by an existing discourse parser, benefits text categorization. Our approach uses a recursive neural network and a newly proposed attention mechanism to compute a representation of the text that focuses on salient content, from the perspective of both RST and the task. Experiments consider variants of the approach and illustrate its strengths and weaknesses.","Advances in text categorization have the potential to improve systems for analyzing sentiment, inferring authorship or author attributes, making predictions, and many more. Several past researchers have noticed that methods that reason about the relative salience or importance of passages within a text can lead to improvements (Ko et al., 2004). Latent variables (Yessenalina et al., 2010), structured-sparse regularizers (Yogatama and Smith, 2014), and neural attention models (Yang et al., 2016) have all been explored. Discourse structure, which represents the organization of a text as a tree (for an example, see Figure 1), might provide cues for the importance of different parts of a text. Some promising results on sentiment classification tasks support this idea: Bhatia et al. (2015) and Hogenboom et al. (2015) applied hand-crafted weighting schemes to the sentences in a document, based on its discourse structure, and showed benefit to sentiment polarity classification. In this paper, we investigate the value of discourse structure for text categorization more broadly, considering five tasks, through the use of a recursive neural network built on an automatically-derived document parse from a topperforming, open-source discourse parser, DPLP (Ji and Eisenstein, 2014). Our models learn to weight the importance of a document’s sentences, based on their positions and relations in the discourse tree. We introduce a new, unnormalized attention mechanism to this end. Experimental results show that variants of our model outperform prior work on four out of five tasks considered. Our method unsurprisingly underperforms on the fifth task, making predictions about legislative bills—a genre in which discourse conventions are quite different from those in the discourse parser’s training data. Further experiments show the effect of discourse parse quality on text categorization performance, suggesting that future improvements to discourse parsing will pay off for text categorization, and validate our new attention mechanism. Our implementation is available at https:// github.com/jiyfeng/disco4textcat.",Can the need for enhanced text categorization in applications like sentiment analysis and author attribute prediction be addressed by utilizing discourse structure through a recursive neural network and a novel attention mechanism to better emphasize salient text content?,2.0,1.0,1.0
187,StereoSet: Measuring stereotypical bias in pretrained language models,"Moin Nadeem, Anna Bethke, and Siva Reddy. 2021. StereoSet: Measuring stereotypical bias in pretrained language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5356–5371, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.416.pdf,https://aclanthology.org/2021.acl-long.416/,"A stereotype is an over-generalized belief about a particular group of people, e.g., Asians are good at math or African Americans are athletic. Such beliefs (biases) are known to hurt target groups. Since pretrained language models are trained on large real world data, they are known to capture stereotypical biases. It is important to quantify to what extent these biases are present in them. Although this is a rapidly growing area of research, existing literature lacks in two important aspects: 1) they mainly evaluate bias of pretrained language models on a small set of artificial sentences, even though these models are trained on natural data; 2) current evaluations focus on measuring bias without considering the language modeling ability of a model, which could lead to misleading trust on a model even if it is a poor language model. We address both these problems. We present StereoSet, a large-scale natural English dataset to measure stereotypical biases in four domains: gender, profession, race, and religion. We contrast both stereotypical bias and language modeling ability of popular models like BERT, GPT2, ROBERTA, and XLNET. We show that these models exhibit strong stereotypical biases. Our data and code are available at https://stereoset. mit.edu.","A key idea behind the current success of neural network models for language is pretrained representations such as word embeddings (Mikolov et al., 2013; Pennington et al., 2014) and pretrained language models (Peters et al., 2018; Howard and Ruder, 2018; Devlin et al., 2019; Radford et al., 2019; Liu et al., 2019). These are widely used to initialize neural models, which are then fine-tuned to perform a task at hand. Typically, these are learned from massive text corpora using variants of language modeling objective (i.e., predicting a word given its surrounding context). In the recent years, these representations empowered neural models to attain unprecedented levels of performance gains on multiple language tasks. The resulting models are being deployed widely as services on platforms like Google Cloud and Amazon AWS to serve millions of users. While this growth is commendable, there are concerns about the fairness of these models. Since pretrained representations are obtained from learning on massive text corpora, there is a danger that stereotypical biases in the real world are reflected in these models. For example, GPT2 (Radford et al., 2019), a pretrained language model, has shown to generate unpleasant stereotypical text when prompted with context containing certain races such as African-Americans (Sheng et al., 2019). In this work, we assess the stereotypical biases of popular pretrained language models. The seminal works of Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word embeddings such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) contain stereotypical biases using diagnostic methods like word analogies and association tests. For example, Caliskan et al. show that male names are more likely to be associated with career terms than female names where the association is measured using embedding similarity. Recently, studies have attempted to evaluate bias in contextual word embeddings where a word is provided with artificial context (May et al., 2019; Kurita et al., 2019), e.g., the contextual embedding of man is obtained from the embedding of man in the sentence This is a man. However, these have limitations. First, the context does not reflect the natural usage of a word. Second, they require stereotypical attribute terms to be predefined (e.g., pleasant and unpleasant terms). Third, they focus on single word terms and ignore multiword terms like construction worker. Lastly, they study bias of a model independent of its language modeling ability which could lead to undeserved trust in a model if it is a poor language model. In this work, we propose methods to evaluate stereotypical bias of pretrained language models. These methods do not have the aforementioned limitations. Specifically, we design two different association tests, one for measuring bias at sentence level (intrasentence), and the other at discourse level (intersentence) as shown in Figure 1.. In these tests, each target term (e.g., Arab) is provided with a natural context in which it appears, along with three possible associative contexts. The associative contexts help us to evaluate the biases of the model, as well as measure its language modeling performance. We crowdsource StereoSet, a dataset for associative contexts in English containing 4 target domains, 321 target terms and 16,995 test instances (triplets).","What is the extent of stereotypical biases present in popular pretrained language models like BERT, GPT2, ROBERTA, and XLNET when evaluated on a large-scale dataset consisting of natural English sentences, and how does it contrast with their language modeling abilities?",0.0,0.0,0.0
188,StereoSet: Measuring stereotypical bias in pretrained language models,"Moin Nadeem, Anna Bethke, and Siva Reddy. 2021. StereoSet: Measuring stereotypical bias in pretrained language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5356–5371, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.416.pdf,https://aclanthology.org/2021.acl-long.416/,"A stereotype is an over-generalized belief about a particular group of people, e.g., Asians are good at math or African Americans are athletic. Such beliefs (biases) are known to hurt target groups. Since pretrained language models are trained on large real world data, they are known to capture stereotypical biases. It is important to quantify to what extent these biases are present in them. Although this is a rapidly growing area of research, existing literature lacks in two important aspects: 1) they mainly evaluate bias of pretrained language models on a small set of artificial sentences, even though these models are trained on natural data; 2) current evaluations focus on measuring bias without considering the language modeling ability of a model, which could lead to misleading trust on a model even if it is a poor language model. We address both these problems. We present StereoSet, a large-scale natural English dataset to measure stereotypical biases in four domains: gender, profession, race, and religion. We contrast both stereotypical bias and language modeling ability of popular models like BERT, GPT2, ROBERTA, and XLNET. We show that these models exhibit strong stereotypical biases. Our data and code are available at https://stereoset. mit.edu.","A key idea behind the current success of neural network models for language is pretrained representations such as word embeddings (Mikolov et al., 2013; Pennington et al., 2014) and pretrained language models (Peters et al., 2018; Howard and Ruder, 2018; Devlin et al., 2019; Radford et al., 2019; Liu et al., 2019). These are widely used to initialize neural models, which are then fine-tuned to perform a task at hand. Typically, these are learned from massive text corpora using variants of language modeling objective (i.e., predicting a word given its surrounding context). In the recent years, these representations empowered neural models to attain unprecedented levels of performance gains on multiple language tasks. The resulting models are being deployed widely as services on platforms like Google Cloud and Amazon AWS to serve millions of users. While this growth is commendable, there are concerns about the fairness of these models. Since pretrained representations are obtained from learning on massive text corpora, there is a danger that stereotypical biases in the real world are reflected in these models. For example, GPT2 (Radford et al., 2019), a pretrained language model, has shown to generate unpleasant stereotypical text when prompted with context containing certain races such as African-Americans (Sheng et al., 2019). In this work, we assess the stereotypical biases of popular pretrained language models. The seminal works of Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word embeddings such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) contain stereotypical biases using diagnostic methods like word analogies and association tests. For example, Caliskan et al. show that male names are more likely to be associated with career terms than female names where the association is measured using embedding similarity. Recently, studies have attempted to evaluate bias in contextual word embeddings where a word is provided with artificial context (May et al., 2019; Kurita et al., 2019), e.g., the contextual embedding of man is obtained from the embedding of man in the sentence This is a man. However, these have limitations. First, the context does not reflect the natural usage of a word. Second, they require stereotypical attribute terms to be predefined (e.g., pleasant and unpleasant terms). Third, they focus on single word terms and ignore multiword terms like construction worker. Lastly, they study bias of a model independent of its language modeling ability which could lead to undeserved trust in a model if it is a poor language model. In this work, we propose methods to evaluate stereotypical bias of pretrained language models. These methods do not have the aforementioned limitations. Specifically, we design two different association tests, one for measuring bias at sentence level (intrasentence), and the other at discourse level (intersentence) as shown in Figure 1.. In these tests, each target term (e.g., Arab) is provided with a natural context in which it appears, along with three possible associative contexts. The associative contexts help us to evaluate the biases of the model, as well as measure its language modeling performance. We crowdsource StereoSet, a dataset for associative contexts in English containing 4 target domains, 321 target terms and 16,995 test instances (triplets).",Can stereotypical biases in pretrained language models be quantified using a large-scale natural English dataset?,1.0,1.0,0.0
189,StereoSet: Measuring stereotypical bias in pretrained language models,"Moin Nadeem, Anna Bethke, and Siva Reddy. 2021. StereoSet: Measuring stereotypical bias in pretrained language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 5356–5371, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.416.pdf,https://aclanthology.org/2021.acl-long.416/,"A stereotype is an over-generalized belief about a particular group of people, e.g., Asians are good at math or African Americans are athletic. Such beliefs (biases) are known to hurt target groups. Since pretrained language models are trained on large real world data, they are known to capture stereotypical biases. It is important to quantify to what extent these biases are present in them. Although this is a rapidly growing area of research, existing literature lacks in two important aspects: 1) they mainly evaluate bias of pretrained language models on a small set of artificial sentences, even though these models are trained on natural data; 2) current evaluations focus on measuring bias without considering the language modeling ability of a model, which could lead to misleading trust on a model even if it is a poor language model. We address both these problems. We present StereoSet, a large-scale natural English dataset to measure stereotypical biases in four domains: gender, profession, race, and religion. We contrast both stereotypical bias and language modeling ability of popular models like BERT, GPT2, ROBERTA, and XLNET. We show that these models exhibit strong stereotypical biases. Our data and code are available at https://stereoset. mit.edu.","A key idea behind the current success of neural network models for language is pretrained representations such as word embeddings (Mikolov et al., 2013; Pennington et al., 2014) and pretrained language models (Peters et al., 2018; Howard and Ruder, 2018; Devlin et al., 2019; Radford et al., 2019; Liu et al., 2019). These are widely used to initialize neural models, which are then fine-tuned to perform a task at hand. Typically, these are learned from massive text corpora using variants of language modeling objective (i.e., predicting a word given its surrounding context). In the recent years, these representations empowered neural models to attain unprecedented levels of performance gains on multiple language tasks. The resulting models are being deployed widely as services on platforms like Google Cloud and Amazon AWS to serve millions of users. While this growth is commendable, there are concerns about the fairness of these models. Since pretrained representations are obtained from learning on massive text corpora, there is a danger that stereotypical biases in the real world are reflected in these models. For example, GPT2 (Radford et al., 2019), a pretrained language model, has shown to generate unpleasant stereotypical text when prompted with context containing certain races such as African-Americans (Sheng et al., 2019). In this work, we assess the stereotypical biases of popular pretrained language models. The seminal works of Bolukbasi et al. (2016) and Caliskan et al. (2017) show that word embeddings such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) contain stereotypical biases using diagnostic methods like word analogies and association tests. For example, Caliskan et al. show that male names are more likely to be associated with career terms than female names where the association is measured using embedding similarity. Recently, studies have attempted to evaluate bias in contextual word embeddings where a word is provided with artificial context (May et al., 2019; Kurita et al., 2019), e.g., the contextual embedding of man is obtained from the embedding of man in the sentence This is a man. However, these have limitations. First, the context does not reflect the natural usage of a word. Second, they require stereotypical attribute terms to be predefined (e.g., pleasant and unpleasant terms). Third, they focus on single word terms and ignore multiword terms like construction worker. Lastly, they study bias of a model independent of its language modeling ability which could lead to undeserved trust in a model if it is a poor language model. In this work, we propose methods to evaluate stereotypical bias of pretrained language models. These methods do not have the aforementioned limitations. Specifically, we design two different association tests, one for measuring bias at sentence level (intrasentence), and the other at discourse level (intersentence) as shown in Figure 1.. In these tests, each target term (e.g., Arab) is provided with a natural context in which it appears, along with three possible associative contexts. The associative contexts help us to evaluate the biases of the model, as well as measure its language modeling performance. We crowdsource StereoSet, a dataset for associative contexts in English containing 4 target domains, 321 target terms and 16,995 test instances (triplets).","Can the presence of stereotypical biases in pretrained language models be accurately quantified by evaluating them on ""StereoSet,"" a dataset that measures biases across gender, profession, race, and religion domains while also considering their language modeling ability?",2.0,2.0,1.0
190,Robust Lottery Tickets for Pre-trained Language Models,"Rui Zheng, Bao Rong, Yuhao Zhou, Di Liang, Sirui Wang, Wei Wu, Tao Gui, Qi Zhang, and Xuanjing Huang. 2022. Robust Lottery Tickets for Pre-trained Language Models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2211–2224, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.157.pdf,https://aclanthology.org/2022.acl-long.157/,"Recent works on Lottery Ticket Hypothesis have shown that pre-trained language models (PLMs) contain smaller matching subnetworks (winning tickets) which are capable of reaching accuracy comparable to the original models. However, these tickets are proved to be not robust to adversarial examples, and even worse than their PLM counterparts. To address this problem, we propose a novel method based on learning binary weight masks to identify robust tickets hidden in the original PLMs. Since the loss is not differentiable for the binary mask, we assign the hard concrete distribution to the masks and encourage their sparsity using a smoothing approximation of L0 regularization. Furthermore, we design an adversarial loss objective to guide the search for robust tickets and ensure that the tickets perform well both in accuracy and robustness. Experimental results show the significant improvement of the proposed method over previous work on adversarial robustness evaluation.","Large-scale pre-trained language models (PLMs), such as BERT (Devlin et al., 2019), Roberta (Liu et al., 2019) and T5 (Raffel et al., 2019) have achieved great success in the field of natural language processing. As more transformer layers are stacked with larger self-attention blocks, the complexity of PLMs increases rapidly. Due to the over-parametrization of PLMs, some Transformer heads and even layers can be pruned without significant losses in performance (Michel et al., 2019; Kovaleva et al., 2019; Rogers et al., 2020). The Lottery Ticket Hypothesis suggests an overparameterized network contains certain subnetworks (i.e., winning tickets) that can match the performance of the original model when trained in isolation (Frankle and Carbin, 2019). Chen et al. (2020); Prasanna et al. (2020) also find these winning tickets exist in PLMs. Chen et al. (2020) prune BERT in an unstructured fashion and obtain winning tickets at sparsity from 40% to 90%. Prasanna et al. (2020) aim at finding structurally sparse tickets for BERT by pruning entire attention heads and MLP. Previous works mainly focused on using winning tickets to reduce model size and speed up training time (Chen et al., 2021), while little work has been done to explore more benefits, such as better adversarial robustness than the original model. As we all know, PLMs are vulnerable to adversarial examples that are legitimately crafted by imposing imperceptible perturbations on normal examples (Jin et al., 2020; Garg and Ramakrishnan, 2020; Wang et al., 2021). Recent studies have shown that pruned subnetworks of PLMs are even less robust than their PLM counterparts (Xu et al., 2021; Du et al., 2021). Xu et al. (2021) observe that when fine-tuning the pruned model again, the model yields a lower robustness. Du et al. (2021) clarify the above phenomenon further: the compressed models overfit on shortcut samples and thus perform consistently less robust than the uncompressed large model on adversarial test sets. In this work, our goal is to find robust PLM tickets that, when fine-tuned on downstream tasks, achieve matching test performance but are more robust than the original PLMs. In order to make the topology structure of tickets learnable, we assign binary masks to pre-trained weights to determine which connections need to be removed. To solve discrete optimization problem of binary masks, we assume the masks follow a hard concrete distribution (a soft version of the Bernoulli distribution), which can be solved using GumbelSoftmax trick (Louizos et al., 2018). We then use an adversarial loss objective to guide the search for robust tickets and an approximate LO regularization is used to encourage the sparsity of robust tickets. Robust tickets can be used as a robust substitute of original PLMs to fine-tune downstream tasks. Experimental results show that robust tickets achieve a significant improvement in adversarial robustness on various tasks and maintain a matching accuracy. Our codes are publicly available at Github1 . The main contributions of our work are summarized as follows: • We demonstrate that PLMs contain robust tickets with matching accuracy but better robustness than the original network. • We propose a novel and effective technique to find the robust tickets based on learnable binary masks rather than the traditional iterative magnitude-based pruning. • We provide a new perspective to explain the vulnerability of PLMs on adversarial examples: some weights of PLMs do not contribute to the accuracy but may harm the robustness.",How can robust subnetworks (winning tickets) within pre-trained language models be identified and utilized to achieve both accuracy comparable to the original models and improved adversarial robustness?,1.0,1.0,1.0
191,Robust Lottery Tickets for Pre-trained Language Models,"Rui Zheng, Bao Rong, Yuhao Zhou, Di Liang, Sirui Wang, Wei Wu, Tao Gui, Qi Zhang, and Xuanjing Huang. 2022. Robust Lottery Tickets for Pre-trained Language Models. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2211–2224, Dublin, Ireland. Association for Computational Linguistics.",https://aclanthology.org/2022.acl-long.157.pdf,https://aclanthology.org/2022.acl-long.157/,"Recent works on Lottery Ticket Hypothesis have shown that pre-trained language models (PLMs) contain smaller matching subnetworks (winning tickets) which are capable of reaching accuracy comparable to the original models. However, these tickets are proved to be not robust to adversarial examples, and even worse than their PLM counterparts. To address this problem, we propose a novel method based on learning binary weight masks to identify robust tickets hidden in the original PLMs. Since the loss is not differentiable for the binary mask, we assign the hard concrete distribution to the masks and encourage their sparsity using a smoothing approximation of L0 regularization. Furthermore, we design an adversarial loss objective to guide the search for robust tickets and ensure that the tickets perform well both in accuracy and robustness. Experimental results show the significant improvement of the proposed method over previous work on adversarial robustness evaluation.","Large-scale pre-trained language models (PLMs), such as BERT (Devlin et al., 2019), Roberta (Liu et al., 2019) and T5 (Raffel et al., 2019) have achieved great success in the field of natural language processing. As more transformer layers are stacked with larger self-attention blocks, the complexity of PLMs increases rapidly. Due to the over-parametrization of PLMs, some Transformer heads and even layers can be pruned without significant losses in performance (Michel et al., 2019; Kovaleva et al., 2019; Rogers et al., 2020). The Lottery Ticket Hypothesis suggests an overparameterized network contains certain subnetworks (i.e., winning tickets) that can match the performance of the original model when trained in isolation (Frankle and Carbin, 2019). Chen et al. (2020); Prasanna et al. (2020) also find these winning tickets exist in PLMs. Chen et al. (2020) prune BERT in an unstructured fashion and obtain winning tickets at sparsity from 40% to 90%. Prasanna et al. (2020) aim at finding structurally sparse tickets for BERT by pruning entire attention heads and MLP. Previous works mainly focused on using winning tickets to reduce model size and speed up training time (Chen et al., 2021), while little work has been done to explore more benefits, such as better adversarial robustness than the original model. As we all know, PLMs are vulnerable to adversarial examples that are legitimately crafted by imposing imperceptible perturbations on normal examples (Jin et al., 2020; Garg and Ramakrishnan, 2020; Wang et al., 2021). Recent studies have shown that pruned subnetworks of PLMs are even less robust than their PLM counterparts (Xu et al., 2021; Du et al., 2021). Xu et al. (2021) observe that when fine-tuning the pruned model again, the model yields a lower robustness. Du et al. (2021) clarify the above phenomenon further: the compressed models overfit on shortcut samples and thus perform consistently less robust than the uncompressed large model on adversarial test sets. In this work, our goal is to find robust PLM tickets that, when fine-tuned on downstream tasks, achieve matching test performance but are more robust than the original PLMs. In order to make the topology structure of tickets learnable, we assign binary masks to pre-trained weights to determine which connections need to be removed. To solve discrete optimization problem of binary masks, we assume the masks follow a hard concrete distribution (a soft version of the Bernoulli distribution), which can be solved using GumbelSoftmax trick (Louizos et al., 2018). We then use an adversarial loss objective to guide the search for robust tickets and an approximate LO regularization is used to encourage the sparsity of robust tickets. Robust tickets can be used as a robust substitute of original PLMs to fine-tune downstream tasks. Experimental results show that robust tickets achieve a significant improvement in adversarial robustness on various tasks and maintain a matching accuracy. Our codes are publicly available at Github1 . The main contributions of our work are summarized as follows: • We demonstrate that PLMs contain robust tickets with matching accuracy but better robustness than the original network. • We propose a novel and effective technique to find the robust tickets based on learnable binary masks rather than the traditional iterative magnitude-based pruning. • We provide a new perspective to explain the vulnerability of PLMs on adversarial examples: some weights of PLMs do not contribute to the accuracy but may harm the robustness.","Can robust tickets hidden in pre-trained language models (PLMs) that achieve matching accuracy but offer better robustness than the original PLMs be identified by learning binary weight masks, applying a hard concrete distribution for non-differentiable loss, and using an adversarial loss objective combined with a smoothing approximation of L0 regularization?",2.0,2.0,1.0
192,Active Learning for Dependency Parsing with Partial Annotation,"Zhenghua Li, Min Zhang, Yue Zhang, Zhanyi Liu, Wenliang Chen, Hua Wu, and Haifeng Wang. 2016. Active Learning for Dependency Parsing with Partial Annotation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 344–354, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1033.pdf,https://aclanthology.org/P16-1033/,"Different from traditional active learning based on sentence-wise full annotation (FA), this paper proposes active learning with dependency-wise partial annotation (PA) as a finer-grained unit for dependency parsing. At each iteration, we select a few most uncertain words from an unlabeled data pool, manually annotate their syntactic heads, and add the partial trees into labeled data for parser retraining. Compared with sentence-wise FA, dependency-wise PA gives us more flexibility in task selection and avoids wasting time on annotating trivial tasks in a sentence. Our work makes the following contributions. First, we are the first to apply a probabilistic model to active learning for dependency parsing, which can 1) provide tree probabilities and dependency marginal probabilities as principled uncertainty metrics, and 2) directly learn parameters from PA based on a forest-based training objective. Second, we propose and compare several uncertainty metrics through simulation experiments on both Chinese and English. Finally, we conduct human annotation experiments to compare FA and PA on real annotation time and quality.","During the past decade, supervised dependency parsing has gained extensive progress in boosting parsing performance on canonical texts, especially on texts from domains or genres similar to existing manually labeled treebanks (Koo and Collins, 2010; Zhang and Nivre, 2011). However, the upsurge of web data (e.g., tweets, blogs, and product comments) imposes great challenges to existing parsing techniques. Meanwhile, previous research on out-of-domain dependency parsing gains little success (Dredze et al., 2007; Petrov and McDonald, 2012). A more feasible way for open-domain parsing is to manually annotate a certain amount of texts from the target domain or genre. Recently, several small-scale treebanks on web texts have been built for study and evaluation (Foster et al., 2011; Petrov and McDonald, 2012; Kong et al., 2014; Wang et al., 2014). Meanwhile, active learning (AL) aims to reduce annotation effort by choosing and manually annotating unlabeled instances that are most valuable for training statistical models (Olsson, 2009). Traditionally, AL utilizes full annotation (FA) for parsing (Tang et al., 2002; Hwa, 2004; Lynn et al., 2012), where a whole syntactic tree is annotated for a given sentence at a time. However, as commented by Mejer and Crammer (2012), the annotation process is complex, slow, and prone to mistakes when FA is required. Particularly, annotators waste a lot of effort on labeling trivial dependencies which can be well handled by current statistical models (Flannery and Mori, 2015). Recently, researchers report promising results with AL based on partial annotation (PA) for dependency parsing (Sassano and Kurohashi, 2010; Mirroshandel and Nasr, 2011; Majidi and Crane, 2013; Flannery and Mori, 2015). They find that smaller units rather than sentences provide more flexibility in choosing potentially informative structures to annotate. Beyond previous work, this paper endeavors to more thoroughly study this issue, and has made substantial progress from the following perspectives. (1) This is the first work that applies a stateof-the-art probabilistic parsing model to AL for dependency parsing. The CRF-based dependency parser on the one hand allows us to use probabilities of trees or marginal probabilities of single dependencies for uncertainty measurement, and on the other hand can directly learn parameters from partially annotated trees. Using probabilistic models may be ubiquitous in AL for relatively simpler tasks like classification and sequence labeling, but is definitely novel for dependency parsing which is dominated by linear models with perceptron-like training. (2) Based on the CRF-based parser, we make systematic comparison among several uncertainty metrics for both FA and PA. Simulation experiments show that compared with using FA, AL with PA can greatly reduce annotation effort in terms of dependency number by 62.2% on Chinese and by 74.2% on English. (3) We build a visualized annotation platform and conduct human annotation experiments to compare FA and PA on real annotation time and quality, where we obtain several interesting observations and conclusions. All codes, along with the data from human annotation experiments, are released at http: //hlt.suda.edu.cn/˜zhli for future research study.",How does active learning with dependency-wise partial annotation compare to traditional sentence-wise full annotation in terms of improving efficiency and accuracy in dependency parsing?,1.0,0.0,1.0
193,Active Learning for Dependency Parsing with Partial Annotation,"Zhenghua Li, Min Zhang, Yue Zhang, Zhanyi Liu, Wenliang Chen, Hua Wu, and Haifeng Wang. 2016. Active Learning for Dependency Parsing with Partial Annotation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 344–354, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1033.pdf,https://aclanthology.org/P16-1033/,"Different from traditional active learning based on sentence-wise full annotation (FA), this paper proposes active learning with dependency-wise partial annotation (PA) as a finer-grained unit for dependency parsing. At each iteration, we select a few most uncertain words from an unlabeled data pool, manually annotate their syntactic heads, and add the partial trees into labeled data for parser retraining. Compared with sentence-wise FA, dependency-wise PA gives us more flexibility in task selection and avoids wasting time on annotating trivial tasks in a sentence. Our work makes the following contributions. First, we are the first to apply a probabilistic model to active learning for dependency parsing, which can 1) provide tree probabilities and dependency marginal probabilities as principled uncertainty metrics, and 2) directly learn parameters from PA based on a forest-based training objective. Second, we propose and compare several uncertainty metrics through simulation experiments on both Chinese and English. Finally, we conduct human annotation experiments to compare FA and PA on real annotation time and quality.","During the past decade, supervised dependency parsing has gained extensive progress in boosting parsing performance on canonical texts, especially on texts from domains or genres similar to existing manually labeled treebanks (Koo and Collins, 2010; Zhang and Nivre, 2011). However, the upsurge of web data (e.g., tweets, blogs, and product comments) imposes great challenges to existing parsing techniques. Meanwhile, previous research on out-of-domain dependency parsing gains little success (Dredze et al., 2007; Petrov and McDonald, 2012). A more feasible way for open-domain parsing is to manually annotate a certain amount of texts from the target domain or genre. Recently, several small-scale treebanks on web texts have been built for study and evaluation (Foster et al., 2011; Petrov and McDonald, 2012; Kong et al., 2014; Wang et al., 2014). Meanwhile, active learning (AL) aims to reduce annotation effort by choosing and manually annotating unlabeled instances that are most valuable for training statistical models (Olsson, 2009). Traditionally, AL utilizes full annotation (FA) for parsing (Tang et al., 2002; Hwa, 2004; Lynn et al., 2012), where a whole syntactic tree is annotated for a given sentence at a time. However, as commented by Mejer and Crammer (2012), the annotation process is complex, slow, and prone to mistakes when FA is required. Particularly, annotators waste a lot of effort on labeling trivial dependencies which can be well handled by current statistical models (Flannery and Mori, 2015). Recently, researchers report promising results with AL based on partial annotation (PA) for dependency parsing (Sassano and Kurohashi, 2010; Mirroshandel and Nasr, 2011; Majidi and Crane, 2013; Flannery and Mori, 2015). They find that smaller units rather than sentences provide more flexibility in choosing potentially informative structures to annotate. Beyond previous work, this paper endeavors to more thoroughly study this issue, and has made substantial progress from the following perspectives. (1) This is the first work that applies a stateof-the-art probabilistic parsing model to AL for dependency parsing. The CRF-based dependency parser on the one hand allows us to use probabilities of trees or marginal probabilities of single dependencies for uncertainty measurement, and on the other hand can directly learn parameters from partially annotated trees. Using probabilistic models may be ubiquitous in AL for relatively simpler tasks like classification and sequence labeling, but is definitely novel for dependency parsing which is dominated by linear models with perceptron-like training. (2) Based on the CRF-based parser, we make systematic comparison among several uncertainty metrics for both FA and PA. Simulation experiments show that compared with using FA, AL with PA can greatly reduce annotation effort in terms of dependency number by 62.2% on Chinese and by 74.2% on English. (3) We build a visualized annotation platform and conduct human annotation experiments to compare FA and PA on real annotation time and quality, where we obtain several interesting observations and conclusions. All codes, along with the data from human annotation experiments, are released at http: //hlt.suda.edu.cn/˜zhli for future research study.",Can dependency parsing performance be improved by applying active learning with dependency-wise partial annotation?,1.0,0.0,1.0
194,Active Learning for Dependency Parsing with Partial Annotation,"Zhenghua Li, Min Zhang, Yue Zhang, Zhanyi Liu, Wenliang Chen, Hua Wu, and Haifeng Wang. 2016. Active Learning for Dependency Parsing with Partial Annotation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 344–354, Berlin, Germany. Association for Computational Linguistics.",https://aclanthology.org/P16-1033.pdf,https://aclanthology.org/P16-1033/,"Different from traditional active learning based on sentence-wise full annotation (FA), this paper proposes active learning with dependency-wise partial annotation (PA) as a finer-grained unit for dependency parsing. At each iteration, we select a few most uncertain words from an unlabeled data pool, manually annotate their syntactic heads, and add the partial trees into labeled data for parser retraining. Compared with sentence-wise FA, dependency-wise PA gives us more flexibility in task selection and avoids wasting time on annotating trivial tasks in a sentence. Our work makes the following contributions. First, we are the first to apply a probabilistic model to active learning for dependency parsing, which can 1) provide tree probabilities and dependency marginal probabilities as principled uncertainty metrics, and 2) directly learn parameters from PA based on a forest-based training objective. Second, we propose and compare several uncertainty metrics through simulation experiments on both Chinese and English. Finally, we conduct human annotation experiments to compare FA and PA on real annotation time and quality.","During the past decade, supervised dependency parsing has gained extensive progress in boosting parsing performance on canonical texts, especially on texts from domains or genres similar to existing manually labeled treebanks (Koo and Collins, 2010; Zhang and Nivre, 2011). However, the upsurge of web data (e.g., tweets, blogs, and product comments) imposes great challenges to existing parsing techniques. Meanwhile, previous research on out-of-domain dependency parsing gains little success (Dredze et al., 2007; Petrov and McDonald, 2012). A more feasible way for open-domain parsing is to manually annotate a certain amount of texts from the target domain or genre. Recently, several small-scale treebanks on web texts have been built for study and evaluation (Foster et al., 2011; Petrov and McDonald, 2012; Kong et al., 2014; Wang et al., 2014). Meanwhile, active learning (AL) aims to reduce annotation effort by choosing and manually annotating unlabeled instances that are most valuable for training statistical models (Olsson, 2009). Traditionally, AL utilizes full annotation (FA) for parsing (Tang et al., 2002; Hwa, 2004; Lynn et al., 2012), where a whole syntactic tree is annotated for a given sentence at a time. However, as commented by Mejer and Crammer (2012), the annotation process is complex, slow, and prone to mistakes when FA is required. Particularly, annotators waste a lot of effort on labeling trivial dependencies which can be well handled by current statistical models (Flannery and Mori, 2015). Recently, researchers report promising results with AL based on partial annotation (PA) for dependency parsing (Sassano and Kurohashi, 2010; Mirroshandel and Nasr, 2011; Majidi and Crane, 2013; Flannery and Mori, 2015). They find that smaller units rather than sentences provide more flexibility in choosing potentially informative structures to annotate. Beyond previous work, this paper endeavors to more thoroughly study this issue, and has made substantial progress from the following perspectives. (1) This is the first work that applies a stateof-the-art probabilistic parsing model to AL for dependency parsing. The CRF-based dependency parser on the one hand allows us to use probabilities of trees or marginal probabilities of single dependencies for uncertainty measurement, and on the other hand can directly learn parameters from partially annotated trees. Using probabilistic models may be ubiquitous in AL for relatively simpler tasks like classification and sequence labeling, but is definitely novel for dependency parsing which is dominated by linear models with perceptron-like training. (2) Based on the CRF-based parser, we make systematic comparison among several uncertainty metrics for both FA and PA. Simulation experiments show that compared with using FA, AL with PA can greatly reduce annotation effort in terms of dependency number by 62.2% on Chinese and by 74.2% on English. (3) We build a visualized annotation platform and conduct human annotation experiments to compare FA and PA on real annotation time and quality, where we obtain several interesting observations and conclusions. All codes, along with the data from human annotation experiments, are released at http: //hlt.suda.edu.cn/˜zhli for future research study.",Can improving the efficiency and effectiveness of dependency parsing in the context of web data challenges be achieved by adopting a novel active learning approach that incorporates dependency-wise partial annotation (PA) and employs a probabilistic model for retraining parsers?,1.0,2.0,1.0
195,A Joint Neural Model for Information Extraction with Global Features,"Ying Lin, Heng Ji, Fei Huang, and Lingfei Wu. 2020. A Joint Neural Model for Information Extraction with Global Features. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7999–8009, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.713.pdf,https://aclanthology.org/2020.acl-main.713/,"Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a VICTIM of a DIE event is likely to be a VICTIM of an ATTACK event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, ONEIE, that aims to extract the globally optimal IE result as a graph from an input sentence. ONEIE performs end-to-end IE in four stages: (1) Encoding a given sentence as contextualized word representations; (2) Identifying entity mentions and event triggers as nodes; (3) Computing label scores for all nodes and their pairwise links using local classifiers; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our model and achieves new state-of-the-art on all subtasks. As ONEIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner. Our code and models for English, Spanish and Chinese are publicly available for research purpose.","Information Extraction (IE) aims to extract structured information from unstructured texts. It is a complex task comprised of a wide range of subtasks, such as named, nominal, and pronominal mention extraction, entity linking, entity coreference resolution, relation extraction, event extraction, and event coreference resolution. Early efforts typically perform IE in a pipelined fashion, which leads to the error propagation problem and disallows interactions among components in the pipeline. As a solution, some researchers propose joint inference and joint modeling methods to improve local prediction (Roth and Yih, 2004; Ji and Grishman, 2005; Ji et al., 2005; Sil and Yates, 2013; Li et al., 2014; Durrett and Klein, 2014; Miwa and Sasaki, 2014; Lu and Roth, 2015; Yang and Mitchell, 2016; Kirschnick et al., 2016). Due to the success of deep learning, neural models have been widely applied to various IE subtasks (Collobert et al., 2011; Chiu and Nichols, 2016; Chen et al., 2015; Lin et al., 2016). Recently, some efforts (Wadden et al., 2019; Luan et al., 2019) revisit global inference approaches by designing neural networks with embedding features to jointly model multiple subtasks. However, these methods use separate local task-specific classifiers in the final layer and do not explicitly model the interdependencies among tasks and instances. Figure 1 shows a real example where the local argument role classifier predicts a redundant PERSON edge. The model should be able to avoid such mistakes if it is capable of learning and leveraging the fact that it is unusual for an ELECT event to have two PERSON arguments. To address this issue, we propose a joint neural framework, ONEIE, to perform end-to-end IE with global constraints. As Figure 2 shows, instead of predicting separate knowledge elements using local classifiers, ONEIE aims to extract a globally optimal information network for the input sentence. When comparing candidate information networks during the decoding process, we not only consider individual label scores for each knowledge element, but evaluate cross-subtask and cross-instance interactions in the network. In this example, a graph with the INJURE-VICTIM-ORG (the VICTIM of an INJURE event is an ORG entity) structure is demoted. Experiments show that our framework achieves comparable or better results compared to the state-of-the-art end-to-end architecture (Wadden et al., 2019). To the best of our knowledge, ONEIE is the first end-to-end neural IE framework that explicitly models cross-subtask and cross-instance interdependencies and predicts the result as a unified graph instead of isolated knowledge elements. Because ONEIE does not rely on language-specific features, it can be rapidly applied to new languages. Furthermore, global features in our framework are highly explainable and can be explicitly analyzed.",How does incorporating global features that capture cross-subtask and cross-instance interactions in a joint neural framework for Information Extraction (IE) impact the accuracy of extracting a globally optimal information network from input sentences?,1.0,1.0,1.0
196,A Joint Neural Model for Information Extraction with Global Features,"Ying Lin, Heng Ji, Fei Huang, and Lingfei Wu. 2020. A Joint Neural Model for Information Extraction with Global Features. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7999–8009, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.713.pdf,https://aclanthology.org/2020.acl-main.713/,"Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a VICTIM of a DIE event is likely to be a VICTIM of an ATTACK event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, ONEIE, that aims to extract the globally optimal IE result as a graph from an input sentence. ONEIE performs end-to-end IE in four stages: (1) Encoding a given sentence as contextualized word representations; (2) Identifying entity mentions and event triggers as nodes; (3) Computing label scores for all nodes and their pairwise links using local classifiers; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our model and achieves new state-of-the-art on all subtasks. As ONEIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner. Our code and models for English, Spanish and Chinese are publicly available for research purpose.","Information Extraction (IE) aims to extract structured information from unstructured texts. It is a complex task comprised of a wide range of subtasks, such as named, nominal, and pronominal mention extraction, entity linking, entity coreference resolution, relation extraction, event extraction, and event coreference resolution. Early efforts typically perform IE in a pipelined fashion, which leads to the error propagation problem and disallows interactions among components in the pipeline. As a solution, some researchers propose joint inference and joint modeling methods to improve local prediction (Roth and Yih, 2004; Ji and Grishman, 2005; Ji et al., 2005; Sil and Yates, 2013; Li et al., 2014; Durrett and Klein, 2014; Miwa and Sasaki, 2014; Lu and Roth, 2015; Yang and Mitchell, 2016; Kirschnick et al., 2016). Due to the success of deep learning, neural models have been widely applied to various IE subtasks (Collobert et al., 2011; Chiu and Nichols, 2016; Chen et al., 2015; Lin et al., 2016). Recently, some efforts (Wadden et al., 2019; Luan et al., 2019) revisit global inference approaches by designing neural networks with embedding features to jointly model multiple subtasks. However, these methods use separate local task-specific classifiers in the final layer and do not explicitly model the interdependencies among tasks and instances. Figure 1 shows a real example where the local argument role classifier predicts a redundant PERSON edge. The model should be able to avoid such mistakes if it is capable of learning and leveraging the fact that it is unusual for an ELECT event to have two PERSON arguments. To address this issue, we propose a joint neural framework, ONEIE, to perform end-to-end IE with global constraints. As Figure 2 shows, instead of predicting separate knowledge elements using local classifiers, ONEIE aims to extract a globally optimal information network for the input sentence. When comparing candidate information networks during the decoding process, we not only consider individual label scores for each knowledge element, but evaluate cross-subtask and cross-instance interactions in the network. In this example, a graph with the INJURE-VICTIM-ORG (the VICTIM of an INJURE event is an ORG entity) structure is demoted. Experiments show that our framework achieves comparable or better results compared to the state-of-the-art end-to-end architecture (Wadden et al., 2019). To the best of our knowledge, ONEIE is the first end-to-end neural IE framework that explicitly models cross-subtask and cross-instance interdependencies and predicts the result as a unified graph instead of isolated knowledge elements. Because ONEIE does not rely on language-specific features, it can be rapidly applied to new languages. Furthermore, global features in our framework are highly explainable and can be explicitly analyzed.","Can cross-subtask and cross-instance interdependencies in Information Extraction be captured by a joint neural framework, ONEIE, to extract the globally optimal result as a graph from an input sentence?",1.0,1.0,1.0
197,A Joint Neural Model for Information Extraction with Global Features,"Ying Lin, Heng Ji, Fei Huang, and Lingfei Wu. 2020. A Joint Neural Model for Information Extraction with Global Features. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7999–8009, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.713.pdf,https://aclanthology.org/2020.acl-main.713/,"Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a VICTIM of a DIE event is likely to be a VICTIM of an ATTACK event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, ONEIE, that aims to extract the globally optimal IE result as a graph from an input sentence. ONEIE performs end-to-end IE in four stages: (1) Encoding a given sentence as contextualized word representations; (2) Identifying entity mentions and event triggers as nodes; (3) Computing label scores for all nodes and their pairwise links using local classifiers; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our model and achieves new state-of-the-art on all subtasks. As ONEIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner. Our code and models for English, Spanish and Chinese are publicly available for research purpose.","Information Extraction (IE) aims to extract structured information from unstructured texts. It is a complex task comprised of a wide range of subtasks, such as named, nominal, and pronominal mention extraction, entity linking, entity coreference resolution, relation extraction, event extraction, and event coreference resolution. Early efforts typically perform IE in a pipelined fashion, which leads to the error propagation problem and disallows interactions among components in the pipeline. As a solution, some researchers propose joint inference and joint modeling methods to improve local prediction (Roth and Yih, 2004; Ji and Grishman, 2005; Ji et al., 2005; Sil and Yates, 2013; Li et al., 2014; Durrett and Klein, 2014; Miwa and Sasaki, 2014; Lu and Roth, 2015; Yang and Mitchell, 2016; Kirschnick et al., 2016). Due to the success of deep learning, neural models have been widely applied to various IE subtasks (Collobert et al., 2011; Chiu and Nichols, 2016; Chen et al., 2015; Lin et al., 2016). Recently, some efforts (Wadden et al., 2019; Luan et al., 2019) revisit global inference approaches by designing neural networks with embedding features to jointly model multiple subtasks. However, these methods use separate local task-specific classifiers in the final layer and do not explicitly model the interdependencies among tasks and instances. Figure 1 shows a real example where the local argument role classifier predicts a redundant PERSON edge. The model should be able to avoid such mistakes if it is capable of learning and leveraging the fact that it is unusual for an ELECT event to have two PERSON arguments. To address this issue, we propose a joint neural framework, ONEIE, to perform end-to-end IE with global constraints. As Figure 2 shows, instead of predicting separate knowledge elements using local classifiers, ONEIE aims to extract a globally optimal information network for the input sentence. When comparing candidate information networks during the decoding process, we not only consider individual label scores for each knowledge element, but evaluate cross-subtask and cross-instance interactions in the network. In this example, a graph with the INJURE-VICTIM-ORG (the VICTIM of an INJURE event is an ORG entity) structure is demoted. Experiments show that our framework achieves comparable or better results compared to the state-of-the-art end-to-end architecture (Wadden et al., 2019). To the best of our knowledge, ONEIE is the first end-to-end neural IE framework that explicitly models cross-subtask and cross-instance interdependencies and predicts the result as a unified graph instead of isolated knowledge elements. Because ONEIE does not rely on language-specific features, it can be rapidly applied to new languages. Furthermore, global features in our framework are highly explainable and can be explicitly analyzed.","Can the problem of suboptimal extraction results due to the lack of modeling interactions among tasks and instances in current joint neural models for Information Extraction (IE) be addressed by a joint neural framework, ONEIE, that extracts globally optimal IE results as graphs by considering cross-subtask and cross-instance dependencies?",2.0,1.0,1.0
198,On-device Structured and Context Partitioned Projection Networks,"Sujith Ravi and Zornitsa Kozareva. 2019. On-device Structured and Context Partitioned Projection Networks. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3784–3793, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1368.pdf,https://aclanthology.org/P19-1368/,"A challenging problem in on-device text classification is to build highly accurate neural models that can fit in small memory footprint and have low latency. To address this challenge, we propose an on-device neural network SGNN++ which dynamically learns compact projection vectors from raw text using structured and context-dependent partition projections. We show that this results in accelerated inference and performance improvements. We conduct extensive evaluation on multiple conversational tasks and languages such as English, Japanese, Spanish and French. Our SGNN++ model significantly outperforms all baselines, improves upon existing on-device neural models and even surpasses RNN, CNN and BiLSTM models on dialog act and intent prediction. Through a series of ablation studies we show the impact of the partitioned projections and structured information leading to 10% improvement. We study the impact of the model size on accuracy and introduce quantization-aware training for SGNN++ to further reduce the model size while preserving the same quality. Finally, we show fast inference on mobile phones.","Over the last years, the usage of conversational assistants has become extremely popular. On a daily basis, people request weather information, check calendar appointments, perform calls. Large part of the conversational and natural language understanding happens on the server side and then fulfilled resulting in response delays, inconsistent experience and privacy concerns. Therefore, there is a huge demand for developing on-device natural language models that work entirely on-device such as mobile phones, tablets, watches and any internet of things (IoT) devices. On-device computation can circumvent the latency delays, can increase the user privacy and further enable new capabilities for real time interaction. One way to develop on-device natural language understanding is to leverage the power of deep neural networks, which over the years have shown tremendous progress and have improved upon state-of-the-art machine learning methods in Natural Language Processing (NLP) (Sutskever et al., 2014), Speech (Hinton et al., 2012) and Vision (Krizhevsky et al., 2012). These advancements were byproducts of the availability of large amounts of data and high performance computing, enabling the development of more complex and robust neural network architectures. However, despite their success, yet it remains challenging to deploy deep networks on-device such as mobile phone, smart watch and IoT. The limited memory and computation power combined with the need of fast latency require the development of novel on-device neural networks. Inspired by (Ravi and Kozareva, 2018), we propose a novel on-device neural network (SGNN++ ) that uses joint structured (word+character) information and context partitioned projections to learn robust models for short text classification. We employ a modified version of the locality sensitive hashing (LSH) to reduce input dimension from millions of unique words/features to a short, fixedlength sequence of bits (Ravi, 2017, 2019). This allows us to compute a projection for an incoming text very fast, on-the-fly, with a small memory footprint on the device without storing any incoming text and word embeddings. Unlike prior work that focused on developing the best neural network for a specific NLP task and language, we develop one SGNN++ architecture with the same parameters and apply it to wide range of tasks and languages such as English, French, Spanish and Japanese. Our experimental results show that SGNN++ improves upon baselines, prior on-device state-of-the-art and even non-on-device RNN, CNN and BiLSTM methods. The main contributions of our paper are: • Novel embedding-free SGNN++ on-device neural model with quantization, and joint structured and context partitioned projections; • Novel context partitioned projections result in small memory footprint with better performance and speedup. • First on-device model evaluated on a wide range of applications such as dialog act, intent prediction, customer feedback. • First on-device model evaluation on English, Spanish, French and Japanese languages demonstrating the language agnostic power of SGNN++ . • Comparison against prior on-device stateof-the-art neural models, which SGNN++ significantly improves upon across multiple tasks. • Ablation studies that show the impact of word vs joint word and character representation on accuracy; the power of the partitioned projection vectors on speed and inference; and the ability of SGNN++ to compress large models while still maintaining high accuracy; the fast latency of the on-device model.",Can on-device text classification accuracy and performance be improved by employing an SGNN++ neural network that uses structured and context-dependent partition projections?,1.0,1.0,1.0
199,On-device Structured and Context Partitioned Projection Networks,"Sujith Ravi and Zornitsa Kozareva. 2019. On-device Structured and Context Partitioned Projection Networks. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3784–3793, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1368.pdf,https://aclanthology.org/P19-1368/,"A challenging problem in on-device text classification is to build highly accurate neural models that can fit in small memory footprint and have low latency. To address this challenge, we propose an on-device neural network SGNN++ which dynamically learns compact projection vectors from raw text using structured and context-dependent partition projections. We show that this results in accelerated inference and performance improvements. We conduct extensive evaluation on multiple conversational tasks and languages such as English, Japanese, Spanish and French. Our SGNN++ model significantly outperforms all baselines, improves upon existing on-device neural models and even surpasses RNN, CNN and BiLSTM models on dialog act and intent prediction. Through a series of ablation studies we show the impact of the partitioned projections and structured information leading to 10% improvement. We study the impact of the model size on accuracy and introduce quantization-aware training for SGNN++ to further reduce the model size while preserving the same quality. Finally, we show fast inference on mobile phones.","Over the last years, the usage of conversational assistants has become extremely popular. On a daily basis, people request weather information, check calendar appointments, perform calls. Large part of the conversational and natural language understanding happens on the server side and then fulfilled resulting in response delays, inconsistent experience and privacy concerns. Therefore, there is a huge demand for developing on-device natural language models that work entirely on-device such as mobile phones, tablets, watches and any internet of things (IoT) devices. On-device computation can circumvent the latency delays, can increase the user privacy and further enable new capabilities for real time interaction. One way to develop on-device natural language understanding is to leverage the power of deep neural networks, which over the years have shown tremendous progress and have improved upon state-of-the-art machine learning methods in Natural Language Processing (NLP) (Sutskever et al., 2014), Speech (Hinton et al., 2012) and Vision (Krizhevsky et al., 2012). These advancements were byproducts of the availability of large amounts of data and high performance computing, enabling the development of more complex and robust neural network architectures. However, despite their success, yet it remains challenging to deploy deep networks on-device such as mobile phone, smart watch and IoT. The limited memory and computation power combined with the need of fast latency require the development of novel on-device neural networks. Inspired by (Ravi and Kozareva, 2018), we propose a novel on-device neural network (SGNN++ ) that uses joint structured (word+character) information and context partitioned projections to learn robust models for short text classification. We employ a modified version of the locality sensitive hashing (LSH) to reduce input dimension from millions of unique words/features to a short, fixedlength sequence of bits (Ravi, 2017, 2019). This allows us to compute a projection for an incoming text very fast, on-the-fly, with a small memory footprint on the device without storing any incoming text and word embeddings. Unlike prior work that focused on developing the best neural network for a specific NLP task and language, we develop one SGNN++ architecture with the same parameters and apply it to wide range of tasks and languages such as English, French, Spanish and Japanese. Our experimental results show that SGNN++ improves upon baselines, prior on-device state-of-the-art and even non-on-device RNN, CNN and BiLSTM methods. The main contributions of our paper are: • Novel embedding-free SGNN++ on-device neural model with quantization, and joint structured and context partitioned projections; • Novel context partitioned projections result in small memory footprint with better performance and speedup. • First on-device model evaluated on a wide range of applications such as dialog act, intent prediction, customer feedback. • First on-device model evaluation on English, Spanish, French and Japanese languages demonstrating the language agnostic power of SGNN++ . • Comparison against prior on-device stateof-the-art neural models, which SGNN++ significantly improves upon across multiple tasks. • Ablation studies that show the impact of word vs joint word and character representation on accuracy; the power of the partitioned projection vectors on speed and inference; and the ability of SGNN++ to compress large models while still maintaining high accuracy; the fast latency of the on-device model.","Can the developing on-device text classification neural models that are highly accurate, have a small memory footprint, and have low latency be addressed by the SGNN++ model that dynamically learns compact projection vectors using structured and context-dependent partition projections, accompanied by quantization-aware training?",2.0,1.0,1.0
200,Distantly Supervised Named Entity Recognition using Positive-Unlabeled Learning,"Minlong Peng, Xiaoyu Xing, Qi Zhang, Jinlan Fu, and Xuanjing Huang. 2019. Distantly Supervised Named Entity Recognition using Positive-Unlabeled Learning. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2409–2419, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1231.pdf,https://aclanthology.org/P19-1231/,"In this work, we explore the way to perform named entity recognition (NER) using only unlabeled data and named entity dictionaries. To this end, we formulate the task as a positive-unlabeled (PU) learning problem and accordingly propose a novel PU learning algorithm to perform the task. We prove that the proposed algorithm can unbiasedly and consistently estimate the task loss as if there is fully labeled data. A key feature of the proposed method is that it does not require the dictionaries to label every entity within a sentence, and it even does not require the dictionaries to label all of the words constituting an entity. This greatly reduces the requirement on the quality of the dictionaries and makes our method generalize well with quite simple dictionaries. Empirical studies on four public NER datasets demonstrate the effectiveness of our proposed method. We have published the source code at https:// github.com/v-mipeng/LexiconNER.","Named Entity Recognition (NER) is concerned with identifying named entities, such as person, location, product and organization names in unstructured text. It is a fundamental component in many natural language processing tasks such as machine translation (Babych and Hartley, 2003), knowledge base construction (Riedel et al., 2013; Shen et al., 2012), automatic question answering (Bordes et al., 2015), search (Zhu et al., 2005), etc. In this field, supervised methods, ranging from the typical graph models (Zhou and Su, 2002; McCallum et al., 2000; McCallum and Li, 2003; Settles, 2004) to current popular neural-networkbased models (Chiu and Nichols, 2016; Lample et al., 2016; Gridach, 2017; Liu et al., 2018; Zhang and Yang, 2018), have achieved great success. However, these supervised methods often require large scale fine-grained annotations (label every word of a sentence) to generalize well. This makes it hard to apply them to label-few domains, e.g., bio/medical domains (Deleger et al. ˙ , 2016). In this work, we explore the way to perform NER using only unlabeled data and named entity dictionaries, which are relatively easier to obtain compared with labeled data. A natural practice to perform the task is to scan through the query text using the dictionary and treat terms matched with a list of entries of the dictionary as the entities (Nadeau et al., 2006; Gerner et al., 2010; Liu et al., 2015; Yang et al., 2018). However, this practice requires very high quality named entity dictionaries that cover most of entities, otherwise it will fail with poor performance. As shown in Figure 1, the constructed dictionary of person names only labels one entity within the query text, which contains two entities “Bobick” and “Joe Frazier”, and it only labels one word “Joe” out of the two-word entity “Joe Frazier”. To address this problem, an intuitive solution is to further perform supervised or semi-supervised learning using the dictionary labeled data. However, since it does not guarantee that the dictionary covers all entity words (words being of entities) within a sentence, we cannot simply treat a word not labeled by the dictionary as the non-entity word. Take the data labeling results depicted in Figure 1 as an example. Simply treating “Bobick” and “Frazier” as non-entity words and then performing supervised learning will introduce label noise to the supervised classifier. Therefore, when using the dictionary to perform data labeling, we can actually only obtain some entity words and a bunch of unlabeled data comprising of both entity and non-entity words. In this case, the conventional supervised or semi-supervised learning algorithms are not suitable, since they usually require labeled data of all classes. With this consideration, we propose to formulate the task as a positive-unlabeled (PU) learning problem and accordingly introduce a novel PU learning algorithm to perform the task. In our proposed method, the labeled entity words form the positive (P) data and the rest form the unlabeled (U) data for PU learning. We proved that the proposed algorithm can unbiasedly and consistently estimate the task loss as if there is fully labeled data, under the assumption that the labeled P data can reveal the data distribution of class P. Of course, since words labeled by the dictionary only cover part of entities, it cannot fully reveal data distribution of entity words. To deal with this problem, we propose an adapted method, motivated by the AdaSampling algorithm (Yang et al., 2017), to enrich the dictionary. We evaluate the effectiveness of our proposed method on four NER datasets. Experimental results show that it can even achieve comparable performance with several supervised methods, using quite simple dictionaries. Contributions of this work can be summarized as follows: 1) We proposed a novel PU learning algorithm to perform the NER task using only unlabeled data and named entity dictionaries. 2) We proved that the proposed algorithm can unbiasedly and consistently estimate the task loss as if there is fully labeled data, under the assumption that the entities found out by the dictionary can reveal the distribution of entities. 3) To make the above assumption hold as far as possible, we propose an adapted method, motivated by the AdaSampling algorithm, to enrich the dictionary. 4) We empirically prove the effectiveness of our proposed method with extensive experimental studies on four NER datasets.",Can named entity recognition (NER) be performed using only unlabeled data and named entity dictionaries by formulating the task as a positive-unlabeled (PU) learning problem?,2.0,2.0,0.0
201,QASR: QCRI Aljazeera Speech Resource A Large Scale Annotated Arabic Speech Corpus,"Hamdy Mubarak, Amir Hussein, Shammur Absar Chowdhury, and Ahmed Ali. 2021. QASR: QCRI Aljazeera Speech Resource A Large Scale Annotated Arabic Speech Corpus. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2274–2285, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.177.pdf,https://aclanthology.org/2021.acl-long.177/,"We introduce the largest transcribed Arabic speech corpus, QASR1 , collected from the broadcast domain. This multi-dialect speech dataset contains 2, 000 hours of speech sampled at 16kHz crawled from Aljazeera news channel. The dataset is released with lightly supervised transcriptions, aligned with the audio segments. Unlike previous datasets, QASR contains linguistically motivated segmentation, punctuation, speaker information among others. QASR is suitable for training and evaluating speech recognition systems, acoustics- and/or linguistics- based Arabic dialect identification, punctuation restoration, speaker identification, speaker linking, and potentially other NLP modules for spoken data. In addition to QASR transcription, we release a dataset of 130M words to aid in designing and training a better language model. We show that end-to-end automatic speech recognition trained on QASR reports a competitive word error rate compared to the previous MGB-2 corpus. We report baseline results for downstream natural language processing tasks such as named entity recognition using speech transcript. We also report the first baseline for Arabic punctuation restoration. We make the corpus available for the research community.","Research on Automatic Speech Recognition (ASR) has attracted a lot of attention in recent years (Chiu et al., 2018; Watanabe et al., 2018). Such success has brought remarkable improvements in reaching human-level performance (Xiong et al., 2016; Saon et al., 2017; Hussein et al., 2021). This has been achieved by the development of large spoken corpora: supervised (Panayotov et al., 2015; Ardila et al., 2019); semi-supervised (Bell et al., 2015; Ali et al., 2016); and more recently unsupervised (Valk and Alumae¨ , 2020; Wang et al., 2021) transcription. This work enables to either reduce Word Error Rate (WER) considerably or extract metadata from speech: dialect-identification (Shon et al., 2020); speaker-identification (Shon et al., 2019); and codeswitching (Chowdhury et al., 2020b, 2021). Natural Language Processing (NLP), on the other hand values large amount of textual information for designing experiments. NLP research for Arabic has achieved a milestone in the last few years in morphological disambiguation, Named Entity Recognition (NER) and diacritization (Pasha et al., 2014; Abdelali et al., 2016; Mubarak et al., 2019). The NLP stack for Modern Standard Arabic (MSA) has reached very high performance in many tasks. With the rise of Dialectal Arabic (DA) content online, more resources and models have been built to study DA textual dialect identification (Abdul-Mageed et al., 2020; Samih et al., 2017). Our objective is to release the first Arabic speech and NLP corpus to study spoken MSA and DA. This is to enable empirical evaluation of learning more than the word sequence from the speech. In our view, existing speech and NLP corpora are missing the link between the two different modalities. Speech poses unique challenges such as disfluency (Pravin and Palanivelan, 2021), overlap speech (Tripathi et al., 2020; Chowdhury et al., 2019), hesitation (Wottawa et al., 2020; Chowdhury et al., 2017), and code-switching (Du et al., 2021; Chowdhury et al., 2021). These challenges are often overlooked when it comes to NLP tasks, since they are not present in typical text data. In this paper, we create and release2 the largest corpus for transcribed Arabic speech. It comprises of 2, 000 hours of speech data with lightly supervised transcriptions. Our contributions are: (i) aligning the transcription with the corresponding audio segments including punctuation for building ASR systems; (ii) providing semi-supervised speaker identification and speaker linking per audio segments; (iii) releasing baseline results for acoustic and linguistic Arabic dialect identification and punctuation restoration; (iv) adding a new layer of annotation in the publicly available MGB-2 testset, for evaluating NER for speech transcription; (v) sharing code-switching data between Arabic and foreign languages for speech and text; and finally, (vi) releasing more than 130M words for Language Model (LM). We believe that providing the research community with access to multi-dialectal speech data along with the corresponding NLP features will foster open research in several areas, such as the analysis of speech and NLP processing jointly. Here, we build models and share the baseline results for all of the aforementioned tasks.","Can the challenges of automatic speech recognition (ASR) and natural language processing (NLP) for Arabic, including dialect identification, speaker identification, and punctuation restoration, be addressed by using the QASR corpus and associated data?",2.0,1.0,1.0
202,QASR: QCRI Aljazeera Speech Resource A Large Scale Annotated Arabic Speech Corpus,"Hamdy Mubarak, Amir Hussein, Shammur Absar Chowdhury, and Ahmed Ali. 2021. QASR: QCRI Aljazeera Speech Resource A Large Scale Annotated Arabic Speech Corpus. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2274–2285, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.177.pdf,https://aclanthology.org/2021.acl-long.177/,"We introduce the largest transcribed Arabic speech corpus, QASR1 , collected from the broadcast domain. This multi-dialect speech dataset contains 2, 000 hours of speech sampled at 16kHz crawled from Aljazeera news channel. The dataset is released with lightly supervised transcriptions, aligned with the audio segments. Unlike previous datasets, QASR contains linguistically motivated segmentation, punctuation, speaker information among others. QASR is suitable for training and evaluating speech recognition systems, acoustics- and/or linguistics- based Arabic dialect identification, punctuation restoration, speaker identification, speaker linking, and potentially other NLP modules for spoken data. In addition to QASR transcription, we release a dataset of 130M words to aid in designing and training a better language model. We show that end-to-end automatic speech recognition trained on QASR reports a competitive word error rate compared to the previous MGB-2 corpus. We report baseline results for downstream natural language processing tasks such as named entity recognition using speech transcript. We also report the first baseline for Arabic punctuation restoration. We make the corpus available for the research community.","Research on Automatic Speech Recognition (ASR) has attracted a lot of attention in recent years (Chiu et al., 2018; Watanabe et al., 2018). Such success has brought remarkable improvements in reaching human-level performance (Xiong et al., 2016; Saon et al., 2017; Hussein et al., 2021). This has been achieved by the development of large spoken corpora: supervised (Panayotov et al., 2015; Ardila et al., 2019); semi-supervised (Bell et al., 2015; Ali et al., 2016); and more recently unsupervised (Valk and Alumae¨ , 2020; Wang et al., 2021) transcription. This work enables to either reduce Word Error Rate (WER) considerably or extract metadata from speech: dialect-identification (Shon et al., 2020); speaker-identification (Shon et al., 2019); and codeswitching (Chowdhury et al., 2020b, 2021). Natural Language Processing (NLP), on the other hand values large amount of textual information for designing experiments. NLP research for Arabic has achieved a milestone in the last few years in morphological disambiguation, Named Entity Recognition (NER) and diacritization (Pasha et al., 2014; Abdelali et al., 2016; Mubarak et al., 2019). The NLP stack for Modern Standard Arabic (MSA) has reached very high performance in many tasks. With the rise of Dialectal Arabic (DA) content online, more resources and models have been built to study DA textual dialect identification (Abdul-Mageed et al., 2020; Samih et al., 2017). Our objective is to release the first Arabic speech and NLP corpus to study spoken MSA and DA. This is to enable empirical evaluation of learning more than the word sequence from the speech. In our view, existing speech and NLP corpora are missing the link between the two different modalities. Speech poses unique challenges such as disfluency (Pravin and Palanivelan, 2021), overlap speech (Tripathi et al., 2020; Chowdhury et al., 2019), hesitation (Wottawa et al., 2020; Chowdhury et al., 2017), and code-switching (Du et al., 2021; Chowdhury et al., 2021). These challenges are often overlooked when it comes to NLP tasks, since they are not present in typical text data. In this paper, we create and release2 the largest corpus for transcribed Arabic speech. It comprises of 2, 000 hours of speech data with lightly supervised transcriptions. Our contributions are: (i) aligning the transcription with the corresponding audio segments including punctuation for building ASR systems; (ii) providing semi-supervised speaker identification and speaker linking per audio segments; (iii) releasing baseline results for acoustic and linguistic Arabic dialect identification and punctuation restoration; (iv) adding a new layer of annotation in the publicly available MGB-2 testset, for evaluating NER for speech transcription; (v) sharing code-switching data between Arabic and foreign languages for speech and text; and finally, (vi) releasing more than 130M words for Language Model (LM). We believe that providing the research community with access to multi-dialectal speech data along with the corresponding NLP features will foster open research in several areas, such as the analysis of speech and NLP processing jointly. Here, we build models and share the baseline results for all of the aforementioned tasks.","Can the lack of comprehensive resources for studying and processing spoken Arabic, considering its unique linguistic and dialectical features, be addressed by creating and releasing the QASR corpus, a large transcribed Arabic speech corpus with various features for supporting a wide range of speech and NLP tasks?",2.0,1.0,1.0
203,A Simple Theoretical Model of Importance for Summarization,"Maxime Peyrard. 2019. A Simple Theoretical Model of Importance for Summarization. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1059–1073, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1101.pdf,https://aclanthology.org/P19-1101/,"Research on summarization has mainly been driven by empirical approaches, crafting systems to perform well on standard datasets with the notion of information Importance remaining latent. We argue that establishing theoretical models of Importance will advance our understanding of the task and help to further improve summarization systems. To this end, we propose simple but rigorous definitions of several concepts that were previously used only intuitively in summarization: Redundancy, Relevance, and Informativeness. Importance arises as a single quantity naturally unifying these concepts. Additionally, we provide intuitions to interpret the proposed quantities and experiments to demonstrate the potential of the framework to inform and guide subsequent works.","Summarization is the process of identifying the most important information from a source to produce a comprehensive output for a particular user and task (Mani, 1999). While producing readable outputs is a problem shared with the field of Natural Language Generation, the core challenge of summarization is the identification and selection of important information. The task definition is rather intuitive but involves vague and undefined terms such as Importance and Information. Since the seminal work of Luhn (1958), automatic text summarization research has focused on empirical developments, crafting summarization systems to perform well on standard datasets leaving the formal definitions of Importance latent (Das and Martins, 2010; Nenkova and McKeown, 2012). This view entails collecting datasets, defining evaluation metrics and iteratively selecting the best-performing systems either via supervised learning or via repeated comparison of unsupervised systems (Yao et al., 2017). Such solely empirical approaches may lack guidance as they are often not motivated by more general theoretical frameworks. While these approaches have facilitated the development of practical solutions, they only identify signals correlating with the vague human intuition of Importance. For instance, structural features like centrality and repetitions are still among the most used proxies for Importance (Yao et al., 2017; Kedzie et al., 2018). However, such features just correlate with Importance in standard datasets. Unsurprisingly, simple adversarial attacks reveal their weaknesses (Zopf et al., 2016). We postulate that theoretical models of Importance are beneficial to organize research and guide future empirical works. Hence, in this work, we propose a simple definition of information importance within an abstract theoretical framework. This requires the notion of information, which has received a lot of attention since the work from Shannon (1948) in the context of communication theory. Information theory provides the means to rigorously discuss the abstract concept of information, which seems particularly well suited as an entry point for a theory of summarization. However, information theory concentrates on uncertainty (entropy) about which message was chosen from a set of possible messages, ignoring the semantics of messages (Shannon, 1948). Yet, summarization is a lossy semantic compression depending on background knowledge. In order to apply information theory to summarization, we assume texts are represented by probability distributions over so-called semantic units (Bao et al., 2011). This view is compatible with the common distributional embedding representation of texts rendering the presented framework applicable in practice. When applied to semantic symbols, the tools of information theory indirectly operate at the semantic level (Carnap and Bar-Hillel, 1953; Zhong, 2017). Contributions: • We define several concepts intuitively connected to summarization: Redundancy, Relevance and Informativeness. These concepts have been used extensively in previous summarization works and we discuss along the way how our framework generalizes them. • From these definitions, we formulate properties required from a useful notion of Importance as the quantity unifying these concepts. We provide intuitions to interpret the proposed quantities. • Experiments show that, even under simplifying assumptions, these quantities correlates well with human judgments making the framework promising in order to guide future empirical works.","How can the establishment of theoretical models of Importance, grounded in rigorously defined concepts of Redundancy, Relevance, and Informativeness, advance our understanding of summarization tasks and improve the performance of summarization systems?",1.0,2.0,1.0
204,A Simple Theoretical Model of Importance for Summarization,"Maxime Peyrard. 2019. A Simple Theoretical Model of Importance for Summarization. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1059–1073, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1101.pdf,https://aclanthology.org/P19-1101/,"Research on summarization has mainly been driven by empirical approaches, crafting systems to perform well on standard datasets with the notion of information Importance remaining latent. We argue that establishing theoretical models of Importance will advance our understanding of the task and help to further improve summarization systems. To this end, we propose simple but rigorous definitions of several concepts that were previously used only intuitively in summarization: Redundancy, Relevance, and Informativeness. Importance arises as a single quantity naturally unifying these concepts. Additionally, we provide intuitions to interpret the proposed quantities and experiments to demonstrate the potential of the framework to inform and guide subsequent works.","Summarization is the process of identifying the most important information from a source to produce a comprehensive output for a particular user and task (Mani, 1999). While producing readable outputs is a problem shared with the field of Natural Language Generation, the core challenge of summarization is the identification and selection of important information. The task definition is rather intuitive but involves vague and undefined terms such as Importance and Information. Since the seminal work of Luhn (1958), automatic text summarization research has focused on empirical developments, crafting summarization systems to perform well on standard datasets leaving the formal definitions of Importance latent (Das and Martins, 2010; Nenkova and McKeown, 2012). This view entails collecting datasets, defining evaluation metrics and iteratively selecting the best-performing systems either via supervised learning or via repeated comparison of unsupervised systems (Yao et al., 2017). Such solely empirical approaches may lack guidance as they are often not motivated by more general theoretical frameworks. While these approaches have facilitated the development of practical solutions, they only identify signals correlating with the vague human intuition of Importance. For instance, structural features like centrality and repetitions are still among the most used proxies for Importance (Yao et al., 2017; Kedzie et al., 2018). However, such features just correlate with Importance in standard datasets. Unsurprisingly, simple adversarial attacks reveal their weaknesses (Zopf et al., 2016). We postulate that theoretical models of Importance are beneficial to organize research and guide future empirical works. Hence, in this work, we propose a simple definition of information importance within an abstract theoretical framework. This requires the notion of information, which has received a lot of attention since the work from Shannon (1948) in the context of communication theory. Information theory provides the means to rigorously discuss the abstract concept of information, which seems particularly well suited as an entry point for a theory of summarization. However, information theory concentrates on uncertainty (entropy) about which message was chosen from a set of possible messages, ignoring the semantics of messages (Shannon, 1948). Yet, summarization is a lossy semantic compression depending on background knowledge. In order to apply information theory to summarization, we assume texts are represented by probability distributions over so-called semantic units (Bao et al., 2011). This view is compatible with the common distributional embedding representation of texts rendering the presented framework applicable in practice. When applied to semantic symbols, the tools of information theory indirectly operate at the semantic level (Carnap and Bar-Hillel, 1953; Zhong, 2017). Contributions: • We define several concepts intuitively connected to summarization: Redundancy, Relevance and Informativeness. These concepts have been used extensively in previous summarization works and we discuss along the way how our framework generalizes them. • From these definitions, we formulate properties required from a useful notion of Importance as the quantity unifying these concepts. We provide intuitions to interpret the proposed quantities. • Experiments show that, even under simplifying assumptions, these quantities correlates well with human judgments making the framework promising in order to guide future empirical works.","Can the understanding and improvement of summarization systems be advanced by defining and applying theoretical models of Importance, incorporating concepts of Redundancy, Relevance, and Informativeness?",1.0,2.0,1.0
205,A Simple Theoretical Model of Importance for Summarization,"Maxime Peyrard. 2019. A Simple Theoretical Model of Importance for Summarization. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1059–1073, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1101.pdf,https://aclanthology.org/P19-1101/,"Research on summarization has mainly been driven by empirical approaches, crafting systems to perform well on standard datasets with the notion of information Importance remaining latent. We argue that establishing theoretical models of Importance will advance our understanding of the task and help to further improve summarization systems. To this end, we propose simple but rigorous definitions of several concepts that were previously used only intuitively in summarization: Redundancy, Relevance, and Informativeness. Importance arises as a single quantity naturally unifying these concepts. Additionally, we provide intuitions to interpret the proposed quantities and experiments to demonstrate the potential of the framework to inform and guide subsequent works.","Summarization is the process of identifying the most important information from a source to produce a comprehensive output for a particular user and task (Mani, 1999). While producing readable outputs is a problem shared with the field of Natural Language Generation, the core challenge of summarization is the identification and selection of important information. The task definition is rather intuitive but involves vague and undefined terms such as Importance and Information. Since the seminal work of Luhn (1958), automatic text summarization research has focused on empirical developments, crafting summarization systems to perform well on standard datasets leaving the formal definitions of Importance latent (Das and Martins, 2010; Nenkova and McKeown, 2012). This view entails collecting datasets, defining evaluation metrics and iteratively selecting the best-performing systems either via supervised learning or via repeated comparison of unsupervised systems (Yao et al., 2017). Such solely empirical approaches may lack guidance as they are often not motivated by more general theoretical frameworks. While these approaches have facilitated the development of practical solutions, they only identify signals correlating with the vague human intuition of Importance. For instance, structural features like centrality and repetitions are still among the most used proxies for Importance (Yao et al., 2017; Kedzie et al., 2018). However, such features just correlate with Importance in standard datasets. Unsurprisingly, simple adversarial attacks reveal their weaknesses (Zopf et al., 2016). We postulate that theoretical models of Importance are beneficial to organize research and guide future empirical works. Hence, in this work, we propose a simple definition of information importance within an abstract theoretical framework. This requires the notion of information, which has received a lot of attention since the work from Shannon (1948) in the context of communication theory. Information theory provides the means to rigorously discuss the abstract concept of information, which seems particularly well suited as an entry point for a theory of summarization. However, information theory concentrates on uncertainty (entropy) about which message was chosen from a set of possible messages, ignoring the semantics of messages (Shannon, 1948). Yet, summarization is a lossy semantic compression depending on background knowledge. In order to apply information theory to summarization, we assume texts are represented by probability distributions over so-called semantic units (Bao et al., 2011). This view is compatible with the common distributional embedding representation of texts rendering the presented framework applicable in practice. When applied to semantic symbols, the tools of information theory indirectly operate at the semantic level (Carnap and Bar-Hillel, 1953; Zhong, 2017). Contributions: • We define several concepts intuitively connected to summarization: Redundancy, Relevance and Informativeness. These concepts have been used extensively in previous summarization works and we discuss along the way how our framework generalizes them. • From these definitions, we formulate properties required from a useful notion of Importance as the quantity unifying these concepts. We provide intuitions to interpret the proposed quantities. • Experiments show that, even under simplifying assumptions, these quantities correlates well with human judgments making the framework promising in order to guide future empirical works.","Can the problem of lacking a theoretical model for defining and measuring ""Importance"" in summarization be addressed by proposing a theoretical framework that defines and unifies key concepts like ""Redundancy"", ""Relevance"", and ""Informativeness"" under the concept of ""Importance""?",2.0,1.0,1.0
206,Verb Metaphor Detection via Contextual Relation Learning,"Wei Song, Shuhui Zhou, Ruiji Fu, Ting Liu, and Lizhen Liu. 2021. Verb Metaphor Detection via Contextual Relation Learning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4240–4251, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.327.pdf,https://aclanthology.org/2021.acl-long.327/,"Correct natural language understanding requires computers to distinguish the literal and metaphorical senses of a word. Recent neural models achieve progress on verb metaphor detection by viewing it as sequence labeling. In this paper, we argue that it is appropriate to view this task as relation classification between a verb and its various contexts. We propose the Metaphor-relation BERT (MrBERT) model, which explicitly models the relation between a verb and its grammatical, sentential and semantic contexts. We evaluate our method on the VUA, MOH-X and TroFi datasets. Our method gets competitive results compared with state-of-the-art approaches.","Metaphor is ubiquitous in our daily life for effective communication (Lakoff and Johnson, 1980). Metaphor processing has become an active research topic in natural language processing due to its importance in understanding implied meanings. This task is challenging, requiring contextual semantic representation and reasoning. Various contexts and linguistic representation techniques have been explored in previous work. Early methods focused on analyzing restricted forms of linguistic context, such as subjectverb-object type grammatical relations, based on hand-crafted features (Shutova and Teufel, 2010b; Tsvetkov et al., 2013; Gutiérrez et al., 2016). Later, word embeddings and neural networks were introduced to alleviate the burden of feature engineering for relation-level metaphor detections (Rei et al., 2017; Mao et al., 2018). However, although grammatical relations provide the most direct clues, other contexts in running text are mostly ignored. Recently, token-level neural metaphor detection draws more attention. Several approaches discovered that wider context can lead to better performance. Do Dinh and Gurevych (2016) considered a fixed window surrounding each target token as context. Gao et al. (2018) and Mao et al. (2018) argued that the full sentential context can provide strong clues for more accurate prediction. Some recent work also attempted to design models motivated by metaphor theories (Mao et al., 2019; Choi et al., 2021). Despite the progress of exploiting sentential context, there are still issues to be addressed. First of all, a word’s local context, its sentential context and other contexts should be all important for detecting metaphors; however, they are not well combined in previous work. More importantly, as shown in Figure 1, most token-level metaphor detection methods formulate metaphor detection as either a single-word classification or a sequence labeling problem (Gao et al., 2018). The context information is mainly used for learning contextual representations of tokens, rather than modeling the interactions between the target word and its contexts (Zayed et al., 2020). In this paper, we focus on token-level verb metaphor detection, since verb metaphors are of the most frequent type of metaphoric expressions (Shutova and Teufel, 2010a). As shown in Figure 1, we propose to formulate verb metaphor detection as a relation extraction problem, instead of token classification or sequence labeling formulations. In analogy to identify the relations between entities, our method models the relations between a target verb and its various contexts, and determines the verb’s metaphoricity based on the relation representation rather than only the verb’s (contextual) representation. We present a simple yet effective model — Metaphor-relation BERT (MrBERT), which is adapted from a BERT (Devlin et al., 2019) based state-of-the-art relation learning model (Baldini Soares et al., 2019). Our model has three highlights, as illustrated in Figure 2. First, we explicitly extract and represent context components, such as a verb’s arguments as the local context, the whole sentence as the global context, and its basic meaning as a distant context. So multiple contexts can be modeled interactively and integrated together. Second, MrBERT enables modeling the metaphorical relation between a verb and its context components, and uses the relation representation for determining the metaphoricity of the verb. Third, the model is flexible to incorporate sophisticated relation modeling methods and new types of contexts. We conduct experiments on the largest metaphor detection corpus VU Amsterdam Metaphor Corpus (VUA) (Steen, 2010). Our method obtains competitive results on the large VUA dataset. Detail analysis demonstrates the benefits of integrating various types of contexts for relation classification. The results on relatively small datasets, such as MOH-X and TroFi, also show good performance and model transferability.",How can modeling the relation between a verb and its various contexts improve metaphor detection in natural language processing?,1.0,1.0,0.0
207,Verb Metaphor Detection via Contextual Relation Learning,"Wei Song, Shuhui Zhou, Ruiji Fu, Ting Liu, and Lizhen Liu. 2021. Verb Metaphor Detection via Contextual Relation Learning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4240–4251, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.327.pdf,https://aclanthology.org/2021.acl-long.327/,"Correct natural language understanding requires computers to distinguish the literal and metaphorical senses of a word. Recent neural models achieve progress on verb metaphor detection by viewing it as sequence labeling. In this paper, we argue that it is appropriate to view this task as relation classification between a verb and its various contexts. We propose the Metaphor-relation BERT (MrBERT) model, which explicitly models the relation between a verb and its grammatical, sentential and semantic contexts. We evaluate our method on the VUA, MOH-X and TroFi datasets. Our method gets competitive results compared with state-of-the-art approaches.","Metaphor is ubiquitous in our daily life for effective communication (Lakoff and Johnson, 1980). Metaphor processing has become an active research topic in natural language processing due to its importance in understanding implied meanings. This task is challenging, requiring contextual semantic representation and reasoning. Various contexts and linguistic representation techniques have been explored in previous work. Early methods focused on analyzing restricted forms of linguistic context, such as subjectverb-object type grammatical relations, based on hand-crafted features (Shutova and Teufel, 2010b; Tsvetkov et al., 2013; Gutiérrez et al., 2016). Later, word embeddings and neural networks were introduced to alleviate the burden of feature engineering for relation-level metaphor detections (Rei et al., 2017; Mao et al., 2018). However, although grammatical relations provide the most direct clues, other contexts in running text are mostly ignored. Recently, token-level neural metaphor detection draws more attention. Several approaches discovered that wider context can lead to better performance. Do Dinh and Gurevych (2016) considered a fixed window surrounding each target token as context. Gao et al. (2018) and Mao et al. (2018) argued that the full sentential context can provide strong clues for more accurate prediction. Some recent work also attempted to design models motivated by metaphor theories (Mao et al., 2019; Choi et al., 2021). Despite the progress of exploiting sentential context, there are still issues to be addressed. First of all, a word’s local context, its sentential context and other contexts should be all important for detecting metaphors; however, they are not well combined in previous work. More importantly, as shown in Figure 1, most token-level metaphor detection methods formulate metaphor detection as either a single-word classification or a sequence labeling problem (Gao et al., 2018). The context information is mainly used for learning contextual representations of tokens, rather than modeling the interactions between the target word and its contexts (Zayed et al., 2020). In this paper, we focus on token-level verb metaphor detection, since verb metaphors are of the most frequent type of metaphoric expressions (Shutova and Teufel, 2010a). As shown in Figure 1, we propose to formulate verb metaphor detection as a relation extraction problem, instead of token classification or sequence labeling formulations. In analogy to identify the relations between entities, our method models the relations between a target verb and its various contexts, and determines the verb’s metaphoricity based on the relation representation rather than only the verb’s (contextual) representation. We present a simple yet effective model — Metaphor-relation BERT (MrBERT), which is adapted from a BERT (Devlin et al., 2019) based state-of-the-art relation learning model (Baldini Soares et al., 2019). Our model has three highlights, as illustrated in Figure 2. First, we explicitly extract and represent context components, such as a verb’s arguments as the local context, the whole sentence as the global context, and its basic meaning as a distant context. So multiple contexts can be modeled interactively and integrated together. Second, MrBERT enables modeling the metaphorical relation between a verb and its context components, and uses the relation representation for determining the metaphoricity of the verb. Third, the model is flexible to incorporate sophisticated relation modeling methods and new types of contexts. We conduct experiments on the largest metaphor detection corpus VU Amsterdam Metaphor Corpus (VUA) (Steen, 2010). Our method obtains competitive results on the large VUA dataset. Detail analysis demonstrates the benefits of integrating various types of contexts for relation classification. The results on relatively small datasets, such as MOH-X and TroFi, also show good performance and model transferability.",Can verb metaphor detection be improved by modeling it as a relation classification task between a verb and its various contexts using the Metaphor-relation BERT (MrBERT) model?,1.0,2.0,0.0
208,Verb Metaphor Detection via Contextual Relation Learning,"Wei Song, Shuhui Zhou, Ruiji Fu, Ting Liu, and Lizhen Liu. 2021. Verb Metaphor Detection via Contextual Relation Learning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 4240–4251, Online. Association for Computational Linguistics.",https://aclanthology.org/2021.acl-long.327.pdf,https://aclanthology.org/2021.acl-long.327/,"Correct natural language understanding requires computers to distinguish the literal and metaphorical senses of a word. Recent neural models achieve progress on verb metaphor detection by viewing it as sequence labeling. In this paper, we argue that it is appropriate to view this task as relation classification between a verb and its various contexts. We propose the Metaphor-relation BERT (MrBERT) model, which explicitly models the relation between a verb and its grammatical, sentential and semantic contexts. We evaluate our method on the VUA, MOH-X and TroFi datasets. Our method gets competitive results compared with state-of-the-art approaches.","Metaphor is ubiquitous in our daily life for effective communication (Lakoff and Johnson, 1980). Metaphor processing has become an active research topic in natural language processing due to its importance in understanding implied meanings. This task is challenging, requiring contextual semantic representation and reasoning. Various contexts and linguistic representation techniques have been explored in previous work. Early methods focused on analyzing restricted forms of linguistic context, such as subjectverb-object type grammatical relations, based on hand-crafted features (Shutova and Teufel, 2010b; Tsvetkov et al., 2013; Gutiérrez et al., 2016). Later, word embeddings and neural networks were introduced to alleviate the burden of feature engineering for relation-level metaphor detections (Rei et al., 2017; Mao et al., 2018). However, although grammatical relations provide the most direct clues, other contexts in running text are mostly ignored. Recently, token-level neural metaphor detection draws more attention. Several approaches discovered that wider context can lead to better performance. Do Dinh and Gurevych (2016) considered a fixed window surrounding each target token as context. Gao et al. (2018) and Mao et al. (2018) argued that the full sentential context can provide strong clues for more accurate prediction. Some recent work also attempted to design models motivated by metaphor theories (Mao et al., 2019; Choi et al., 2021). Despite the progress of exploiting sentential context, there are still issues to be addressed. First of all, a word’s local context, its sentential context and other contexts should be all important for detecting metaphors; however, they are not well combined in previous work. More importantly, as shown in Figure 1, most token-level metaphor detection methods formulate metaphor detection as either a single-word classification or a sequence labeling problem (Gao et al., 2018). The context information is mainly used for learning contextual representations of tokens, rather than modeling the interactions between the target word and its contexts (Zayed et al., 2020). In this paper, we focus on token-level verb metaphor detection, since verb metaphors are of the most frequent type of metaphoric expressions (Shutova and Teufel, 2010a). As shown in Figure 1, we propose to formulate verb metaphor detection as a relation extraction problem, instead of token classification or sequence labeling formulations. In analogy to identify the relations between entities, our method models the relations between a target verb and its various contexts, and determines the verb’s metaphoricity based on the relation representation rather than only the verb’s (contextual) representation. We present a simple yet effective model — Metaphor-relation BERT (MrBERT), which is adapted from a BERT (Devlin et al., 2019) based state-of-the-art relation learning model (Baldini Soares et al., 2019). Our model has three highlights, as illustrated in Figure 2. First, we explicitly extract and represent context components, such as a verb’s arguments as the local context, the whole sentence as the global context, and its basic meaning as a distant context. So multiple contexts can be modeled interactively and integrated together. Second, MrBERT enables modeling the metaphorical relation between a verb and its context components, and uses the relation representation for determining the metaphoricity of the verb. Third, the model is flexible to incorporate sophisticated relation modeling methods and new types of contexts. We conduct experiments on the largest metaphor detection corpus VU Amsterdam Metaphor Corpus (VUA) (Steen, 2010). Our method obtains competitive results on the large VUA dataset. Detail analysis demonstrates the benefits of integrating various types of contexts for relation classification. The results on relatively small datasets, such as MOH-X and TroFi, also show good performance and model transferability.","Can the problem of accurate metaphor detection in natural language processing, especially for verbs, be solved by viewing it as a relation classification issue, using the Metaphor-relation BERT (MrBERT) model that integrates various contexts to model the relations between a verb and its contexts?",1.0,2.0,1.0
209,Harvesting and Refining Question-Answer Pairs for Unsupervised QA,"Zhongli Li, Wenhui Wang, Li Dong, Furu Wei, and Ke Xu. 2020. Harvesting and Refining Question-Answer Pairs for Unsupervised QA. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6719–6728, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.600.pdf,https://aclanthology.org/2020.acl-main.600/,"Question Answering (QA) has shown great success thanks to the availability of largescale datasets and the effectiveness of neural models. Recent research works have attempted to extend these successes to the settings with few or no labeled data available. In this work, we introduce two approaches to improve unsupervised QA. First, we harvest lexically and syntactically divergent questions from Wikipedia to automatically construct a corpus of question-answer pairs (named as REFQA). Second, we take advantage of the QA model to extract more appropriate answers, which iteratively refines data over REFQA. We conduct experiments1 on SQuAD 1.1, and NewsQA by fine-tuning BERT without access to manually annotated data. Our approach outperforms previous unsupervised approaches by a large margin and is competitive with early supervised models. We also show the effectiveness of our approach in the fewshot learning setting.","Extractive question answering aims to extract a span from the given document to answer the question. Rapid progress has been made because of the release of large-scale annotated datasets (Rajpurkar et al., 2016, 2018; Joshi et al., 2017), and well-designed neural models (Wang and Jiang, 2016; Seo et al., 2016; Yu et al., 2018). Recently, unsupervised pre-training of language models on large corpora, such as BERT (Devlin et al., 2019), has brought further performance gains. However, the above approaches heavily rely on the availability of large-scale datasets. The collection of high-quality training data is timeconsuming and requires significant resources, especially for new domains or languages. In order to tackle the setting in which no training data available, Lewis et al. (2019) leverage unsupervised machine translation to generate synthetic contextquestion-answer triples. The paragraphs are sampled from Wikipedia. NER and noun chunkers are employed to identify answer candidates. Cloze questions are first extracted from the sentences of the paragraph, and then translated into natural questions. However, there are a lot of lexical overlaps between the generated questions and the paragraph. Similar lexical and syntactic structures render the QA model tend to predict the answer just by word matching. Moreover, the answer category is limited to the named entity or noun phrase, which restricts the coverage of the learnt model. In this work, we present two approaches to improve the quality of synthetic context-questionanswer triples. First, we introduce the REFQA dataset, which harvests lexically and syntactically divergent questions from Wikipedia by using the cited documents. As shown in Figure 1, the sentence (statement) in Wikipedia and its cited documents are semantically consistent, but written with different expressions. More informative context-question-answer triples can be created by using the cited document as the context paragraph and extracting questions from the statement in Wikipedia. Second, we propose to iteratively refine data over REFQA. Given a QA model and some REFQA examples, we first filter its predicted answers with a probability threshold. Then we refine questions based on the predicted answers, and obtain the refined question-answer pairs to continue the model training. Thanks to the pretrained linguistic knowledge in the BERTbased QA model, there are more appropriate and diverse answer candidates in the filtered predictions, some of which do not appear in the candidates extracted by NER tools. We also show that iteratively refining the data further improves model performance. We conduct experiments on SQuAD 1.1 (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2017). Our method yields state-of-the-art results against strong baselines in the unsupervised setting. Specifically, the proposed model achieves 71.4 F1 on the SQuAD 1.1 test set and 45.1 F1 on the NewsQA test set without using annotated data. We also evaluate our method in a few-shot learning setting. Our approach achieves 79.4 F1 on the SQuAD 1.1 dev set with only 100 labeled examples, compared to 63.0 F1 using the method of Lewis et al. (2019). To summarize, the contributions of this paper include: i) REFQA constructing in an unsupervised manner, which contains more informative context-question-answer triples. ii) Using the QA model to iteratively refine and augment the question-answer pairs in REFQA.",How can the quality and performance of unsupervised question-answering models be improved by constructing and refining a dataset of context-question-answer triples derived from lexically and syntactically divergent sources?,1.0,2.0,1.0
210,Harvesting and Refining Question-Answer Pairs for Unsupervised QA,"Zhongli Li, Wenhui Wang, Li Dong, Furu Wei, and Ke Xu. 2020. Harvesting and Refining Question-Answer Pairs for Unsupervised QA. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6719–6728, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.600.pdf,https://aclanthology.org/2020.acl-main.600/,"Question Answering (QA) has shown great success thanks to the availability of largescale datasets and the effectiveness of neural models. Recent research works have attempted to extend these successes to the settings with few or no labeled data available. In this work, we introduce two approaches to improve unsupervised QA. First, we harvest lexically and syntactically divergent questions from Wikipedia to automatically construct a corpus of question-answer pairs (named as REFQA). Second, we take advantage of the QA model to extract more appropriate answers, which iteratively refines data over REFQA. We conduct experiments1 on SQuAD 1.1, and NewsQA by fine-tuning BERT without access to manually annotated data. Our approach outperforms previous unsupervised approaches by a large margin and is competitive with early supervised models. We also show the effectiveness of our approach in the fewshot learning setting.","Extractive question answering aims to extract a span from the given document to answer the question. Rapid progress has been made because of the release of large-scale annotated datasets (Rajpurkar et al., 2016, 2018; Joshi et al., 2017), and well-designed neural models (Wang and Jiang, 2016; Seo et al., 2016; Yu et al., 2018). Recently, unsupervised pre-training of language models on large corpora, such as BERT (Devlin et al., 2019), has brought further performance gains. However, the above approaches heavily rely on the availability of large-scale datasets. The collection of high-quality training data is timeconsuming and requires significant resources, especially for new domains or languages. In order to tackle the setting in which no training data available, Lewis et al. (2019) leverage unsupervised machine translation to generate synthetic contextquestion-answer triples. The paragraphs are sampled from Wikipedia. NER and noun chunkers are employed to identify answer candidates. Cloze questions are first extracted from the sentences of the paragraph, and then translated into natural questions. However, there are a lot of lexical overlaps between the generated questions and the paragraph. Similar lexical and syntactic structures render the QA model tend to predict the answer just by word matching. Moreover, the answer category is limited to the named entity or noun phrase, which restricts the coverage of the learnt model. In this work, we present two approaches to improve the quality of synthetic context-questionanswer triples. First, we introduce the REFQA dataset, which harvests lexically and syntactically divergent questions from Wikipedia by using the cited documents. As shown in Figure 1, the sentence (statement) in Wikipedia and its cited documents are semantically consistent, but written with different expressions. More informative context-question-answer triples can be created by using the cited document as the context paragraph and extracting questions from the statement in Wikipedia. Second, we propose to iteratively refine data over REFQA. Given a QA model and some REFQA examples, we first filter its predicted answers with a probability threshold. Then we refine questions based on the predicted answers, and obtain the refined question-answer pairs to continue the model training. Thanks to the pretrained linguistic knowledge in the BERTbased QA model, there are more appropriate and diverse answer candidates in the filtered predictions, some of which do not appear in the candidates extracted by NER tools. We also show that iteratively refining the data further improves model performance. We conduct experiments on SQuAD 1.1 (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2017). Our method yields state-of-the-art results against strong baselines in the unsupervised setting. Specifically, the proposed model achieves 71.4 F1 on the SQuAD 1.1 test set and 45.1 F1 on the NewsQA test set without using annotated data. We also evaluate our method in a few-shot learning setting. Our approach achieves 79.4 F1 on the SQuAD 1.1 dev set with only 100 labeled examples, compared to 63.0 F1 using the method of Lewis et al. (2019). To summarize, the contributions of this paper include: i) REFQA constructing in an unsupervised manner, which contains more informative context-question-answer triples. ii) Using the QA model to iteratively refine and augment the question-answer pairs in REFQA.",Can unsupervised question answering be improved by constructing and iteratively refining a corpus of question-answer pairs from Wikipedia?,1.0,1.0,0.0
211,Harvesting and Refining Question-Answer Pairs for Unsupervised QA,"Zhongli Li, Wenhui Wang, Li Dong, Furu Wei, and Ke Xu. 2020. Harvesting and Refining Question-Answer Pairs for Unsupervised QA. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6719–6728, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.600.pdf,https://aclanthology.org/2020.acl-main.600/,"Question Answering (QA) has shown great success thanks to the availability of largescale datasets and the effectiveness of neural models. Recent research works have attempted to extend these successes to the settings with few or no labeled data available. In this work, we introduce two approaches to improve unsupervised QA. First, we harvest lexically and syntactically divergent questions from Wikipedia to automatically construct a corpus of question-answer pairs (named as REFQA). Second, we take advantage of the QA model to extract more appropriate answers, which iteratively refines data over REFQA. We conduct experiments1 on SQuAD 1.1, and NewsQA by fine-tuning BERT without access to manually annotated data. Our approach outperforms previous unsupervised approaches by a large margin and is competitive with early supervised models. We also show the effectiveness of our approach in the fewshot learning setting.","Extractive question answering aims to extract a span from the given document to answer the question. Rapid progress has been made because of the release of large-scale annotated datasets (Rajpurkar et al., 2016, 2018; Joshi et al., 2017), and well-designed neural models (Wang and Jiang, 2016; Seo et al., 2016; Yu et al., 2018). Recently, unsupervised pre-training of language models on large corpora, such as BERT (Devlin et al., 2019), has brought further performance gains. However, the above approaches heavily rely on the availability of large-scale datasets. The collection of high-quality training data is timeconsuming and requires significant resources, especially for new domains or languages. In order to tackle the setting in which no training data available, Lewis et al. (2019) leverage unsupervised machine translation to generate synthetic contextquestion-answer triples. The paragraphs are sampled from Wikipedia. NER and noun chunkers are employed to identify answer candidates. Cloze questions are first extracted from the sentences of the paragraph, and then translated into natural questions. However, there are a lot of lexical overlaps between the generated questions and the paragraph. Similar lexical and syntactic structures render the QA model tend to predict the answer just by word matching. Moreover, the answer category is limited to the named entity or noun phrase, which restricts the coverage of the learnt model. In this work, we present two approaches to improve the quality of synthetic context-questionanswer triples. First, we introduce the REFQA dataset, which harvests lexically and syntactically divergent questions from Wikipedia by using the cited documents. As shown in Figure 1, the sentence (statement) in Wikipedia and its cited documents are semantically consistent, but written with different expressions. More informative context-question-answer triples can be created by using the cited document as the context paragraph and extracting questions from the statement in Wikipedia. Second, we propose to iteratively refine data over REFQA. Given a QA model and some REFQA examples, we first filter its predicted answers with a probability threshold. Then we refine questions based on the predicted answers, and obtain the refined question-answer pairs to continue the model training. Thanks to the pretrained linguistic knowledge in the BERTbased QA model, there are more appropriate and diverse answer candidates in the filtered predictions, some of which do not appear in the candidates extracted by NER tools. We also show that iteratively refining the data further improves model performance. We conduct experiments on SQuAD 1.1 (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2017). Our method yields state-of-the-art results against strong baselines in the unsupervised setting. Specifically, the proposed model achieves 71.4 F1 on the SQuAD 1.1 test set and 45.1 F1 on the NewsQA test set without using annotated data. We also evaluate our method in a few-shot learning setting. Our approach achieves 79.4 F1 on the SQuAD 1.1 dev set with only 100 labeled examples, compared to 63.0 F1 using the method of Lewis et al. (2019). To summarize, the contributions of this paper include: i) REFQA constructing in an unsupervised manner, which contains more informative context-question-answer triples. ii) Using the QA model to iteratively refine and augment the question-answer pairs in REFQA.",Can the dependency of Question Answering (QA) systems on large-scale labeled datasets for effective training be mitigated by constructing an unsupervised corpus through harvesting lexically and syntactically divergent questions from Wikipedia and iteratively refining this data using a QA model?,1.0,2.0,1.0
212,"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned","Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, and Ivan Titov. 2019. Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5797–5808, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1580.pdf,https://aclanthology.org/P19-1580/,"Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads in the encoder to the overall performance of the model and analyze the roles played by them. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.","The Transformer (Vaswani et al., 2017) has become the dominant modeling paradigm in neural machine translation. It follows the encoderdecoder framework using stacked multi-head selfattention and fully connected layers. Multi-head attention was shown to make more efficient use of the model’s capacity: performance of the model with 8 heads is almost 1 BLEU point higher than that of a model of the same size with single-head attention (Vaswani et al., 2017). The Transformer achieved state-of-the-art results in recent shared translation tasks (Bojar et al., 2018; Niehues et al., 2018). Despite the model’s widespread adoption and recent attempts to investigate the kinds of information learned by the model’s encoder (Raganato and Tiedemann, 2018), the analysis of multi-head attention and its importance for translation is challenging. Previous analysis of multi-head attention considered the average of attention weights over all heads at a given position or focused only on the maximum attention weights (Voita et al., 2018; Tang et al., 2018), but neither method explicitly takes into account the varying importance of different heads. Also, this obscures the roles played by individual heads which, as we show, influence the generated translations to differing extents. We attempt to answer the following questions: • To what extent does translation quality depend on individual encoder heads? • Do individual encoder heads play consistent and interpretable roles? If so, which are the most important ones for translation quality? • Which types of model attention (encoder self-attention, decoder self-attention or decoder-encoder attention) are most sensitive to the number of attention heads and on which layers? • Can we significantly reduce the number of attention heads while preserving translation quality? We start by identifying the most important heads in each encoder layer using layer-wise relevance propagation (Ding et al., 2017). For heads judged to be important, we then attempt to characterize the roles they perform. We observe the following types of role: positional (heads attending to an adjacent token), syntactic (heads attending to tokens in a specific syntactic dependency relation) and attention to rare words (heads pointing to the least frequent tokens in the sentence). To understand whether the remaining heads perform vital but less easily defined roles, or are simply redundant to the performance of the model as measured by translation quality, we introduce a method for pruning heads based on Louizos et al. (2018). While we cannot easily incorporate the number of active heads as a penalty term in our learning objective (i.e. the L0 regularizer), we can use a differentiable relaxation. We prune attention heads in a continuous learning scenario starting from the converged full model and identify the roles of those which remain in the model. These experiments corroborate the findings of layer-wise relevance propagation; in particular, heads with clearly identifiable positional and syntactic functions are pruned last and hence shown to be most important for the translation task. Our key findings are as follows: • Only a small subset of heads are important for translation; • Important heads have one or more specialized and interpretable functions in the model; • The functions correspond to attention to neighbouring words and to tokens in specific syntactic dependency relations.",Can the translation quality be preserved by significantly reducing the number of attention heads in a Transformer model's encoder using a novel pruning method based on stochastic gates and a differentiable relaxation of the L0 penalty?,1.0,2.0,0.0
213,"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned","Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, and Ivan Titov. 2019. Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5797–5808, Florence, Italy. Association for Computational Linguistics.",https://aclanthology.org/P19-1580.pdf,https://aclanthology.org/P19-1580/,"Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads in the encoder to the overall performance of the model and analyze the roles played by them. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.","The Transformer (Vaswani et al., 2017) has become the dominant modeling paradigm in neural machine translation. It follows the encoderdecoder framework using stacked multi-head selfattention and fully connected layers. Multi-head attention was shown to make more efficient use of the model’s capacity: performance of the model with 8 heads is almost 1 BLEU point higher than that of a model of the same size with single-head attention (Vaswani et al., 2017). The Transformer achieved state-of-the-art results in recent shared translation tasks (Bojar et al., 2018; Niehues et al., 2018). Despite the model’s widespread adoption and recent attempts to investigate the kinds of information learned by the model’s encoder (Raganato and Tiedemann, 2018), the analysis of multi-head attention and its importance for translation is challenging. Previous analysis of multi-head attention considered the average of attention weights over all heads at a given position or focused only on the maximum attention weights (Voita et al., 2018; Tang et al., 2018), but neither method explicitly takes into account the varying importance of different heads. Also, this obscures the roles played by individual heads which, as we show, influence the generated translations to differing extents. We attempt to answer the following questions: • To what extent does translation quality depend on individual encoder heads? • Do individual encoder heads play consistent and interpretable roles? If so, which are the most important ones for translation quality? • Which types of model attention (encoder self-attention, decoder self-attention or decoder-encoder attention) are most sensitive to the number of attention heads and on which layers? • Can we significantly reduce the number of attention heads while preserving translation quality? We start by identifying the most important heads in each encoder layer using layer-wise relevance propagation (Ding et al., 2017). For heads judged to be important, we then attempt to characterize the roles they perform. We observe the following types of role: positional (heads attending to an adjacent token), syntactic (heads attending to tokens in a specific syntactic dependency relation) and attention to rare words (heads pointing to the least frequent tokens in the sentence). To understand whether the remaining heads perform vital but less easily defined roles, or are simply redundant to the performance of the model as measured by translation quality, we introduce a method for pruning heads based on Louizos et al. (2018). While we cannot easily incorporate the number of active heads as a penalty term in our learning objective (i.e. the L0 regularizer), we can use a differentiable relaxation. We prune attention heads in a continuous learning scenario starting from the converged full model and identify the roles of those which remain in the model. These experiments corroborate the findings of layer-wise relevance propagation; in particular, heads with clearly identifiable positional and syntactic functions are pruned last and hence shown to be most important for the translation task. Our key findings are as follows: • Only a small subset of heads are important for translation; • Important heads have one or more specialized and interpretable functions in the model; • The functions correspond to attention to neighbouring words and to tokens in specific syntactic dependency relations.","Can the contribution and roles of individual attention heads in the Transformer model for neural machine translation be understood and the model's performance maintained by evaluating their importance through a novel pruning method based on stochastic gates and a differentiable relaxation of the L0 penalty, and analyzing their roles?",2.0,2.0,1.0
214,Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering,"Hao Cheng, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2020. Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5657–5667, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.501.pdf,https://aclanthology.org/2020.acl-main.501/,"We address the problem of extractive question answering using document-level distant supervision, pairing questions and relevant documents with answer strings. We compare previously used probability space and distant supervision assumptions (assumptions on the correspondence between the weak answer string labels and possible answer mention spans). We show that these assumptions interact, and that different configurations provide complementary benefits. We demonstrate that a multiobjective model can efficiently combine the advantages of multiple assumptions and outperform the best individual formulation. Our approach outperforms previous state-of-the-art models by 4.3 points in F1 on TriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries.","Distant supervision assumptions have enabled the creation of large-scale datasets that can be used to train fine-grained extractive short answer question answering (QA) systems. One example is TriviaQA (Joshi et al., 2017). There the authors utilized a pre-existing set of Trivia questionanswer string pairs and coupled them with relevant documents, such that, with high likelihood, the documents support answering the questions (see Fig. 1 for an illustration). Another example is the NarrativeQA dataset (Kocisk ˇ y et al. ´ , 2018), where crowd-sourced abstractive answer strings were used to weakly supervise answer mentions in the text of movie scripts or their summaries. In this work, we focus on the setting of documentlevel extractive QA, where distant supervision is specified as a set A of answer strings for an input question-document pair. Depending on the data generation process, the properties of the resulting supervision from the sets A may differ. For example, the provided answer sets in TriviaQA include aliases of original trivia question answers, aimed at capturing semantically equivalent answers but liable to introducing semantic drift. In Fig. 1, the possible answer string “Diary of a Mad Diva” is related to “Joan Rivers”, but is not a valid answer for the given question. On the other hand, the sets of answer strings in NarrativeQA are mostly valid since they have high overlap with human-generated answers for the given question/document pair. As shown in Fig. 1, “in the spring at mount helicon” and “mount helicon” are both valid answers with relevant mentions. In this case, the annotators chose answers that appear verbatim in the text but in the more general case, noise may come from partial phrases and irrelevant mentions. While distant supervision reduces the annotation cost, increased coverage often comes with increased noise (e.g., expanding entity answer strings with aliases improves coverage but also increases noise). Even for fixed document-level distant supervision in the form of a set of answers A, different interpretations of the partial supervision lead to different points in the coverage/noise space and their relative performance is not well understood. This work systematically studies methods for learning and inference with document-level distantly supervised extractive QA models. Using a BERT (Devlin et al., 2019) joint question-passage encoder, we study the compound impact of: • Probability space (§2): ways to define the model’s probability space based on independent paragraphs or whole documents. • Distant supervision assumptions (§3): ways to translate the supervision from possible strings A to possible locations of answer mentions in the document. • Optimization and inference (§4): ways to define corresponding training objectives (e.g. Hard EM as in Min et al. (2019) vs. Maximum Marginal Likelihood) and make answer string predictions during inference (Viterbi or marginal inference). We show that the choice of probability space puts constraints on the distant supervision assumptions that can be captured, and that all three choices interact, leading to large differences in performance. Specifically, we provide a framework for understanding different distant supervision assumptions and the corresponding trade-off among the coverage, quality and strength of distant supervision signal. The best configuration depends on the properties of the possible annotations A and is thus data-dependent. Compared with recent work also using BERT representations, our study show that the model with most suitable probabilistic treatment achieves large improvements of 4.6 F1 on TriviaQA and 1.7 Rouge-L on NarrativeQA respectively. Additionally, we design an efficient multi-loss objective that can combine the benefits of different formulations, leading to significant improvements in accuracy, surpassing the best previously reported results on the two studied tasks. Results are further strengthened by transfer learning from fully labeled short-answer extraction data in SQuAD 2.0 (Rajpurkar et al., 2018), leading to a final state-of-the-art performance of 76.3 F1 on TriviaQA-Wiki and 62.9 on the NarrativeQA summaries task.","What are the effects of different distant supervision assumptions on the performance of document-level extractive question answering systems, and how can a multiobjective model that combines these assumptions enhance the system's accuracy?",1.0,1.0,1.0
215,Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering,"Hao Cheng, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2020. Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5657–5667, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.501.pdf,https://aclanthology.org/2020.acl-main.501/,"We address the problem of extractive question answering using document-level distant supervision, pairing questions and relevant documents with answer strings. We compare previously used probability space and distant supervision assumptions (assumptions on the correspondence between the weak answer string labels and possible answer mention spans). We show that these assumptions interact, and that different configurations provide complementary benefits. We demonstrate that a multiobjective model can efficiently combine the advantages of multiple assumptions and outperform the best individual formulation. Our approach outperforms previous state-of-the-art models by 4.3 points in F1 on TriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries.","Distant supervision assumptions have enabled the creation of large-scale datasets that can be used to train fine-grained extractive short answer question answering (QA) systems. One example is TriviaQA (Joshi et al., 2017). There the authors utilized a pre-existing set of Trivia questionanswer string pairs and coupled them with relevant documents, such that, with high likelihood, the documents support answering the questions (see Fig. 1 for an illustration). Another example is the NarrativeQA dataset (Kocisk ˇ y et al. ´ , 2018), where crowd-sourced abstractive answer strings were used to weakly supervise answer mentions in the text of movie scripts or their summaries. In this work, we focus on the setting of documentlevel extractive QA, where distant supervision is specified as a set A of answer strings for an input question-document pair. Depending on the data generation process, the properties of the resulting supervision from the sets A may differ. For example, the provided answer sets in TriviaQA include aliases of original trivia question answers, aimed at capturing semantically equivalent answers but liable to introducing semantic drift. In Fig. 1, the possible answer string “Diary of a Mad Diva” is related to “Joan Rivers”, but is not a valid answer for the given question. On the other hand, the sets of answer strings in NarrativeQA are mostly valid since they have high overlap with human-generated answers for the given question/document pair. As shown in Fig. 1, “in the spring at mount helicon” and “mount helicon” are both valid answers with relevant mentions. In this case, the annotators chose answers that appear verbatim in the text but in the more general case, noise may come from partial phrases and irrelevant mentions. While distant supervision reduces the annotation cost, increased coverage often comes with increased noise (e.g., expanding entity answer strings with aliases improves coverage but also increases noise). Even for fixed document-level distant supervision in the form of a set of answers A, different interpretations of the partial supervision lead to different points in the coverage/noise space and their relative performance is not well understood. This work systematically studies methods for learning and inference with document-level distantly supervised extractive QA models. Using a BERT (Devlin et al., 2019) joint question-passage encoder, we study the compound impact of: • Probability space (§2): ways to define the model’s probability space based on independent paragraphs or whole documents. • Distant supervision assumptions (§3): ways to translate the supervision from possible strings A to possible locations of answer mentions in the document. • Optimization and inference (§4): ways to define corresponding training objectives (e.g. Hard EM as in Min et al. (2019) vs. Maximum Marginal Likelihood) and make answer string predictions during inference (Viterbi or marginal inference). We show that the choice of probability space puts constraints on the distant supervision assumptions that can be captured, and that all three choices interact, leading to large differences in performance. Specifically, we provide a framework for understanding different distant supervision assumptions and the corresponding trade-off among the coverage, quality and strength of distant supervision signal. The best configuration depends on the properties of the possible annotations A and is thus data-dependent. Compared with recent work also using BERT representations, our study show that the model with most suitable probabilistic treatment achieves large improvements of 4.6 F1 on TriviaQA and 1.7 Rouge-L on NarrativeQA respectively. Additionally, we design an efficient multi-loss objective that can combine the benefits of different formulations, leading to significant improvements in accuracy, surpassing the best previously reported results on the two studied tasks. Results are further strengthened by transfer learning from fully labeled short-answer extraction data in SQuAD 2.0 (Rajpurkar et al., 2018), leading to a final state-of-the-art performance of 76.3 F1 on TriviaQA-Wiki and 62.9 on the NarrativeQA summaries task.",Can the problem of extractive question answering using document-level distant supervision be solved by combining multiple distant supervision assumptions with a BERT-based multiobjective model?,1.0,1.0,1.0
216,Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering,"Hao Cheng, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2020. Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5657–5667, Online. Association for Computational Linguistics.",https://aclanthology.org/2020.acl-main.501.pdf,https://aclanthology.org/2020.acl-main.501/,"We address the problem of extractive question answering using document-level distant supervision, pairing questions and relevant documents with answer strings. We compare previously used probability space and distant supervision assumptions (assumptions on the correspondence between the weak answer string labels and possible answer mention spans). We show that these assumptions interact, and that different configurations provide complementary benefits. We demonstrate that a multiobjective model can efficiently combine the advantages of multiple assumptions and outperform the best individual formulation. Our approach outperforms previous state-of-the-art models by 4.3 points in F1 on TriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries.","Distant supervision assumptions have enabled the creation of large-scale datasets that can be used to train fine-grained extractive short answer question answering (QA) systems. One example is TriviaQA (Joshi et al., 2017). There the authors utilized a pre-existing set of Trivia questionanswer string pairs and coupled them with relevant documents, such that, with high likelihood, the documents support answering the questions (see Fig. 1 for an illustration). Another example is the NarrativeQA dataset (Kocisk ˇ y et al. ´ , 2018), where crowd-sourced abstractive answer strings were used to weakly supervise answer mentions in the text of movie scripts or their summaries. In this work, we focus on the setting of documentlevel extractive QA, where distant supervision is specified as a set A of answer strings for an input question-document pair. Depending on the data generation process, the properties of the resulting supervision from the sets A may differ. For example, the provided answer sets in TriviaQA include aliases of original trivia question answers, aimed at capturing semantically equivalent answers but liable to introducing semantic drift. In Fig. 1, the possible answer string “Diary of a Mad Diva” is related to “Joan Rivers”, but is not a valid answer for the given question. On the other hand, the sets of answer strings in NarrativeQA are mostly valid since they have high overlap with human-generated answers for the given question/document pair. As shown in Fig. 1, “in the spring at mount helicon” and “mount helicon” are both valid answers with relevant mentions. In this case, the annotators chose answers that appear verbatim in the text but in the more general case, noise may come from partial phrases and irrelevant mentions. While distant supervision reduces the annotation cost, increased coverage often comes with increased noise (e.g., expanding entity answer strings with aliases improves coverage but also increases noise). Even for fixed document-level distant supervision in the form of a set of answers A, different interpretations of the partial supervision lead to different points in the coverage/noise space and their relative performance is not well understood. This work systematically studies methods for learning and inference with document-level distantly supervised extractive QA models. Using a BERT (Devlin et al., 2019) joint question-passage encoder, we study the compound impact of: • Probability space (§2): ways to define the model’s probability space based on independent paragraphs or whole documents. • Distant supervision assumptions (§3): ways to translate the supervision from possible strings A to possible locations of answer mentions in the document. • Optimization and inference (§4): ways to define corresponding training objectives (e.g. Hard EM as in Min et al. (2019) vs. Maximum Marginal Likelihood) and make answer string predictions during inference (Viterbi or marginal inference). We show that the choice of probability space puts constraints on the distant supervision assumptions that can be captured, and that all three choices interact, leading to large differences in performance. Specifically, we provide a framework for understanding different distant supervision assumptions and the corresponding trade-off among the coverage, quality and strength of distant supervision signal. The best configuration depends on the properties of the possible annotations A and is thus data-dependent. Compared with recent work also using BERT representations, our study show that the model with most suitable probabilistic treatment achieves large improvements of 4.6 F1 on TriviaQA and 1.7 Rouge-L on NarrativeQA respectively. Additionally, we design an efficient multi-loss objective that can combine the benefits of different formulations, leading to significant improvements in accuracy, surpassing the best previously reported results on the two studied tasks. Results are further strengthened by transfer learning from fully labeled short-answer extraction data in SQuAD 2.0 (Rajpurkar et al., 2018), leading to a final state-of-the-art performance of 76.3 F1 on TriviaQA-Wiki and 62.9 on the NarrativeQA summaries task.","Can the challenges of creating large-scale datasets for training fine-grained extractive short answer question answering (QA) systems with distant supervision be addressed by systematically studying methods for learning and inference with document-level distantly supervised extractive QA models through examining the compound impact of probability space, distant supervision assumptions, and optimization and inference methods?",2.0,2.0,1.0